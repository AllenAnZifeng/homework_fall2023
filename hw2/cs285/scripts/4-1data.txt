C:\My_Project\ALLEN_Python\homework_fall2023\venv\Scripts\python.exe C:\My_Project\ALLEN_Python\homework_fall2023\hw2\cs285\scripts\run_hw2.py --env_name HalfCheetah-v4 -n 100 -b 5000 -rtg --discount 0.95 -lr 0.01 --exp_name cheetah
########################
logging outputs to  C:\My_Project\ALLEN_Python\homework_fall2023\hw2\cs285\scripts\../../data\q2_pg_cheetah_HalfCheetah-v4_25-09-2023_21-31-05
########################
Using CPU.
C:\My_Project\ALLEN_Python\homework_fall2023\venv\lib\site-packages\gym\core.py:317: DeprecationWarning: WARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.
  deprecation(
C:\My_Project\ALLEN_Python\homework_fall2023\venv\lib\site-packages\gym\wrappers\step_api_compatibility.py:39: DeprecationWarning: WARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.
  deprecation(
C:\My_Project\ALLEN_Python\homework_fall2023\venv\lib\site-packages\gym\utils\passive_env_checker.py:241: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):

********** Iteration 0 ************
C:\My_Project\ALLEN_Python\homework_fall2023\venv\lib\site-packages\tensorboardX\summary.py:153: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)
  scalar = float(scalar)
Eval_AverageReturn : -684.64013671875
Eval_StdReturn : 0.0
Eval_MaxReturn : -684.64013671875
Eval_MinReturn : -684.64013671875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -712.095703125
Train_StdReturn : 67.566162109375
Train_MaxReturn : -649.4592895507812
Train_MinReturn : -842.0916748046875
Train_AverageEpLen : 1000.0
Actor Loss : -599285.625
Train_EnvstepsSoFar : 5000
TimeSinceStart : 1.290334701538086
Initial_DataCollection_AverageReturn : -712.095703125

********** Iteration 1 ************
Eval_AverageReturn : -870.8155517578125
Eval_StdReturn : 0.0
Eval_MaxReturn : -870.8155517578125
Eval_MinReturn : -870.8155517578125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -842.8111572265625
Train_StdReturn : 30.77361297607422
Train_MaxReturn : -802.9783935546875
Train_MinReturn : -883.790771484375
Train_AverageEpLen : 1000.0
Actor Loss : -701084.5625
Train_EnvstepsSoFar : 10000
TimeSinceStart : 2.5609774589538574

********** Iteration 2 ************
Eval_AverageReturn : -1080.746826171875
Eval_StdReturn : 0.0
Eval_MaxReturn : -1080.746826171875
Eval_MinReturn : -1080.746826171875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -884.8837890625
Train_StdReturn : 19.935556411743164
Train_MaxReturn : -851.171142578125
Train_MinReturn : -912.8795166015625
Train_AverageEpLen : 1000.0
Actor Loss : -731490.625
Train_EnvstepsSoFar : 15000
TimeSinceStart : 3.818605899810791

********** Iteration 3 ************
Eval_AverageReturn : -965.9161376953125
Eval_StdReturn : 0.0
Eval_MaxReturn : -965.9161376953125
Eval_MinReturn : -965.9161376953125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -925.2415771484375
Train_StdReturn : 45.77596664428711
Train_MaxReturn : -852.51416015625
Train_MinReturn : -968.8385009765625
Train_AverageEpLen : 1000.0
Actor Loss : -760787.0625
Train_EnvstepsSoFar : 20000
TimeSinceStart : 5.1028218269348145

********** Iteration 4 ************
Eval_AverageReturn : -1010.9664306640625
Eval_StdReturn : 0.0
Eval_MaxReturn : -1010.9664306640625
Eval_MinReturn : -1010.9664306640625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -1010.9569091796875
Train_StdReturn : 81.8462905883789
Train_MaxReturn : -913.7705078125
Train_MinReturn : -1108.95458984375
Train_AverageEpLen : 1000.0
Actor Loss : -829360.9375
Train_EnvstepsSoFar : 25000
TimeSinceStart : 6.371160984039307

********** Iteration 5 ************
Eval_AverageReturn : -942.8276977539062
Eval_StdReturn : 0.0
Eval_MaxReturn : -942.8276977539062
Eval_MinReturn : -942.8276977539062
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -979.9249877929688
Train_StdReturn : 45.509517669677734
Train_MaxReturn : -909.4283447265625
Train_MinReturn : -1043.6357421875
Train_AverageEpLen : 1000.0
Actor Loss : -799507.75
Train_EnvstepsSoFar : 30000
TimeSinceStart : 7.661728382110596

********** Iteration 6 ************
Eval_AverageReturn : -906.2181396484375
Eval_StdReturn : 0.0
Eval_MaxReturn : -906.2181396484375
Eval_MinReturn : -906.2181396484375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -950.7853393554688
Train_StdReturn : 34.563133239746094
Train_MaxReturn : -909.91015625
Train_MinReturn : -1004.65478515625
Train_AverageEpLen : 1000.0
Actor Loss : -773676.75
Train_EnvstepsSoFar : 35000
TimeSinceStart : 8.968749284744263

********** Iteration 7 ************
Eval_AverageReturn : -884.677978515625
Eval_StdReturn : 0.0
Eval_MaxReturn : -884.677978515625
Eval_MinReturn : -884.677978515625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -960.01171875
Train_StdReturn : 55.82536697387695
Train_MaxReturn : -868.7076416015625
Train_MinReturn : -1038.0946044921875
Train_AverageEpLen : 1000.0
Actor Loss : -783788.0625
Train_EnvstepsSoFar : 40000
TimeSinceStart : 10.277586698532104

********** Iteration 8 ************
Eval_AverageReturn : -962.2034912109375
Eval_StdReturn : 0.0
Eval_MaxReturn : -962.2034912109375
Eval_MinReturn : -962.2034912109375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -886.7132568359375
Train_StdReturn : 74.77995300292969
Train_MaxReturn : -823.9867553710938
Train_MinReturn : -1029.327392578125
Train_AverageEpLen : 1000.0
Actor Loss : -716890.0
Train_EnvstepsSoFar : 45000
TimeSinceStart : 11.706888198852539

********** Iteration 9 ************
Eval_AverageReturn : -970.29736328125
Eval_StdReturn : 0.0
Eval_MaxReturn : -970.29736328125
Eval_MinReturn : -970.29736328125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -929.9641723632812
Train_StdReturn : 15.093591690063477
Train_MaxReturn : -908.5723876953125
Train_MinReturn : -948.2017822265625
Train_AverageEpLen : 1000.0
Actor Loss : -753548.6875
Train_EnvstepsSoFar : 50000
TimeSinceStart : 13.029124736785889

********** Iteration 10 ************
Eval_AverageReturn : -991.3782348632812
Eval_StdReturn : 0.0
Eval_MaxReturn : -991.3782348632812
Eval_MinReturn : -991.3782348632812
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -976.2894287109375
Train_StdReturn : 73.43817138671875
Train_MaxReturn : -875.1078491210938
Train_MinReturn : -1102.596435546875
Train_AverageEpLen : 1000.0
Actor Loss : -782719.5625
Train_EnvstepsSoFar : 55000
TimeSinceStart : 14.366820096969604

********** Iteration 11 ************
Eval_AverageReturn : -852.4827880859375
Eval_StdReturn : 0.0
Eval_MaxReturn : -852.4827880859375
Eval_MinReturn : -852.4827880859375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -1018.0676879882812
Train_StdReturn : 52.70427703857422
Train_MaxReturn : -923.9296875
Train_MinReturn : -1080.71142578125
Train_AverageEpLen : 1000.0
Actor Loss : -823668.0625
Train_EnvstepsSoFar : 60000
TimeSinceStart : 15.674113988876343

********** Iteration 12 ************
Eval_AverageReturn : -966.8348388671875
Eval_StdReturn : 0.0
Eval_MaxReturn : -966.8348388671875
Eval_MinReturn : -966.8348388671875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -1017.3639526367188
Train_StdReturn : 85.48582458496094
Train_MaxReturn : -924.7926025390625
Train_MinReturn : -1152.094482421875
Train_AverageEpLen : 1000.0
Actor Loss : -818399.625
Train_EnvstepsSoFar : 65000
TimeSinceStart : 16.999778032302856

********** Iteration 13 ************
Eval_AverageReturn : -981.6898193359375
Eval_StdReturn : 0.0
Eval_MaxReturn : -981.6898193359375
Eval_MinReturn : -981.6898193359375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -1030.3641357421875
Train_StdReturn : 99.27731323242188
Train_MaxReturn : -845.0418090820312
Train_MinReturn : -1118.3863525390625
Train_AverageEpLen : 1000.0
Actor Loss : -828368.6875
Train_EnvstepsSoFar : 70000
TimeSinceStart : 18.372580766677856

********** Iteration 14 ************
Eval_AverageReturn : -1047.98828125
Eval_StdReturn : 0.0
Eval_MaxReturn : -1047.98828125
Eval_MinReturn : -1047.98828125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -1039.7750244140625
Train_StdReturn : 72.66826629638672
Train_MaxReturn : -957.751953125
Train_MinReturn : -1163.052490234375
Train_AverageEpLen : 1000.0
Actor Loss : -830087.5625
Train_EnvstepsSoFar : 75000
TimeSinceStart : 19.69609260559082

********** Iteration 15 ************
Eval_AverageReturn : -846.3781127929688
Eval_StdReturn : 0.0
Eval_MaxReturn : -846.3781127929688
Eval_MinReturn : -846.3781127929688
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -1076.1673583984375
Train_StdReturn : 43.603485107421875
Train_MaxReturn : -997.799560546875
Train_MinReturn : -1123.9351806640625
Train_AverageEpLen : 1000.0
Actor Loss : -854570.4375
Train_EnvstepsSoFar : 80000
TimeSinceStart : 20.9722740650177

********** Iteration 16 ************
Eval_AverageReturn : -937.286865234375
Eval_StdReturn : 0.0
Eval_MaxReturn : -937.286865234375
Eval_MinReturn : -937.286865234375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -1013.7835693359375
Train_StdReturn : 83.849853515625
Train_MaxReturn : -865.7312622070312
Train_MinReturn : -1118.8814697265625
Train_AverageEpLen : 1000.0
Actor Loss : -802166.0
Train_EnvstepsSoFar : 85000
TimeSinceStart : 22.364442110061646

********** Iteration 17 ************
Eval_AverageReturn : -978.801025390625
Eval_StdReturn : 0.0
Eval_MaxReturn : -978.801025390625
Eval_MinReturn : -978.801025390625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -987.3782958984375
Train_StdReturn : 60.10273742675781
Train_MaxReturn : -887.3490600585938
Train_MinReturn : -1074.0892333984375
Train_AverageEpLen : 1000.0
Actor Loss : -775754.9375
Train_EnvstepsSoFar : 90000
TimeSinceStart : 23.869330883026123

********** Iteration 18 ************
Eval_AverageReturn : -1030.10205078125
Eval_StdReturn : 0.0
Eval_MaxReturn : -1030.10205078125
Eval_MinReturn : -1030.10205078125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -1002.6739501953125
Train_StdReturn : 131.3462371826172
Train_MaxReturn : -840.3629150390625
Train_MinReturn : -1231.266357421875
Train_AverageEpLen : 1000.0
Actor Loss : -785162.375
Train_EnvstepsSoFar : 95000
TimeSinceStart : 25.22776222229004

********** Iteration 19 ************
Eval_AverageReturn : -1020.8290405273438
Eval_StdReturn : 0.0
Eval_MaxReturn : -1020.8290405273438
Eval_MinReturn : -1020.8290405273438
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -903.6990356445312
Train_StdReturn : 126.53528594970703
Train_MaxReturn : -685.9559936523438
Train_MinReturn : -1033.365234375
Train_AverageEpLen : 1000.0
Actor Loss : -712901.8125
Train_EnvstepsSoFar : 100000
TimeSinceStart : 26.552263975143433

********** Iteration 20 ************
Eval_AverageReturn : -907.862548828125
Eval_StdReturn : 0.0
Eval_MaxReturn : -907.862548828125
Eval_MinReturn : -907.862548828125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -915.0126953125
Train_StdReturn : 75.67720031738281
Train_MaxReturn : -776.1785888671875
Train_MinReturn : -980.8223876953125
Train_AverageEpLen : 1000.0
Actor Loss : -713661.375
Train_EnvstepsSoFar : 105000
TimeSinceStart : 27.90129542350769

********** Iteration 21 ************
Eval_AverageReturn : -1043.3262939453125
Eval_StdReturn : 0.0
Eval_MaxReturn : -1043.3262939453125
Eval_MinReturn : -1043.3262939453125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -980.3746337890625
Train_StdReturn : 48.732940673828125
Train_MaxReturn : -892.4586791992188
Train_MinReturn : -1016.7349853515625
Train_AverageEpLen : 1000.0
Actor Loss : -769204.0625
Train_EnvstepsSoFar : 110000
TimeSinceStart : 29.211719036102295

********** Iteration 22 ************
Eval_AverageReturn : -1009.5341796875
Eval_StdReturn : 0.0
Eval_MaxReturn : -1009.5341796875
Eval_MinReturn : -1009.5341796875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -947.5748291015625
Train_StdReturn : 103.46675109863281
Train_MaxReturn : -812.120849609375
Train_MinReturn : -1097.01171875
Train_AverageEpLen : 1000.0
Actor Loss : -740574.5
Train_EnvstepsSoFar : 115000
TimeSinceStart : 30.523913145065308

********** Iteration 23 ************
Eval_AverageReturn : -993.4199829101562
Eval_StdReturn : 0.0
Eval_MaxReturn : -993.4199829101562
Eval_MinReturn : -993.4199829101562
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -999.2203979492188
Train_StdReturn : 37.365482330322266
Train_MaxReturn : -963.3731079101562
Train_MinReturn : -1064.76953125
Train_AverageEpLen : 1000.0
Actor Loss : -780187.6875
Train_EnvstepsSoFar : 120000
TimeSinceStart : 31.911692142486572

********** Iteration 24 ************
Eval_AverageReturn : -807.092529296875
Eval_StdReturn : 0.0
Eval_MaxReturn : -807.092529296875
Eval_MinReturn : -807.092529296875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -944.3922119140625
Train_StdReturn : 46.952449798583984
Train_MaxReturn : -863.2131958007812
Train_MinReturn : -1000.8707275390625
Train_AverageEpLen : 1000.0
Actor Loss : -731585.25
Train_EnvstepsSoFar : 125000
TimeSinceStart : 33.210821866989136

********** Iteration 25 ************
Eval_AverageReturn : -931.6585693359375
Eval_StdReturn : 0.0
Eval_MaxReturn : -931.6585693359375
Eval_MinReturn : -931.6585693359375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -982.5216674804688
Train_StdReturn : 66.7049789428711
Train_MaxReturn : -900.7507934570312
Train_MinReturn : -1052.540771484375
Train_AverageEpLen : 1000.0
Actor Loss : -757298.375
Train_EnvstepsSoFar : 130000
TimeSinceStart : 34.536670207977295

********** Iteration 26 ************
Eval_AverageReturn : -988.4059448242188
Eval_StdReturn : 0.0
Eval_MaxReturn : -988.4059448242188
Eval_MinReturn : -988.4059448242188
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -898.20361328125
Train_StdReturn : 56.0894660949707
Train_MaxReturn : -809.5650634765625
Train_MinReturn : -973.750732421875
Train_AverageEpLen : 1000.0
Actor Loss : -691449.625
Train_EnvstepsSoFar : 135000
TimeSinceStart : 35.83990287780762

********** Iteration 27 ************
Eval_AverageReturn : -966.7469482421875
Eval_StdReturn : 0.0
Eval_MaxReturn : -966.7469482421875
Eval_MinReturn : -966.7469482421875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -892.1481323242188
Train_StdReturn : 71.82683563232422
Train_MaxReturn : -805.1015625
Train_MinReturn : -992.734130859375
Train_AverageEpLen : 1000.0
Actor Loss : -682665.0
Train_EnvstepsSoFar : 140000
TimeSinceStart : 37.152199029922485

********** Iteration 28 ************
Eval_AverageReturn : -692.0253295898438
Eval_StdReturn : 0.0
Eval_MaxReturn : -692.0253295898438
Eval_MinReturn : -692.0253295898438
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -794.8308715820312
Train_StdReturn : 62.76460266113281
Train_MaxReturn : -717.3160400390625
Train_MinReturn : -879.004150390625
Train_AverageEpLen : 1000.0
Actor Loss : -605632.25
Train_EnvstepsSoFar : 145000
TimeSinceStart : 38.48732805252075

********** Iteration 29 ************
Eval_AverageReturn : -727.9347534179688
Eval_StdReturn : 0.0
Eval_MaxReturn : -727.9347534179688
Eval_MinReturn : -727.9347534179688
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -760.818603515625
Train_StdReturn : 32.088645935058594
Train_MaxReturn : -720.463623046875
Train_MinReturn : -813.724609375
Train_AverageEpLen : 1000.0
Actor Loss : -584318.0
Train_EnvstepsSoFar : 150000
TimeSinceStart : 39.781007051467896

********** Iteration 30 ************
Eval_AverageReturn : -609.4285888671875
Eval_StdReturn : 0.0
Eval_MaxReturn : -609.4285888671875
Eval_MinReturn : -609.4285888671875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -742.015380859375
Train_StdReturn : 29.490894317626953
Train_MaxReturn : -699.465087890625
Train_MinReturn : -767.6989135742188
Train_AverageEpLen : 1000.0
Actor Loss : -566004.9375
Train_EnvstepsSoFar : 155000
TimeSinceStart : 41.10598158836365

********** Iteration 31 ************
Eval_AverageReturn : -745.6317138671875
Eval_StdReturn : 0.0
Eval_MaxReturn : -745.6317138671875
Eval_MinReturn : -745.6317138671875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -733.8546142578125
Train_StdReturn : 109.42105102539062
Train_MaxReturn : -515.970947265625
Train_MinReturn : -805.3131103515625
Train_AverageEpLen : 1000.0
Actor Loss : -557442.3125
Train_EnvstepsSoFar : 160000
TimeSinceStart : 42.45933532714844

********** Iteration 32 ************
Eval_AverageReturn : -626.4454345703125
Eval_StdReturn : 0.0
Eval_MaxReturn : -626.4454345703125
Eval_MinReturn : -626.4454345703125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -673.5740966796875
Train_StdReturn : 33.911495208740234
Train_MaxReturn : -624.4827880859375
Train_MinReturn : -712.4186401367188
Train_AverageEpLen : 1000.0
Actor Loss : -508511.0625
Train_EnvstepsSoFar : 165000
TimeSinceStart : 43.78477954864502

********** Iteration 33 ************
Eval_AverageReturn : -577.976318359375
Eval_StdReturn : 0.0
Eval_MaxReturn : -577.976318359375
Eval_MinReturn : -577.976318359375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -655.8727416992188
Train_StdReturn : 167.4604949951172
Train_MaxReturn : -326.150390625
Train_MinReturn : -765.9115600585938
Train_AverageEpLen : 1000.0
Actor Loss : -491671.40625
Train_EnvstepsSoFar : 170000
TimeSinceStart : 45.07875180244446

********** Iteration 34 ************
Eval_AverageReturn : -608.34228515625
Eval_StdReturn : 0.0
Eval_MaxReturn : -608.34228515625
Eval_MinReturn : -608.34228515625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -578.5150756835938
Train_StdReturn : 66.8755874633789
Train_MaxReturn : -464.19598388671875
Train_MinReturn : -651.3699340820312
Train_AverageEpLen : 1000.0
Actor Loss : -428553.0625
Train_EnvstepsSoFar : 175000
TimeSinceStart : 46.39814019203186

********** Iteration 35 ************
Eval_AverageReturn : -631.95751953125
Eval_StdReturn : 0.0
Eval_MaxReturn : -631.95751953125
Eval_MinReturn : -631.95751953125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -575.9436645507812
Train_StdReturn : 72.48979949951172
Train_MaxReturn : -482.3628845214844
Train_MinReturn : -666.6800537109375
Train_AverageEpLen : 1000.0
Actor Loss : -429334.125
Train_EnvstepsSoFar : 180000
TimeSinceStart : 47.707757234573364

********** Iteration 36 ************
Eval_AverageReturn : -503.4906005859375
Eval_StdReturn : 0.0
Eval_MaxReturn : -503.4906005859375
Eval_MinReturn : -503.4906005859375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -549.3821411132812
Train_StdReturn : 53.048221588134766
Train_MaxReturn : -456.072998046875
Train_MinReturn : -613.3150634765625
Train_AverageEpLen : 1000.0
Actor Loss : -408289.3125
Train_EnvstepsSoFar : 185000
TimeSinceStart : 49.033175468444824

********** Iteration 37 ************
Eval_AverageReturn : -486.1973876953125
Eval_StdReturn : 0.0
Eval_MaxReturn : -486.1973876953125
Eval_MinReturn : -486.1973876953125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -478.79779052734375
Train_StdReturn : 58.04833984375
Train_MaxReturn : -393.5576171875
Train_MinReturn : -536.0903930664062
Train_AverageEpLen : 1000.0
Actor Loss : -353371.8125
Train_EnvstepsSoFar : 190000
TimeSinceStart : 50.327436447143555

********** Iteration 38 ************
Eval_AverageReturn : -473.03851318359375
Eval_StdReturn : 0.0
Eval_MaxReturn : -473.03851318359375
Eval_MinReturn : -473.03851318359375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -471.46490478515625
Train_StdReturn : 98.5696029663086
Train_MaxReturn : -295.40692138671875
Train_MinReturn : -564.5720825195312
Train_AverageEpLen : 1000.0
Actor Loss : -343301.3125
Train_EnvstepsSoFar : 195000
TimeSinceStart : 51.617966413497925

********** Iteration 39 ************
Eval_AverageReturn : -610.732421875
Eval_StdReturn : 0.0
Eval_MaxReturn : -610.732421875
Eval_MinReturn : -610.732421875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -432.32421875
Train_StdReturn : 54.58634567260742
Train_MaxReturn : -365.10723876953125
Train_MinReturn : -503.6800537109375
Train_AverageEpLen : 1000.0
Actor Loss : -317547.5625
Train_EnvstepsSoFar : 200000
TimeSinceStart : 52.90726041793823

********** Iteration 40 ************
Eval_AverageReturn : -449.3076171875
Eval_StdReturn : 0.0
Eval_MaxReturn : -449.3076171875
Eval_MinReturn : -449.3076171875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -460.9478454589844
Train_StdReturn : 88.29778289794922
Train_MaxReturn : -370.7541809082031
Train_MinReturn : -582.7725830078125
Train_AverageEpLen : 1000.0
Actor Loss : -340433.625
Train_EnvstepsSoFar : 205000
TimeSinceStart : 54.19649863243103

********** Iteration 41 ************
Eval_AverageReturn : -564.5020141601562
Eval_StdReturn : 0.0
Eval_MaxReturn : -564.5020141601562
Eval_MinReturn : -564.5020141601562
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -515.6505126953125
Train_StdReturn : 49.67405319213867
Train_MaxReturn : -432.71453857421875
Train_MinReturn : -587.408447265625
Train_AverageEpLen : 1000.0
Actor Loss : -375488.6875
Train_EnvstepsSoFar : 210000
TimeSinceStart : 55.51120710372925

********** Iteration 42 ************
Eval_AverageReturn : -446.8756408691406
Eval_StdReturn : 0.0
Eval_MaxReturn : -446.8756408691406
Eval_MinReturn : -446.8756408691406
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -453.7904357910156
Train_StdReturn : 33.27254867553711
Train_MaxReturn : -417.378173828125
Train_MinReturn : -506.36065673828125
Train_AverageEpLen : 1000.0
Actor Loss : -328492.6875
Train_EnvstepsSoFar : 215000
TimeSinceStart : 56.83310556411743

********** Iteration 43 ************
Eval_AverageReturn : -361.0972595214844
Eval_StdReturn : 0.0
Eval_MaxReturn : -361.0972595214844
Eval_MinReturn : -361.0972595214844
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -520.2630615234375
Train_StdReturn : 62.43366241455078
Train_MaxReturn : -461.2588806152344
Train_MinReturn : -640.73486328125
Train_AverageEpLen : 1000.0
Actor Loss : -379269.28125
Train_EnvstepsSoFar : 220000
TimeSinceStart : 58.12950301170349

********** Iteration 44 ************
Eval_AverageReturn : -481.6197509765625
Eval_StdReturn : 0.0
Eval_MaxReturn : -481.6197509765625
Eval_MinReturn : -481.6197509765625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -479.50634765625
Train_StdReturn : 117.06950378417969
Train_MaxReturn : -255.78271484375
Train_MinReturn : -581.20947265625
Train_AverageEpLen : 1000.0
Actor Loss : -345186.65625
Train_EnvstepsSoFar : 225000
TimeSinceStart : 59.43869471549988

********** Iteration 45 ************
Eval_AverageReturn : -591.6104736328125
Eval_StdReturn : 0.0
Eval_MaxReturn : -591.6104736328125
Eval_MinReturn : -591.6104736328125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -501.09454345703125
Train_StdReturn : 66.8613052368164
Train_MaxReturn : -399.8255920410156
Train_MinReturn : -574.0421142578125
Train_AverageEpLen : 1000.0
Actor Loss : -362335.40625
Train_EnvstepsSoFar : 230000
TimeSinceStart : 60.74272680282593

********** Iteration 46 ************
Eval_AverageReturn : -402.1318359375
Eval_StdReturn : 0.0
Eval_MaxReturn : -402.1318359375
Eval_MinReturn : -402.1318359375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -573.3966064453125
Train_StdReturn : 23.652456283569336
Train_MaxReturn : -533.1727905273438
Train_MinReturn : -600.05810546875
Train_AverageEpLen : 1000.0
Actor Loss : -414681.84375
Train_EnvstepsSoFar : 235000
TimeSinceStart : 62.08710312843323

********** Iteration 47 ************
Eval_AverageReturn : -577.478759765625
Eval_StdReturn : 0.0
Eval_MaxReturn : -577.478759765625
Eval_MinReturn : -577.478759765625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -476.324462890625
Train_StdReturn : 90.48762512207031
Train_MaxReturn : -369.869384765625
Train_MinReturn : -599.1356201171875
Train_AverageEpLen : 1000.0
Actor Loss : -344021.1875
Train_EnvstepsSoFar : 240000
TimeSinceStart : 63.42409062385559

********** Iteration 48 ************
Eval_AverageReturn : -347.90185546875
Eval_StdReturn : 0.0
Eval_MaxReturn : -347.90185546875
Eval_MinReturn : -347.90185546875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -570.6828002929688
Train_StdReturn : 58.20846939086914
Train_MaxReturn : -473.8555908203125
Train_MinReturn : -634.7366333007812
Train_AverageEpLen : 1000.0
Actor Loss : -409197.375
Train_EnvstepsSoFar : 245000
TimeSinceStart : 64.7560064792633

********** Iteration 49 ************
Eval_AverageReturn : -395.7765197753906
Eval_StdReturn : 0.0
Eval_MaxReturn : -395.7765197753906
Eval_MinReturn : -395.7765197753906
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -473.593017578125
Train_StdReturn : 63.00669479370117
Train_MaxReturn : -376.67523193359375
Train_MinReturn : -566.7279052734375
Train_AverageEpLen : 1000.0
Actor Loss : -338106.0
Train_EnvstepsSoFar : 250000
TimeSinceStart : 66.077805519104

********** Iteration 50 ************
Eval_AverageReturn : -432.23602294921875
Eval_StdReturn : 0.0
Eval_MaxReturn : -432.23602294921875
Eval_MinReturn : -432.23602294921875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -463.35052490234375
Train_StdReturn : 76.38722229003906
Train_MaxReturn : -365.13055419921875
Train_MinReturn : -542.70556640625
Train_AverageEpLen : 1000.0
Actor Loss : -327986.59375
Train_EnvstepsSoFar : 255000
TimeSinceStart : 67.4168951511383

********** Iteration 51 ************
Eval_AverageReturn : -468.32708740234375
Eval_StdReturn : 0.0
Eval_MaxReturn : -468.32708740234375
Eval_MinReturn : -468.32708740234375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -463.25567626953125
Train_StdReturn : 101.49467468261719
Train_MaxReturn : -319.5172119140625
Train_MinReturn : -632.6546630859375
Train_AverageEpLen : 1000.0
Actor Loss : -324469.21875
Train_EnvstepsSoFar : 260000
TimeSinceStart : 68.74969363212585

********** Iteration 52 ************
Eval_AverageReturn : -567.709228515625
Eval_StdReturn : 0.0
Eval_MaxReturn : -567.709228515625
Eval_MinReturn : -567.709228515625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -496.5310974121094
Train_StdReturn : 71.1363754272461
Train_MaxReturn : -389.6331787109375
Train_MinReturn : -565.343994140625
Train_AverageEpLen : 1000.0
Actor Loss : -350863.3125
Train_EnvstepsSoFar : 265000
TimeSinceStart : 70.12290692329407

********** Iteration 53 ************
Eval_AverageReturn : -498.2126770019531
Eval_StdReturn : 0.0
Eval_MaxReturn : -498.2126770019531
Eval_MinReturn : -498.2126770019531
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -495.25091552734375
Train_StdReturn : 60.72562026977539
Train_MaxReturn : -390.1934814453125
Train_MinReturn : -553.324462890625
Train_AverageEpLen : 1000.0
Actor Loss : -346634.375
Train_EnvstepsSoFar : 270000
TimeSinceStart : 71.45993852615356

********** Iteration 54 ************
Eval_AverageReturn : -524.874755859375
Eval_StdReturn : 0.0
Eval_MaxReturn : -524.874755859375
Eval_MinReturn : -524.874755859375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -481.1815490722656
Train_StdReturn : 53.31471252441406
Train_MaxReturn : -390.06939697265625
Train_MinReturn : -545.926513671875
Train_AverageEpLen : 1000.0
Actor Loss : -335887.25
Train_EnvstepsSoFar : 275000
TimeSinceStart : 72.80067944526672

********** Iteration 55 ************
Eval_AverageReturn : -477.83740234375
Eval_StdReturn : 0.0
Eval_MaxReturn : -477.83740234375
Eval_MinReturn : -477.83740234375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -466.8793029785156
Train_StdReturn : 45.29479217529297
Train_MaxReturn : -397.6072998046875
Train_MinReturn : -510.9651794433594
Train_AverageEpLen : 1000.0
Actor Loss : -326390.65625
Train_EnvstepsSoFar : 280000
TimeSinceStart : 74.16574025154114

********** Iteration 56 ************
Eval_AverageReturn : -421.608642578125
Eval_StdReturn : 0.0
Eval_MaxReturn : -421.608642578125
Eval_MinReturn : -421.608642578125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -549.3410034179688
Train_StdReturn : 75.84326934814453
Train_MaxReturn : -435.10577392578125
Train_MinReturn : -628.0735473632812
Train_AverageEpLen : 1000.0
Actor Loss : -376084.1875
Train_EnvstepsSoFar : 285000
TimeSinceStart : 75.51819491386414

********** Iteration 57 ************
Eval_AverageReturn : -496.4308166503906
Eval_StdReturn : 0.0
Eval_MaxReturn : -496.4308166503906
Eval_MinReturn : -496.4308166503906
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -507.43231201171875
Train_StdReturn : 27.130300521850586
Train_MaxReturn : -480.3256530761719
Train_MinReturn : -550.48828125
Train_AverageEpLen : 1000.0
Actor Loss : -348498.5625
Train_EnvstepsSoFar : 290000
TimeSinceStart : 76.82398557662964

********** Iteration 58 ************
Eval_AverageReturn : -579.0712890625
Eval_StdReturn : 0.0
Eval_MaxReturn : -579.0712890625
Eval_MinReturn : -579.0712890625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -504.5196228027344
Train_StdReturn : 44.94272994995117
Train_MaxReturn : -428.7275390625
Train_MinReturn : -555.9058837890625
Train_AverageEpLen : 1000.0
Actor Loss : -348116.5
Train_EnvstepsSoFar : 295000
TimeSinceStart : 78.15036249160767

********** Iteration 59 ************
Eval_AverageReturn : -541.889404296875
Eval_StdReturn : 0.0
Eval_MaxReturn : -541.889404296875
Eval_MinReturn : -541.889404296875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -460.4814453125
Train_StdReturn : 42.88071823120117
Train_MaxReturn : -388.5595703125
Train_MinReturn : -514.5025634765625
Train_AverageEpLen : 1000.0
Actor Loss : -315715.3125
Train_EnvstepsSoFar : 300000
TimeSinceStart : 79.44763207435608

********** Iteration 60 ************
Eval_AverageReturn : -568.3356323242188
Eval_StdReturn : 0.0
Eval_MaxReturn : -568.3356323242188
Eval_MinReturn : -568.3356323242188
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -412.25299072265625
Train_StdReturn : 92.09716796875
Train_MaxReturn : -275.13250732421875
Train_MinReturn : -537.0006103515625
Train_AverageEpLen : 1000.0
Actor Loss : -279327.3125
Train_EnvstepsSoFar : 305000
TimeSinceStart : 80.73886847496033

********** Iteration 61 ************
Eval_AverageReturn : -429.5343017578125
Eval_StdReturn : 0.0
Eval_MaxReturn : -429.5343017578125
Eval_MinReturn : -429.5343017578125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -427.5690002441406
Train_StdReturn : 58.741722106933594
Train_MaxReturn : -330.70562744140625
Train_MinReturn : -513.9818115234375
Train_AverageEpLen : 1000.0
Actor Loss : -291390.6875
Train_EnvstepsSoFar : 310000
TimeSinceStart : 82.04155492782593

********** Iteration 62 ************
Eval_AverageReturn : -403.206298828125
Eval_StdReturn : 0.0
Eval_MaxReturn : -403.206298828125
Eval_MinReturn : -403.206298828125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -444.11322021484375
Train_StdReturn : 30.874954223632812
Train_MaxReturn : -393.00982666015625
Train_MinReturn : -483.9393615722656
Train_AverageEpLen : 1000.0
Actor Loss : -302205.84375
Train_EnvstepsSoFar : 315000
TimeSinceStart : 83.41226840019226

********** Iteration 63 ************
Eval_AverageReturn : -661.7581176757812
Eval_StdReturn : 0.0
Eval_MaxReturn : -661.7581176757812
Eval_MinReturn : -661.7581176757812
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -443.42291259765625
Train_StdReturn : 85.81231689453125
Train_MaxReturn : -290.079345703125
Train_MinReturn : -528.9835205078125
Train_AverageEpLen : 1000.0
Actor Loss : -303893.0
Train_EnvstepsSoFar : 320000
TimeSinceStart : 84.77232027053833

********** Iteration 64 ************
Eval_AverageReturn : -385.89739990234375
Eval_StdReturn : 0.0
Eval_MaxReturn : -385.89739990234375
Eval_MinReturn : -385.89739990234375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -433.6725158691406
Train_StdReturn : 67.51912689208984
Train_MaxReturn : -336.0207214355469
Train_MinReturn : -538.781005859375
Train_AverageEpLen : 1000.0
Actor Loss : -289892.78125
Train_EnvstepsSoFar : 325000
TimeSinceStart : 86.08431243896484

********** Iteration 65 ************
Eval_AverageReturn : -445.67486572265625
Eval_StdReturn : 0.0
Eval_MaxReturn : -445.67486572265625
Eval_MinReturn : -445.67486572265625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -409.65557861328125
Train_StdReturn : 37.206871032714844
Train_MaxReturn : -365.1788330078125
Train_MinReturn : -465.39141845703125
Train_AverageEpLen : 1000.0
Actor Loss : -276627.375
Train_EnvstepsSoFar : 330000
TimeSinceStart : 87.39613938331604

********** Iteration 66 ************
Eval_AverageReturn : -390.7550048828125
Eval_StdReturn : 0.0
Eval_MaxReturn : -390.7550048828125
Eval_MinReturn : -390.7550048828125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -393.04638671875
Train_StdReturn : 64.22149658203125
Train_MaxReturn : -322.62530517578125
Train_MinReturn : -494.0932312011719
Train_AverageEpLen : 1000.0
Actor Loss : -268972.1875
Train_EnvstepsSoFar : 335000
TimeSinceStart : 88.70508861541748

********** Iteration 67 ************
Eval_AverageReturn : -347.3851623535156
Eval_StdReturn : 0.0
Eval_MaxReturn : -347.3851623535156
Eval_MinReturn : -347.3851623535156
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -425.1094665527344
Train_StdReturn : 59.81776428222656
Train_MaxReturn : -343.2329406738281
Train_MinReturn : -520.7061157226562
Train_AverageEpLen : 1000.0
Actor Loss : -282672.03125
Train_EnvstepsSoFar : 340000
TimeSinceStart : 90.02348852157593

********** Iteration 68 ************
Eval_AverageReturn : -533.3560180664062
Eval_StdReturn : 0.0
Eval_MaxReturn : -533.3560180664062
Eval_MinReturn : -533.3560180664062
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -390.05645751953125
Train_StdReturn : 35.03660583496094
Train_MaxReturn : -351.14886474609375
Train_MinReturn : -455.44757080078125
Train_AverageEpLen : 1000.0
Actor Loss : -260076.46875
Train_EnvstepsSoFar : 345000
TimeSinceStart : 91.34303665161133

********** Iteration 69 ************
Eval_AverageReturn : -492.23211669921875
Eval_StdReturn : 0.0
Eval_MaxReturn : -492.23211669921875
Eval_MinReturn : -492.23211669921875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -336.12890625
Train_StdReturn : 41.11289596557617
Train_MaxReturn : -285.4790954589844
Train_MinReturn : -392.0301208496094
Train_AverageEpLen : 1000.0
Actor Loss : -223201.703125
Train_EnvstepsSoFar : 350000
TimeSinceStart : 92.68305110931396

********** Iteration 70 ************
Eval_AverageReturn : -417.91156005859375
Eval_StdReturn : 0.0
Eval_MaxReturn : -417.91156005859375
Eval_MinReturn : -417.91156005859375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -429.16278076171875
Train_StdReturn : 69.92343139648438
Train_MaxReturn : -348.9254150390625
Train_MinReturn : -550.4610595703125
Train_AverageEpLen : 1000.0
Actor Loss : -286457.875
Train_EnvstepsSoFar : 355000
TimeSinceStart : 94.01521062850952

********** Iteration 71 ************
Eval_AverageReturn : -618.4615478515625
Eval_StdReturn : 0.0
Eval_MaxReturn : -618.4615478515625
Eval_MinReturn : -618.4615478515625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -379.94195556640625
Train_StdReturn : 33.216636657714844
Train_MaxReturn : -338.6548767089844
Train_MinReturn : -420.51995849609375
Train_AverageEpLen : 1000.0
Actor Loss : -249029.234375
Train_EnvstepsSoFar : 360000
TimeSinceStart : 95.31068587303162

********** Iteration 72 ************
Eval_AverageReturn : -512.31689453125
Eval_StdReturn : 0.0
Eval_MaxReturn : -512.31689453125
Eval_MinReturn : -512.31689453125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -366.81866455078125
Train_StdReturn : 23.947311401367188
Train_MaxReturn : -339.4012145996094
Train_MinReturn : -405.53033447265625
Train_AverageEpLen : 1000.0
Actor Loss : -242399.078125
Train_EnvstepsSoFar : 365000
TimeSinceStart : 96.72157955169678

********** Iteration 73 ************
Eval_AverageReturn : -476.5701904296875
Eval_StdReturn : 0.0
Eval_MaxReturn : -476.5701904296875
Eval_MinReturn : -476.5701904296875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -419.53741455078125
Train_StdReturn : 36.821128845214844
Train_MaxReturn : -351.9613037109375
Train_MinReturn : -456.8698425292969
Train_AverageEpLen : 1000.0
Actor Loss : -274258.9375
Train_EnvstepsSoFar : 370000
TimeSinceStart : 98.07361650466919

********** Iteration 74 ************
Eval_AverageReturn : -428.1092529296875
Eval_StdReturn : 0.0
Eval_MaxReturn : -428.1092529296875
Eval_MinReturn : -428.1092529296875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -403.83038330078125
Train_StdReturn : 43.661285400390625
Train_MaxReturn : -352.6483459472656
Train_MinReturn : -476.0987548828125
Train_AverageEpLen : 1000.0
Actor Loss : -262443.375
Train_EnvstepsSoFar : 375000
TimeSinceStart : 99.41141319274902

********** Iteration 75 ************
Eval_AverageReturn : -397.52166748046875
Eval_StdReturn : 0.0
Eval_MaxReturn : -397.52166748046875
Eval_MinReturn : -397.52166748046875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -422.71820068359375
Train_StdReturn : 67.61744689941406
Train_MaxReturn : -305.99420166015625
Train_MinReturn : -483.143310546875
Train_AverageEpLen : 1000.0
Actor Loss : -275043.1875
Train_EnvstepsSoFar : 380000
TimeSinceStart : 100.78937530517578

********** Iteration 76 ************
Eval_AverageReturn : -431.73004150390625
Eval_StdReturn : 0.0
Eval_MaxReturn : -431.73004150390625
Eval_MinReturn : -431.73004150390625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -377.90472412109375
Train_StdReturn : 44.675540924072266
Train_MaxReturn : -309.6536865234375
Train_MinReturn : -441.3235778808594
Train_AverageEpLen : 1000.0
Actor Loss : -242406.03125
Train_EnvstepsSoFar : 385000
TimeSinceStart : 102.14627766609192

********** Iteration 77 ************
Eval_AverageReturn : -403.1224365234375
Eval_StdReturn : 0.0
Eval_MaxReturn : -403.1224365234375
Eval_MinReturn : -403.1224365234375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -408.3898010253906
Train_StdReturn : 59.753116607666016
Train_MaxReturn : -335.79217529296875
Train_MinReturn : -506.74249267578125
Train_AverageEpLen : 1000.0
Actor Loss : -262138.6875
Train_EnvstepsSoFar : 390000
TimeSinceStart : 103.48695874214172

********** Iteration 78 ************
Eval_AverageReturn : -663.814453125
Eval_StdReturn : 0.0
Eval_MaxReturn : -663.814453125
Eval_MinReturn : -663.814453125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -440.9864196777344
Train_StdReturn : 35.47105407714844
Train_MaxReturn : -394.6056213378906
Train_MinReturn : -484.04058837890625
Train_AverageEpLen : 1000.0
Actor Loss : -280175.1875
Train_EnvstepsSoFar : 395000
TimeSinceStart : 104.88199090957642

********** Iteration 79 ************
Eval_AverageReturn : -340.456298828125
Eval_StdReturn : 0.0
Eval_MaxReturn : -340.456298828125
Eval_MinReturn : -340.456298828125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -417.27081298828125
Train_StdReturn : 58.20027542114258
Train_MaxReturn : -365.23760986328125
Train_MinReturn : -519.5048828125
Train_AverageEpLen : 1000.0
Actor Loss : -264318.25
Train_EnvstepsSoFar : 400000
TimeSinceStart : 106.19643950462341

********** Iteration 80 ************
Eval_AverageReturn : -472.67303466796875
Eval_StdReturn : 0.0
Eval_MaxReturn : -472.67303466796875
Eval_MinReturn : -472.67303466796875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -501.5547790527344
Train_StdReturn : 151.17726135253906
Train_MaxReturn : -331.7530517578125
Train_MinReturn : -688.9462890625
Train_AverageEpLen : 1000.0
Actor Loss : -320124.4375
Train_EnvstepsSoFar : 405000
TimeSinceStart : 107.54604840278625

********** Iteration 81 ************
Eval_AverageReturn : -464.46624755859375
Eval_StdReturn : 0.0
Eval_MaxReturn : -464.46624755859375
Eval_MinReturn : -464.46624755859375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -456.00848388671875
Train_StdReturn : 76.88351440429688
Train_MaxReturn : -380.96734619140625
Train_MinReturn : -604.24609375
Train_AverageEpLen : 1000.0
Actor Loss : -291854.8125
Train_EnvstepsSoFar : 410000
TimeSinceStart : 108.93251061439514

********** Iteration 82 ************
Eval_AverageReturn : -436.6702575683594
Eval_StdReturn : 0.0
Eval_MaxReturn : -436.6702575683594
Eval_MinReturn : -436.6702575683594
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -416.656982421875
Train_StdReturn : 59.368717193603516
Train_MaxReturn : -303.4546203613281
Train_MinReturn : -472.16143798828125
Train_AverageEpLen : 1000.0
Actor Loss : -262761.125
Train_EnvstepsSoFar : 415000
TimeSinceStart : 110.2730860710144

********** Iteration 83 ************
Eval_AverageReturn : -519.3204345703125
Eval_StdReturn : 0.0
Eval_MaxReturn : -519.3204345703125
Eval_MinReturn : -519.3204345703125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -457.9092712402344
Train_StdReturn : 81.9976577758789
Train_MaxReturn : -343.9453430175781
Train_MinReturn : -582.7008056640625
Train_AverageEpLen : 1000.0
Actor Loss : -285900.28125
Train_EnvstepsSoFar : 420000
TimeSinceStart : 111.59392857551575

********** Iteration 84 ************
Eval_AverageReturn : -382.75372314453125
Eval_StdReturn : 0.0
Eval_MaxReturn : -382.75372314453125
Eval_MinReturn : -382.75372314453125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -524.2977905273438
Train_StdReturn : 98.01334381103516
Train_MaxReturn : -434.05975341796875
Train_MinReturn : -699.316650390625
Train_AverageEpLen : 1000.0
Actor Loss : -329880.0625
Train_EnvstepsSoFar : 425000
TimeSinceStart : 112.91177988052368

********** Iteration 85 ************
Eval_AverageReturn : -541.4869384765625
Eval_StdReturn : 0.0
Eval_MaxReturn : -541.4869384765625
Eval_MinReturn : -541.4869384765625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -473.76873779296875
Train_StdReturn : 50.12752151489258
Train_MaxReturn : -399.5790100097656
Train_MinReturn : -539.0546875
Train_AverageEpLen : 1000.0
Actor Loss : -292290.15625
Train_EnvstepsSoFar : 430000
TimeSinceStart : 114.24681115150452

********** Iteration 86 ************
Eval_AverageReturn : -532.0514526367188
Eval_StdReturn : 0.0
Eval_MaxReturn : -532.0514526367188
Eval_MinReturn : -532.0514526367188
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -569.497802734375
Train_StdReturn : 56.032108306884766
Train_MaxReturn : -488.24945068359375
Train_MinReturn : -635.7356567382812
Train_AverageEpLen : 1000.0
Actor Loss : -347780.3125
Train_EnvstepsSoFar : 435000
TimeSinceStart : 115.58023738861084

********** Iteration 87 ************
Eval_AverageReturn : -616.3533935546875
Eval_StdReturn : 0.0
Eval_MaxReturn : -616.3533935546875
Eval_MinReturn : -616.3533935546875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -468.53839111328125
Train_StdReturn : 104.49925231933594
Train_MaxReturn : -369.9750671386719
Train_MinReturn : -656.165771484375
Train_AverageEpLen : 1000.0
Actor Loss : -286116.65625
Train_EnvstepsSoFar : 440000
TimeSinceStart : 116.89739346504211

********** Iteration 88 ************
Eval_AverageReturn : -578.8143310546875
Eval_StdReturn : 0.0
Eval_MaxReturn : -578.8143310546875
Eval_MinReturn : -578.8143310546875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -516.59912109375
Train_StdReturn : 76.3231430053711
Train_MaxReturn : -434.142822265625
Train_MinReturn : -610.0526733398438
Train_AverageEpLen : 1000.0
Actor Loss : -318373.34375
Train_EnvstepsSoFar : 445000
TimeSinceStart : 118.24889278411865

********** Iteration 89 ************
Eval_AverageReturn : -337.3291015625
Eval_StdReturn : 0.0
Eval_MaxReturn : -337.3291015625
Eval_MinReturn : -337.3291015625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -465.1634826660156
Train_StdReturn : 57.26347732543945
Train_MaxReturn : -372.3326721191406
Train_MinReturn : -531.5621337890625
Train_AverageEpLen : 1000.0
Actor Loss : -281678.3125
Train_EnvstepsSoFar : 450000
TimeSinceStart : 119.59542083740234

********** Iteration 90 ************
Eval_AverageReturn : -457.3135986328125
Eval_StdReturn : 0.0
Eval_MaxReturn : -457.3135986328125
Eval_MinReturn : -457.3135986328125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -457.470703125
Train_StdReturn : 184.61956787109375
Train_MaxReturn : -319.48150634765625
Train_MinReturn : -802.449951171875
Train_AverageEpLen : 1000.0
Actor Loss : -279959.25
Train_EnvstepsSoFar : 455000
TimeSinceStart : 120.94366407394409

********** Iteration 91 ************
Eval_AverageReturn : -190.2017822265625
Eval_StdReturn : 0.0
Eval_MaxReturn : -190.2017822265625
Eval_MinReturn : -190.2017822265625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -484.021728515625
Train_StdReturn : 142.01370239257812
Train_MaxReturn : -300.3853759765625
Train_MinReturn : -684.1824951171875
Train_AverageEpLen : 1000.0
Actor Loss : -292341.3125
Train_EnvstepsSoFar : 460000
TimeSinceStart : 122.27291417121887

********** Iteration 92 ************
Eval_AverageReturn : -375.26910400390625
Eval_StdReturn : 0.0
Eval_MaxReturn : -375.26910400390625
Eval_MinReturn : -375.26910400390625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -393.90802001953125
Train_StdReturn : 48.010894775390625
Train_MaxReturn : -327.4315185546875
Train_MinReturn : -459.9939880371094
Train_AverageEpLen : 1000.0
Actor Loss : -238728.640625
Train_EnvstepsSoFar : 465000
TimeSinceStart : 123.65851593017578

********** Iteration 93 ************
Eval_AverageReturn : -346.6281433105469
Eval_StdReturn : 0.0
Eval_MaxReturn : -346.6281433105469
Eval_MinReturn : -346.6281433105469
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -413.91729736328125
Train_StdReturn : 118.38191986083984
Train_MaxReturn : -258.61212158203125
Train_MinReturn : -588.044677734375
Train_AverageEpLen : 1000.0
Actor Loss : -250032.515625
Train_EnvstepsSoFar : 470000
TimeSinceStart : 125.0080075263977

********** Iteration 94 ************
Eval_AverageReturn : -407.084716796875
Eval_StdReturn : 0.0
Eval_MaxReturn : -407.084716796875
Eval_MinReturn : -407.084716796875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -347.75262451171875
Train_StdReturn : 32.694828033447266
Train_MaxReturn : -303.6712341308594
Train_MinReturn : -392.82611083984375
Train_AverageEpLen : 1000.0
Actor Loss : -211525.5625
Train_EnvstepsSoFar : 475000
TimeSinceStart : 126.31484055519104

********** Iteration 95 ************
Eval_AverageReturn : -283.1227111816406
Eval_StdReturn : 0.0
Eval_MaxReturn : -283.1227111816406
Eval_MinReturn : -283.1227111816406
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -285.10894775390625
Train_StdReturn : 92.59516906738281
Train_MaxReturn : -156.24655151367188
Train_MinReturn : -376.60626220703125
Train_AverageEpLen : 1000.0
Actor Loss : -170889.171875
Train_EnvstepsSoFar : 480000
TimeSinceStart : 127.66893553733826

********** Iteration 96 ************
Eval_AverageReturn : -367.78387451171875
Eval_StdReturn : 0.0
Eval_MaxReturn : -367.78387451171875
Eval_MinReturn : -367.78387451171875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -375.07366943359375
Train_StdReturn : 44.51418685913086
Train_MaxReturn : -333.61346435546875
Train_MinReturn : -461.58343505859375
Train_AverageEpLen : 1000.0
Actor Loss : -222270.640625
Train_EnvstepsSoFar : 485000
TimeSinceStart : 129.068941116333

********** Iteration 97 ************
Eval_AverageReturn : -177.49093627929688
Eval_StdReturn : 0.0
Eval_MaxReturn : -177.49093627929688
Eval_MinReturn : -177.49093627929688
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -316.23809814453125
Train_StdReturn : 72.39115905761719
Train_MaxReturn : -200.52584838867188
Train_MinReturn : -398.752685546875
Train_AverageEpLen : 1000.0
Actor Loss : -190552.515625
Train_EnvstepsSoFar : 490000
TimeSinceStart : 130.46070885658264

********** Iteration 98 ************
Eval_AverageReturn : -307.2226867675781
Eval_StdReturn : 0.0
Eval_MaxReturn : -307.2226867675781
Eval_MinReturn : -307.2226867675781
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -333.3387451171875
Train_StdReturn : 81.77031707763672
Train_MaxReturn : -195.9260711669922
Train_MinReturn : -434.4019775390625
Train_AverageEpLen : 1000.0
Actor Loss : -197746.03125
Train_EnvstepsSoFar : 495000
TimeSinceStart : 131.76665210723877

********** Iteration 99 ************
Eval_AverageReturn : -469.83087158203125
Eval_StdReturn : 0.0
Eval_MaxReturn : -469.83087158203125
Eval_MinReturn : -469.83087158203125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -261.7013854980469
Train_StdReturn : 58.03715133666992
Train_MaxReturn : -198.4591522216797
Train_MinReturn : -354.88623046875
Train_AverageEpLen : 1000.0
Actor Loss : -153972.75
Train_EnvstepsSoFar : 500000
TimeSinceStart : 133.0747630596161

Process finished with exit code 0
