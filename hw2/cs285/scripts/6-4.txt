C:\My_Project\ALLEN_Python\homework_fall2023\venv\Scripts\python.exe C:\My_Project\ALLEN_Python\homework_fall2023\hw2\cs285\scripts\run_hw2.py --env_name InvertedPendulum-v4 -n 100 --exp_name pendulum_default_s3 -rtg --use_baseline -na --batch_size 3000 --seed 3 --gae_lambda 0.99
########################
logging outputs to  C:\My_Project\ALLEN_Python\homework_fall2023\hw2\cs285\scripts\../../data\q2_pg_pendulum_default_s3_InvertedPendulum-v4_25-09-2023_23-54-24
########################
Using CPU.
C:\My_Project\ALLEN_Python\homework_fall2023\venv\lib\site-packages\gym\core.py:317: DeprecationWarning: WARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.
  deprecation(
C:\My_Project\ALLEN_Python\homework_fall2023\venv\lib\site-packages\gym\wrappers\step_api_compatibility.py:39: DeprecationWarning: WARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.
  deprecation(
C:\My_Project\ALLEN_Python\homework_fall2023\venv\lib\site-packages\gym\utils\passive_env_checker.py:241: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):

********** Iteration 0 ************
C:\My_Project\ALLEN_Python\homework_fall2023\venv\lib\site-packages\tensorboardX\summary.py:153: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)
  scalar = float(scalar)
Eval_AverageReturn : 10.410256385803223
Eval_StdReturn : 7.044611930847168
Eval_MaxReturn : 28.0
Eval_MinReturn : 3.0
Eval_AverageEpLen : 10.41025641025641
Train_AverageReturn : 8.083333015441895
Train_StdReturn : 4.602014541625977
Train_MaxReturn : 33.0
Train_MinReturn : 3.0
Train_AverageEpLen : 8.083333333333334
Actor Loss : -123.18669891357422
Baseline Loss : 50.357582092285156
Train_EnvstepsSoFar : 3007
TimeSinceStart : 0.9833855628967285
Initial_DataCollection_AverageReturn : 8.083333015441895

********** Iteration 1 ************
Eval_AverageReturn : 16.83333396911621
Eval_StdReturn : 8.51795482635498
Eval_MaxReturn : 42.0
Eval_MinReturn : 6.0
Eval_AverageEpLen : 16.833333333333332
Train_AverageReturn : 10.767024993896484
Train_StdReturn : 7.0558085441589355
Train_MaxReturn : 61.0
Train_MinReturn : 3.0
Train_AverageEpLen : 10.767025089605735
Actor Loss : -86.91065216064453
Baseline Loss : 87.07560729980469
Train_EnvstepsSoFar : 6011
TimeSinceStart : 1.8840484619140625

********** Iteration 2 ************
Eval_AverageReturn : 25.3125
Eval_StdReturn : 16.10015106201172
Eval_MaxReturn : 76.0
Eval_MinReturn : 6.0
Eval_AverageEpLen : 25.3125
Train_AverageReturn : 14.802955627441406
Train_StdReturn : 11.441458702087402
Train_MaxReturn : 85.0
Train_MinReturn : 3.0
Train_AverageEpLen : 14.80295566502463
Actor Loss : -161.7502899169922
Baseline Loss : 208.8632049560547
Train_EnvstepsSoFar : 9016
TimeSinceStart : 2.8480749130249023

********** Iteration 3 ************
Eval_AverageReturn : 37.0
Eval_StdReturn : 20.467267990112305
Eval_MaxReturn : 84.0
Eval_MinReturn : 10.0
Eval_AverageEpLen : 37.0
Train_AverageReturn : 20.33108139038086
Train_StdReturn : 13.517950057983398
Train_MaxReturn : 84.0
Train_MinReturn : 4.0
Train_AverageEpLen : 20.33108108108108
Actor Loss : -189.87982177734375
Baseline Loss : 219.7593536376953
Train_EnvstepsSoFar : 12025
TimeSinceStart : 3.7629234790802

********** Iteration 4 ************
Eval_AverageReturn : 31.538461685180664
Eval_StdReturn : 17.521923065185547
Eval_MaxReturn : 70.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 31.53846153846154
Train_AverageReturn : 29.441177368164062
Train_StdReturn : 16.59469223022461
Train_MaxReturn : 92.0
Train_MinReturn : 6.0
Train_AverageEpLen : 29.441176470588236
Actor Loss : -93.12157440185547
Baseline Loss : 342.54522705078125
Train_EnvstepsSoFar : 15028
TimeSinceStart : 4.6753294467926025

********** Iteration 5 ************
Eval_AverageReturn : 39.272727966308594
Eval_StdReturn : 23.265623092651367
Eval_MaxReturn : 97.0
Eval_MinReturn : 11.0
Eval_AverageEpLen : 39.27272727272727
Train_AverageReturn : 38.40506362915039
Train_StdReturn : 22.055463790893555
Train_MaxReturn : 117.0
Train_MinReturn : 7.0
Train_AverageEpLen : 38.40506329113924
Actor Loss : -56.6997184753418
Baseline Loss : 623.3206787109375
Train_EnvstepsSoFar : 18062
TimeSinceStart : 5.571781873703003

********** Iteration 6 ************
Eval_AverageReturn : 67.0
Eval_StdReturn : 24.09010887145996
Eval_MaxReturn : 118.0
Eval_MinReturn : 45.0
Eval_AverageEpLen : 67.0
Train_AverageReturn : 44.882354736328125
Train_StdReturn : 24.4549560546875
Train_MaxReturn : 137.0
Train_MinReturn : 8.0
Train_AverageEpLen : 44.88235294117647
Actor Loss : -128.36752319335938
Baseline Loss : 784.5457763671875
Train_EnvstepsSoFar : 21114
TimeSinceStart : 6.42390513420105

********** Iteration 7 ************
Eval_AverageReturn : 89.5999984741211
Eval_StdReturn : 35.81396484375
Eval_MaxReturn : 142.0
Eval_MinReturn : 48.0
Eval_AverageEpLen : 89.6
Train_AverageReturn : 54.08928680419922
Train_StdReturn : 26.872900009155273
Train_MaxReturn : 121.0
Train_MinReturn : 7.0
Train_AverageEpLen : 54.089285714285715
Actor Loss : -156.2583770751953
Baseline Loss : 977.5545043945312
Train_EnvstepsSoFar : 24143
TimeSinceStart : 7.41956639289856

********** Iteration 8 ************
Eval_AverageReturn : 73.71428680419922
Eval_StdReturn : 47.321739196777344
Eval_MaxReturn : 173.0
Eval_MinReturn : 18.0
Eval_AverageEpLen : 73.71428571428571
Train_AverageReturn : 55.98147964477539
Train_StdReturn : 23.267757415771484
Train_MaxReturn : 122.0
Train_MinReturn : 17.0
Train_AverageEpLen : 55.98148148148148
Actor Loss : -82.82267761230469
Baseline Loss : 785.7761840820312
Train_EnvstepsSoFar : 27166
TimeSinceStart : 8.330503702163696

********** Iteration 9 ************
Eval_AverageReturn : 52.375
Eval_StdReturn : 13.228165626525879
Eval_MaxReturn : 71.0
Eval_MinReturn : 30.0
Eval_AverageEpLen : 52.375
Train_AverageReturn : 58.80769348144531
Train_StdReturn : 24.54747200012207
Train_MaxReturn : 146.0
Train_MinReturn : 17.0
Train_AverageEpLen : 58.80769230769231
Actor Loss : -50.791847229003906
Baseline Loss : 850.6047973632812
Train_EnvstepsSoFar : 30224
TimeSinceStart : 9.254578828811646

********** Iteration 10 ************
Eval_AverageReturn : 55.0
Eval_StdReturn : 23.31844711303711
Eval_MaxReturn : 95.0
Eval_MinReturn : 13.0
Eval_AverageEpLen : 55.0
Train_AverageReturn : 61.93877410888672
Train_StdReturn : 25.770896911621094
Train_MaxReturn : 141.0
Train_MinReturn : 19.0
Train_AverageEpLen : 61.93877551020408
Actor Loss : -58.16874313354492
Baseline Loss : 934.7637939453125
Train_EnvstepsSoFar : 33259
TimeSinceStart : 10.168624877929688

********** Iteration 11 ************
Eval_AverageReturn : 67.66666412353516
Eval_StdReturn : 20.483055114746094
Eval_MaxReturn : 106.0
Eval_MinReturn : 43.0
Eval_AverageEpLen : 67.66666666666667
Train_AverageReturn : 64.02127838134766
Train_StdReturn : 26.204992294311523
Train_MaxReturn : 155.0
Train_MinReturn : 25.0
Train_AverageEpLen : 64.02127659574468
Actor Loss : 18.43977165222168
Baseline Loss : 961.16845703125
Train_EnvstepsSoFar : 36268
TimeSinceStart : 11.004055261611938

********** Iteration 12 ************
Eval_AverageReturn : 72.71428680419922
Eval_StdReturn : 34.796199798583984
Eval_MaxReturn : 115.0
Eval_MinReturn : 21.0
Eval_AverageEpLen : 72.71428571428571
Train_AverageReturn : 57.82692337036133
Train_StdReturn : 24.710416793823242
Train_MaxReturn : 143.0
Train_MinReturn : 14.0
Train_AverageEpLen : 57.82692307692308
Actor Loss : 12.351484298706055
Baseline Loss : 685.609375
Train_EnvstepsSoFar : 39275
TimeSinceStart : 11.948423147201538

********** Iteration 13 ************
Eval_AverageReturn : 50.625
Eval_StdReturn : 26.57036590576172
Eval_MaxReturn : 102.0
Eval_MinReturn : 19.0
Eval_AverageEpLen : 50.625
Train_AverageReturn : 75.5250015258789
Train_StdReturn : 30.382549285888672
Train_MaxReturn : 177.0
Train_MinReturn : 37.0
Train_AverageEpLen : 75.525
Actor Loss : 4.432273864746094
Baseline Loss : 1259.9388427734375
Train_EnvstepsSoFar : 42296
TimeSinceStart : 12.79100751876831

********** Iteration 14 ************
Eval_AverageReturn : 110.5
Eval_StdReturn : 26.433879852294922
Eval_MaxReturn : 151.0
Eval_MinReturn : 85.0
Eval_AverageEpLen : 110.5
Train_AverageReturn : 68.84091186523438
Train_StdReturn : 27.93657112121582
Train_MaxReturn : 140.0
Train_MinReturn : 36.0
Train_AverageEpLen : 68.8409090909091
Actor Loss : -55.18537139892578
Baseline Loss : 916.9822998046875
Train_EnvstepsSoFar : 45325
TimeSinceStart : 13.839470386505127

********** Iteration 15 ************
Eval_AverageReturn : 80.19999694824219
Eval_StdReturn : 12.073110580444336
Eval_MaxReturn : 97.0
Eval_MinReturn : 62.0
Eval_AverageEpLen : 80.2
Train_AverageReturn : 74.0
Train_StdReturn : 28.76566505432129
Train_MaxReturn : 169.0
Train_MinReturn : 16.0
Train_AverageEpLen : 74.0
Actor Loss : -13.406295776367188
Baseline Loss : 1037.957763671875
Train_EnvstepsSoFar : 48359
TimeSinceStart : 14.735370397567749

********** Iteration 16 ************
Eval_AverageReturn : 62.0
Eval_StdReturn : 17.18803596496582
Eval_MaxReturn : 99.0
Eval_MinReturn : 38.0
Eval_AverageEpLen : 62.0
Train_AverageReturn : 73.26190185546875
Train_StdReturn : 29.174402236938477
Train_MaxReturn : 152.0
Train_MinReturn : 27.0
Train_AverageEpLen : 73.26190476190476
Actor Loss : -9.442230224609375
Baseline Loss : 951.2140502929688
Train_EnvstepsSoFar : 51436
TimeSinceStart : 15.620319128036499

********** Iteration 17 ************
Eval_AverageReturn : 134.75
Eval_StdReturn : 43.71141052246094
Eval_MaxReturn : 192.0
Eval_MinReturn : 70.0
Eval_AverageEpLen : 134.75
Train_AverageReturn : 86.4857177734375
Train_StdReturn : 32.82453155517578
Train_MaxReturn : 172.0
Train_MinReturn : 37.0
Train_AverageEpLen : 86.48571428571428
Actor Loss : -50.627384185791016
Baseline Loss : 1457.970458984375
Train_EnvstepsSoFar : 54463
TimeSinceStart : 16.533732891082764

********** Iteration 18 ************
Eval_AverageReturn : 116.75
Eval_StdReturn : 48.87419891357422
Eval_MaxReturn : 181.0
Eval_MinReturn : 50.0
Eval_AverageEpLen : 116.75
Train_AverageReturn : 95.59375
Train_StdReturn : 52.190670013427734
Train_MaxReturn : 293.0
Train_MinReturn : 35.0
Train_AverageEpLen : 95.59375
Actor Loss : -31.83297348022461
Baseline Loss : 3501.237548828125
Train_EnvstepsSoFar : 57522
TimeSinceStart : 17.545221090316772

********** Iteration 19 ************
Eval_AverageReturn : 103.75
Eval_StdReturn : 43.63699722290039
Eval_MaxReturn : 178.0
Eval_MinReturn : 67.0
Eval_AverageEpLen : 103.75
Train_AverageReturn : 115.88461303710938
Train_StdReturn : 49.258602142333984
Train_MaxReturn : 283.0
Train_MinReturn : 34.0
Train_AverageEpLen : 115.88461538461539
Actor Loss : -10.935646057128906
Baseline Loss : 3679.34619140625
Train_EnvstepsSoFar : 60535
TimeSinceStart : 18.416646480560303

********** Iteration 20 ************
Eval_AverageReturn : 145.0
Eval_StdReturn : 70.21039581298828
Eval_MaxReturn : 263.0
Eval_MinReturn : 85.0
Eval_AverageEpLen : 145.0
Train_AverageReturn : 123.68000030517578
Train_StdReturn : 58.367610931396484
Train_MaxReturn : 238.0
Train_MinReturn : 33.0
Train_AverageEpLen : 123.68
Actor Loss : -20.133426666259766
Baseline Loss : 4233.6962890625
Train_EnvstepsSoFar : 63627
TimeSinceStart : 19.35079836845398

********** Iteration 21 ************
Eval_AverageReturn : 85.5999984741211
Eval_StdReturn : 30.916662216186523
Eval_MaxReturn : 130.0
Eval_MinReturn : 40.0
Eval_AverageEpLen : 85.6
Train_AverageReturn : 126.45833587646484
Train_StdReturn : 69.31268310546875
Train_MaxReturn : 317.0
Train_MinReturn : 63.0
Train_AverageEpLen : 126.45833333333333
Actor Loss : 7.536157608032227
Baseline Loss : 6116.22412109375
Train_EnvstepsSoFar : 66662
TimeSinceStart : 20.233200788497925

********** Iteration 22 ************
Eval_AverageReturn : 139.6666717529297
Eval_StdReturn : 16.539514541625977
Eval_MaxReturn : 156.0
Eval_MinReturn : 117.0
Eval_AverageEpLen : 139.66666666666666
Train_AverageReturn : 112.85185241699219
Train_StdReturn : 47.680809020996094
Train_MaxReturn : 247.0
Train_MinReturn : 40.0
Train_AverageEpLen : 112.85185185185185
Actor Loss : -5.835237503051758
Baseline Loss : 2785.48779296875
Train_EnvstepsSoFar : 69709
TimeSinceStart : 21.100234508514404

********** Iteration 23 ************
Eval_AverageReturn : 104.0
Eval_StdReturn : 52.5280876159668
Eval_MaxReturn : 184.0
Eval_MinReturn : 43.0
Eval_AverageEpLen : 104.0
Train_AverageReturn : 118.42308044433594
Train_StdReturn : 54.33384704589844
Train_MaxReturn : 280.0
Train_MinReturn : 29.0
Train_AverageEpLen : 118.42307692307692
Actor Loss : -80.01174926757812
Baseline Loss : 3350.28857421875
Train_EnvstepsSoFar : 72788
TimeSinceStart : 21.988383054733276

********** Iteration 24 ************
Eval_AverageReturn : 88.80000305175781
Eval_StdReturn : 15.740394592285156
Eval_MaxReturn : 110.0
Eval_MinReturn : 65.0
Eval_AverageEpLen : 88.8
Train_AverageReturn : 115.57691955566406
Train_StdReturn : 39.98766326904297
Train_MaxReturn : 188.0
Train_MinReturn : 53.0
Train_AverageEpLen : 115.57692307692308
Actor Loss : -41.1888542175293
Baseline Loss : 2045.572265625
Train_EnvstepsSoFar : 75793
TimeSinceStart : 22.842997550964355

********** Iteration 25 ************
Eval_AverageReturn : 85.80000305175781
Eval_StdReturn : 30.921836853027344
Eval_MaxReturn : 144.0
Eval_MinReturn : 58.0
Eval_AverageEpLen : 85.8
Train_AverageReturn : 108.25
Train_StdReturn : 36.77987289428711
Train_MaxReturn : 187.0
Train_MinReturn : 51.0
Train_AverageEpLen : 108.25
Actor Loss : 10.858325958251953
Baseline Loss : 1698.133544921875
Train_EnvstepsSoFar : 78824
TimeSinceStart : 23.833064317703247

********** Iteration 26 ************
Eval_AverageReturn : 83.19999694824219
Eval_StdReturn : 30.889480590820312
Eval_MaxReturn : 122.0
Eval_MinReturn : 36.0
Eval_AverageEpLen : 83.2
Train_AverageReturn : 102.73332977294922
Train_StdReturn : 38.32225799560547
Train_MaxReturn : 163.0
Train_MinReturn : 35.0
Train_AverageEpLen : 102.73333333333333
Actor Loss : -23.581554412841797
Baseline Loss : 1512.830322265625
Train_EnvstepsSoFar : 81906
TimeSinceStart : 24.667157888412476

********** Iteration 27 ************
Eval_AverageReturn : 264.0
Eval_StdReturn : 87.0
Eval_MaxReturn : 351.0
Eval_MinReturn : 177.0
Eval_AverageEpLen : 264.0
Train_AverageReturn : 122.38461303710938
Train_StdReturn : 45.07094955444336
Train_MaxReturn : 250.0
Train_MinReturn : 55.0
Train_AverageEpLen : 122.38461538461539
Actor Loss : -31.7176570892334
Baseline Loss : 2703.04541015625
Train_EnvstepsSoFar : 85088
TimeSinceStart : 25.697826623916626

********** Iteration 28 ************
Eval_AverageReturn : 159.5
Eval_StdReturn : 86.98706817626953
Eval_MaxReturn : 282.0
Eval_MinReturn : 36.0
Eval_AverageEpLen : 159.5
Train_AverageReturn : 133.7916717529297
Train_StdReturn : 58.142051696777344
Train_MaxReturn : 281.0
Train_MinReturn : 46.0
Train_AverageEpLen : 133.79166666666666
Actor Loss : -24.853069305419922
Baseline Loss : 3874.397705078125
Train_EnvstepsSoFar : 88299
TimeSinceStart : 26.625505685806274

********** Iteration 29 ************
Eval_AverageReturn : 142.6666717529297
Eval_StdReturn : 52.25790786743164
Eval_MaxReturn : 207.0
Eval_MinReturn : 79.0
Eval_AverageEpLen : 142.66666666666666
Train_AverageReturn : 161.42105102539062
Train_StdReturn : 85.4242172241211
Train_MaxReturn : 326.0
Train_MinReturn : 38.0
Train_AverageEpLen : 161.42105263157896
Actor Loss : -81.91510009765625
Baseline Loss : 7815.8876953125
Train_EnvstepsSoFar : 91366
TimeSinceStart : 27.53991723060608

********** Iteration 30 ************
Eval_AverageReturn : 108.5
Eval_StdReturn : 37.83186340332031
Eval_MaxReturn : 171.0
Eval_MinReturn : 76.0
Eval_AverageEpLen : 108.5
Train_AverageReturn : 128.5
Train_StdReturn : 59.961097717285156
Train_MaxReturn : 251.0
Train_MinReturn : 32.0
Train_AverageEpLen : 128.5
Actor Loss : -87.86551666259766
Baseline Loss : 3284.748046875
Train_EnvstepsSoFar : 94450
TimeSinceStart : 28.402599573135376

********** Iteration 31 ************
Eval_AverageReturn : 130.0
Eval_StdReturn : 31.59113883972168
Eval_MaxReturn : 180.0
Eval_MinReturn : 100.0
Eval_AverageEpLen : 130.0
Train_AverageReturn : 143.85714721679688
Train_StdReturn : 37.568077087402344
Train_MaxReturn : 221.0
Train_MinReturn : 85.0
Train_AverageEpLen : 143.85714285714286
Actor Loss : -35.96404266357422
Baseline Loss : 2296.044921875
Train_EnvstepsSoFar : 97471
TimeSinceStart : 29.27684259414673

********** Iteration 32 ************
Eval_AverageReturn : 276.0
Eval_StdReturn : 37.0
Eval_MaxReturn : 313.0
Eval_MinReturn : 239.0
Eval_AverageEpLen : 276.0
Train_AverageReturn : 168.2105255126953
Train_StdReturn : 84.09366607666016
Train_MaxReturn : 316.0
Train_MinReturn : 27.0
Train_AverageEpLen : 168.21052631578948
Actor Loss : -30.753814697265625
Baseline Loss : 6899.5341796875
Train_EnvstepsSoFar : 100667
TimeSinceStart : 30.214646339416504

********** Iteration 33 ************
Eval_AverageReturn : 288.5
Eval_StdReturn : 91.5
Eval_MaxReturn : 380.0
Eval_MinReturn : 197.0
Eval_AverageEpLen : 288.5
Train_AverageReturn : 205.1999969482422
Train_StdReturn : 89.79249572753906
Train_MaxReturn : 386.0
Train_MinReturn : 53.0
Train_AverageEpLen : 205.2
Actor Loss : -13.2748384475708
Baseline Loss : 10228.7001953125
Train_EnvstepsSoFar : 103745
TimeSinceStart : 31.168842792510986

********** Iteration 34 ************
Eval_AverageReturn : 161.0
Eval_StdReturn : 74.97999572753906
Eval_MaxReturn : 257.0
Eval_MinReturn : 74.0
Eval_AverageEpLen : 161.0
Train_AverageReturn : 204.6666717529297
Train_StdReturn : 103.85417175292969
Train_MaxReturn : 441.0
Train_MinReturn : 67.0
Train_AverageEpLen : 204.66666666666666
Actor Loss : -86.14322662353516
Baseline Loss : 13014.005859375
Train_EnvstepsSoFar : 106815
TimeSinceStart : 32.049062967300415

********** Iteration 35 ************
Eval_AverageReturn : 229.0
Eval_StdReturn : 33.0
Eval_MaxReturn : 262.0
Eval_MinReturn : 196.0
Eval_AverageEpLen : 229.0
Train_AverageReturn : 214.06666564941406
Train_StdReturn : 120.23558044433594
Train_MaxReturn : 538.0
Train_MinReturn : 32.0
Train_AverageEpLen : 214.06666666666666
Actor Loss : -89.17350006103516
Baseline Loss : 17143.052734375
Train_EnvstepsSoFar : 110026
TimeSinceStart : 32.9758939743042

********** Iteration 36 ************
Eval_AverageReturn : 204.0
Eval_StdReturn : 84.58525848388672
Eval_MaxReturn : 280.0
Eval_MinReturn : 86.0
Eval_AverageEpLen : 204.0
Train_AverageReturn : 204.6666717529297
Train_StdReturn : 90.8211898803711
Train_MaxReturn : 483.0
Train_MinReturn : 102.0
Train_AverageEpLen : 204.66666666666666
Actor Loss : -10.810070991516113
Baseline Loss : 11393.0185546875
Train_EnvstepsSoFar : 113096
TimeSinceStart : 33.86328864097595

********** Iteration 37 ************
Eval_AverageReturn : 433.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 433.0
Eval_MinReturn : 433.0
Eval_AverageEpLen : 433.0
Train_AverageReturn : 306.18182373046875
Train_StdReturn : 214.17572021484375
Train_MaxReturn : 742.0
Train_MinReturn : 63.0
Train_AverageEpLen : 306.1818181818182
Actor Loss : -66.02125549316406
Baseline Loss : 55008.34375
Train_EnvstepsSoFar : 116464
TimeSinceStart : 34.792022943496704

********** Iteration 38 ************
Eval_AverageReturn : 221.5
Eval_StdReturn : 3.5
Eval_MaxReturn : 225.0
Eval_MinReturn : 218.0
Eval_AverageEpLen : 221.5
Train_AverageReturn : 330.4545593261719
Train_StdReturn : 213.15310668945312
Train_MaxReturn : 871.0
Train_MinReturn : 90.0
Train_AverageEpLen : 330.45454545454544
Actor Loss : -3.4147109985351562
Baseline Loss : 61498.4765625
Train_EnvstepsSoFar : 120099
TimeSinceStart : 35.80318760871887

********** Iteration 39 ************
Eval_AverageReturn : 258.3333435058594
Eval_StdReturn : 151.48231506347656
Eval_MaxReturn : 442.0
Eval_MinReturn : 71.0
Eval_AverageEpLen : 258.3333333333333
Train_AverageReturn : 314.79998779296875
Train_StdReturn : 74.58793640136719
Train_MaxReturn : 406.0
Train_MinReturn : 133.0
Train_AverageEpLen : 314.8
Actor Loss : -71.70073699951172
Baseline Loss : 16171.181640625
Train_EnvstepsSoFar : 123247
TimeSinceStart : 36.80214500427246

********** Iteration 40 ************
Eval_AverageReturn : 521.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 521.0
Eval_MinReturn : 521.0
Eval_AverageEpLen : 521.0
Train_AverageReturn : 276.5833435058594
Train_StdReturn : 169.39276123046875
Train_MaxReturn : 530.0
Train_MinReturn : 34.0
Train_AverageEpLen : 276.5833333333333
Actor Loss : -39.77054977416992
Baseline Loss : 27371.60546875
Train_EnvstepsSoFar : 126566
TimeSinceStart : 37.80562162399292

********** Iteration 41 ************
Eval_AverageReturn : 229.5
Eval_StdReturn : 38.5
Eval_MaxReturn : 268.0
Eval_MinReturn : 191.0
Eval_AverageEpLen : 229.5
Train_AverageReturn : 330.0
Train_StdReturn : 357.1839904785156
Train_MaxReturn : 1000.0
Train_MinReturn : 45.0
Train_AverageEpLen : 330.0
Actor Loss : -117.3915786743164
Baseline Loss : 156513.75
Train_EnvstepsSoFar : 129866
TimeSinceStart : 38.74431490898132

********** Iteration 42 ************
Eval_AverageReturn : 1000.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 1000.0
Eval_MinReturn : 1000.0
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 423.5
Train_StdReturn : 305.0512390136719
Train_MaxReturn : 1000.0
Train_MinReturn : 62.0
Train_AverageEpLen : 423.5
Actor Loss : -41.06932830810547
Baseline Loss : 117383.1015625
Train_EnvstepsSoFar : 133254
TimeSinceStart : 39.85854506492615

********** Iteration 43 ************
Eval_AverageReturn : 510.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 510.0
Eval_MinReturn : 510.0
Eval_AverageEpLen : 510.0
Train_AverageReturn : 449.0
Train_StdReturn : 185.35525512695312
Train_MaxReturn : 722.0
Train_MinReturn : 217.0
Train_AverageEpLen : 449.0
Actor Loss : -78.37367248535156
Baseline Loss : 57768.3046875
Train_EnvstepsSoFar : 136397
TimeSinceStart : 40.94810128211975

********** Iteration 44 ************
Eval_AverageReturn : 289.0
Eval_StdReturn : 38.0
Eval_MaxReturn : 327.0
Eval_MinReturn : 251.0
Eval_AverageEpLen : 289.0
Train_AverageReturn : 531.5
Train_StdReturn : 386.5616760253906
Train_MaxReturn : 964.0
Train_MinReturn : 104.0
Train_AverageEpLen : 531.5
Actor Loss : -27.53072738647461
Baseline Loss : 167967.65625
Train_EnvstepsSoFar : 139586
TimeSinceStart : 41.899658203125

********** Iteration 45 ************
Eval_AverageReturn : 463.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 463.0
Eval_MinReturn : 463.0
Eval_AverageEpLen : 463.0
Train_AverageReturn : 611.1666870117188
Train_StdReturn : 246.2535400390625
Train_MaxReturn : 1000.0
Train_MinReturn : 264.0
Train_AverageEpLen : 611.1666666666666
Actor Loss : -28.681907653808594
Baseline Loss : 120809.375
Train_EnvstepsSoFar : 143253
TimeSinceStart : 42.84153723716736

********** Iteration 46 ************
Eval_AverageReturn : 1000.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 1000.0
Eval_MinReturn : 1000.0
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 645.0
Train_StdReturn : 421.98199462890625
Train_MaxReturn : 1000.0
Train_MinReturn : 114.0
Train_AverageEpLen : 645.0
Actor Loss : -13.328267097473145
Baseline Loss : 207652.875
Train_EnvstepsSoFar : 146478
TimeSinceStart : 43.958473443984985

********** Iteration 47 ************
Eval_AverageReturn : 1000.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 1000.0
Eval_MinReturn : 1000.0
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 657.0
Train_StdReturn : 370.86114501953125
Train_MaxReturn : 1000.0
Train_MinReturn : 183.0
Train_AverageEpLen : 657.0
Actor Loss : 8.210644721984863
Baseline Loss : 182144.90625
Train_EnvstepsSoFar : 149763
TimeSinceStart : 44.97627925872803

********** Iteration 48 ************
Eval_AverageReturn : 996.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 996.0
Eval_MinReturn : 996.0
Eval_AverageEpLen : 996.0
Train_AverageReturn : 661.2000122070312
Train_StdReturn : 329.1743469238281
Train_MaxReturn : 1000.0
Train_MinReturn : 185.0
Train_AverageEpLen : 661.2
Actor Loss : 38.77664566040039
Baseline Loss : 161906.125
Train_EnvstepsSoFar : 153069
TimeSinceStart : 46.133575439453125

********** Iteration 49 ************
Eval_AverageReturn : 1000.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 1000.0
Eval_MinReturn : 1000.0
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 945.0
Train_StdReturn : 95.2627944946289
Train_MaxReturn : 1000.0
Train_MinReturn : 780.0
Train_AverageEpLen : 945.0
Actor Loss : 37.02139663696289
Baseline Loss : 200679.03125
Train_EnvstepsSoFar : 156849
TimeSinceStart : 47.34068512916565

********** Iteration 50 ************
Eval_AverageReturn : 994.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 994.0
Eval_MinReturn : 994.0
Eval_AverageEpLen : 994.0
Train_AverageReturn : 606.0
Train_StdReturn : 324.052978515625
Train_MaxReturn : 1000.0
Train_MinReturn : 109.0
Train_AverageEpLen : 606.0
Actor Loss : -16.296680450439453
Baseline Loss : 140950.40625
Train_EnvstepsSoFar : 160485
TimeSinceStart : 48.67446303367615

********** Iteration 51 ************
Eval_AverageReturn : 883.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 883.0
Eval_MinReturn : 883.0
Eval_AverageEpLen : 883.0
Train_AverageReturn : 640.0
Train_StdReturn : 324.7265625
Train_MaxReturn : 1000.0
Train_MinReturn : 177.0
Train_AverageEpLen : 640.0
Actor Loss : -112.4290771484375
Baseline Loss : 148968.84375
Train_EnvstepsSoFar : 164325
TimeSinceStart : 49.85869288444519

********** Iteration 52 ************
Eval_AverageReturn : 416.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 416.0
Eval_MinReturn : 416.0
Eval_AverageEpLen : 416.0
Train_AverageReturn : 780.25
Train_StdReturn : 295.5506591796875
Train_MaxReturn : 1000.0
Train_MinReturn : 281.0
Train_AverageEpLen : 780.25
Actor Loss : -7.0911407470703125
Baseline Loss : 174961.828125
Train_EnvstepsSoFar : 167446
TimeSinceStart : 50.759902477264404

********** Iteration 53 ************
Eval_AverageReturn : 906.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 906.0
Eval_MinReturn : 906.0
Eval_AverageEpLen : 906.0
Train_AverageReturn : 672.0
Train_StdReturn : 227.51702880859375
Train_MaxReturn : 931.0
Train_MinReturn : 355.0
Train_AverageEpLen : 672.0
Actor Loss : -123.67454528808594
Baseline Loss : 115196.7890625
Train_EnvstepsSoFar : 170806
TimeSinceStart : 51.828354597091675

********** Iteration 54 ************
Eval_AverageReturn : 644.0
Eval_StdReturn : 294.0
Eval_MaxReturn : 938.0
Eval_MinReturn : 350.0
Eval_AverageEpLen : 644.0
Train_AverageReturn : 797.5
Train_StdReturn : 342.7050476074219
Train_MaxReturn : 1000.0
Train_MinReturn : 204.0
Train_AverageEpLen : 797.5
Actor Loss : -10.829198837280273
Baseline Loss : 194302.96875
Train_EnvstepsSoFar : 173996
TimeSinceStart : 52.95170044898987

********** Iteration 55 ************
Eval_AverageReturn : 589.5
Eval_StdReturn : 377.5
Eval_MaxReturn : 967.0
Eval_MinReturn : 212.0
Eval_AverageEpLen : 589.5
Train_AverageReturn : 380.25
Train_StdReturn : 147.2784423828125
Train_MaxReturn : 704.0
Train_MinReturn : 245.0
Train_AverageEpLen : 380.25
Actor Loss : -14.7372465133667
Baseline Loss : 29864.640625
Train_EnvstepsSoFar : 177038
TimeSinceStart : 54.20866537094116

********** Iteration 56 ************
Eval_AverageReturn : 1000.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 1000.0
Eval_MinReturn : 1000.0
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 463.5714416503906
Train_StdReturn : 87.54077911376953
Train_MaxReturn : 554.0
Train_MinReturn : 268.0
Train_AverageEpLen : 463.57142857142856
Actor Loss : 51.19304656982422
Baseline Loss : 28418.5
Train_EnvstepsSoFar : 180283
TimeSinceStart : 55.3580048084259

********** Iteration 57 ************
Eval_AverageReturn : 1000.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 1000.0
Eval_MinReturn : 1000.0
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 765.25
Train_StdReturn : 406.59893798828125
Train_MaxReturn : 1000.0
Train_MinReturn : 61.0
Train_AverageEpLen : 765.25
Actor Loss : -50.729759216308594
Baseline Loss : 201014.390625
Train_EnvstepsSoFar : 183344
TimeSinceStart : 56.38043403625488

********** Iteration 58 ************
Eval_AverageReturn : 904.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 904.0
Eval_MinReturn : 904.0
Eval_AverageEpLen : 904.0
Train_AverageReturn : 1000.0
Train_StdReturn : 0.0
Train_MaxReturn : 1000.0
Train_MinReturn : 1000.0
Train_AverageEpLen : 1000.0
Actor Loss : -24.468936920166016
Baseline Loss : 203088.109375
Train_EnvstepsSoFar : 186344
TimeSinceStart : 57.309476375579834

********** Iteration 59 ************
Eval_AverageReturn : 1000.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 1000.0
Eval_MinReturn : 1000.0
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 929.75
Train_StdReturn : 121.67656707763672
Train_MaxReturn : 1000.0
Train_MinReturn : 719.0
Train_AverageEpLen : 929.75
Actor Loss : 31.732593536376953
Baseline Loss : 178585.453125
Train_EnvstepsSoFar : 190063
TimeSinceStart : 58.763519525527954

********** Iteration 60 ************
Eval_AverageReturn : 1000.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 1000.0
Eval_MinReturn : 1000.0
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 1000.0
Train_StdReturn : 0.0
Train_MaxReturn : 1000.0
Train_MinReturn : 1000.0
Train_AverageEpLen : 1000.0
Actor Loss : 29.115074157714844
Baseline Loss : 199252.953125
Train_EnvstepsSoFar : 193063
TimeSinceStart : 59.75801706314087

********** Iteration 61 ************
Eval_AverageReturn : 1000.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 1000.0
Eval_MinReturn : 1000.0
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 1000.0
Train_StdReturn : 0.0
Train_MaxReturn : 1000.0
Train_MinReturn : 1000.0
Train_AverageEpLen : 1000.0
Actor Loss : 3.3441009521484375
Baseline Loss : 197267.578125
Train_EnvstepsSoFar : 196063
TimeSinceStart : 61.07712912559509

********** Iteration 62 ************
Eval_AverageReturn : 1000.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 1000.0
Eval_MinReturn : 1000.0
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 1000.0
Train_StdReturn : 0.0
Train_MaxReturn : 1000.0
Train_MinReturn : 1000.0
Train_AverageEpLen : 1000.0
Actor Loss : -29.802345275878906
Baseline Loss : 195286.90625
Train_EnvstepsSoFar : 199063
TimeSinceStart : 62.04317355155945

********** Iteration 63 ************
Eval_AverageReturn : 1000.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 1000.0
Eval_MinReturn : 1000.0
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 1000.0
Train_StdReturn : 0.0
Train_MaxReturn : 1000.0
Train_MinReturn : 1000.0
Train_AverageEpLen : 1000.0
Actor Loss : 10.614803314208984
Baseline Loss : 193339.671875
Train_EnvstepsSoFar : 202063
TimeSinceStart : 63.03311204910278

********** Iteration 64 ************
Eval_AverageReturn : 1000.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 1000.0
Eval_MinReturn : 1000.0
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 1000.0
Train_StdReturn : 0.0
Train_MaxReturn : 1000.0
Train_MinReturn : 1000.0
Train_AverageEpLen : 1000.0
Actor Loss : -37.06318283081055
Baseline Loss : 191439.515625
Train_EnvstepsSoFar : 205063
TimeSinceStart : 63.99166560173035

********** Iteration 65 ************
Eval_AverageReturn : 1000.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 1000.0
Eval_MinReturn : 1000.0
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 1000.0
Train_StdReturn : 0.0
Train_MaxReturn : 1000.0
Train_MinReturn : 1000.0
Train_AverageEpLen : 1000.0
Actor Loss : -43.62061309814453
Baseline Loss : 189592.15625
Train_EnvstepsSoFar : 208063
TimeSinceStart : 64.97665858268738

********** Iteration 66 ************
Eval_AverageReturn : 1000.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 1000.0
Eval_MinReturn : 1000.0
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 1000.0
Train_StdReturn : 0.0
Train_MaxReturn : 1000.0
Train_MinReturn : 1000.0
Train_AverageEpLen : 1000.0
Actor Loss : 67.45658874511719
Baseline Loss : 187798.625
Train_EnvstepsSoFar : 211063
TimeSinceStart : 66.04483890533447

********** Iteration 67 ************
Eval_AverageReturn : 1000.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 1000.0
Eval_MinReturn : 1000.0
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 1000.0
Train_StdReturn : 0.0
Train_MaxReturn : 1000.0
Train_MinReturn : 1000.0
Train_AverageEpLen : 1000.0
Actor Loss : 40.34485626220703
Baseline Loss : 186058.0
Train_EnvstepsSoFar : 214063
TimeSinceStart : 67.02959370613098

********** Iteration 68 ************
Eval_AverageReturn : 1000.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 1000.0
Eval_MinReturn : 1000.0
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 1000.0
Train_StdReturn : 0.0
Train_MaxReturn : 1000.0
Train_MinReturn : 1000.0
Train_AverageEpLen : 1000.0
Actor Loss : 55.310184478759766
Baseline Loss : 184368.21875
Train_EnvstepsSoFar : 217063
TimeSinceStart : 67.91973280906677

********** Iteration 69 ************
Eval_AverageReturn : 1000.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 1000.0
Eval_MinReturn : 1000.0
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 1000.0
Train_StdReturn : 0.0
Train_MaxReturn : 1000.0
Train_MinReturn : 1000.0
Train_AverageEpLen : 1000.0
Actor Loss : 27.184389114379883
Baseline Loss : 182727.453125
Train_EnvstepsSoFar : 220063
TimeSinceStart : 68.83822703361511

********** Iteration 70 ************
Eval_AverageReturn : 618.0
Eval_StdReturn : 382.0
Eval_MaxReturn : 1000.0
Eval_MinReturn : 236.0
Eval_AverageEpLen : 618.0
Train_AverageReturn : 1000.0
Train_StdReturn : 0.0
Train_MaxReturn : 1000.0
Train_MinReturn : 1000.0
Train_AverageEpLen : 1000.0
Actor Loss : 2.260523796081543
Baseline Loss : 181131.28125
Train_EnvstepsSoFar : 223063
TimeSinceStart : 69.98193168640137

********** Iteration 71 ************
Eval_AverageReturn : 1000.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 1000.0
Eval_MinReturn : 1000.0
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 689.4000244140625
Train_StdReturn : 380.62664794921875
Train_MaxReturn : 1000.0
Train_MinReturn : 203.0
Train_AverageEpLen : 689.4
Actor Loss : 13.67251205444336
Baseline Loss : 157626.4375
Train_EnvstepsSoFar : 226510
TimeSinceStart : 70.92351984977722

********** Iteration 72 ************
Eval_AverageReturn : 1000.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 1000.0
Eval_MinReturn : 1000.0
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 1000.0
Train_StdReturn : 0.0
Train_MaxReturn : 1000.0
Train_MinReturn : 1000.0
Train_AverageEpLen : 1000.0
Actor Loss : -112.51812744140625
Baseline Loss : 178202.28125
Train_EnvstepsSoFar : 229510
TimeSinceStart : 71.76595640182495

********** Iteration 73 ************
Eval_AverageReturn : 463.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 463.0
Eval_MinReturn : 463.0
Eval_AverageEpLen : 463.0
Train_AverageReturn : 1000.0
Train_StdReturn : 0.0
Train_MaxReturn : 1000.0
Train_MinReturn : 1000.0
Train_AverageEpLen : 1000.0
Actor Loss : -4.575138568878174
Baseline Loss : 176750.0625
Train_EnvstepsSoFar : 232510
TimeSinceStart : 72.47991752624512

********** Iteration 74 ************
Eval_AverageReturn : 1000.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 1000.0
Eval_MinReturn : 1000.0
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 809.25
Train_StdReturn : 330.3887023925781
Train_MaxReturn : 1000.0
Train_MinReturn : 237.0
Train_AverageEpLen : 809.25
Actor Loss : -17.79610824584961
Baseline Loss : 163284.21875
Train_EnvstepsSoFar : 235747
TimeSinceStart : 73.3895332813263

********** Iteration 75 ************
Eval_AverageReturn : 1000.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 1000.0
Eval_MinReturn : 1000.0
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 926.25
Train_StdReturn : 127.7387466430664
Train_MaxReturn : 1000.0
Train_MinReturn : 705.0
Train_AverageEpLen : 926.25
Actor Loss : -59.987056732177734
Baseline Loss : 153201.25
Train_EnvstepsSoFar : 239452
TimeSinceStart : 74.38397359848022

********** Iteration 76 ************
Eval_AverageReturn : 363.5
Eval_StdReturn : 162.5
Eval_MaxReturn : 526.0
Eval_MinReturn : 201.0
Eval_AverageEpLen : 363.5
Train_AverageReturn : 520.0
Train_StdReturn : 297.127197265625
Train_MaxReturn : 890.0
Train_MinReturn : 43.0
Train_AverageEpLen : 520.0
Actor Loss : -173.9535675048828
Baseline Loss : 70167.0703125
Train_EnvstepsSoFar : 243092
TimeSinceStart : 75.30483675003052

********** Iteration 77 ************
Eval_AverageReturn : 1000.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 1000.0
Eval_MinReturn : 1000.0
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 676.2000122070312
Train_StdReturn : 314.2384033203125
Train_MaxReturn : 1000.0
Train_MinReturn : 169.0
Train_AverageEpLen : 676.2
Actor Loss : -49.455360412597656
Baseline Loss : 118892.796875
Train_EnvstepsSoFar : 246473
TimeSinceStart : 76.25192356109619

********** Iteration 78 ************
Eval_AverageReturn : 1000.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 1000.0
Eval_MinReturn : 1000.0
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 1000.0
Train_StdReturn : 0.0
Train_MaxReturn : 1000.0
Train_MinReturn : 1000.0
Train_AverageEpLen : 1000.0
Actor Loss : -20.874698638916016
Baseline Loss : 170630.875
Train_EnvstepsSoFar : 249473
TimeSinceStart : 77.12510061264038

********** Iteration 79 ************
Eval_AverageReturn : 1000.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 1000.0
Eval_MinReturn : 1000.0
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 835.0
Train_StdReturn : 285.78839111328125
Train_MaxReturn : 1000.0
Train_MinReturn : 340.0
Train_AverageEpLen : 835.0
Actor Loss : -9.660883903503418
Baseline Loss : 153380.09375
Train_EnvstepsSoFar : 252813
TimeSinceStart : 78.06510710716248

********** Iteration 80 ************
Eval_AverageReturn : 1000.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 1000.0
Eval_MinReturn : 1000.0
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 1000.0
Train_StdReturn : 0.0
Train_MaxReturn : 1000.0
Train_MinReturn : 1000.0
Train_AverageEpLen : 1000.0
Actor Loss : -0.1983623504638672
Baseline Loss : 168384.046875
Train_EnvstepsSoFar : 255813
TimeSinceStart : 78.90581202507019

********** Iteration 81 ************
Eval_AverageReturn : 1000.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 1000.0
Eval_MinReturn : 1000.0
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 1000.0
Train_StdReturn : 0.0
Train_MaxReturn : 1000.0
Train_MinReturn : 1000.0
Train_AverageEpLen : 1000.0
Actor Loss : -69.52776336669922
Baseline Loss : 167207.421875
Train_EnvstepsSoFar : 258813
TimeSinceStart : 79.8254280090332

********** Iteration 82 ************
Eval_AverageReturn : 1000.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 1000.0
Eval_MinReturn : 1000.0
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 762.75
Train_StdReturn : 410.9290466308594
Train_MaxReturn : 1000.0
Train_MinReturn : 51.0
Train_AverageEpLen : 762.75
Actor Loss : -34.177703857421875
Baseline Loss : 163824.921875
Train_EnvstepsSoFar : 261864
TimeSinceStart : 80.70627856254578

********** Iteration 83 ************
Eval_AverageReturn : 1000.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 1000.0
Eval_MinReturn : 1000.0
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 1000.0
Train_StdReturn : 0.0
Train_MaxReturn : 1000.0
Train_MinReturn : 1000.0
Train_AverageEpLen : 1000.0
Actor Loss : 27.033767700195312
Baseline Loss : 164822.09375
Train_EnvstepsSoFar : 264864
TimeSinceStart : 81.50362634658813

********** Iteration 84 ************
Eval_AverageReturn : 599.5
Eval_StdReturn : 400.5
Eval_MaxReturn : 1000.0
Eval_MinReturn : 199.0
Eval_AverageEpLen : 599.5
Train_AverageReturn : 1000.0
Train_StdReturn : 0.0
Train_MaxReturn : 1000.0
Train_MinReturn : 1000.0
Train_AverageEpLen : 1000.0
Actor Loss : -34.829742431640625
Baseline Loss : 163637.515625
Train_EnvstepsSoFar : 267864
TimeSinceStart : 82.37949538230896

********** Iteration 85 ************
Eval_AverageReturn : 1000.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 1000.0
Eval_MinReturn : 1000.0
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 1000.0
Train_StdReturn : 0.0
Train_MaxReturn : 1000.0
Train_MinReturn : 1000.0
Train_AverageEpLen : 1000.0
Actor Loss : -29.165218353271484
Baseline Loss : 162463.59375
Train_EnvstepsSoFar : 270864
TimeSinceStart : 83.40464854240417

********** Iteration 86 ************
Eval_AverageReturn : 1000.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 1000.0
Eval_MinReturn : 1000.0
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 1000.0
Train_StdReturn : 0.0
Train_MaxReturn : 1000.0
Train_MinReturn : 1000.0
Train_AverageEpLen : 1000.0
Actor Loss : 48.80793762207031
Baseline Loss : 161304.78125
Train_EnvstepsSoFar : 273864
TimeSinceStart : 84.2474296092987

********** Iteration 87 ************
Eval_AverageReturn : 1000.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 1000.0
Eval_MinReturn : 1000.0
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 916.25
Train_StdReturn : 145.0592498779297
Train_MaxReturn : 1000.0
Train_MinReturn : 665.0
Train_AverageEpLen : 916.25
Actor Loss : 9.068490982055664
Baseline Loss : 139979.765625
Train_EnvstepsSoFar : 277529
TimeSinceStart : 85.2459626197815

********** Iteration 88 ************
Eval_AverageReturn : 1000.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 1000.0
Eval_MinReturn : 1000.0
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 1000.0
Train_StdReturn : 0.0
Train_MaxReturn : 1000.0
Train_MinReturn : 1000.0
Train_AverageEpLen : 1000.0
Actor Loss : -79.57231140136719
Baseline Loss : 159086.625
Train_EnvstepsSoFar : 280529
TimeSinceStart : 86.11272525787354

********** Iteration 89 ************
Eval_AverageReturn : 1000.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 1000.0
Eval_MinReturn : 1000.0
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 1000.0
Train_StdReturn : 0.0
Train_MaxReturn : 1000.0
Train_MinReturn : 1000.0
Train_AverageEpLen : 1000.0
Actor Loss : 48.11541748046875
Baseline Loss : 158009.859375
Train_EnvstepsSoFar : 283529
TimeSinceStart : 86.94982838630676

********** Iteration 90 ************
Eval_AverageReturn : 1000.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 1000.0
Eval_MinReturn : 1000.0
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 1000.0
Train_StdReturn : 0.0
Train_MaxReturn : 1000.0
Train_MinReturn : 1000.0
Train_AverageEpLen : 1000.0
Actor Loss : 17.397192001342773
Baseline Loss : 156939.34375
Train_EnvstepsSoFar : 286529
TimeSinceStart : 87.80111622810364

********** Iteration 91 ************
Eval_AverageReturn : 1000.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 1000.0
Eval_MinReturn : 1000.0
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 797.5
Train_StdReturn : 329.166748046875
Train_MaxReturn : 1000.0
Train_MinReturn : 228.0
Train_AverageEpLen : 797.5
Actor Loss : 8.514620780944824
Baseline Loss : 141177.78125
Train_EnvstepsSoFar : 289719
TimeSinceStart : 88.65242624282837

********** Iteration 92 ************
Eval_AverageReturn : 1000.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 1000.0
Eval_MinReturn : 1000.0
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 1000.0
Train_StdReturn : 0.0
Train_MaxReturn : 1000.0
Train_MinReturn : 1000.0
Train_AverageEpLen : 1000.0
Actor Loss : -10.816997528076172
Baseline Loss : 154883.171875
Train_EnvstepsSoFar : 292719
TimeSinceStart : 89.48771452903748

********** Iteration 93 ************
Eval_AverageReturn : 1000.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 1000.0
Eval_MinReturn : 1000.0
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 1000.0
Train_StdReturn : 0.0
Train_MaxReturn : 1000.0
Train_MinReturn : 1000.0
Train_AverageEpLen : 1000.0
Actor Loss : 7.246247291564941
Baseline Loss : 153881.796875
Train_EnvstepsSoFar : 295719
TimeSinceStart : 90.3284559249878

********** Iteration 94 ************
Eval_AverageReturn : 1000.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 1000.0
Eval_MinReturn : 1000.0
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 957.25
Train_StdReturn : 74.04517364501953
Train_MaxReturn : 1000.0
Train_MinReturn : 829.0
Train_AverageEpLen : 957.25
Actor Loss : -68.3525390625
Baseline Loss : 139063.796875
Train_EnvstepsSoFar : 299548
TimeSinceStart : 91.3133339881897

********** Iteration 95 ************
Eval_AverageReturn : 1000.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 1000.0
Eval_MinReturn : 1000.0
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 1000.0
Train_StdReturn : 0.0
Train_MaxReturn : 1000.0
Train_MinReturn : 1000.0
Train_AverageEpLen : 1000.0
Actor Loss : 37.959232330322266
Baseline Loss : 151918.578125
Train_EnvstepsSoFar : 302548
TimeSinceStart : 92.28713130950928

********** Iteration 96 ************
Eval_AverageReturn : 1000.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 1000.0
Eval_MinReturn : 1000.0
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 1000.0
Train_StdReturn : 0.0
Train_MaxReturn : 1000.0
Train_MinReturn : 1000.0
Train_AverageEpLen : 1000.0
Actor Loss : -25.773723602294922
Baseline Loss : 150954.90625
Train_EnvstepsSoFar : 305548
TimeSinceStart : 93.23837471008301

********** Iteration 97 ************
Eval_AverageReturn : 1000.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 1000.0
Eval_MinReturn : 1000.0
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 977.25
Train_StdReturn : 39.40415573120117
Train_MaxReturn : 1000.0
Train_MinReturn : 909.0
Train_AverageEpLen : 977.25
Actor Loss : -26.326908111572266
Baseline Loss : 141651.078125
Train_EnvstepsSoFar : 309457
TimeSinceStart : 94.20664501190186

********** Iteration 98 ************
Eval_AverageReturn : 1000.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 1000.0
Eval_MinReturn : 1000.0
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 1000.0
Train_StdReturn : 0.0
Train_MaxReturn : 1000.0
Train_MinReturn : 1000.0
Train_AverageEpLen : 1000.0
Actor Loss : -80.61589050292969
Baseline Loss : 149063.5
Train_EnvstepsSoFar : 312457
TimeSinceStart : 94.98376941680908

********** Iteration 99 ************
Eval_AverageReturn : 1000.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 1000.0
Eval_MinReturn : 1000.0
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 788.5
Train_StdReturn : 366.3287353515625
Train_MaxReturn : 1000.0
Train_MinReturn : 154.0
Train_AverageEpLen : 788.5
Actor Loss : 9.338977813720703
Baseline Loss : 142389.421875
Train_EnvstepsSoFar : 315611
TimeSinceStart : 95.80949020385742

Process finished with exit code 0
