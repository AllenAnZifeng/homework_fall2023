C:\My_Project\ALLEN_Python\homework_fall2023\venv\Scripts\python.exe C:\My_Project\ALLEN_Python\homework_fall2023\hw2\cs285\scripts\run_hw2.py --env_name CartPole-v0 -n 100 -b 1000 -rtg -na --exp_name cartpole_rtg_na
########################
logging outputs to  C:\My_Project\ALLEN_Python\homework_fall2023\hw2\cs285\scripts\../../data\q2_pg_cartpole_rtg_na_CartPole-v0_25-09-2023_20-08-06
########################
Using CPU.

********** Iteration 0 ************
C:\My_Project\ALLEN_Python\homework_fall2023\venv\lib\site-packages\gym\envs\registration.py:593: UserWarning: WARN: The environment CartPole-v0 is out of date. You should consider upgrading to version `v1`.
  logger.warn(
C:\My_Project\ALLEN_Python\homework_fall2023\venv\lib\site-packages\gym\core.py:317: DeprecationWarning: WARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.
  deprecation(
C:\My_Project\ALLEN_Python\homework_fall2023\venv\lib\site-packages\gym\wrappers\step_api_compatibility.py:39: DeprecationWarning: WARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.
  deprecation(
C:\My_Project\ALLEN_Python\homework_fall2023\venv\lib\site-packages\gym\utils\passive_env_checker.py:241: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
C:\My_Project\ALLEN_Python\homework_fall2023\venv\lib\site-packages\tensorboardX\summary.py:153: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)
  scalar = float(scalar)
Eval_AverageReturn : 29.64285659790039
Eval_StdReturn : 14.315860748291016
Eval_MaxReturn : 60.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 29.642857142857142
Train_AverageReturn : 25.769229888916016
Train_StdReturn : 14.133904457092285
Train_MaxReturn : 66.0
Train_MinReturn : 11.0
Train_AverageEpLen : 25.76923076923077
Actor Loss : -4.350818634033203
Train_EnvstepsSoFar : 1005
TimeSinceStart : 0.503364086151123
Initial_DataCollection_AverageReturn : 25.769229888916016

********** Iteration 1 ************
Eval_AverageReturn : 35.16666793823242
Eval_StdReturn : 17.290813446044922
Eval_MaxReturn : 59.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 35.166666666666664
Train_AverageReturn : 27.0256404876709
Train_StdReturn : 11.171133041381836
Train_MaxReturn : 70.0
Train_MinReturn : 10.0
Train_AverageEpLen : 27.025641025641026
Actor Loss : -10.408586502075195
Train_EnvstepsSoFar : 2059
TimeSinceStart : 1.0410728454589844

********** Iteration 2 ************
Eval_AverageReturn : 42.5
Eval_StdReturn : 21.78187370300293
Eval_MaxReturn : 88.0
Eval_MinReturn : 17.0
Eval_AverageEpLen : 42.5
Train_AverageReturn : 44.04166793823242
Train_StdReturn : 26.30506706237793
Train_MaxReturn : 126.0
Train_MinReturn : 15.0
Train_AverageEpLen : 44.041666666666664
Actor Loss : -8.542257308959961
Train_EnvstepsSoFar : 3116
TimeSinceStart : 1.5963218212127686

********** Iteration 3 ************
Eval_AverageReturn : 50.125
Eval_StdReturn : 25.83329963684082
Eval_MaxReturn : 96.0
Eval_MinReturn : 17.0
Eval_AverageEpLen : 50.125
Train_AverageReturn : 54.21052551269531
Train_StdReturn : 23.275419235229492
Train_MaxReturn : 105.0
Train_MinReturn : 29.0
Train_AverageEpLen : 54.21052631578947
Actor Loss : -3.041788339614868
Train_EnvstepsSoFar : 4146
TimeSinceStart : 2.0680694580078125

********** Iteration 4 ************
Eval_AverageReturn : 73.33333587646484
Eval_StdReturn : 43.72515106201172
Eval_MaxReturn : 156.0
Eval_MinReturn : 28.0
Eval_AverageEpLen : 73.33333333333333
Train_AverageReturn : 63.125
Train_StdReturn : 23.36363410949707
Train_MaxReturn : 130.0
Train_MinReturn : 34.0
Train_AverageEpLen : 63.125
Actor Loss : -1.6899468898773193
Train_EnvstepsSoFar : 5156
TimeSinceStart : 2.6288845539093018

********** Iteration 5 ************
Eval_AverageReturn : 91.19999694824219
Eval_StdReturn : 29.04754638671875
Eval_MaxReturn : 130.0
Eval_MinReturn : 58.0
Eval_AverageEpLen : 91.2
Train_AverageReturn : 55.83333206176758
Train_StdReturn : 22.54193687438965
Train_MaxReturn : 121.0
Train_MinReturn : 30.0
Train_AverageEpLen : 55.833333333333336
Actor Loss : -11.998385429382324
Train_EnvstepsSoFar : 6161
TimeSinceStart : 3.180650472640991

********** Iteration 6 ************
Eval_AverageReturn : 137.6666717529297
Eval_StdReturn : 47.14752197265625
Eval_MaxReturn : 200.0
Eval_MinReturn : 86.0
Eval_AverageEpLen : 137.66666666666666
Train_AverageReturn : 70.06666564941406
Train_StdReturn : 34.6207389831543
Train_MaxReturn : 173.0
Train_MinReturn : 29.0
Train_AverageEpLen : 70.06666666666666
Actor Loss : -0.04574871063232422
Train_EnvstepsSoFar : 7212
TimeSinceStart : 3.6689629554748535

********** Iteration 7 ************
Eval_AverageReturn : 92.0
Eval_StdReturn : 30.64636993408203
Eval_MaxReturn : 142.0
Eval_MinReturn : 51.0
Eval_AverageEpLen : 92.0
Train_AverageReturn : 76.0
Train_StdReturn : 36.821964263916016
Train_MaxReturn : 170.0
Train_MinReturn : 25.0
Train_AverageEpLen : 76.0
Actor Loss : -7.3590898513793945
Train_EnvstepsSoFar : 8276
TimeSinceStart : 4.2187340259552

********** Iteration 8 ************
Eval_AverageReturn : 94.0
Eval_StdReturn : 35.485206604003906
Eval_MaxReturn : 154.0
Eval_MinReturn : 52.0
Eval_AverageEpLen : 94.0
Train_AverageReturn : 97.7272720336914
Train_StdReturn : 40.758914947509766
Train_MaxReturn : 185.0
Train_MinReturn : 48.0
Train_AverageEpLen : 97.72727272727273
Actor Loss : -11.942626953125
Train_EnvstepsSoFar : 9351
TimeSinceStart : 4.803589582443237

********** Iteration 9 ************
Eval_AverageReturn : 101.75
Eval_StdReturn : 40.696285247802734
Eval_MaxReturn : 161.0
Eval_MinReturn : 64.0
Eval_AverageEpLen : 101.75
Train_AverageReturn : 87.66666412353516
Train_StdReturn : 26.693737030029297
Train_MaxReturn : 141.0
Train_MinReturn : 38.0
Train_AverageEpLen : 87.66666666666667
Actor Loss : -8.855460166931152
Train_EnvstepsSoFar : 10403
TimeSinceStart : 5.290448188781738

********** Iteration 10 ************
Eval_AverageReturn : 109.0
Eval_StdReturn : 30.041637420654297
Eval_MaxReturn : 147.0
Eval_MinReturn : 71.0
Eval_AverageEpLen : 109.0
Train_AverageReturn : 107.19999694824219
Train_StdReturn : 43.66875457763672
Train_MaxReturn : 200.0
Train_MinReturn : 51.0
Train_AverageEpLen : 107.2
Actor Loss : -9.792211532592773
Train_EnvstepsSoFar : 11475
TimeSinceStart : 5.882969617843628

********** Iteration 11 ************
Eval_AverageReturn : 139.6666717529297
Eval_StdReturn : 45.84272384643555
Eval_MaxReturn : 198.0
Eval_MinReturn : 86.0
Eval_AverageEpLen : 139.66666666666666
Train_AverageReturn : 121.55555725097656
Train_StdReturn : 37.30686950683594
Train_MaxReturn : 188.0
Train_MinReturn : 55.0
Train_AverageEpLen : 121.55555555555556
Actor Loss : -12.940103530883789
Train_EnvstepsSoFar : 12569
TimeSinceStart : 6.4531896114349365

********** Iteration 12 ************
Eval_AverageReturn : 172.3333282470703
Eval_StdReturn : 20.49932098388672
Eval_MaxReturn : 200.0
Eval_MinReturn : 151.0
Eval_AverageEpLen : 172.33333333333334
Train_AverageReturn : 148.14285278320312
Train_StdReturn : 55.929622650146484
Train_MaxReturn : 200.0
Train_MinReturn : 56.0
Train_AverageEpLen : 148.14285714285714
Actor Loss : -5.82577657699585
Train_EnvstepsSoFar : 13606
TimeSinceStart : 7.075209617614746

********** Iteration 13 ************
Eval_AverageReturn : 191.3333282470703
Eval_StdReturn : 8.956686019897461
Eval_MaxReturn : 200.0
Eval_MinReturn : 179.0
Eval_AverageEpLen : 191.33333333333334
Train_AverageReturn : 160.0
Train_StdReturn : 33.153324127197266
Train_MaxReturn : 200.0
Train_MinReturn : 106.0
Train_AverageEpLen : 160.0
Actor Loss : -9.9859619140625
Train_EnvstepsSoFar : 14726
TimeSinceStart : 7.678235769271851

********** Iteration 14 ************
Eval_AverageReturn : 161.0
Eval_StdReturn : 27.82085609436035
Eval_MaxReturn : 200.0
Eval_MinReturn : 137.0
Eval_AverageEpLen : 161.0
Train_AverageReturn : 157.85714721679688
Train_StdReturn : 30.684703826904297
Train_MaxReturn : 200.0
Train_MinReturn : 118.0
Train_AverageEpLen : 157.85714285714286
Actor Loss : -11.058698654174805
Train_EnvstepsSoFar : 15831
TimeSinceStart : 8.245069026947021

********** Iteration 15 ************
Eval_AverageReturn : 176.0
Eval_StdReturn : 30.47403335571289
Eval_MaxReturn : 200.0
Eval_MinReturn : 133.0
Eval_AverageEpLen : 176.0
Train_AverageReturn : 167.1666717529297
Train_StdReturn : 26.804330825805664
Train_MaxReturn : 200.0
Train_MinReturn : 135.0
Train_AverageEpLen : 167.16666666666666
Actor Loss : -31.99074935913086
Train_EnvstepsSoFar : 16834
TimeSinceStart : 8.769999980926514

********** Iteration 16 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 186.6666717529297
Train_StdReturn : 18.935562133789062
Train_MaxReturn : 200.0
Train_MinReturn : 157.0
Train_AverageEpLen : 186.66666666666666
Actor Loss : 0.06308627128601074
Train_EnvstepsSoFar : 17954
TimeSinceStart : 9.302247524261475

********** Iteration 17 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -10.95482063293457
Train_EnvstepsSoFar : 18954
TimeSinceStart : 9.752972602844238

********** Iteration 18 ************
Eval_AverageReturn : 186.0
Eval_StdReturn : 11.860298156738281
Eval_MaxReturn : 200.0
Eval_MinReturn : 171.0
Eval_AverageEpLen : 186.0
Train_AverageReturn : 190.3333282470703
Train_StdReturn : 21.615324020385742
Train_MaxReturn : 200.0
Train_MinReturn : 142.0
Train_AverageEpLen : 190.33333333333334
Actor Loss : -2.800138473510742
Train_EnvstepsSoFar : 20096
TimeSinceStart : 10.419427394866943

********** Iteration 19 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 190.8333282470703
Train_StdReturn : 13.861417770385742
Train_MaxReturn : 200.0
Train_MinReturn : 164.0
Train_AverageEpLen : 190.83333333333334
Actor Loss : -0.2337646484375
Train_EnvstepsSoFar : 21241
TimeSinceStart : 10.961172819137573

********** Iteration 20 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 183.8333282470703
Train_StdReturn : 25.745010375976562
Train_MaxReturn : 200.0
Train_MinReturn : 131.0
Train_AverageEpLen : 183.83333333333334
Actor Loss : 5.165214538574219
Train_EnvstepsSoFar : 22344
TimeSinceStart : 11.471485137939453

********** Iteration 21 ************
Eval_AverageReturn : 186.3333282470703
Eval_StdReturn : 19.327585220336914
Eval_MaxReturn : 200.0
Eval_MinReturn : 159.0
Eval_AverageEpLen : 186.33333333333334
Train_AverageReturn : 186.0
Train_StdReturn : 16.94107437133789
Train_MaxReturn : 200.0
Train_MinReturn : 161.0
Train_AverageEpLen : 186.0
Actor Loss : -28.442989349365234
Train_EnvstepsSoFar : 23460
TimeSinceStart : 12.035748481750488

********** Iteration 22 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 184.8333282470703
Train_StdReturn : 26.346515655517578
Train_MaxReturn : 200.0
Train_MinReturn : 128.0
Train_AverageEpLen : 184.83333333333334
Actor Loss : -12.032630920410156
Train_EnvstepsSoFar : 24569
TimeSinceStart : 12.555997371673584

********** Iteration 23 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -17.50725555419922
Train_EnvstepsSoFar : 25569
TimeSinceStart : 13.059857845306396

********** Iteration 24 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -19.117660522460938
Train_EnvstepsSoFar : 26569
TimeSinceStart : 13.526710271835327

********** Iteration 25 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -11.695564270019531
Train_EnvstepsSoFar : 27569
TimeSinceStart : 14.015997409820557

********** Iteration 26 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 187.3333282470703
Train_StdReturn : 28.32352638244629
Train_MaxReturn : 200.0
Train_MinReturn : 124.0
Train_AverageEpLen : 187.33333333333334
Actor Loss : -31.081951141357422
Train_EnvstepsSoFar : 28693
TimeSinceStart : 14.527517557144165

********** Iteration 27 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -22.984912872314453
Train_EnvstepsSoFar : 29693
TimeSinceStart : 15.013321161270142

********** Iteration 28 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 4.7967963218688965
Train_EnvstepsSoFar : 30693
TimeSinceStart : 15.490205764770508

********** Iteration 29 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -28.461835861206055
Train_EnvstepsSoFar : 31693
TimeSinceStart : 15.98329758644104

********** Iteration 30 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -13.009343147277832
Train_EnvstepsSoFar : 32693
TimeSinceStart : 16.47357201576233

********** Iteration 31 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -16.517086029052734
Train_EnvstepsSoFar : 33693
TimeSinceStart : 16.975751876831055

********** Iteration 32 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -18.83549690246582
Train_EnvstepsSoFar : 34693
TimeSinceStart : 17.495330572128296

********** Iteration 33 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -6.434883117675781
Train_EnvstepsSoFar : 35693
TimeSinceStart : 17.964659690856934

********** Iteration 34 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -9.501236915588379
Train_EnvstepsSoFar : 36693
TimeSinceStart : 18.485078811645508

********** Iteration 35 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -28.53369903564453
Train_EnvstepsSoFar : 37693
TimeSinceStart : 18.98147749900818

********** Iteration 36 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 0.4567375183105469
Train_EnvstepsSoFar : 38693
TimeSinceStart : 19.493659019470215

********** Iteration 37 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -11.11468505859375
Train_EnvstepsSoFar : 39693
TimeSinceStart : 20.0640287399292

********** Iteration 38 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 13.503859519958496
Train_EnvstepsSoFar : 40693
TimeSinceStart : 20.643978595733643

********** Iteration 39 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -12.1692533493042
Train_EnvstepsSoFar : 41693
TimeSinceStart : 21.14501690864563

********** Iteration 40 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 5.008070468902588
Train_EnvstepsSoFar : 42693
TimeSinceStart : 21.656718492507935

********** Iteration 41 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 12.207562446594238
Train_EnvstepsSoFar : 43693
TimeSinceStart : 22.17207145690918

********** Iteration 42 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 3.7507948875427246
Train_EnvstepsSoFar : 44693
TimeSinceStart : 22.674583911895752

********** Iteration 43 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -21.137901306152344
Train_EnvstepsSoFar : 45693
TimeSinceStart : 23.187073469161987

********** Iteration 44 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 2.634178400039673
Train_EnvstepsSoFar : 46693
TimeSinceStart : 23.70229959487915

********** Iteration 45 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 2.0584163665771484
Train_EnvstepsSoFar : 47693
TimeSinceStart : 24.25178098678589

********** Iteration 46 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 7.850680828094482
Train_EnvstepsSoFar : 48693
TimeSinceStart : 24.761332988739014

********** Iteration 47 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -8.26497745513916
Train_EnvstepsSoFar : 49693
TimeSinceStart : 25.246060848236084

********** Iteration 48 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 0.4760885238647461
Train_EnvstepsSoFar : 50693
TimeSinceStart : 25.717214822769165

********** Iteration 49 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 14.291669845581055
Train_EnvstepsSoFar : 51693
TimeSinceStart : 26.17867374420166

********** Iteration 50 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -8.578605651855469
Train_EnvstepsSoFar : 52693
TimeSinceStart : 26.681289196014404

********** Iteration 51 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -3.4701809883117676
Train_EnvstepsSoFar : 53693
TimeSinceStart : 27.15509271621704

********** Iteration 52 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -1.0394797325134277
Train_EnvstepsSoFar : 54693
TimeSinceStart : 27.661466360092163

********** Iteration 53 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 15.511372566223145
Train_EnvstepsSoFar : 55693
TimeSinceStart : 28.135002613067627

********** Iteration 54 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -15.215335845947266
Train_EnvstepsSoFar : 56693
TimeSinceStart : 28.607953786849976

********** Iteration 55 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -9.591168403625488
Train_EnvstepsSoFar : 57693
TimeSinceStart : 29.097272396087646

********** Iteration 56 ************
Eval_AverageReturn : 194.3333282470703
Eval_StdReturn : 8.013876914978027
Eval_MaxReturn : 200.0
Eval_MinReturn : 183.0
Eval_AverageEpLen : 194.33333333333334
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 6.069199085235596
Train_EnvstepsSoFar : 58693
TimeSinceStart : 29.688051223754883

********** Iteration 57 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -21.324642181396484
Train_EnvstepsSoFar : 59693
TimeSinceStart : 30.14357876777649

********** Iteration 58 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 197.3333282470703
Train_StdReturn : 5.96284818649292
Train_MaxReturn : 200.0
Train_MinReturn : 184.0
Train_AverageEpLen : 197.33333333333334
Actor Loss : -6.341634750366211
Train_EnvstepsSoFar : 60877
TimeSinceStart : 30.671638250350952

********** Iteration 59 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -6.793461322784424
Train_EnvstepsSoFar : 61877
TimeSinceStart : 31.12466263771057

********** Iteration 60 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -27.050434112548828
Train_EnvstepsSoFar : 62877
TimeSinceStart : 31.60660696029663

********** Iteration 61 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -12.497705459594727
Train_EnvstepsSoFar : 63877
TimeSinceStart : 32.06148028373718

********** Iteration 62 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -21.944278717041016
Train_EnvstepsSoFar : 64877
TimeSinceStart : 32.47248387336731

********** Iteration 63 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -14.544811248779297
Train_EnvstepsSoFar : 65877
TimeSinceStart : 32.8988995552063

********** Iteration 64 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 180.1666717529297
Train_StdReturn : 44.34868240356445
Train_MaxReturn : 200.0
Train_MinReturn : 81.0
Train_AverageEpLen : 180.16666666666666
Actor Loss : -1.9606962203979492
Train_EnvstepsSoFar : 66958
TimeSinceStart : 33.341556549072266

********** Iteration 65 ************
Eval_AverageReturn : 190.3333282470703
Eval_StdReturn : 13.670731544494629
Eval_MaxReturn : 200.0
Eval_MinReturn : 171.0
Eval_AverageEpLen : 190.33333333333334
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -38.767974853515625
Train_EnvstepsSoFar : 67958
TimeSinceStart : 33.83289098739624

********** Iteration 66 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -19.435327529907227
Train_EnvstepsSoFar : 68958
TimeSinceStart : 34.259294509887695

********** Iteration 67 ************
Eval_AverageReturn : 156.3333282470703
Eval_StdReturn : 57.56349182128906
Eval_MaxReturn : 200.0
Eval_MinReturn : 75.0
Eval_AverageEpLen : 156.33333333333334
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -13.902167320251465
Train_EnvstepsSoFar : 69958
TimeSinceStart : 34.72244620323181

********** Iteration 68 ************
Eval_AverageReturn : 161.0
Eval_StdReturn : 55.154327392578125
Eval_MaxReturn : 200.0
Eval_MinReturn : 83.0
Eval_AverageEpLen : 161.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -23.226619720458984
Train_EnvstepsSoFar : 70958
TimeSinceStart : 35.18848371505737

********** Iteration 69 ************
Eval_AverageReturn : 198.0
Eval_StdReturn : 2.8284270763397217
Eval_MaxReturn : 200.0
Eval_MinReturn : 194.0
Eval_AverageEpLen : 198.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -5.580410003662109
Train_EnvstepsSoFar : 71958
TimeSinceStart : 35.68341946601868

********** Iteration 70 ************
Eval_AverageReturn : 193.0
Eval_StdReturn : 9.899495124816895
Eval_MaxReturn : 200.0
Eval_MinReturn : 179.0
Eval_AverageEpLen : 193.0
Train_AverageReturn : 178.3333282470703
Train_StdReturn : 43.303836822509766
Train_MaxReturn : 200.0
Train_MinReturn : 82.0
Train_AverageEpLen : 178.33333333333334
Actor Loss : -16.5148983001709
Train_EnvstepsSoFar : 73028
TimeSinceStart : 36.223589181900024

********** Iteration 71 ************
Eval_AverageReturn : 198.0
Eval_StdReturn : 2.8284270763397217
Eval_MaxReturn : 200.0
Eval_MinReturn : 194.0
Eval_AverageEpLen : 198.0
Train_AverageReturn : 175.0
Train_StdReturn : 47.13809585571289
Train_MaxReturn : 200.0
Train_MinReturn : 71.0
Train_AverageEpLen : 175.0
Actor Loss : -6.745887756347656
Train_EnvstepsSoFar : 74078
TimeSinceStart : 36.73745059967041

********** Iteration 72 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 172.3333282470703
Train_StdReturn : 43.8659553527832
Train_MaxReturn : 200.0
Train_MinReturn : 77.0
Train_AverageEpLen : 172.33333333333334
Actor Loss : -16.878860473632812
Train_EnvstepsSoFar : 75112
TimeSinceStart : 37.199769735336304

********** Iteration 73 ************
Eval_AverageReturn : 177.6666717529297
Eval_StdReturn : 31.584104537963867
Eval_MaxReturn : 200.0
Eval_MinReturn : 133.0
Eval_AverageEpLen : 177.66666666666666
Train_AverageReturn : 193.8333282470703
Train_StdReturn : 8.725759506225586
Train_MaxReturn : 200.0
Train_MinReturn : 181.0
Train_AverageEpLen : 193.83333333333334
Actor Loss : -8.229507446289062
Train_EnvstepsSoFar : 76275
TimeSinceStart : 37.723280906677246

********** Iteration 74 ************
Eval_AverageReturn : 141.25
Eval_StdReturn : 58.75957489013672
Eval_MaxReturn : 200.0
Eval_MinReturn : 81.0
Eval_AverageEpLen : 141.25
Train_AverageReturn : 186.0
Train_StdReturn : 25.56038475036621
Train_MaxReturn : 200.0
Train_MinReturn : 130.0
Train_AverageEpLen : 186.0
Actor Loss : -3.1326565742492676
Train_EnvstepsSoFar : 77391
TimeSinceStart : 38.23037266731262

********** Iteration 75 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 146.0
Train_StdReturn : 62.64411926269531
Train_MaxReturn : 200.0
Train_MinReturn : 67.0
Train_AverageEpLen : 146.0
Actor Loss : -23.432540893554688
Train_EnvstepsSoFar : 78413
TimeSinceStart : 38.66067123413086

********** Iteration 76 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -6.035563945770264
Train_EnvstepsSoFar : 79413
TimeSinceStart : 39.06787991523743

********** Iteration 77 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 174.0
Train_StdReturn : 38.897300720214844
Train_MaxReturn : 200.0
Train_MinReturn : 94.0
Train_AverageEpLen : 174.0
Actor Loss : -2.0331509113311768
Train_EnvstepsSoFar : 80457
TimeSinceStart : 39.535216093063354

********** Iteration 78 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -3.9915874004364014
Train_EnvstepsSoFar : 81457
TimeSinceStart : 39.94911742210388

********** Iteration 79 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 17.500377655029297
Train_EnvstepsSoFar : 82457
TimeSinceStart : 40.361804723739624

********** Iteration 80 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -8.676536560058594
Train_EnvstepsSoFar : 83457
TimeSinceStart : 40.77259683609009

********** Iteration 81 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -21.270313262939453
Train_EnvstepsSoFar : 84457
TimeSinceStart : 41.21103048324585

********** Iteration 82 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -16.24489402770996
Train_EnvstepsSoFar : 85457
TimeSinceStart : 41.660208225250244

********** Iteration 83 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 11.193751335144043
Train_EnvstepsSoFar : 86457
TimeSinceStart : 42.07456636428833

********** Iteration 84 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -21.614200592041016
Train_EnvstepsSoFar : 87457
TimeSinceStart : 42.49637961387634

********** Iteration 85 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 14.16972541809082
Train_EnvstepsSoFar : 88457
TimeSinceStart : 42.936678886413574

********** Iteration 86 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -10.80366039276123
Train_EnvstepsSoFar : 89457
TimeSinceStart : 43.352834701538086

********** Iteration 87 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 3.317139148712158
Train_EnvstepsSoFar : 90457
TimeSinceStart : 43.78100275993347

********** Iteration 88 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 25.772769927978516
Train_EnvstepsSoFar : 91457
TimeSinceStart : 44.192251682281494

********** Iteration 89 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 12.102956771850586
Train_EnvstepsSoFar : 92457
TimeSinceStart : 44.6026976108551

********** Iteration 90 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 1.1038765907287598
Train_EnvstepsSoFar : 93457
TimeSinceStart : 45.00984239578247

********** Iteration 91 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -12.370323181152344
Train_EnvstepsSoFar : 94457
TimeSinceStart : 45.413339614868164

********** Iteration 92 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 19.19886016845703
Train_EnvstepsSoFar : 95457
TimeSinceStart : 45.8390371799469

********** Iteration 93 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -11.752721786499023
Train_EnvstepsSoFar : 96457
TimeSinceStart : 46.257649421691895

********** Iteration 94 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 20.396677017211914
Train_EnvstepsSoFar : 97457
TimeSinceStart : 46.645934104919434

********** Iteration 95 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -0.029503822326660156
Train_EnvstepsSoFar : 98457
TimeSinceStart : 47.12495732307434

********** Iteration 96 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 5.16945219039917
Train_EnvstepsSoFar : 99457
TimeSinceStart : 47.523844957351685

********** Iteration 97 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 1.8830018043518066
Train_EnvstepsSoFar : 100457
TimeSinceStart : 47.90165138244629

********** Iteration 98 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -21.45632553100586
Train_EnvstepsSoFar : 101457
TimeSinceStart : 48.29161620140076

********** Iteration 99 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 6.827139854431152
Train_EnvstepsSoFar : 102457
TimeSinceStart : 48.67532467842102

Process finished with exit code 0
