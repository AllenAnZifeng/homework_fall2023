C:\My_Project\ALLEN_Python\homework_fall2023\venv\Scripts\python.exe C:\My_Project\ALLEN_Python\homework_fall2023\hw2\cs285\scripts\run_hw2.py --env_name InvertedPendulum-v4 -n 100 --exp_name pendulum_default_s3 -rtg --use_baseline -na --batch_size 2000 --seed 3 --gae_lambda 0.99
########################
logging outputs to  C:\My_Project\ALLEN_Python\homework_fall2023\hw2\cs285\scripts\../../data\q2_pg_pendulum_default_s3_InvertedPendulum-v4_25-09-2023_23-54-18
########################
Using CPU.
C:\My_Project\ALLEN_Python\homework_fall2023\venv\lib\site-packages\gym\core.py:317: DeprecationWarning: WARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.
  deprecation(
C:\My_Project\ALLEN_Python\homework_fall2023\venv\lib\site-packages\gym\wrappers\step_api_compatibility.py:39: DeprecationWarning: WARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.
  deprecation(
C:\My_Project\ALLEN_Python\homework_fall2023\venv\lib\site-packages\gym\utils\passive_env_checker.py:241: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):

********** Iteration 0 ************
C:\My_Project\ALLEN_Python\homework_fall2023\venv\lib\site-packages\tensorboardX\summary.py:153: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)
  scalar = float(scalar)
Eval_AverageReturn : 10.578947067260742
Eval_StdReturn : 7.386444091796875
Eval_MaxReturn : 40.0
Eval_MinReturn : 4.0
Eval_AverageEpLen : 10.578947368421053
Train_AverageReturn : 7.980079650878906
Train_StdReturn : 4.555501461029053
Train_MaxReturn : 36.0
Train_MinReturn : 3.0
Train_AverageEpLen : 7.9800796812749
Actor Loss : -98.65986633300781
Baseline Loss : 51.0474853515625
Train_EnvstepsSoFar : 2003
TimeSinceStart : 0.5904340744018555
Initial_DataCollection_AverageReturn : 7.980079650878906

********** Iteration 1 ************
Eval_AverageReturn : 16.68000030517578
Eval_StdReturn : 7.492502689361572
Eval_MaxReturn : 36.0
Eval_MinReturn : 7.0
Eval_AverageEpLen : 16.68
Train_AverageReturn : 10.100502967834473
Train_StdReturn : 5.622098445892334
Train_MaxReturn : 33.0
Train_MinReturn : 3.0
Train_AverageEpLen : 10.100502512562814
Actor Loss : -153.75714111328125
Baseline Loss : 48.90937042236328
Train_EnvstepsSoFar : 4013
TimeSinceStart : 1.1459825038909912

********** Iteration 2 ************
Eval_AverageReturn : 23.11111068725586
Eval_StdReturn : 12.714335441589355
Eval_MaxReturn : 63.0
Eval_MinReturn : 7.0
Eval_AverageEpLen : 23.11111111111111
Train_AverageReturn : 15.09774398803711
Train_StdReturn : 9.558576583862305
Train_MaxReturn : 53.0
Train_MinReturn : 4.0
Train_AverageEpLen : 15.097744360902256
Actor Loss : -92.09522247314453
Baseline Loss : 119.76263427734375
Train_EnvstepsSoFar : 6021
TimeSinceStart : 1.727644920349121

********** Iteration 3 ************
Eval_AverageReturn : 26.799999237060547
Eval_StdReturn : 12.012215614318848
Eval_MaxReturn : 46.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 26.8
Train_AverageReturn : 21.56989288330078
Train_StdReturn : 15.534489631652832
Train_MaxReturn : 74.0
Train_MinReturn : 3.0
Train_AverageEpLen : 21.56989247311828
Actor Loss : -115.43583679199219
Baseline Loss : 289.9252624511719
Train_EnvstepsSoFar : 8027
TimeSinceStart : 2.305535316467285

********** Iteration 4 ************
Eval_AverageReturn : 55.875
Eval_StdReturn : 14.641016960144043
Eval_MaxReturn : 78.0
Eval_MinReturn : 29.0
Eval_AverageEpLen : 55.875
Train_AverageReturn : 27.66216278076172
Train_StdReturn : 16.622419357299805
Train_MaxReturn : 80.0
Train_MinReturn : 6.0
Train_AverageEpLen : 27.66216216216216
Actor Loss : -60.54612731933594
Baseline Loss : 321.6449279785156
Train_EnvstepsSoFar : 10074
TimeSinceStart : 2.9220876693725586

********** Iteration 5 ************
Eval_AverageReturn : 35.5
Eval_StdReturn : 11.17661190032959
Eval_MaxReturn : 57.0
Eval_MinReturn : 17.0
Eval_AverageEpLen : 35.5
Train_AverageReturn : 38.769229888916016
Train_StdReturn : 22.101701736450195
Train_MaxReturn : 113.0
Train_MinReturn : 6.0
Train_AverageEpLen : 38.76923076923077
Actor Loss : -58.222312927246094
Baseline Loss : 613.4826049804688
Train_EnvstepsSoFar : 12090
TimeSinceStart : 3.4824905395507812

********** Iteration 6 ************
Eval_AverageReturn : 48.11111068725586
Eval_StdReturn : 12.077936172485352
Eval_MaxReturn : 64.0
Eval_MinReturn : 25.0
Eval_AverageEpLen : 48.111111111111114
Train_AverageReturn : 43.12765884399414
Train_StdReturn : 16.939964294433594
Train_MaxReturn : 84.0
Train_MinReturn : 16.0
Train_AverageEpLen : 43.12765957446808
Actor Loss : -47.30913162231445
Baseline Loss : 430.1695251464844
Train_EnvstepsSoFar : 14117
TimeSinceStart : 4.11335563659668

********** Iteration 7 ************
Eval_AverageReturn : 51.375
Eval_StdReturn : 13.828751564025879
Eval_MaxReturn : 67.0
Eval_MinReturn : 20.0
Eval_AverageEpLen : 51.375
Train_AverageReturn : 61.14285659790039
Train_StdReturn : 31.814769744873047
Train_MaxReturn : 150.0
Train_MinReturn : 14.0
Train_AverageEpLen : 61.142857142857146
Actor Loss : 22.437170028686523
Baseline Loss : 1455.174072265625
Train_EnvstepsSoFar : 16257
TimeSinceStart : 4.748599052429199

********** Iteration 8 ************
Eval_AverageReturn : 63.85714340209961
Eval_StdReturn : 13.1630277633667
Eval_MaxReturn : 83.0
Eval_MinReturn : 43.0
Eval_AverageEpLen : 63.857142857142854
Train_AverageReturn : 60.14706039428711
Train_StdReturn : 32.22542953491211
Train_MaxReturn : 158.0
Train_MinReturn : 15.0
Train_AverageEpLen : 60.14705882352941
Actor Loss : -68.05816650390625
Baseline Loss : 1388.00244140625
Train_EnvstepsSoFar : 18302
TimeSinceStart : 5.404450178146362

********** Iteration 9 ************
Eval_AverageReturn : 67.5
Eval_StdReturn : 37.712730407714844
Eval_MaxReturn : 125.0
Eval_MinReturn : 34.0
Eval_AverageEpLen : 67.5
Train_AverageReturn : 61.47058868408203
Train_StdReturn : 23.99906349182129
Train_MaxReturn : 119.0
Train_MinReturn : 14.0
Train_AverageEpLen : 61.470588235294116
Actor Loss : -39.89031982421875
Baseline Loss : 850.5792236328125
Train_EnvstepsSoFar : 20392
TimeSinceStart : 6.013618230819702

********** Iteration 10 ************
Eval_AverageReturn : 85.83333587646484
Eval_StdReturn : 54.93455505371094
Eval_MaxReturn : 173.0
Eval_MinReturn : 34.0
Eval_AverageEpLen : 85.83333333333333
Train_AverageReturn : 67.66666412353516
Train_StdReturn : 31.542917251586914
Train_MaxReturn : 167.0
Train_MinReturn : 22.0
Train_AverageEpLen : 67.66666666666667
Actor Loss : -92.60070037841797
Baseline Loss : 1401.6070556640625
Train_EnvstepsSoFar : 22422
TimeSinceStart : 6.65373158454895

********** Iteration 11 ************
Eval_AverageReturn : 80.0
Eval_StdReturn : 46.57252502441406
Eval_MaxReturn : 155.0
Eval_MinReturn : 23.0
Eval_AverageEpLen : 80.0
Train_AverageReturn : 71.92857360839844
Train_StdReturn : 37.55179977416992
Train_MaxReturn : 219.0
Train_MinReturn : 31.0
Train_AverageEpLen : 71.92857142857143
Actor Loss : 7.399858474731445
Baseline Loss : 2100.09716796875
Train_EnvstepsSoFar : 24436
TimeSinceStart : 7.353379249572754

********** Iteration 12 ************
Eval_AverageReturn : 73.16666412353516
Eval_StdReturn : 14.299378395080566
Eval_MaxReturn : 92.0
Eval_MinReturn : 52.0
Eval_AverageEpLen : 73.16666666666667
Train_AverageReturn : 78.38461303710938
Train_StdReturn : 35.75351333618164
Train_MaxReturn : 153.0
Train_MinReturn : 18.0
Train_AverageEpLen : 78.38461538461539
Actor Loss : 7.956142425537109
Baseline Loss : 1647.4169921875
Train_EnvstepsSoFar : 26474
TimeSinceStart : 7.990114212036133

********** Iteration 13 ************
Eval_AverageReturn : 88.66666412353516
Eval_StdReturn : 39.77296829223633
Eval_MaxReturn : 168.0
Eval_MinReturn : 53.0
Eval_AverageEpLen : 88.66666666666667
Train_AverageReturn : 65.87096405029297
Train_StdReturn : 33.547019958496094
Train_MaxReturn : 156.0
Train_MinReturn : 15.0
Train_AverageEpLen : 65.87096774193549
Actor Loss : -48.909549713134766
Baseline Loss : 1251.1793212890625
Train_EnvstepsSoFar : 28516
TimeSinceStart : 8.663105249404907

********** Iteration 14 ************
Eval_AverageReturn : 79.5
Eval_StdReturn : 46.36000442504883
Eval_MaxReturn : 164.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 79.5
Train_AverageReturn : 83.79166412353516
Train_StdReturn : 28.395977020263672
Train_MaxReturn : 151.0
Train_MinReturn : 36.0
Train_AverageEpLen : 83.79166666666667
Actor Loss : -56.084449768066406
Baseline Loss : 1280.9466552734375
Train_EnvstepsSoFar : 30527
TimeSinceStart : 9.2927725315094

********** Iteration 15 ************
Eval_AverageReturn : 78.5
Eval_StdReturn : 30.478134155273438
Eval_MaxReturn : 130.0
Eval_MinReturn : 43.0
Eval_AverageEpLen : 78.5
Train_AverageReturn : 83.08000183105469
Train_StdReturn : 33.09370803833008
Train_MaxReturn : 139.0
Train_MinReturn : 29.0
Train_AverageEpLen : 83.08
Actor Loss : 2.3622331619262695
Baseline Loss : 1343.461669921875
Train_EnvstepsSoFar : 32604
TimeSinceStart : 9.976893186569214

********** Iteration 16 ************
Eval_AverageReturn : 70.83333587646484
Eval_StdReturn : 17.449132919311523
Eval_MaxReturn : 99.0
Eval_MinReturn : 42.0
Eval_AverageEpLen : 70.83333333333333
Train_AverageReturn : 78.26923370361328
Train_StdReturn : 43.077354431152344
Train_MaxReturn : 232.0
Train_MinReturn : 22.0
Train_AverageEpLen : 78.26923076923077
Actor Loss : 24.690643310546875
Baseline Loss : 2197.346923828125
Train_EnvstepsSoFar : 34639
TimeSinceStart : 10.603655099868774

********** Iteration 17 ************
Eval_AverageReturn : 110.5999984741211
Eval_StdReturn : 24.856388092041016
Eval_MaxReturn : 154.0
Eval_MinReturn : 78.0
Eval_AverageEpLen : 110.6
Train_AverageReturn : 87.47826385498047
Train_StdReturn : 37.89329147338867
Train_MaxReturn : 199.0
Train_MinReturn : 32.0
Train_AverageEpLen : 87.47826086956522
Actor Loss : -23.308917999267578
Baseline Loss : 1835.325927734375
Train_EnvstepsSoFar : 36651
TimeSinceStart : 11.251091003417969

********** Iteration 18 ************
Eval_AverageReturn : 109.25
Eval_StdReturn : 35.82160568237305
Eval_MaxReturn : 156.0
Eval_MinReturn : 67.0
Eval_AverageEpLen : 109.25
Train_AverageReturn : 92.45454406738281
Train_StdReturn : 35.246826171875
Train_MaxReturn : 190.0
Train_MinReturn : 36.0
Train_AverageEpLen : 92.45454545454545
Actor Loss : -12.742637634277344
Baseline Loss : 1666.4296875
Train_EnvstepsSoFar : 38685
TimeSinceStart : 11.85468864440918

********** Iteration 19 ************
Eval_AverageReturn : 157.3333282470703
Eval_StdReturn : 21.545818328857422
Eval_MaxReturn : 175.0
Eval_MinReturn : 127.0
Eval_AverageEpLen : 157.33333333333334
Train_AverageReturn : 84.79166412353516
Train_StdReturn : 27.664627075195312
Train_MaxReturn : 168.0
Train_MinReturn : 34.0
Train_AverageEpLen : 84.79166666666667
Actor Loss : -64.65087890625
Baseline Loss : 1047.630126953125
Train_EnvstepsSoFar : 40720
TimeSinceStart : 12.587517023086548

********** Iteration 20 ************
Eval_AverageReturn : 117.19999694824219
Eval_StdReturn : 57.58958435058594
Eval_MaxReturn : 220.0
Eval_MinReturn : 52.0
Eval_AverageEpLen : 117.2
Train_AverageReturn : 127.0625
Train_StdReturn : 45.41677474975586
Train_MaxReturn : 241.0
Train_MinReturn : 69.0
Train_AverageEpLen : 127.0625
Actor Loss : 4.040882110595703
Baseline Loss : 3448.00927734375
Train_EnvstepsSoFar : 42753
TimeSinceStart : 13.285991907119751

********** Iteration 21 ************
Eval_AverageReturn : 122.5
Eval_StdReturn : 8.381526947021484
Eval_MaxReturn : 134.0
Eval_MinReturn : 114.0
Eval_AverageEpLen : 122.5
Train_AverageReturn : 125.875
Train_StdReturn : 57.795841217041016
Train_MaxReturn : 233.0
Train_MinReturn : 50.0
Train_AverageEpLen : 125.875
Actor Loss : 16.260284423828125
Baseline Loss : 4123.00341796875
Train_EnvstepsSoFar : 44767
TimeSinceStart : 13.893051624298096

********** Iteration 22 ************
Eval_AverageReturn : 125.75
Eval_StdReturn : 35.187889099121094
Eval_MaxReturn : 176.0
Eval_MinReturn : 77.0
Eval_AverageEpLen : 125.75
Train_AverageReturn : 122.0
Train_StdReturn : 31.607891082763672
Train_MaxReturn : 184.0
Train_MinReturn : 56.0
Train_AverageEpLen : 122.0
Actor Loss : 1.9504165649414062
Baseline Loss : 2039.9176025390625
Train_EnvstepsSoFar : 46841
TimeSinceStart : 14.560612440109253

********** Iteration 23 ************
Eval_AverageReturn : 153.3333282470703
Eval_StdReturn : 83.44392395019531
Eval_MaxReturn : 259.0
Eval_MinReturn : 55.0
Eval_AverageEpLen : 153.33333333333334
Train_AverageReturn : 127.47058868408203
Train_StdReturn : 61.44353485107422
Train_MaxReturn : 277.0
Train_MinReturn : 39.0
Train_AverageEpLen : 127.47058823529412
Actor Loss : -0.9475839138031006
Baseline Loss : 4448.9326171875
Train_EnvstepsSoFar : 49008
TimeSinceStart : 15.235535144805908

********** Iteration 24 ************
Eval_AverageReturn : 140.25
Eval_StdReturn : 23.66827964782715
Eval_MaxReturn : 178.0
Eval_MinReturn : 114.0
Eval_AverageEpLen : 140.25
Train_AverageReturn : 125.83333587646484
Train_StdReturn : 79.65707397460938
Train_MaxReturn : 414.0
Train_MinReturn : 39.0
Train_AverageEpLen : 125.83333333333333
Actor Loss : -123.08372497558594
Baseline Loss : 8611.263671875
Train_EnvstepsSoFar : 51273
TimeSinceStart : 15.947579860687256

********** Iteration 25 ************
Eval_AverageReturn : 163.3333282470703
Eval_StdReturn : 81.22944641113281
Eval_MaxReturn : 268.0
Eval_MinReturn : 70.0
Eval_AverageEpLen : 163.33333333333334
Train_AverageReturn : 168.0833282470703
Train_StdReturn : 68.99451446533203
Train_MaxReturn : 304.0
Train_MinReturn : 94.0
Train_AverageEpLen : 168.08333333333334
Actor Loss : -23.143465042114258
Baseline Loss : 6917.4765625
Train_EnvstepsSoFar : 53290
TimeSinceStart : 16.571831464767456

********** Iteration 26 ************
Eval_AverageReturn : 406.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 406.0
Eval_MinReturn : 406.0
Eval_AverageEpLen : 406.0
Train_AverageReturn : 170.0
Train_StdReturn : 84.58329010009766
Train_MaxReturn : 376.0
Train_MinReturn : 77.0
Train_AverageEpLen : 170.0
Actor Loss : -57.37456512451172
Baseline Loss : 9358.2294921875
Train_EnvstepsSoFar : 55330
TimeSinceStart : 17.253443956375122

********** Iteration 27 ************
Eval_AverageReturn : 114.5
Eval_StdReturn : 36.89512252807617
Eval_MaxReturn : 170.0
Eval_MinReturn : 68.0
Eval_AverageEpLen : 114.5
Train_AverageReturn : 154.92308044433594
Train_StdReturn : 43.0964241027832
Train_MaxReturn : 247.0
Train_MinReturn : 100.0
Train_AverageEpLen : 154.92307692307693
Actor Loss : -18.107650756835938
Baseline Loss : 3521.998046875
Train_EnvstepsSoFar : 57344
TimeSinceStart : 17.904296159744263

********** Iteration 28 ************
Eval_AverageReturn : 151.75
Eval_StdReturn : 81.65897369384766
Eval_MaxReturn : 271.0
Eval_MinReturn : 48.0
Eval_AverageEpLen : 151.75
Train_AverageReturn : 131.0625
Train_StdReturn : 45.37547302246094
Train_MaxReturn : 233.0
Train_MinReturn : 73.0
Train_AverageEpLen : 131.0625
Actor Loss : -56.0651969909668
Baseline Loss : 2715.452392578125
Train_EnvstepsSoFar : 59441
TimeSinceStart : 18.584470987319946

********** Iteration 29 ************
Eval_AverageReturn : 110.75
Eval_StdReturn : 26.498821258544922
Eval_MaxReturn : 151.0
Eval_MinReturn : 79.0
Eval_AverageEpLen : 110.75
Train_AverageReturn : 118.52941131591797
Train_StdReturn : 29.593555450439453
Train_MaxReturn : 192.0
Train_MinReturn : 62.0
Train_AverageEpLen : 118.52941176470588
Actor Loss : 43.85093688964844
Baseline Loss : 1638.7730712890625
Train_EnvstepsSoFar : 61456
TimeSinceStart : 19.335530042648315

********** Iteration 30 ************
Eval_AverageReturn : 304.0
Eval_StdReturn : 5.0
Eval_MaxReturn : 309.0
Eval_MinReturn : 299.0
Eval_AverageEpLen : 304.0
Train_AverageReturn : 143.92857360839844
Train_StdReturn : 38.06285095214844
Train_MaxReturn : 213.0
Train_MinReturn : 66.0
Train_AverageEpLen : 143.92857142857142
Actor Loss : -39.66371154785156
Baseline Loss : 2553.77880859375
Train_EnvstepsSoFar : 63471
TimeSinceStart : 20.024750471115112

********** Iteration 31 ************
Eval_AverageReturn : 136.5
Eval_StdReturn : 40.74616622924805
Eval_MaxReturn : 174.0
Eval_MinReturn : 70.0
Eval_AverageEpLen : 136.5
Train_AverageReturn : 170.53846740722656
Train_StdReturn : 79.5019302368164
Train_MaxReturn : 411.0
Train_MinReturn : 85.0
Train_AverageEpLen : 170.53846153846155
Actor Loss : -10.79137134552002
Baseline Loss : 8636.0419921875
Train_EnvstepsSoFar : 65688
TimeSinceStart : 20.68328309059143

********** Iteration 32 ************
Eval_AverageReturn : 155.5
Eval_StdReturn : 82.85379028320312
Eval_MaxReturn : 268.0
Eval_MinReturn : 76.0
Eval_AverageEpLen : 155.5
Train_AverageReturn : 156.61538696289062
Train_StdReturn : 63.93691635131836
Train_MaxReturn : 289.0
Train_MinReturn : 35.0
Train_AverageEpLen : 156.6153846153846
Actor Loss : -30.960006713867188
Baseline Loss : 4469.267578125
Train_EnvstepsSoFar : 67724
TimeSinceStart : 21.31116771697998

********** Iteration 33 ************
Eval_AverageReturn : 154.5
Eval_StdReturn : 73.69701385498047
Eval_MaxReturn : 250.0
Eval_MinReturn : 51.0
Eval_AverageEpLen : 154.5
Train_AverageReturn : 207.1999969482422
Train_StdReturn : 71.99833679199219
Train_MaxReturn : 317.0
Train_MinReturn : 63.0
Train_AverageEpLen : 207.2
Actor Loss : -4.863569259643555
Baseline Loss : 7684.7373046875
Train_EnvstepsSoFar : 69796
TimeSinceStart : 22.040406703948975

********** Iteration 34 ************
Eval_AverageReturn : 170.3333282470703
Eval_StdReturn : 21.20272445678711
Eval_MaxReturn : 193.0
Eval_MinReturn : 142.0
Eval_AverageEpLen : 170.33333333333334
Train_AverageReturn : 171.6666717529297
Train_StdReturn : 66.67874908447266
Train_MaxReturn : 325.0
Train_MinReturn : 84.0
Train_AverageEpLen : 171.66666666666666
Actor Loss : -72.3215103149414
Baseline Loss : 5328.37890625
Train_EnvstepsSoFar : 71856
TimeSinceStart : 22.79818868637085

********** Iteration 35 ************
Eval_AverageReturn : 163.3333282470703
Eval_StdReturn : 29.00957489013672
Eval_MaxReturn : 198.0
Eval_MinReturn : 127.0
Eval_AverageEpLen : 163.33333333333334
Train_AverageReturn : 159.23077392578125
Train_StdReturn : 73.84615325927734
Train_MaxReturn : 283.0
Train_MinReturn : 32.0
Train_AverageEpLen : 159.23076923076923
Actor Loss : 43.850555419921875
Baseline Loss : 4488.77490234375
Train_EnvstepsSoFar : 73926
TimeSinceStart : 23.469308376312256

********** Iteration 36 ************
Eval_AverageReturn : 160.0
Eval_StdReturn : 37.665191650390625
Eval_MaxReturn : 196.0
Eval_MinReturn : 108.0
Eval_AverageEpLen : 160.0
Train_AverageReturn : 205.10000610351562
Train_StdReturn : 102.00142669677734
Train_MaxReturn : 459.0
Train_MinReturn : 46.0
Train_AverageEpLen : 205.1
Actor Loss : -19.166841506958008
Baseline Loss : 12558.857421875
Train_EnvstepsSoFar : 75977
TimeSinceStart : 24.088553428649902

********** Iteration 37 ************
Eval_AverageReturn : 214.0
Eval_StdReturn : 108.0
Eval_MaxReturn : 322.0
Eval_MinReturn : 106.0
Eval_AverageEpLen : 214.0
Train_AverageReturn : 264.625
Train_StdReturn : 117.62433624267578
Train_MaxReturn : 472.0
Train_MinReturn : 132.0
Train_AverageEpLen : 264.625
Actor Loss : 7.463618278503418
Baseline Loss : 19498.447265625
Train_EnvstepsSoFar : 78094
TimeSinceStart : 24.69704532623291

********** Iteration 38 ************
Eval_AverageReturn : 233.5
Eval_StdReturn : 5.5
Eval_MaxReturn : 239.0
Eval_MinReturn : 228.0
Eval_AverageEpLen : 233.5
Train_AverageReturn : 286.4285583496094
Train_StdReturn : 155.0786590576172
Train_MaxReturn : 580.0
Train_MinReturn : 81.0
Train_AverageEpLen : 286.42857142857144
Actor Loss : -50.158512115478516
Baseline Loss : 30120.197265625
Train_EnvstepsSoFar : 80099
TimeSinceStart : 25.339277267456055

********** Iteration 39 ************
Eval_AverageReturn : 155.6666717529297
Eval_StdReturn : 52.55050277709961
Eval_MaxReturn : 201.0
Eval_MinReturn : 82.0
Eval_AverageEpLen : 155.66666666666666
Train_AverageReturn : 280.125
Train_StdReturn : 102.74292755126953
Train_MaxReturn : 495.0
Train_MinReturn : 149.0
Train_AverageEpLen : 280.125
Actor Loss : -73.1824951171875
Baseline Loss : 17913.447265625
Train_EnvstepsSoFar : 82340
TimeSinceStart : 26.03264856338501

********** Iteration 40 ************
Eval_AverageReturn : 269.0
Eval_StdReturn : 50.0
Eval_MaxReturn : 319.0
Eval_MinReturn : 219.0
Eval_AverageEpLen : 269.0
Train_AverageReturn : 251.5
Train_StdReturn : 89.81787109375
Train_MaxReturn : 436.0
Train_MinReturn : 155.0
Train_AverageEpLen : 251.5
Actor Loss : -43.116943359375
Baseline Loss : 12780.0556640625
Train_EnvstepsSoFar : 84352
TimeSinceStart : 26.65774440765381

********** Iteration 41 ************
Eval_AverageReturn : 215.0
Eval_StdReturn : 105.93394470214844
Eval_MaxReturn : 303.0
Eval_MinReturn : 66.0
Eval_AverageEpLen : 215.0
Train_AverageReturn : 224.39999389648438
Train_StdReturn : 78.40689086914062
Train_MaxReturn : 324.0
Train_MinReturn : 64.0
Train_AverageEpLen : 224.4
Actor Loss : -54.83045959472656
Baseline Loss : 7923.140625
Train_EnvstepsSoFar : 86596
TimeSinceStart : 27.449265480041504

********** Iteration 42 ************
Eval_AverageReturn : 382.5
Eval_StdReturn : 5.5
Eval_MaxReturn : 388.0
Eval_MinReturn : 377.0
Eval_AverageEpLen : 382.5
Train_AverageReturn : 210.6999969482422
Train_StdReturn : 84.01910400390625
Train_MaxReturn : 359.0
Train_MinReturn : 78.0
Train_AverageEpLen : 210.7
Actor Loss : -85.06013488769531
Baseline Loss : 8000.5517578125
Train_EnvstepsSoFar : 88703
TimeSinceStart : 28.226105213165283

********** Iteration 43 ************
Eval_AverageReturn : 227.5
Eval_StdReturn : 168.5
Eval_MaxReturn : 396.0
Eval_MinReturn : 59.0
Eval_AverageEpLen : 227.5
Train_AverageReturn : 296.28570556640625
Train_StdReturn : 138.7224578857422
Train_MaxReturn : 537.0
Train_MinReturn : 121.0
Train_AverageEpLen : 296.2857142857143
Actor Loss : -30.523468017578125
Baseline Loss : 24356.359375
Train_EnvstepsSoFar : 90777
TimeSinceStart : 28.848287105560303

********** Iteration 44 ************
Eval_AverageReturn : 587.0
Eval_StdReturn : 413.0
Eval_MaxReturn : 1000.0
Eval_MinReturn : 174.0
Eval_AverageEpLen : 587.0
Train_AverageReturn : 717.6666870117188
Train_StdReturn : 290.5240478515625
Train_MaxReturn : 1000.0
Train_MinReturn : 318.0
Train_AverageEpLen : 717.6666666666666
Actor Loss : 9.08484935760498
Baseline Loss : 177409.90625
Train_EnvstepsSoFar : 92930
TimeSinceStart : 29.77269196510315

********** Iteration 45 ************
Eval_AverageReturn : 518.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 518.0
Eval_MinReturn : 518.0
Eval_AverageEpLen : 518.0
Train_AverageReturn : 600.5
Train_StdReturn : 377.4827880859375
Train_MaxReturn : 1000.0
Train_MinReturn : 50.0
Train_AverageEpLen : 600.5
Actor Loss : -75.59397888183594
Baseline Loss : 176095.65625
Train_EnvstepsSoFar : 95332
TimeSinceStart : 30.45476007461548

********** Iteration 46 ************
Eval_AverageReturn : 427.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 427.0
Eval_MinReturn : 427.0
Eval_AverageEpLen : 427.0
Train_AverageReturn : 690.3333129882812
Train_StdReturn : 437.934814453125
Train_MaxReturn : 1000.0
Train_MinReturn : 71.0
Train_AverageEpLen : 690.3333333333334
Actor Loss : 66.87751007080078
Baseline Loss : 229633.71875
Train_EnvstepsSoFar : 97403
TimeSinceStart : 31.126131772994995

********** Iteration 47 ************
Eval_AverageReturn : 585.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 585.0
Eval_MinReturn : 585.0
Eval_AverageEpLen : 585.0
Train_AverageReturn : 908.3333129882812
Train_StdReturn : 129.63624572753906
Train_MaxReturn : 1000.0
Train_MinReturn : 725.0
Train_AverageEpLen : 908.3333333333334
Actor Loss : 37.683815002441406
Baseline Loss : 199995.96875
Train_EnvstepsSoFar : 100128
TimeSinceStart : 31.953217267990112

********** Iteration 48 ************
Eval_AverageReturn : 1000.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 1000.0
Eval_MinReturn : 1000.0
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 825.3333129882812
Train_StdReturn : 247.01597595214844
Train_MaxReturn : 1000.0
Train_MinReturn : 476.0
Train_AverageEpLen : 825.3333333333334
Actor Loss : -60.24720764160156
Baseline Loss : 192504.203125
Train_EnvstepsSoFar : 102604
TimeSinceStart : 32.81826066970825

********** Iteration 49 ************
Eval_AverageReturn : 695.5
Eval_StdReturn : 304.5
Eval_MaxReturn : 1000.0
Eval_MinReturn : 391.0
Eval_AverageEpLen : 695.5
Train_AverageReturn : 1000.0
Train_StdReturn : 0.0
Train_MaxReturn : 1000.0
Train_MinReturn : 1000.0
Train_AverageEpLen : 1000.0
Actor Loss : 42.772926330566406
Baseline Loss : 226983.5
Train_EnvstepsSoFar : 104604
TimeSinceStart : 33.66493058204651

********** Iteration 50 ************
Eval_AverageReturn : 1000.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 1000.0
Eval_MinReturn : 1000.0
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 827.0
Train_StdReturn : 244.65895080566406
Train_MaxReturn : 1000.0
Train_MinReturn : 481.0
Train_AverageEpLen : 827.0
Actor Loss : 1.0455913543701172
Baseline Loss : 186732.078125
Train_EnvstepsSoFar : 107085
TimeSinceStart : 34.538328409194946

********** Iteration 51 ************
Eval_AverageReturn : 752.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 752.0
Eval_MinReturn : 752.0
Eval_AverageEpLen : 752.0
Train_AverageReturn : 1000.0
Train_StdReturn : 0.0
Train_MaxReturn : 1000.0
Train_MinReturn : 1000.0
Train_AverageEpLen : 1000.0
Actor Loss : 17.974075317382812
Baseline Loss : 220848.53125
Train_EnvstepsSoFar : 109085
TimeSinceStart : 35.25765013694763

********** Iteration 52 ************
Eval_AverageReturn : 716.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 716.0
Eval_MinReturn : 716.0
Eval_AverageEpLen : 716.0
Train_AverageReturn : 811.6666870117188
Train_StdReturn : 137.021484375
Train_MaxReturn : 1000.0
Train_MinReturn : 678.0
Train_AverageEpLen : 811.6666666666666
Actor Loss : -7.661532402038574
Baseline Loss : 145587.359375
Train_EnvstepsSoFar : 111520
TimeSinceStart : 36.083141565322876

********** Iteration 53 ************
Eval_AverageReturn : 894.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 894.0
Eval_MinReturn : 894.0
Eval_AverageEpLen : 894.0
Train_AverageReturn : 795.6666870117188
Train_StdReturn : 188.62013244628906
Train_MaxReturn : 1000.0
Train_MinReturn : 545.0
Train_AverageEpLen : 795.6666666666666
Actor Loss : 4.420131206512451
Baseline Loss : 149502.609375
Train_EnvstepsSoFar : 113907
TimeSinceStart : 36.85592722892761

********** Iteration 54 ************
Eval_AverageReturn : 1000.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 1000.0
Eval_MinReturn : 1000.0
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 699.3333129882812
Train_StdReturn : 354.87493896484375
Train_MaxReturn : 1000.0
Train_MinReturn : 201.0
Train_AverageEpLen : 699.3333333333334
Actor Loss : -8.893058776855469
Baseline Loss : 171538.859375
Train_EnvstepsSoFar : 116005
TimeSinceStart : 37.61440134048462

********** Iteration 55 ************
Eval_AverageReturn : 1000.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 1000.0
Eval_MinReturn : 1000.0
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 1000.0
Train_StdReturn : 0.0
Train_MaxReturn : 1000.0
Train_MinReturn : 1000.0
Train_AverageEpLen : 1000.0
Actor Loss : 9.942955017089844
Baseline Loss : 210960.71875
Train_EnvstepsSoFar : 118005
TimeSinceStart : 38.424708127975464

********** Iteration 56 ************
Eval_AverageReturn : 1000.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 1000.0
Eval_MinReturn : 1000.0
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 1000.0
Train_StdReturn : 0.0
Train_MaxReturn : 1000.0
Train_MinReturn : 1000.0
Train_AverageEpLen : 1000.0
Actor Loss : -0.6203126907348633
Baseline Loss : 208698.59375
Train_EnvstepsSoFar : 120005
TimeSinceStart : 39.13140916824341

********** Iteration 57 ************
Eval_AverageReturn : 1000.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 1000.0
Eval_MinReturn : 1000.0
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 1000.0
Train_StdReturn : 0.0
Train_MaxReturn : 1000.0
Train_MinReturn : 1000.0
Train_AverageEpLen : 1000.0
Actor Loss : 19.92896842956543
Baseline Loss : 206462.5
Train_EnvstepsSoFar : 122005
TimeSinceStart : 39.82922625541687

********** Iteration 58 ************
Eval_AverageReturn : 1000.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 1000.0
Eval_MinReturn : 1000.0
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 1000.0
Train_StdReturn : 0.0
Train_MaxReturn : 1000.0
Train_MinReturn : 1000.0
Train_AverageEpLen : 1000.0
Actor Loss : 16.661518096923828
Baseline Loss : 204276.21875
Train_EnvstepsSoFar : 124005
TimeSinceStart : 40.53492975234985

********** Iteration 59 ************
Eval_AverageReturn : 1000.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 1000.0
Eval_MinReturn : 1000.0
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 1000.0
Train_StdReturn : 0.0
Train_MaxReturn : 1000.0
Train_MinReturn : 1000.0
Train_AverageEpLen : 1000.0
Actor Loss : -45.42832565307617
Baseline Loss : 202153.96875
Train_EnvstepsSoFar : 126005
TimeSinceStart : 41.244951486587524

********** Iteration 60 ************
Eval_AverageReturn : 1000.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 1000.0
Eval_MinReturn : 1000.0
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 1000.0
Train_StdReturn : 0.0
Train_MaxReturn : 1000.0
Train_MinReturn : 1000.0
Train_AverageEpLen : 1000.0
Actor Loss : 47.84197998046875
Baseline Loss : 200100.46875
Train_EnvstepsSoFar : 128005
TimeSinceStart : 41.99192142486572

********** Iteration 61 ************
Eval_AverageReturn : 736.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 736.0
Eval_MinReturn : 736.0
Eval_AverageEpLen : 736.0
Train_AverageReturn : 1000.0
Train_StdReturn : 0.0
Train_MaxReturn : 1000.0
Train_MinReturn : 1000.0
Train_AverageEpLen : 1000.0
Actor Loss : 24.290102005004883
Baseline Loss : 198115.515625
Train_EnvstepsSoFar : 130005
TimeSinceStart : 42.71235132217407

********** Iteration 62 ************
Eval_AverageReturn : 1000.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 1000.0
Eval_MinReturn : 1000.0
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 1000.0
Train_StdReturn : 0.0
Train_MaxReturn : 1000.0
Train_MinReturn : 1000.0
Train_AverageEpLen : 1000.0
Actor Loss : 25.374046325683594
Baseline Loss : 196196.4375
Train_EnvstepsSoFar : 132005
TimeSinceStart : 43.42482304573059

********** Iteration 63 ************
Eval_AverageReturn : 1000.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 1000.0
Eval_MinReturn : 1000.0
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 1000.0
Train_StdReturn : 0.0
Train_MaxReturn : 1000.0
Train_MinReturn : 1000.0
Train_AverageEpLen : 1000.0
Actor Loss : 38.152244567871094
Baseline Loss : 194339.578125
Train_EnvstepsSoFar : 134005
TimeSinceStart : 44.16360950469971

********** Iteration 64 ************
Eval_AverageReturn : 1000.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 1000.0
Eval_MinReturn : 1000.0
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 1000.0
Train_StdReturn : 0.0
Train_MaxReturn : 1000.0
Train_MinReturn : 1000.0
Train_AverageEpLen : 1000.0
Actor Loss : 24.62906265258789
Baseline Loss : 192541.0
Train_EnvstepsSoFar : 136005
TimeSinceStart : 44.98379111289978

********** Iteration 65 ************
Eval_AverageReturn : 1000.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 1000.0
Eval_MinReturn : 1000.0
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 1000.0
Train_StdReturn : 0.0
Train_MaxReturn : 1000.0
Train_MinReturn : 1000.0
Train_AverageEpLen : 1000.0
Actor Loss : -4.2039995193481445
Baseline Loss : 190796.78125
Train_EnvstepsSoFar : 138005
TimeSinceStart : 45.723023414611816

********** Iteration 66 ************
Eval_AverageReturn : 1000.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 1000.0
Eval_MinReturn : 1000.0
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 1000.0
Train_StdReturn : 0.0
Train_MaxReturn : 1000.0
Train_MinReturn : 1000.0
Train_AverageEpLen : 1000.0
Actor Loss : -8.919004440307617
Baseline Loss : 189103.3125
Train_EnvstepsSoFar : 140005
TimeSinceStart : 46.49934363365173

********** Iteration 67 ************
Eval_AverageReturn : 786.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 786.0
Eval_MinReturn : 786.0
Eval_AverageEpLen : 786.0
Train_AverageReturn : 1000.0
Train_StdReturn : 0.0
Train_MaxReturn : 1000.0
Train_MinReturn : 1000.0
Train_AverageEpLen : 1000.0
Actor Loss : 10.981688499450684
Baseline Loss : 187457.171875
Train_EnvstepsSoFar : 142005
TimeSinceStart : 47.33601427078247

********** Iteration 68 ************
Eval_AverageReturn : 1000.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 1000.0
Eval_MinReturn : 1000.0
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 570.5
Train_StdReturn : 239.5772247314453
Train_MaxReturn : 954.0
Train_MinReturn : 323.0
Train_AverageEpLen : 570.5
Actor Loss : 10.089836120605469
Baseline Loss : 82992.25
Train_EnvstepsSoFar : 144287
TimeSinceStart : 48.146155834198

********** Iteration 69 ************
Eval_AverageReturn : 1000.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 1000.0
Eval_MinReturn : 1000.0
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 1000.0
Train_StdReturn : 0.0
Train_MaxReturn : 1000.0
Train_MinReturn : 1000.0
Train_AverageEpLen : 1000.0
Actor Loss : 10.16145133972168
Baseline Loss : 184643.25
Train_EnvstepsSoFar : 146287
TimeSinceStart : 48.910417318344116

********** Iteration 70 ************
Eval_AverageReturn : 381.5
Eval_StdReturn : 155.5
Eval_MaxReturn : 537.0
Eval_MinReturn : 226.0
Eval_AverageEpLen : 381.5
Train_AverageReturn : 1000.0
Train_StdReturn : 0.0
Train_MaxReturn : 1000.0
Train_MinReturn : 1000.0
Train_AverageEpLen : 1000.0
Actor Loss : 89.84571838378906
Baseline Loss : 183247.4375
Train_EnvstepsSoFar : 148287
TimeSinceStart : 49.60360026359558

********** Iteration 71 ************
Eval_AverageReturn : 263.0
Eval_StdReturn : 107.0
Eval_MaxReturn : 370.0
Eval_MinReturn : 156.0
Eval_AverageEpLen : 263.0
Train_AverageReturn : 686.3333129882812
Train_StdReturn : 277.13092041015625
Train_MaxReturn : 1000.0
Train_MinReturn : 326.0
Train_AverageEpLen : 686.3333333333334
Actor Loss : 0.14985275268554688
Baseline Loss : 117143.546875
Train_EnvstepsSoFar : 150346
TimeSinceStart : 50.28230547904968

********** Iteration 72 ************
Eval_AverageReturn : 1000.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 1000.0
Eval_MinReturn : 1000.0
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 552.75
Train_StdReturn : 344.7226257324219
Train_MaxReturn : 1000.0
Train_MinReturn : 135.0
Train_AverageEpLen : 552.75
Actor Loss : -106.1453857421875
Baseline Loss : 113277.203125
Train_EnvstepsSoFar : 152557
TimeSinceStart : 51.115620613098145

********** Iteration 73 ************
Eval_AverageReturn : 1000.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 1000.0
Eval_MinReturn : 1000.0
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 1000.0
Train_StdReturn : 0.0
Train_MaxReturn : 1000.0
Train_MinReturn : 1000.0
Train_AverageEpLen : 1000.0
Actor Loss : -19.04526138305664
Baseline Loss : 179506.15625
Train_EnvstepsSoFar : 154557
TimeSinceStart : 51.9853675365448

********** Iteration 74 ************
Eval_AverageReturn : 1000.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 1000.0
Eval_MinReturn : 1000.0
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 1000.0
Train_StdReturn : 0.0
Train_MaxReturn : 1000.0
Train_MinReturn : 1000.0
Train_AverageEpLen : 1000.0
Actor Loss : -37.93946075439453
Baseline Loss : 178271.9375
Train_EnvstepsSoFar : 156557
TimeSinceStart : 52.73754930496216

********** Iteration 75 ************
Eval_AverageReturn : 768.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 768.0
Eval_MinReturn : 768.0
Eval_AverageEpLen : 768.0
Train_AverageReturn : 1000.0
Train_StdReturn : 0.0
Train_MaxReturn : 1000.0
Train_MinReturn : 1000.0
Train_AverageEpLen : 1000.0
Actor Loss : -34.91610336303711
Baseline Loss : 176983.078125
Train_EnvstepsSoFar : 158557
TimeSinceStart : 53.60950064659119

********** Iteration 76 ************
Eval_AverageReturn : 1000.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 1000.0
Eval_MinReturn : 1000.0
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 1000.0
Train_StdReturn : 0.0
Train_MaxReturn : 1000.0
Train_MinReturn : 1000.0
Train_AverageEpLen : 1000.0
Actor Loss : 39.79227828979492
Baseline Loss : 175673.265625
Train_EnvstepsSoFar : 160557
TimeSinceStart : 54.37916588783264

********** Iteration 77 ************
Eval_AverageReturn : 1000.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 1000.0
Eval_MinReturn : 1000.0
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 1000.0
Train_StdReturn : 0.0
Train_MaxReturn : 1000.0
Train_MinReturn : 1000.0
Train_AverageEpLen : 1000.0
Actor Loss : -9.82767391204834
Baseline Loss : 174360.609375
Train_EnvstepsSoFar : 162557
TimeSinceStart : 55.160295248031616

********** Iteration 78 ************
Eval_AverageReturn : 648.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 648.0
Eval_MinReturn : 648.0
Eval_AverageEpLen : 648.0
Train_AverageReturn : 570.5999755859375
Train_StdReturn : 394.375244140625
Train_MaxReturn : 1000.0
Train_MinReturn : 116.0
Train_AverageEpLen : 570.6
Actor Loss : -57.680259704589844
Baseline Loss : 132296.171875
Train_EnvstepsSoFar : 165410
TimeSinceStart : 56.058674812316895

********** Iteration 79 ************
Eval_AverageReturn : 908.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 908.0
Eval_MinReturn : 908.0
Eval_AverageEpLen : 908.0
Train_AverageReturn : 1000.0
Train_StdReturn : 0.0
Train_MaxReturn : 1000.0
Train_MinReturn : 1000.0
Train_AverageEpLen : 1000.0
Actor Loss : -2.6417388916015625
Baseline Loss : 171898.78125
Train_EnvstepsSoFar : 167410
TimeSinceStart : 56.787015438079834

********** Iteration 80 ************
Eval_AverageReturn : 1000.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 1000.0
Eval_MinReturn : 1000.0
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 719.3333129882812
Train_StdReturn : 217.17018127441406
Train_MaxReturn : 1000.0
Train_MinReturn : 471.0
Train_AverageEpLen : 719.3333333333334
Actor Loss : -39.154319763183594
Baseline Loss : 102047.875
Train_EnvstepsSoFar : 169568
TimeSinceStart : 57.575260162353516

********** Iteration 81 ************
Eval_AverageReturn : 1000.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 1000.0
Eval_MinReturn : 1000.0
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 1000.0
Train_StdReturn : 0.0
Train_MaxReturn : 1000.0
Train_MinReturn : 1000.0
Train_AverageEpLen : 1000.0
Actor Loss : -39.105506896972656
Baseline Loss : 169667.375
Train_EnvstepsSoFar : 171568
TimeSinceStart : 58.322473764419556

********** Iteration 82 ************
Eval_AverageReturn : 1000.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 1000.0
Eval_MinReturn : 1000.0
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 942.6666870117188
Train_StdReturn : 70.74052429199219
Train_MaxReturn : 1000.0
Train_MinReturn : 843.0
Train_AverageEpLen : 942.6666666666666
Actor Loss : -62.769493103027344
Baseline Loss : 147001.78125
Train_EnvstepsSoFar : 174396
TimeSinceStart : 59.35309600830078

********** Iteration 83 ************
Eval_AverageReturn : 1000.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 1000.0
Eval_MinReturn : 1000.0
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 1000.0
Train_StdReturn : 0.0
Train_MaxReturn : 1000.0
Train_MinReturn : 1000.0
Train_AverageEpLen : 1000.0
Actor Loss : 10.483580589294434
Baseline Loss : 167482.0
Train_EnvstepsSoFar : 176396
TimeSinceStart : 60.32221841812134

********** Iteration 84 ************
Eval_AverageReturn : 1000.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 1000.0
Eval_MinReturn : 1000.0
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 825.0
Train_StdReturn : 104.17613220214844
Train_MaxReturn : 907.0
Train_MinReturn : 678.0
Train_AverageEpLen : 825.0
Actor Loss : -21.076385498046875
Baseline Loss : 104458.6796875
Train_EnvstepsSoFar : 178871
TimeSinceStart : 61.19847369194031

********** Iteration 85 ************
Eval_AverageReturn : 1000.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 1000.0
Eval_MinReturn : 1000.0
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 885.3333129882812
Train_StdReturn : 162.1631622314453
Train_MaxReturn : 1000.0
Train_MinReturn : 656.0
Train_AverageEpLen : 885.3333333333334
Actor Loss : -65.47579956054688
Baseline Loss : 136635.40625
Train_EnvstepsSoFar : 181527
TimeSinceStart : 62.135338306427

********** Iteration 86 ************
Eval_AverageReturn : 1000.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 1000.0
Eval_MinReturn : 1000.0
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 1000.0
Train_StdReturn : 0.0
Train_MaxReturn : 1000.0
Train_MinReturn : 1000.0
Train_AverageEpLen : 1000.0
Actor Loss : -23.959957122802734
Baseline Loss : 164302.828125
Train_EnvstepsSoFar : 183527
TimeSinceStart : 62.88201403617859

********** Iteration 87 ************
Eval_AverageReturn : 1000.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 1000.0
Eval_MinReturn : 1000.0
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 1000.0
Train_StdReturn : 0.0
Train_MaxReturn : 1000.0
Train_MinReturn : 1000.0
Train_AverageEpLen : 1000.0
Actor Loss : -17.611557006835938
Baseline Loss : 163249.5
Train_EnvstepsSoFar : 185527
TimeSinceStart : 63.61337399482727

********** Iteration 88 ************
Eval_AverageReturn : 1000.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 1000.0
Eval_MinReturn : 1000.0
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 1000.0
Train_StdReturn : 0.0
Train_MaxReturn : 1000.0
Train_MinReturn : 1000.0
Train_AverageEpLen : 1000.0
Actor Loss : -62.97624969482422
Baseline Loss : 162172.09375
Train_EnvstepsSoFar : 187527
TimeSinceStart : 64.57962369918823

********** Iteration 89 ************
Eval_AverageReturn : 1000.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 1000.0
Eval_MinReturn : 1000.0
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 1000.0
Train_StdReturn : 0.0
Train_MaxReturn : 1000.0
Train_MinReturn : 1000.0
Train_AverageEpLen : 1000.0
Actor Loss : -49.91072082519531
Baseline Loss : 161088.421875
Train_EnvstepsSoFar : 189527
TimeSinceStart : 65.34843420982361

********** Iteration 90 ************
Eval_AverageReturn : 1000.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 1000.0
Eval_MinReturn : 1000.0
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 1000.0
Train_StdReturn : 0.0
Train_MaxReturn : 1000.0
Train_MinReturn : 1000.0
Train_AverageEpLen : 1000.0
Actor Loss : 15.865154266357422
Baseline Loss : 160008.671875
Train_EnvstepsSoFar : 191527
TimeSinceStart : 66.22504711151123

********** Iteration 91 ************
Eval_AverageReturn : 1000.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 1000.0
Eval_MinReturn : 1000.0
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 1000.0
Train_StdReturn : 0.0
Train_MaxReturn : 1000.0
Train_MinReturn : 1000.0
Train_AverageEpLen : 1000.0
Actor Loss : 1.5873088836669922
Baseline Loss : 158938.59375
Train_EnvstepsSoFar : 193527
TimeSinceStart : 67.09085249900818

********** Iteration 92 ************
Eval_AverageReturn : 1000.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 1000.0
Eval_MinReturn : 1000.0
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 1000.0
Train_StdReturn : 0.0
Train_MaxReturn : 1000.0
Train_MinReturn : 1000.0
Train_AverageEpLen : 1000.0
Actor Loss : 5.849145889282227
Baseline Loss : 157881.421875
Train_EnvstepsSoFar : 195527
TimeSinceStart : 67.79107999801636

********** Iteration 93 ************
Eval_AverageReturn : 296.0
Eval_StdReturn : 111.0
Eval_MaxReturn : 407.0
Eval_MinReturn : 185.0
Eval_AverageEpLen : 296.0
Train_AverageReturn : 514.5
Train_StdReturn : 303.4579772949219
Train_MaxReturn : 1000.0
Train_MinReturn : 166.0
Train_AverageEpLen : 514.5
Actor Loss : -31.244556427001953
Baseline Loss : 85258.796875
Train_EnvstepsSoFar : 197585
TimeSinceStart : 68.44395208358765

********** Iteration 94 ************
Eval_AverageReturn : 693.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 693.0
Eval_MinReturn : 693.0
Eval_AverageEpLen : 693.0
Train_AverageReturn : 319.71429443359375
Train_StdReturn : 116.12889099121094
Train_MaxReturn : 488.0
Train_MinReturn : 134.0
Train_AverageEpLen : 319.7142857142857
Actor Loss : 4.986769676208496
Baseline Loss : 16249.0439453125
Train_EnvstepsSoFar : 199823
TimeSinceStart : 69.14605522155762

********** Iteration 95 ************
Eval_AverageReturn : 1000.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 1000.0
Eval_MinReturn : 1000.0
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 501.20001220703125
Train_StdReturn : 244.70176696777344
Train_MaxReturn : 829.0
Train_MinReturn : 181.0
Train_AverageEpLen : 501.2
Actor Loss : -78.97673034667969
Baseline Loss : 53128.84375
Train_EnvstepsSoFar : 202329
TimeSinceStart : 70.03304195404053

********** Iteration 96 ************
Eval_AverageReturn : 1000.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 1000.0
Eval_MinReturn : 1000.0
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 933.0
Train_StdReturn : 94.75231170654297
Train_MaxReturn : 1000.0
Train_MinReturn : 799.0
Train_AverageEpLen : 933.0
Actor Loss : 19.10090446472168
Baseline Loss : 133708.15625
Train_EnvstepsSoFar : 205128
TimeSinceStart : 70.92539477348328

********** Iteration 97 ************
Eval_AverageReturn : 1000.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 1000.0
Eval_MinReturn : 1000.0
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 573.75
Train_StdReturn : 355.1783752441406
Train_MaxReturn : 1000.0
Train_MinReturn : 45.0
Train_AverageEpLen : 573.75
Actor Loss : -3.5027503967285156
Baseline Loss : 95942.484375
Train_EnvstepsSoFar : 207423
TimeSinceStart : 71.93592357635498

********** Iteration 98 ************
Eval_AverageReturn : 1000.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 1000.0
Eval_MinReturn : 1000.0
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 705.25
Train_StdReturn : 296.57830810546875
Train_MaxReturn : 1000.0
Train_MinReturn : 364.0
Train_AverageEpLen : 705.25
Actor Loss : 5.978275299072266
Baseline Loss : 113805.4140625
Train_EnvstepsSoFar : 210244
TimeSinceStart : 72.8227379322052

********** Iteration 99 ************
Eval_AverageReturn : 1000.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 1000.0
Eval_MinReturn : 1000.0
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 704.3333129882812
Train_StdReturn : 418.13580322265625
Train_MaxReturn : 1000.0
Train_MinReturn : 113.0
Train_AverageEpLen : 704.3333333333334
Actor Loss : 4.125288963317871
Baseline Loss : 146942.953125
Train_EnvstepsSoFar : 212357
TimeSinceStart : 73.52611899375916

Process finished with exit code 0
