C:\My_Project\ALLEN_Python\homework_fall2023\venv\Scripts\python.exe C:\My_Project\ALLEN_Python\homework_fall2023\hw2\cs285\scripts\run_hw2.py --env_name LunarLander-v2 --ep_len 1000 --discount 0.99 -n 300 -l 3 -s 128 -b 2000 -lr 0.001 --use_reward_to_go --use_baseline --gae_lambda 0.95 --exp_name lunar_lander_lambda0_95
########################
logging outputs to  C:\My_Project\ALLEN_Python\homework_fall2023\hw2\cs285\scripts\../../data\q2_pg_lunar_lander_lambda0_95_LunarLander-v2_25-09-2023_22-13-08
########################
Using CPU.
C:\My_Project\ALLEN_Python\homework_fall2023\venv\lib\site-packages\gym\core.py:317: DeprecationWarning: WARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.
  deprecation(
C:\My_Project\ALLEN_Python\homework_fall2023\venv\lib\site-packages\gym\wrappers\step_api_compatibility.py:39: DeprecationWarning: WARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.
  deprecation(
C:\My_Project\ALLEN_Python\homework_fall2023\venv\lib\site-packages\gym\utils\passive_env_checker.py:241: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):

********** Iteration 0 ************
C:\My_Project\ALLEN_Python\homework_fall2023\venv\lib\site-packages\tensorboardX\summary.py:153: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)
  scalar = float(scalar)
Eval_AverageReturn : -116.85432434082031
Eval_StdReturn : 32.82181930541992
Eval_MaxReturn : -90.94070434570312
Eval_MinReturn : -180.47720336914062
Eval_AverageEpLen : 93.4
Train_AverageReturn : -227.00376892089844
Train_StdReturn : 114.91324615478516
Train_MaxReturn : -87.97223663330078
Train_MinReturn : -450.1386413574219
Train_AverageEpLen : 95.42857142857143
Actor Loss : -103483.46875
Baseline Loss : 17014.5078125
Train_EnvstepsSoFar : 2004
TimeSinceStart : 1.231848955154419
Initial_DataCollection_AverageReturn : -227.00376892089844

********** Iteration 1 ************
Eval_AverageReturn : -160.7622833251953
Eval_StdReturn : 98.70277404785156
Eval_MaxReturn : -82.19722747802734
Eval_MinReturn : -348.2453918457031
Eval_AverageEpLen : 84.8
Train_AverageReturn : -114.13299560546875
Train_StdReturn : 60.174564361572266
Train_MaxReturn : -25.93621826171875
Train_MinReturn : -276.85321044921875
Train_AverageEpLen : 92.47826086956522
Actor Loss : -49414.734375
Baseline Loss : 4472.83447265625
Train_EnvstepsSoFar : 4131
TimeSinceStart : 2.566600799560547

********** Iteration 2 ************
Eval_AverageReturn : -89.51429748535156
Eval_StdReturn : 39.79632568359375
Eval_MaxReturn : -32.81222915649414
Eval_MinReturn : -142.19210815429688
Eval_AverageEpLen : 96.4
Train_AverageReturn : -148.98843383789062
Train_StdReturn : 98.53987884521484
Train_MaxReturn : -10.163711547851562
Train_MinReturn : -377.48382568359375
Train_AverageEpLen : 90.6086956521739
Actor Loss : -66220.3046875
Baseline Loss : 8632.673828125
Train_EnvstepsSoFar : 6215
TimeSinceStart : 3.9041428565979004

********** Iteration 3 ************
Eval_AverageReturn : -197.3852081298828
Eval_StdReturn : 68.93533325195312
Eval_MaxReturn : -113.20375061035156
Eval_MinReturn : -314.9114685058594
Eval_AverageEpLen : 94.0
Train_AverageReturn : -174.8396453857422
Train_StdReturn : 91.57037353515625
Train_MaxReturn : -25.363418579101562
Train_MinReturn : -361.24835205078125
Train_AverageEpLen : 91.04545454545455
Actor Loss : -70485.0
Baseline Loss : 8679.7353515625
Train_EnvstepsSoFar : 8218
TimeSinceStart : 5.302865505218506

********** Iteration 4 ************
Eval_AverageReturn : -232.36685180664062
Eval_StdReturn : 99.3661117553711
Eval_MaxReturn : -97.25326538085938
Eval_MinReturn : -333.6014404296875
Eval_AverageEpLen : 115.5
Train_AverageReturn : -151.27993774414062
Train_StdReturn : 71.96853637695312
Train_MaxReturn : -67.31748962402344
Train_MinReturn : -358.85302734375
Train_AverageEpLen : 96.52380952380952
Actor Loss : -53866.4296875
Baseline Loss : 5635.0673828125
Train_EnvstepsSoFar : 10245
TimeSinceStart : 6.612526893615723

********** Iteration 5 ************
Eval_AverageReturn : 79.56695556640625
Eval_StdReturn : 0.0
Eval_MaxReturn : 79.56695556640625
Eval_MinReturn : 79.56695556640625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -142.47132873535156
Train_StdReturn : 63.701515197753906
Train_MaxReturn : -49.41391372680664
Train_MinReturn : -292.4786682128906
Train_AverageEpLen : 101.2
Actor Loss : -42758.1796875
Baseline Loss : 3452.268798828125
Train_EnvstepsSoFar : 12269
TimeSinceStart : 9.126564741134644

********** Iteration 6 ************
Eval_AverageReturn : -206.16452026367188
Eval_StdReturn : 64.86405181884766
Eval_MaxReturn : -122.62773132324219
Eval_MinReturn : -300.56182861328125
Eval_AverageEpLen : 109.5
Train_AverageReturn : -142.25698852539062
Train_StdReturn : 63.22209548950195
Train_MaxReturn : -62.61945724487305
Train_MinReturn : -307.1531677246094
Train_AverageEpLen : 106.78947368421052
Actor Loss : -39000.1875
Baseline Loss : 4125.13330078125
Train_EnvstepsSoFar : 14298
TimeSinceStart : 10.783944129943848

********** Iteration 7 ************
Eval_AverageReturn : -197.26846313476562
Eval_StdReturn : 95.50450134277344
Eval_MaxReturn : -75.67926025390625
Eval_MinReturn : -292.5731506347656
Eval_AverageEpLen : 120.75
Train_AverageReturn : -98.85565948486328
Train_StdReturn : 53.66121292114258
Train_MaxReturn : -34.420745849609375
Train_MinReturn : -247.4792022705078
Train_AverageEpLen : 106.15789473684211
Actor Loss : -19460.740234375
Baseline Loss : 2041.797607421875
Train_EnvstepsSoFar : 16315
TimeSinceStart : 13.13316297531128

********** Iteration 8 ************
Eval_AverageReturn : -286.053466796875
Eval_StdReturn : 156.18177795410156
Eval_MaxReturn : -114.12654113769531
Eval_MinReturn : -536.949462890625
Eval_AverageEpLen : 142.75
Train_AverageReturn : -187.1231689453125
Train_StdReturn : 95.26297760009766
Train_MaxReturn : -37.39678192138672
Train_MinReturn : -377.6257019042969
Train_AverageEpLen : 112.84210526315789
Actor Loss : -51556.53515625
Baseline Loss : 6738.8916015625
Train_EnvstepsSoFar : 18459
TimeSinceStart : 15.76374888420105

********** Iteration 9 ************
Eval_AverageReturn : -244.09898376464844
Eval_StdReturn : 226.140380859375
Eval_MaxReturn : -48.162109375
Eval_MinReturn : -619.96630859375
Eval_AverageEpLen : 124.25
Train_AverageReturn : -130.47500610351562
Train_StdReturn : 133.06561279296875
Train_MaxReturn : -21.75452423095703
Train_MinReturn : -648.3967895507812
Train_AverageEpLen : 120.22222222222223
Actor Loss : -25845.0390625
Baseline Loss : 6898.06103515625
Train_EnvstepsSoFar : 20623
TimeSinceStart : 18.270730018615723

********** Iteration 10 ************
Eval_AverageReturn : -65.40037536621094
Eval_StdReturn : 46.60263442993164
Eval_MaxReturn : -2.5101318359375
Eval_MinReturn : -124.07119750976562
Eval_AverageEpLen : 106.5
Train_AverageReturn : -194.9058837890625
Train_StdReturn : 115.26853942871094
Train_MaxReturn : -18.974002838134766
Train_MinReturn : -383.26141357421875
Train_AverageEpLen : 128.5625
Actor Loss : -38876.140625
Baseline Loss : 7032.22119140625
Train_EnvstepsSoFar : 22680
TimeSinceStart : 20.569008588790894

********** Iteration 11 ************
Eval_AverageReturn : -170.8675994873047
Eval_StdReturn : 68.71354675292969
Eval_MaxReturn : -86.55856323242188
Eval_MinReturn : -272.6300354003906
Eval_AverageEpLen : 110.5
Train_AverageReturn : -130.49697875976562
Train_StdReturn : 130.395263671875
Train_MaxReturn : 40.6611213684082
Train_MinReturn : -448.3566589355469
Train_AverageEpLen : 232.88888888888889
Actor Loss : -2031.9254150390625
Baseline Loss : 3283.09765625
Train_EnvstepsSoFar : 24776
TimeSinceStart : 23.7962806224823

********** Iteration 12 ************
Eval_AverageReturn : -195.9933319091797
Eval_StdReturn : 38.43172073364258
Eval_MaxReturn : -156.64401245117188
Eval_MinReturn : -248.13673400878906
Eval_AverageEpLen : 163.66666666666666
Train_AverageReturn : -177.83432006835938
Train_StdReturn : 106.79249572753906
Train_MaxReturn : -27.94823455810547
Train_MinReturn : -367.7444763183594
Train_AverageEpLen : 138.33333333333334
Actor Loss : -28867.814453125
Baseline Loss : 4564.0185546875
Train_EnvstepsSoFar : 26851
TimeSinceStart : 26.082838535308838

********** Iteration 13 ************
Eval_AverageReturn : -104.28555297851562
Eval_StdReturn : 83.67975616455078
Eval_MaxReturn : -29.168426513671875
Eval_MinReturn : -221.03701782226562
Eval_AverageEpLen : 179.66666666666666
Train_AverageReturn : -195.39938354492188
Train_StdReturn : 131.69801330566406
Train_MaxReturn : 11.274375915527344
Train_MinReturn : -447.19873046875
Train_AverageEpLen : 131.5
Actor Loss : -32036.0859375
Baseline Loss : 6414.85791015625
Train_EnvstepsSoFar : 28955
TimeSinceStart : 29.57750391960144

********** Iteration 14 ************
Eval_AverageReturn : -122.30477142333984
Eval_StdReturn : 71.509765625
Eval_MaxReturn : -28.697479248046875
Eval_MinReturn : -202.25546264648438
Eval_AverageEpLen : 139.66666666666666
Train_AverageReturn : -228.2337646484375
Train_StdReturn : 131.3651580810547
Train_MaxReturn : 20.60462188720703
Train_MinReturn : -476.5116271972656
Train_AverageEpLen : 188.33333333333334
Actor Loss : -24609.421875
Baseline Loss : 4005.449951171875
Train_EnvstepsSoFar : 31215
TimeSinceStart : 32.6264226436615

********** Iteration 15 ************
Eval_AverageReturn : -58.52614974975586
Eval_StdReturn : 49.45427703857422
Eval_MaxReturn : -9.204275131225586
Eval_MinReturn : -126.13011169433594
Eval_AverageEpLen : 159.66666666666666
Train_AverageReturn : -196.1349334716797
Train_StdReturn : 108.53369903564453
Train_MaxReturn : -21.139999389648438
Train_MinReturn : -372.1544494628906
Train_AverageEpLen : 172.83333333333334
Actor Loss : -16879.046875
Baseline Loss : 3434.572265625
Train_EnvstepsSoFar : 33289
TimeSinceStart : 35.331610918045044

********** Iteration 16 ************
Eval_AverageReturn : -56.702667236328125
Eval_StdReturn : 83.74297332763672
Eval_MaxReturn : 52.02717590332031
Eval_MinReturn : -151.72093200683594
Eval_AverageEpLen : 174.33333333333334
Train_AverageReturn : -164.89024353027344
Train_StdReturn : 91.87699127197266
Train_MaxReturn : -9.815388679504395
Train_MinReturn : -371.72637939453125
Train_AverageEpLen : 157.69230769230768
Actor Loss : -10790.728515625
Baseline Loss : 3142.447021484375
Train_EnvstepsSoFar : 35339
TimeSinceStart : 38.011775970458984

********** Iteration 17 ************
Eval_AverageReturn : -89.3010025024414
Eval_StdReturn : 82.18730926513672
Eval_MaxReturn : 16.3157958984375
Eval_MinReturn : -184.1326141357422
Eval_AverageEpLen : 144.0
Train_AverageReturn : -195.3569793701172
Train_StdReturn : 97.8301773071289
Train_MaxReturn : -37.29661560058594
Train_MinReturn : -342.9963073730469
Train_AverageEpLen : 171.16666666666666
Actor Loss : -14387.3828125
Baseline Loss : 2966.54443359375
Train_EnvstepsSoFar : 37393
TimeSinceStart : 40.554224491119385

********** Iteration 18 ************
Eval_AverageReturn : -80.68440246582031
Eval_StdReturn : 57.05094528198242
Eval_MaxReturn : -21.50737762451172
Eval_MinReturn : -143.46804809570312
Eval_AverageEpLen : 124.0
Train_AverageReturn : -146.80870056152344
Train_StdReturn : 104.74137878417969
Train_MaxReturn : 5.849678039550781
Train_MinReturn : -312.3974609375
Train_AverageEpLen : 135.66666666666666
Actor Loss : -9102.9462890625
Baseline Loss : 2816.9013671875
Train_EnvstepsSoFar : 39428
TimeSinceStart : 43.1105272769928

********** Iteration 19 ************
Eval_AverageReturn : -66.20437622070312
Eval_StdReturn : 49.6540412902832
Eval_MaxReturn : 4.0008392333984375
Eval_MinReturn : -102.61321258544922
Eval_AverageEpLen : 140.33333333333334
Train_AverageReturn : -136.5828857421875
Train_StdReturn : 101.89341735839844
Train_MaxReturn : 26.05370330810547
Train_MinReturn : -318.28662109375
Train_AverageEpLen : 131.0
Actor Loss : -4860.28466796875
Baseline Loss : 2730.25390625
Train_EnvstepsSoFar : 41524
TimeSinceStart : 45.56937575340271

********** Iteration 20 ************
Eval_AverageReturn : -26.931629180908203
Eval_StdReturn : 0.0
Eval_MaxReturn : -26.931629180908203
Eval_MinReturn : -26.931629180908203
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -102.86894226074219
Train_StdReturn : 86.71941375732422
Train_MaxReturn : 22.62769317626953
Train_MinReturn : -307.38165283203125
Train_AverageEpLen : 122.70588235294117
Actor Loss : 4357.3564453125
Baseline Loss : 2306.25048828125
Train_EnvstepsSoFar : 43610
TimeSinceStart : 49.34061336517334

********** Iteration 21 ************
Eval_AverageReturn : -105.00013732910156
Eval_StdReturn : 51.65045166015625
Eval_MaxReturn : -45.91032791137695
Eval_MinReturn : -186.62203979492188
Eval_AverageEpLen : 135.25
Train_AverageReturn : -63.51103591918945
Train_StdReturn : 49.02397918701172
Train_MaxReturn : 27.898117065429688
Train_MinReturn : -150.53750610351562
Train_AverageEpLen : 136.53333333333333
Actor Loss : 16729.439453125
Baseline Loss : 2393.084716796875
Train_EnvstepsSoFar : 45658
TimeSinceStart : 51.919880628585815

********** Iteration 22 ************
Eval_AverageReturn : -125.77843475341797
Eval_StdReturn : 75.91539001464844
Eval_MaxReturn : -32.40472412109375
Eval_MinReturn : -218.3535614013672
Eval_AverageEpLen : 156.0
Train_AverageReturn : -84.83023071289062
Train_StdReturn : 80.24394989013672
Train_MaxReturn : 25.723876953125
Train_MinReturn : -261.6380310058594
Train_AverageEpLen : 139.13333333333333
Actor Loss : 11826.314453125
Baseline Loss : 2619.60400390625
Train_EnvstepsSoFar : 47745
TimeSinceStart : 54.46560263633728

********** Iteration 23 ************
Eval_AverageReturn : -101.05697631835938
Eval_StdReturn : 59.03361129760742
Eval_MaxReturn : -31.239463806152344
Eval_MinReturn : -162.48162841796875
Eval_AverageEpLen : 137.75
Train_AverageReturn : -82.12505340576172
Train_StdReturn : 81.39764404296875
Train_MaxReturn : 65.27782440185547
Train_MinReturn : -193.57064819335938
Train_AverageEpLen : 227.66666666666666
Actor Loss : 15966.376953125
Baseline Loss : 3200.810791015625
Train_EnvstepsSoFar : 49794
TimeSinceStart : 57.839125633239746

********** Iteration 24 ************
Eval_AverageReturn : -98.11339569091797
Eval_StdReturn : 87.29376220703125
Eval_MaxReturn : 3.4790191650390625
Eval_MinReturn : -209.6511688232422
Eval_AverageEpLen : 182.33333333333334
Train_AverageReturn : -43.4916877746582
Train_StdReturn : 38.54658889770508
Train_MaxReturn : 15.279273986816406
Train_MinReturn : -114.47776794433594
Train_AverageEpLen : 144.13333333333333
Actor Loss : 21803.08984375
Baseline Loss : 2583.92431640625
Train_EnvstepsSoFar : 51956
TimeSinceStart : 60.52853846549988

********** Iteration 25 ************
Eval_AverageReturn : -142.4849395751953
Eval_StdReturn : 70.72305297851562
Eval_MaxReturn : -50.49009704589844
Eval_MinReturn : -222.4726104736328
Eval_AverageEpLen : 180.66666666666666
Train_AverageReturn : -66.43282318115234
Train_StdReturn : 90.5860366821289
Train_MaxReturn : 15.661415100097656
Train_MinReturn : -249.50750732421875
Train_AverageEpLen : 183.1818181818182
Actor Loss : 15474.5537109375
Baseline Loss : 2194.97509765625
Train_EnvstepsSoFar : 53971
TimeSinceStart : 63.17198324203491

********** Iteration 26 ************
Eval_AverageReturn : -192.9329071044922
Eval_StdReturn : 94.25157165527344
Eval_MaxReturn : -64.84440612792969
Eval_MinReturn : -288.91522216796875
Eval_AverageEpLen : 219.66666666666666
Train_AverageReturn : -130.8118133544922
Train_StdReturn : 109.72750091552734
Train_MaxReturn : -20.959434509277344
Train_MinReturn : -399.487060546875
Train_AverageEpLen : 221.9090909090909
Actor Loss : 5920.13525390625
Baseline Loss : 3139.06298828125
Train_EnvstepsSoFar : 56412
TimeSinceStart : 66.83613324165344

********** Iteration 27 ************
Eval_AverageReturn : -121.8072738647461
Eval_StdReturn : 48.12621307373047
Eval_MaxReturn : -54.169124603271484
Eval_MinReturn : -162.18455505371094
Eval_AverageEpLen : 157.33333333333334
Train_AverageReturn : -44.2836799621582
Train_StdReturn : 53.67325210571289
Train_MaxReturn : 35.068870544433594
Train_MinReturn : -173.62179565429688
Train_AverageEpLen : 175.5
Actor Loss : 18649.392578125
Baseline Loss : 2154.67431640625
Train_EnvstepsSoFar : 58518
TimeSinceStart : 69.47925329208374

********** Iteration 28 ************
Eval_AverageReturn : -14.678728103637695
Eval_StdReturn : 61.7445068359375
Eval_MaxReturn : 47.06577682495117
Eval_MinReturn : -76.42323303222656
Eval_AverageEpLen : 250.5
Train_AverageReturn : -75.63836669921875
Train_StdReturn : 71.20037078857422
Train_MaxReturn : -3.965555191040039
Train_MinReturn : -249.36398315429688
Train_AverageEpLen : 199.8181818181818
Actor Loss : 10957.255859375
Baseline Loss : 1838.3031005859375
Train_EnvstepsSoFar : 60716
TimeSinceStart : 72.37189531326294

********** Iteration 29 ************
Eval_AverageReturn : -52.44303512573242
Eval_StdReturn : 71.81439971923828
Eval_MaxReturn : -0.1410980224609375
Eval_MinReturn : -153.98858642578125
Eval_AverageEpLen : 145.33333333333334
Train_AverageReturn : -63.76066207885742
Train_StdReturn : 72.81363677978516
Train_MaxReturn : 27.379478454589844
Train_MinReturn : -192.22312927246094
Train_AverageEpLen : 172.33333333333334
Actor Loss : 11164.623046875
Baseline Loss : 1566.9832763671875
Train_EnvstepsSoFar : 62784
TimeSinceStart : 74.98460102081299

********** Iteration 30 ************
Eval_AverageReturn : 12.00281047821045
Eval_StdReturn : 33.54728317260742
Eval_MaxReturn : 45.55009460449219
Eval_MinReturn : -21.54447364807129
Eval_AverageEpLen : 230.0
Train_AverageReturn : -55.4324951171875
Train_StdReturn : 76.98062896728516
Train_MaxReturn : 61.48163986206055
Train_MinReturn : -226.84107971191406
Train_AverageEpLen : 183.54545454545453
Actor Loss : 10089.197265625
Baseline Loss : 2035.8251953125
Train_EnvstepsSoFar : 64803
TimeSinceStart : 77.57731246948242

********** Iteration 31 ************
Eval_AverageReturn : -34.01450729370117
Eval_StdReturn : 63.18843460083008
Eval_MaxReturn : 29.173925399780273
Eval_MinReturn : -97.20294189453125
Eval_AverageEpLen : 201.0
Train_AverageReturn : -48.184017181396484
Train_StdReturn : 71.28038787841797
Train_MaxReturn : 27.961196899414062
Train_MinReturn : -195.39022827148438
Train_AverageEpLen : 216.1
Actor Loss : 10969.7451171875
Baseline Loss : 1497.936279296875
Train_EnvstepsSoFar : 66964
TimeSinceStart : 80.37605571746826

********** Iteration 32 ************
Eval_AverageReturn : -171.16766357421875
Eval_StdReturn : 0.0
Eval_MaxReturn : -171.16766357421875
Eval_MinReturn : -171.16766357421875
Eval_AverageEpLen : 485.0
Train_AverageReturn : -116.6641616821289
Train_StdReturn : 46.729469299316406
Train_MaxReturn : -37.511207580566406
Train_MinReturn : -173.74978637695312
Train_AverageEpLen : 429.1666666666667
Actor Loss : 10608.09765625
Baseline Loss : 1943.742919921875
Train_EnvstepsSoFar : 69539
TimeSinceStart : 84.77080941200256

********** Iteration 33 ************
Eval_AverageReturn : -276.57952880859375
Eval_StdReturn : 0.0
Eval_MaxReturn : -276.57952880859375
Eval_MinReturn : -276.57952880859375
Eval_AverageEpLen : 415.0
Train_AverageReturn : -162.4572296142578
Train_StdReturn : 104.47808837890625
Train_MaxReturn : -30.724288940429688
Train_MinReturn : -323.126220703125
Train_AverageEpLen : 503.5
Actor Loss : 3936.650634765625
Baseline Loss : 2497.386962890625
Train_EnvstepsSoFar : 71553
TimeSinceStart : 89.03948998451233

********** Iteration 34 ************
Eval_AverageReturn : -188.97425842285156
Eval_StdReturn : 0.0
Eval_MaxReturn : -188.97425842285156
Eval_MinReturn : -188.97425842285156
Eval_AverageEpLen : 423.0
Train_AverageReturn : -172.1183624267578
Train_StdReturn : 103.92391204833984
Train_MaxReturn : -34.775146484375
Train_MinReturn : -306.61163330078125
Train_AverageEpLen : 430.8
Actor Loss : 2742.5
Baseline Loss : 1923.5380859375
Train_EnvstepsSoFar : 73707
TimeSinceStart : 92.74744129180908

********** Iteration 35 ************
Eval_AverageReturn : -30.75304412841797
Eval_StdReturn : 0.0
Eval_MaxReturn : -30.75304412841797
Eval_MinReturn : -30.75304412841797
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -24.904794692993164
Train_StdReturn : 43.880863189697266
Train_MaxReturn : 21.76885223388672
Train_MinReturn : -83.66016387939453
Train_AverageEpLen : 749.0
Actor Loss : 15521.380859375
Baseline Loss : 2599.979248046875
Train_EnvstepsSoFar : 75954
TimeSinceStart : 100.03981280326843

********** Iteration 36 ************
Eval_AverageReturn : -198.55943298339844
Eval_StdReturn : 32.59040832519531
Eval_MaxReturn : -165.96902465820312
Eval_MinReturn : -231.14984130859375
Eval_AverageEpLen : 483.0
Train_AverageReturn : -79.36795043945312
Train_StdReturn : 110.81040954589844
Train_MaxReturn : 75.81036376953125
Train_MinReturn : -222.56692504882812
Train_AverageEpLen : 251.625
Actor Loss : 5211.806640625
Baseline Loss : 2388.65283203125
Train_EnvstepsSoFar : 77967
TimeSinceStart : 103.8060040473938

********** Iteration 37 ************
Eval_AverageReturn : -58.86159133911133
Eval_StdReturn : 4.932437896728516
Eval_MaxReturn : -53.92915344238281
Eval_MinReturn : -63.794029235839844
Eval_AverageEpLen : 285.0
Train_AverageReturn : -87.36270141601562
Train_StdReturn : 140.9201202392578
Train_MaxReturn : 36.435691833496094
Train_MinReturn : -311.3594055175781
Train_AverageEpLen : 407.6666666666667
Actor Loss : 9500.3095703125
Baseline Loss : 2117.972412109375
Train_EnvstepsSoFar : 80413
TimeSinceStart : 108.4753770828247

********** Iteration 38 ************
Eval_AverageReturn : 3.3030853271484375
Eval_StdReturn : 0.0
Eval_MaxReturn : 3.3030853271484375
Eval_MinReturn : 3.3030853271484375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -95.94074249267578
Train_StdReturn : 104.7883529663086
Train_MaxReturn : 8.610300064086914
Train_MinReturn : -239.17068481445312
Train_AverageEpLen : 709.6666666666666
Actor Loss : 8866.7412109375
Baseline Loss : 1807.831298828125
Train_EnvstepsSoFar : 82542
TimeSinceStart : 114.6595892906189

********** Iteration 39 ************
Eval_AverageReturn : -126.6509780883789
Eval_StdReturn : 0.0
Eval_MaxReturn : -126.6509780883789
Eval_MinReturn : -126.6509780883789
Eval_AverageEpLen : 503.0
Train_AverageReturn : -89.6333999633789
Train_StdReturn : 117.74529266357422
Train_MaxReturn : 18.54479217529297
Train_MinReturn : -288.5869140625
Train_AverageEpLen : 690.5
Actor Loss : 12091.08203125
Baseline Loss : 2225.7509765625
Train_EnvstepsSoFar : 85304
TimeSinceStart : 120.66476511955261

********** Iteration 40 ************
Eval_AverageReturn : -8.982868194580078
Eval_StdReturn : 6.326175689697266
Eval_MaxReturn : -2.6566925048828125
Eval_MinReturn : -15.309043884277344
Eval_AverageEpLen : 615.0
Train_AverageReturn : -11.746891021728516
Train_StdReturn : 34.855751037597656
Train_MaxReturn : 52.21140670776367
Train_MinReturn : -61.69801330566406
Train_AverageEpLen : 253.625
Actor Loss : 11813.53125
Baseline Loss : 1645.646240234375
Train_EnvstepsSoFar : 87333
TimeSinceStart : 125.4320936203003

********** Iteration 41 ************
Eval_AverageReturn : -36.36273193359375
Eval_StdReturn : 24.131385803222656
Eval_MaxReturn : -18.119247436523438
Eval_MinReturn : -70.46180725097656
Eval_AverageEpLen : 199.0
Train_AverageReturn : -59.91144943237305
Train_StdReturn : 61.88334655761719
Train_MaxReturn : -9.607263565063477
Train_MinReturn : -199.10923767089844
Train_AverageEpLen : 294.42857142857144
Actor Loss : 4304.18359375
Baseline Loss : 1698.737548828125
Train_EnvstepsSoFar : 89394
TimeSinceStart : 128.9792459011078

********** Iteration 42 ************
Eval_AverageReturn : 6.3234543800354
Eval_StdReturn : 4.606517314910889
Eval_MaxReturn : 11.369754791259766
Eval_MinReturn : 0.23223114013671875
Eval_AverageEpLen : 170.0
Train_AverageReturn : 14.557528495788574
Train_StdReturn : 25.63535499572754
Train_MaxReturn : 47.68561553955078
Train_MinReturn : -31.95301628112793
Train_AverageEpLen : 195.27272727272728
Actor Loss : 14657.830078125
Baseline Loss : 1755.778076171875
Train_EnvstepsSoFar : 91542
TimeSinceStart : 132.00828766822815

********** Iteration 43 ************
Eval_AverageReturn : 8.790664672851562
Eval_StdReturn : 0.0
Eval_MaxReturn : 8.790664672851562
Eval_MinReturn : 8.790664672851562
Eval_AverageEpLen : 692.0
Train_AverageReturn : -5.2356486320495605
Train_StdReturn : 24.15919303894043
Train_MaxReturn : 37.861629486083984
Train_MinReturn : -30.179393768310547
Train_AverageEpLen : 464.1666666666667
Actor Loss : 14869.9208984375
Baseline Loss : 1168.5908203125
Train_EnvstepsSoFar : 94327
TimeSinceStart : 139.05654215812683

********** Iteration 44 ************
Eval_AverageReturn : 2.4298629760742188
Eval_StdReturn : 0.0
Eval_MaxReturn : 2.4298629760742188
Eval_MinReturn : 2.4298629760742188
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -9.409613609313965
Train_StdReturn : 20.26430320739746
Train_MaxReturn : 18.670738220214844
Train_MinReturn : -32.58826446533203
Train_AverageEpLen : 468.5
Actor Loss : 12494.5654296875
Baseline Loss : 1306.763427734375
Train_EnvstepsSoFar : 97138
TimeSinceStart : 145.97330474853516

********** Iteration 45 ************
Eval_AverageReturn : -6.2569580078125
Eval_StdReturn : 65.73280334472656
Eval_MaxReturn : 59.47584533691406
Eval_MinReturn : -71.98976135253906
Eval_AverageEpLen : 621.5
Train_AverageReturn : -9.189518928527832
Train_StdReturn : 20.651256561279297
Train_MaxReturn : 27.164207458496094
Train_MinReturn : -41.145042419433594
Train_AverageEpLen : 314.7142857142857
Actor Loss : 8928.79296875
Baseline Loss : 1263.19140625
Train_EnvstepsSoFar : 99341
TimeSinceStart : 151.95739650726318

********** Iteration 46 ************
Eval_AverageReturn : -51.79546356201172
Eval_StdReturn : 22.739850997924805
Eval_MaxReturn : -29.055614471435547
Eval_MinReturn : -74.53531646728516
Eval_AverageEpLen : 665.0
Train_AverageReturn : 6.476701259613037
Train_StdReturn : 35.13688278198242
Train_MaxReturn : 75.66294860839844
Train_MinReturn : -31.5898494720459
Train_AverageEpLen : 374.5
Actor Loss : 9174.26171875
Baseline Loss : 1281.839111328125
Train_EnvstepsSoFar : 101588
TimeSinceStart : 157.9693009853363

********** Iteration 47 ************
Eval_AverageReturn : -71.888916015625
Eval_StdReturn : 22.108722686767578
Eval_MaxReturn : -49.780189514160156
Eval_MinReturn : -93.99763488769531
Eval_AverageEpLen : 335.5
Train_AverageReturn : -0.6718307733535767
Train_StdReturn : 43.59825897216797
Train_MaxReturn : 64.60099029541016
Train_MinReturn : -70.60028076171875
Train_AverageEpLen : 504.4
Actor Loss : 9672.9091796875
Baseline Loss : 1040.19677734375
Train_EnvstepsSoFar : 104110
TimeSinceStart : 164.04558968544006

********** Iteration 48 ************
Eval_AverageReturn : 55.27873992919922
Eval_StdReturn : 42.28715515136719
Eval_MaxReturn : 97.5658950805664
Eval_MinReturn : 12.991580963134766
Eval_AverageEpLen : 593.0
Train_AverageReturn : 19.645748138427734
Train_StdReturn : 39.33464813232422
Train_MaxReturn : 62.5586051940918
Train_MinReturn : -21.31072998046875
Train_AverageEpLen : 663.0
Actor Loss : 9455.5205078125
Baseline Loss : 754.4296264648438
Train_EnvstepsSoFar : 106762
TimeSinceStart : 170.94496035575867

********** Iteration 49 ************
Eval_AverageReturn : -14.67202377319336
Eval_StdReturn : 27.96945571899414
Eval_MaxReturn : 13.297431945800781
Eval_MinReturn : -42.6414794921875
Eval_AverageEpLen : 265.0
Train_AverageReturn : 36.76543426513672
Train_StdReturn : 30.271831512451172
Train_MaxReturn : 79.4404296875
Train_MinReturn : -13.90740966796875
Train_AverageEpLen : 530.2
Actor Loss : 10452.7041015625
Baseline Loss : 1050.383056640625
Train_EnvstepsSoFar : 109413
TimeSinceStart : 176.8539423942566

********** Iteration 50 ************
Eval_AverageReturn : 13.996646881103516
Eval_StdReturn : 33.44109344482422
Eval_MaxReturn : 47.437740325927734
Eval_MinReturn : -19.444446563720703
Eval_AverageEpLen : 309.0
Train_AverageReturn : 4.105535984039307
Train_StdReturn : 47.35976791381836
Train_MaxReturn : 57.23207473754883
Train_MinReturn : -81.1707992553711
Train_AverageEpLen : 575.4
Actor Loss : 8535.13671875
Baseline Loss : 748.5447998046875
Train_EnvstepsSoFar : 112290
TimeSinceStart : 183.42618417739868

********** Iteration 51 ************
Eval_AverageReturn : 41.18444061279297
Eval_StdReturn : 42.92021942138672
Eval_MaxReturn : 84.10466003417969
Eval_MinReturn : -1.73577880859375
Eval_AverageEpLen : 659.5
Train_AverageReturn : 17.17588996887207
Train_StdReturn : 22.91940689086914
Train_MaxReturn : 62.508697509765625
Train_MinReturn : -9.181890487670898
Train_AverageEpLen : 473.3333333333333
Actor Loss : 7107.84716796875
Baseline Loss : 970.9886474609375
Train_EnvstepsSoFar : 115130
TimeSinceStart : 191.01461148262024

********** Iteration 52 ************
Eval_AverageReturn : -89.13658142089844
Eval_StdReturn : 31.775371551513672
Eval_MaxReturn : -57.36121368408203
Eval_MinReturn : -120.91195678710938
Eval_AverageEpLen : 469.5
Train_AverageReturn : -35.764007568359375
Train_StdReturn : 36.07791519165039
Train_MaxReturn : 11.968866348266602
Train_MinReturn : -75.2382583618164
Train_AverageEpLen : 752.6666666666666
Actor Loss : 2271.581298828125
Baseline Loss : 631.2398071289062
Train_EnvstepsSoFar : 117388
TimeSinceStart : 197.2867889404297

********** Iteration 53 ************
Eval_AverageReturn : -1.2666301727294922
Eval_StdReturn : 54.69635009765625
Eval_MaxReturn : 53.42972183227539
Eval_MinReturn : -55.962982177734375
Eval_AverageEpLen : 674.5
Train_AverageReturn : 36.061737060546875
Train_StdReturn : 15.930097579956055
Train_MaxReturn : 51.99183654785156
Train_MinReturn : 20.131641387939453
Train_AverageEpLen : 1000.0
Actor Loss : 4312.8984375
Baseline Loss : 504.8155212402344
Train_EnvstepsSoFar : 119388
TimeSinceStart : 203.71891021728516

********** Iteration 54 ************
Eval_AverageReturn : 127.15335083007812
Eval_StdReturn : 0.0
Eval_MaxReturn : 127.15335083007812
Eval_MinReturn : 127.15335083007812
Eval_AverageEpLen : 824.0
Train_AverageReturn : -91.56021881103516
Train_StdReturn : 88.59351348876953
Train_MaxReturn : 14.210746765136719
Train_MinReturn : -202.60577392578125
Train_AverageEpLen : 811.6666666666666
Actor Loss : 225.6422882080078
Baseline Loss : 592.241455078125
Train_EnvstepsSoFar : 121823
TimeSinceStart : 210.6832685470581

********** Iteration 55 ************
Eval_AverageReturn : -189.157958984375
Eval_StdReturn : 0.0
Eval_MaxReturn : -189.157958984375
Eval_MinReturn : -189.157958984375
Eval_AverageEpLen : 839.0
Train_AverageReturn : -63.78688430786133
Train_StdReturn : 117.6735610961914
Train_MaxReturn : 83.1391830444336
Train_MinReturn : -204.9267120361328
Train_AverageEpLen : 772.3333333333334
Actor Loss : -241.29290771484375
Baseline Loss : 671.6692504882812
Train_EnvstepsSoFar : 124140
TimeSinceStart : 216.53671431541443

********** Iteration 56 ************
Eval_AverageReturn : -198.38475036621094
Eval_StdReturn : 0.0
Eval_MaxReturn : -198.38475036621094
Eval_MinReturn : -198.38475036621094
Eval_AverageEpLen : 987.0
Train_AverageReturn : -267.3512268066406
Train_StdReturn : 246.5870361328125
Train_MaxReturn : 34.99195098876953
Train_MinReturn : -569.0193481445312
Train_AverageEpLen : 859.0
Actor Loss : -9076.2451171875
Baseline Loss : 1681.799560546875
Train_EnvstepsSoFar : 126717
TimeSinceStart : 223.93613862991333

********** Iteration 57 ************
Eval_AverageReturn : 84.59086608886719
Eval_StdReturn : 0.0
Eval_MaxReturn : 84.59086608886719
Eval_MinReturn : 84.59086608886719
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -72.12091827392578
Train_StdReturn : 88.16339111328125
Train_MaxReturn : 52.1497917175293
Train_MinReturn : -143.01805114746094
Train_AverageEpLen : 772.6666666666666
Actor Loss : -1667.055419921875
Baseline Loss : 958.1861572265625
Train_EnvstepsSoFar : 129035
TimeSinceStart : 230.25367617607117

********** Iteration 58 ************
Eval_AverageReturn : -26.232402801513672
Eval_StdReturn : 7.400608062744141
Eval_MaxReturn : -18.83179473876953
Eval_MinReturn : -33.63301086425781
Eval_AverageEpLen : 320.5
Train_AverageReturn : 8.001380920410156
Train_StdReturn : 96.01685333251953
Train_MaxReturn : 158.66220092773438
Train_MinReturn : -91.10559844970703
Train_AverageEpLen : 525.75
Actor Loss : 572.3596801757812
Baseline Loss : 1037.423583984375
Train_EnvstepsSoFar : 131138
TimeSinceStart : 235.1741943359375

********** Iteration 59 ************
Eval_AverageReturn : -22.986175537109375
Eval_StdReturn : 0.0
Eval_MaxReturn : -22.986175537109375
Eval_MinReturn : -22.986175537109375
Eval_AverageEpLen : 458.0
Train_AverageReturn : 13.53021240234375
Train_StdReturn : 67.71641540527344
Train_MaxReturn : 107.43214416503906
Train_MinReturn : -75.1709976196289
Train_AverageEpLen : 710.25
Actor Loss : 3534.552734375
Baseline Loss : 509.67303466796875
Train_EnvstepsSoFar : 133979
TimeSinceStart : 240.88581728935242

********** Iteration 60 ************
Eval_AverageReturn : 129.2034149169922
Eval_StdReturn : 0.0
Eval_MaxReturn : 129.2034149169922
Eval_MinReturn : 129.2034149169922
Eval_AverageEpLen : 604.0
Train_AverageReturn : 38.450706481933594
Train_StdReturn : 75.70571899414062
Train_MaxReturn : 153.85414123535156
Train_MinReturn : -33.455623626708984
Train_AverageEpLen : 506.5
Actor Loss : 4640.6455078125
Baseline Loss : 684.4564208984375
Train_EnvstepsSoFar : 136005
TimeSinceStart : 245.1552712917328

********** Iteration 61 ************
Eval_AverageReturn : 73.03040313720703
Eval_StdReturn : 47.477989196777344
Eval_MaxReturn : 120.50839233398438
Eval_MinReturn : 25.552413940429688
Eval_AverageEpLen : 592.0
Train_AverageReturn : 3.575234889984131
Train_StdReturn : 50.8934440612793
Train_MaxReturn : 91.75144958496094
Train_MinReturn : -61.76042938232422
Train_AverageEpLen : 524.4
Actor Loss : 1771.29296875
Baseline Loss : 1042.239501953125
Train_EnvstepsSoFar : 138627
TimeSinceStart : 252.0713038444519

********** Iteration 62 ************
Eval_AverageReturn : 116.37614440917969
Eval_StdReturn : 0.0
Eval_MaxReturn : 116.37614440917969
Eval_MinReturn : 116.37614440917969
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 1.5248374938964844
Train_StdReturn : 88.83627319335938
Train_MaxReturn : 143.69398498535156
Train_MinReturn : -86.63542175292969
Train_AverageEpLen : 509.75
Actor Loss : 2054.961181640625
Baseline Loss : 753.6051025390625
Train_EnvstepsSoFar : 140666
TimeSinceStart : 257.32080817222595

********** Iteration 63 ************
Eval_AverageReturn : -82.58142852783203
Eval_StdReturn : 0.0
Eval_MaxReturn : -82.58142852783203
Eval_MinReturn : -82.58142852783203
Eval_AverageEpLen : 547.0
Train_AverageReturn : 56.542362213134766
Train_StdReturn : 93.71965026855469
Train_MaxReturn : 154.0681610107422
Train_MinReturn : -69.94824981689453
Train_AverageEpLen : 818.0
Actor Loss : 5245.62451171875
Baseline Loss : 547.5653686523438
Train_EnvstepsSoFar : 143120
TimeSinceStart : 262.3555247783661

********** Iteration 64 ************
Eval_AverageReturn : 110.36643981933594
Eval_StdReturn : 0.0
Eval_MaxReturn : 110.36643981933594
Eval_MinReturn : 110.36643981933594
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 37.54811096191406
Train_StdReturn : 58.619380950927734
Train_MaxReturn : 105.09312438964844
Train_MinReturn : -37.84892654418945
Train_AverageEpLen : 812.0
Actor Loss : 2874.396240234375
Baseline Loss : 500.9512634277344
Train_EnvstepsSoFar : 145556
TimeSinceStart : 268.4263343811035

********** Iteration 65 ************
Eval_AverageReturn : -164.61090087890625
Eval_StdReturn : 0.0
Eval_MaxReturn : -164.61090087890625
Eval_MinReturn : -164.61090087890625
Eval_AverageEpLen : 534.0
Train_AverageReturn : 145.8614959716797
Train_StdReturn : 29.960752487182617
Train_MaxReturn : 183.40966796875
Train_MinReturn : 110.08531951904297
Train_AverageEpLen : 830.3333333333334
Actor Loss : 7669.92431640625
Baseline Loss : 827.2726440429688
Train_EnvstepsSoFar : 148047
TimeSinceStart : 273.80964159965515

********** Iteration 66 ************
Eval_AverageReturn : -27.05404281616211
Eval_StdReturn : 0.0
Eval_MaxReturn : -27.05404281616211
Eval_MinReturn : -27.05404281616211
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -12.078256607055664
Train_StdReturn : 53.19756317138672
Train_MaxReturn : 41.11930465698242
Train_MinReturn : -65.27581787109375
Train_AverageEpLen : 1000.0
Actor Loss : 491.9264221191406
Baseline Loss : 177.9362030029297
Train_EnvstepsSoFar : 150047
TimeSinceStart : 279.78913283348083

********** Iteration 67 ************
Eval_AverageReturn : -138.93359375
Eval_StdReturn : 0.0
Eval_MaxReturn : -138.93359375
Eval_MinReturn : -138.93359375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -96.3260498046875
Train_StdReturn : 55.7707633972168
Train_MaxReturn : -32.92632293701172
Train_MinReturn : -168.657470703125
Train_AverageEpLen : 928.3333333333334
Actor Loss : -4759.720703125
Baseline Loss : 410.0604553222656
Train_EnvstepsSoFar : 152832
TimeSinceStart : 287.28939414024353

********** Iteration 68 ************
Eval_AverageReturn : -164.48028564453125
Eval_StdReturn : 0.0
Eval_MaxReturn : -164.48028564453125
Eval_MinReturn : -164.48028564453125
Eval_AverageEpLen : 818.0
Train_AverageReturn : -10.771001815795898
Train_StdReturn : 68.12094116210938
Train_MaxReturn : 57.34994125366211
Train_MinReturn : -78.8919448852539
Train_AverageEpLen : 1000.0
Actor Loss : -966.86376953125
Baseline Loss : 237.6007080078125
Train_EnvstepsSoFar : 154832
TimeSinceStart : 292.75471210479736

********** Iteration 69 ************
Eval_AverageReturn : -84.1846923828125
Eval_StdReturn : 0.0
Eval_MaxReturn : -84.1846923828125
Eval_MinReturn : -84.1846923828125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -37.203407287597656
Train_StdReturn : 129.22592163085938
Train_MaxReturn : 92.02252197265625
Train_MinReturn : -166.42933654785156
Train_AverageEpLen : 1000.0
Actor Loss : -1382.405517578125
Baseline Loss : 286.82318115234375
Train_EnvstepsSoFar : 156832
TimeSinceStart : 298.8888375759125

********** Iteration 70 ************
Eval_AverageReturn : -112.9305648803711
Eval_StdReturn : 0.0
Eval_MaxReturn : -112.9305648803711
Eval_MinReturn : -112.9305648803711
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -136.01602172851562
Train_StdReturn : 19.250972747802734
Train_MaxReturn : -116.76505279541016
Train_MinReturn : -155.26699829101562
Train_AverageEpLen : 1000.0
Actor Loss : -3822.33935546875
Baseline Loss : 220.4467010498047
Train_EnvstepsSoFar : 158832
TimeSinceStart : 304.6254496574402

********** Iteration 71 ************
Eval_AverageReturn : -54.50770950317383
Eval_StdReturn : 0.0
Eval_MaxReturn : -54.50770950317383
Eval_MinReturn : -54.50770950317383
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -42.72010803222656
Train_StdReturn : 15.015748977661133
Train_MaxReturn : -27.704360961914062
Train_MinReturn : -57.73585891723633
Train_AverageEpLen : 1000.0
Actor Loss : -1762.106689453125
Baseline Loss : 135.0609588623047
Train_EnvstepsSoFar : 160832
TimeSinceStart : 310.8932144641876

********** Iteration 72 ************
Eval_AverageReturn : -32.801265716552734
Eval_StdReturn : 0.0
Eval_MaxReturn : -32.801265716552734
Eval_MinReturn : -32.801265716552734
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -40.05476760864258
Train_StdReturn : 4.56805419921875
Train_MaxReturn : -35.48671340942383
Train_MinReturn : -44.62282180786133
Train_AverageEpLen : 1000.0
Actor Loss : -909.7166748046875
Baseline Loss : 223.2525634765625
Train_EnvstepsSoFar : 162832
TimeSinceStart : 316.57631635665894

********** Iteration 73 ************
Eval_AverageReturn : -23.63446044921875
Eval_StdReturn : 0.0
Eval_MaxReturn : -23.63446044921875
Eval_MinReturn : -23.63446044921875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -37.891151428222656
Train_StdReturn : 24.19928741455078
Train_MaxReturn : -13.691865921020508
Train_MinReturn : -62.09043884277344
Train_AverageEpLen : 1000.0
Actor Loss : -1591.3681640625
Baseline Loss : 107.38310241699219
Train_EnvstepsSoFar : 164832
TimeSinceStart : 323.32798075675964

********** Iteration 74 ************
Eval_AverageReturn : 30.31908416748047
Eval_StdReturn : 0.0
Eval_MaxReturn : 30.31908416748047
Eval_MinReturn : 30.31908416748047
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -37.876922607421875
Train_StdReturn : 21.664812088012695
Train_MaxReturn : -16.212108612060547
Train_MinReturn : -59.54173278808594
Train_AverageEpLen : 1000.0
Actor Loss : -700.47998046875
Baseline Loss : 118.32037353515625
Train_EnvstepsSoFar : 166832
TimeSinceStart : 330.4896659851074

********** Iteration 75 ************
Eval_AverageReturn : -14.134384155273438
Eval_StdReturn : 0.0
Eval_MaxReturn : -14.134384155273438
Eval_MinReturn : -14.134384155273438
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 39.247676849365234
Train_StdReturn : 1.3689308166503906
Train_MaxReturn : 40.616607666015625
Train_MinReturn : 37.878746032714844
Train_AverageEpLen : 1000.0
Actor Loss : 1312.6102294921875
Baseline Loss : 239.0594482421875
Train_EnvstepsSoFar : 168832
TimeSinceStart : 337.2898111343384

********** Iteration 76 ************
Eval_AverageReturn : -54.9722785949707
Eval_StdReturn : 0.0
Eval_MaxReturn : -54.9722785949707
Eval_MinReturn : -54.9722785949707
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 58.607872009277344
Train_StdReturn : 4.482137680053711
Train_MaxReturn : 63.09001159667969
Train_MinReturn : 54.125736236572266
Train_AverageEpLen : 1000.0
Actor Loss : 1928.18896484375
Baseline Loss : 169.4868621826172
Train_EnvstepsSoFar : 170832
TimeSinceStart : 344.4981026649475

********** Iteration 77 ************
Eval_AverageReturn : 11.05661392211914
Eval_StdReturn : 0.0
Eval_MaxReturn : 11.05661392211914
Eval_MinReturn : 11.05661392211914
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -21.987709045410156
Train_StdReturn : 41.288536071777344
Train_MaxReturn : 19.30082893371582
Train_MinReturn : -63.2762451171875
Train_AverageEpLen : 1000.0
Actor Loss : -307.27685546875
Baseline Loss : 121.44221496582031
Train_EnvstepsSoFar : 172832
TimeSinceStart : 351.00698256492615

********** Iteration 78 ************
Eval_AverageReturn : 51.67903137207031
Eval_StdReturn : 0.0
Eval_MaxReturn : 51.67903137207031
Eval_MinReturn : 51.67903137207031
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 28.219486236572266
Train_StdReturn : 20.993038177490234
Train_MaxReturn : 49.2125244140625
Train_MinReturn : 7.226448059082031
Train_AverageEpLen : 1000.0
Actor Loss : 1038.4998779296875
Baseline Loss : 199.29690551757812
Train_EnvstepsSoFar : 174832
TimeSinceStart : 358.40674328804016

********** Iteration 79 ************
Eval_AverageReturn : -29.997703552246094
Eval_StdReturn : 0.0
Eval_MaxReturn : -29.997703552246094
Eval_MinReturn : -29.997703552246094
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 4.891191005706787
Train_StdReturn : 0.7423834800720215
Train_MaxReturn : 5.633574485778809
Train_MinReturn : 4.148807525634766
Train_AverageEpLen : 1000.0
Actor Loss : 118.1493148803711
Baseline Loss : 127.46470642089844
Train_EnvstepsSoFar : 176832
TimeSinceStart : 365.5629062652588

********** Iteration 80 ************
Eval_AverageReturn : -51.216102600097656
Eval_StdReturn : 0.0
Eval_MaxReturn : -51.216102600097656
Eval_MinReturn : -51.216102600097656
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -22.936439514160156
Train_StdReturn : 11.10684871673584
Train_MaxReturn : -11.829591751098633
Train_MinReturn : -34.04328918457031
Train_AverageEpLen : 1000.0
Actor Loss : -812.7085571289062
Baseline Loss : 100.64755249023438
Train_EnvstepsSoFar : 178832
TimeSinceStart : 373.00160360336304

********** Iteration 81 ************
Eval_AverageReturn : 94.94046783447266
Eval_StdReturn : 0.0
Eval_MaxReturn : 94.94046783447266
Eval_MinReturn : 94.94046783447266
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 73.31478881835938
Train_StdReturn : 50.570552825927734
Train_MaxReturn : 123.88533782958984
Train_MinReturn : 22.744232177734375
Train_AverageEpLen : 1000.0
Actor Loss : 1384.1873779296875
Baseline Loss : 240.04638671875
Train_EnvstepsSoFar : 180832
TimeSinceStart : 380.1285309791565

********** Iteration 82 ************
Eval_AverageReturn : 41.79826736450195
Eval_StdReturn : 0.0
Eval_MaxReturn : 41.79826736450195
Eval_MinReturn : 41.79826736450195
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -14.50232219696045
Train_StdReturn : 82.88854217529297
Train_MaxReturn : 102.71382904052734
Train_MinReturn : -74.13333129882812
Train_AverageEpLen : 811.0
Actor Loss : -1101.60546875
Baseline Loss : 780.7567138671875
Train_EnvstepsSoFar : 183265
TimeSinceStart : 386.1410291194916

********** Iteration 83 ************
Eval_AverageReturn : 17.826770782470703
Eval_StdReturn : 0.0
Eval_MaxReturn : 17.826770782470703
Eval_MinReturn : 17.826770782470703
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 49.424400329589844
Train_StdReturn : 20.39204978942871
Train_MaxReturn : 69.81645202636719
Train_MinReturn : 29.032352447509766
Train_AverageEpLen : 1000.0
Actor Loss : 1251.95263671875
Baseline Loss : 109.50846099853516
Train_EnvstepsSoFar : 185265
TimeSinceStart : 392.6905665397644

********** Iteration 84 ************
Eval_AverageReturn : 123.19482421875
Eval_StdReturn : 0.0
Eval_MaxReturn : 123.19482421875
Eval_MinReturn : 123.19482421875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 117.8984375
Train_StdReturn : 18.522838592529297
Train_MaxReturn : 136.42127990722656
Train_MinReturn : 99.37560272216797
Train_AverageEpLen : 1000.0
Actor Loss : 3334.94677734375
Baseline Loss : 339.2361755371094
Train_EnvstepsSoFar : 187265
TimeSinceStart : 398.16825771331787

********** Iteration 85 ************
Eval_AverageReturn : -137.13192749023438
Eval_StdReturn : 0.0
Eval_MaxReturn : -137.13192749023438
Eval_MinReturn : -137.13192749023438
Eval_AverageEpLen : 892.0
Train_AverageReturn : 86.90548706054688
Train_StdReturn : 20.78432846069336
Train_MaxReturn : 107.68981170654297
Train_MinReturn : 66.12115478515625
Train_AverageEpLen : 1000.0
Actor Loss : 2162.194091796875
Baseline Loss : 218.7294921875
Train_EnvstepsSoFar : 189265
TimeSinceStart : 404.6395125389099

********** Iteration 86 ************
Eval_AverageReturn : 49.86249542236328
Eval_StdReturn : 0.0
Eval_MaxReturn : 49.86249542236328
Eval_MinReturn : 49.86249542236328
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 72.57411193847656
Train_StdReturn : 4.5548553466796875
Train_MaxReturn : 77.12896728515625
Train_MinReturn : 68.01925659179688
Train_AverageEpLen : 1000.0
Actor Loss : 994.931640625
Baseline Loss : 157.35113525390625
Train_EnvstepsSoFar : 191265
TimeSinceStart : 412.2824537754059

********** Iteration 87 ************
Eval_AverageReturn : -25.366806030273438
Eval_StdReturn : 0.0
Eval_MaxReturn : -25.366806030273438
Eval_MinReturn : -25.366806030273438
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -42.94480514526367
Train_StdReturn : 42.18095779418945
Train_MaxReturn : -0.7638473510742188
Train_MinReturn : -85.12576293945312
Train_AverageEpLen : 1000.0
Actor Loss : -2947.3466796875
Baseline Loss : 226.2109375
Train_EnvstepsSoFar : 193265
TimeSinceStart : 418.85787081718445

********** Iteration 88 ************
Eval_AverageReturn : -60.42854309082031
Eval_StdReturn : 0.0
Eval_MaxReturn : -60.42854309082031
Eval_MinReturn : -60.42854309082031
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 45.63653564453125
Train_StdReturn : 64.64617919921875
Train_MaxReturn : 110.28271484375
Train_MinReturn : -19.0096435546875
Train_AverageEpLen : 1000.0
Actor Loss : -246.22384643554688
Baseline Loss : 218.0540771484375
Train_EnvstepsSoFar : 195265
TimeSinceStart : 425.720232963562

********** Iteration 89 ************
Eval_AverageReturn : 2.2242584228515625
Eval_StdReturn : 0.0
Eval_MaxReturn : 2.2242584228515625
Eval_MinReturn : 2.2242584228515625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -56.835113525390625
Train_StdReturn : 20.375869750976562
Train_MaxReturn : -36.45924377441406
Train_MinReturn : -77.21098327636719
Train_AverageEpLen : 1000.0
Actor Loss : -3339.6357421875
Baseline Loss : 121.59217834472656
Train_EnvstepsSoFar : 197265
TimeSinceStart : 432.8414545059204

********** Iteration 90 ************
Eval_AverageReturn : -102.74174499511719
Eval_StdReturn : 0.0
Eval_MaxReturn : -102.74174499511719
Eval_MinReturn : -102.74174499511719
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -66.80679321289062
Train_StdReturn : 14.782268524169922
Train_MaxReturn : -52.02452087402344
Train_MinReturn : -81.58905792236328
Train_AverageEpLen : 1000.0
Actor Loss : -3880.16845703125
Baseline Loss : 154.79696655273438
Train_EnvstepsSoFar : 199265
TimeSinceStart : 440.27696537971497

********** Iteration 91 ************
Eval_AverageReturn : -96.88143920898438
Eval_StdReturn : 0.0
Eval_MaxReturn : -96.88143920898438
Eval_MinReturn : -96.88143920898438
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -56.616607666015625
Train_StdReturn : 17.12114715576172
Train_MaxReturn : -39.495460510253906
Train_MinReturn : -73.73775482177734
Train_AverageEpLen : 1000.0
Actor Loss : -3509.189453125
Baseline Loss : 244.3186492919922
Train_EnvstepsSoFar : 201265
TimeSinceStart : 446.8988697528839

********** Iteration 92 ************
Eval_AverageReturn : -74.36698150634766
Eval_StdReturn : 0.0
Eval_MaxReturn : -74.36698150634766
Eval_MinReturn : -74.36698150634766
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -99.49137115478516
Train_StdReturn : 3.0851364135742188
Train_MaxReturn : -96.40623474121094
Train_MinReturn : -102.57650756835938
Train_AverageEpLen : 1000.0
Actor Loss : -3954.603515625
Baseline Loss : 188.6479949951172
Train_EnvstepsSoFar : 203265
TimeSinceStart : 453.0693588256836

********** Iteration 93 ************
Eval_AverageReturn : -74.38307189941406
Eval_StdReturn : 0.0
Eval_MaxReturn : -74.38307189941406
Eval_MinReturn : -74.38307189941406
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -60.06945037841797
Train_StdReturn : 11.192977905273438
Train_MaxReturn : -48.87647247314453
Train_MinReturn : -71.2624282836914
Train_AverageEpLen : 1000.0
Actor Loss : -2608.037109375
Baseline Loss : 189.72427368164062
Train_EnvstepsSoFar : 205265
TimeSinceStart : 460.18439745903015

********** Iteration 94 ************
Eval_AverageReturn : -111.99957275390625
Eval_StdReturn : 0.0
Eval_MaxReturn : -111.99957275390625
Eval_MinReturn : -111.99957275390625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -70.67798614501953
Train_StdReturn : 23.77372169494629
Train_MaxReturn : -46.90426254272461
Train_MinReturn : -94.45170593261719
Train_AverageEpLen : 1000.0
Actor Loss : -2443.168212890625
Baseline Loss : 175.19859313964844
Train_EnvstepsSoFar : 207265
TimeSinceStart : 466.15365505218506

********** Iteration 95 ************
Eval_AverageReturn : -72.8343505859375
Eval_StdReturn : 0.0
Eval_MaxReturn : -72.8343505859375
Eval_MinReturn : -72.8343505859375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -92.46886444091797
Train_StdReturn : 30.32402801513672
Train_MaxReturn : -62.14483642578125
Train_MinReturn : -122.79289245605469
Train_AverageEpLen : 1000.0
Actor Loss : -2475.99169921875
Baseline Loss : 150.7256622314453
Train_EnvstepsSoFar : 209265
TimeSinceStart : 472.90425086021423

********** Iteration 96 ************
Eval_AverageReturn : -54.16141891479492
Eval_StdReturn : 0.0
Eval_MaxReturn : -54.16141891479492
Eval_MinReturn : -54.16141891479492
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -58.572120666503906
Train_StdReturn : 23.163066864013672
Train_MaxReturn : -35.409053802490234
Train_MinReturn : -81.73519134521484
Train_AverageEpLen : 1000.0
Actor Loss : -1284.908935546875
Baseline Loss : 161.449462890625
Train_EnvstepsSoFar : 211265
TimeSinceStart : 480.03184366226196

********** Iteration 97 ************
Eval_AverageReturn : 17.98131561279297
Eval_StdReturn : 0.0
Eval_MaxReturn : 17.98131561279297
Eval_MinReturn : 17.98131561279297
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -64.15428924560547
Train_StdReturn : 24.49370574951172
Train_MaxReturn : -39.66058349609375
Train_MinReturn : -88.64799499511719
Train_AverageEpLen : 1000.0
Actor Loss : -1175.50390625
Baseline Loss : 52.242469787597656
Train_EnvstepsSoFar : 213265
TimeSinceStart : 487.7028248310089

********** Iteration 98 ************
Eval_AverageReturn : -48.5589599609375
Eval_StdReturn : 0.0
Eval_MaxReturn : -48.5589599609375
Eval_MinReturn : -48.5589599609375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -9.671658515930176
Train_StdReturn : 3.3722715377807617
Train_MaxReturn : -6.299386978149414
Train_MinReturn : -13.043930053710938
Train_AverageEpLen : 1000.0
Actor Loss : 176.3177490234375
Baseline Loss : 189.8917236328125
Train_EnvstepsSoFar : 215265
TimeSinceStart : 493.2819788455963

********** Iteration 99 ************
Eval_AverageReturn : 24.381397247314453
Eval_StdReturn : 0.0
Eval_MaxReturn : 24.381397247314453
Eval_MinReturn : 24.381397247314453
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 46.911293029785156
Train_StdReturn : 4.320646286010742
Train_MaxReturn : 51.231937408447266
Train_MinReturn : 42.59064483642578
Train_AverageEpLen : 1000.0
Actor Loss : 2139.951171875
Baseline Loss : 172.03724670410156
Train_EnvstepsSoFar : 217265
TimeSinceStart : 500.56433749198914

********** Iteration 100 ************
Eval_AverageReturn : -18.04926300048828
Eval_StdReturn : 0.0
Eval_MaxReturn : -18.04926300048828
Eval_MinReturn : -18.04926300048828
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -1.9313912391662598
Train_StdReturn : 15.071989059448242
Train_MaxReturn : 13.140597343444824
Train_MinReturn : -17.003379821777344
Train_AverageEpLen : 1000.0
Actor Loss : 641.513916015625
Baseline Loss : 127.1763687133789
Train_EnvstepsSoFar : 219265
TimeSinceStart : 507.15295338630676

********** Iteration 101 ************
Eval_AverageReturn : -54.70148468017578
Eval_StdReturn : 0.0
Eval_MaxReturn : -54.70148468017578
Eval_MinReturn : -54.70148468017578
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -51.0950927734375
Train_StdReturn : 52.85691452026367
Train_MaxReturn : 19.505596160888672
Train_MinReturn : -107.66600036621094
Train_AverageEpLen : 870.6666666666666
Actor Loss : -1385.029052734375
Baseline Loss : 385.1791076660156
Train_EnvstepsSoFar : 221877
TimeSinceStart : 515.1512081623077

********** Iteration 102 ************
Eval_AverageReturn : -11.633163452148438
Eval_StdReturn : 0.0
Eval_MaxReturn : -11.633163452148438
Eval_MinReturn : -11.633163452148438
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -34.48591995239258
Train_StdReturn : 86.4014663696289
Train_MaxReturn : 71.94393157958984
Train_MinReturn : -139.684814453125
Train_AverageEpLen : 998.6666666666666
Actor Loss : -843.5157470703125
Baseline Loss : 309.076171875
Train_EnvstepsSoFar : 224873
TimeSinceStart : 523.5984933376312

********** Iteration 103 ************
Eval_AverageReturn : -62.60797882080078
Eval_StdReturn : 0.0
Eval_MaxReturn : -62.60797882080078
Eval_MinReturn : -62.60797882080078
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -67.02093505859375
Train_StdReturn : 11.441351890563965
Train_MaxReturn : -50.94654083251953
Train_MinReturn : -76.66036224365234
Train_AverageEpLen : 934.6666666666666
Actor Loss : -2499.172607421875
Baseline Loss : 350.3406677246094
Train_EnvstepsSoFar : 227677
TimeSinceStart : 532.2269616127014

********** Iteration 104 ************
Eval_AverageReturn : -27.057891845703125
Eval_StdReturn : 0.0
Eval_MaxReturn : -27.057891845703125
Eval_MinReturn : -27.057891845703125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -74.12544250488281
Train_StdReturn : 5.0943756103515625
Train_MaxReturn : -69.03106689453125
Train_MinReturn : -79.21981811523438
Train_AverageEpLen : 1000.0
Actor Loss : -1486.282470703125
Baseline Loss : 121.0466537475586
Train_EnvstepsSoFar : 229677
TimeSinceStart : 538.3996267318726

********** Iteration 105 ************
Eval_AverageReturn : -94.11021423339844
Eval_StdReturn : 0.0
Eval_MaxReturn : -94.11021423339844
Eval_MinReturn : -94.11021423339844
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -79.6718521118164
Train_StdReturn : 8.332420349121094
Train_MaxReturn : -71.33943176269531
Train_MinReturn : -88.0042724609375
Train_AverageEpLen : 1000.0
Actor Loss : -2125.093994140625
Baseline Loss : 198.53054809570312
Train_EnvstepsSoFar : 231677
TimeSinceStart : 544.3161008358002

********** Iteration 106 ************
Eval_AverageReturn : -20.457645416259766
Eval_StdReturn : 0.0
Eval_MaxReturn : -20.457645416259766
Eval_MinReturn : -20.457645416259766
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -39.5087776184082
Train_StdReturn : 6.399364471435547
Train_MaxReturn : -33.109413146972656
Train_MinReturn : -45.90814208984375
Train_AverageEpLen : 1000.0
Actor Loss : -588.4354248046875
Baseline Loss : 156.44650268554688
Train_EnvstepsSoFar : 233677
TimeSinceStart : 551.2118904590607

********** Iteration 107 ************
Eval_AverageReturn : -83.53679656982422
Eval_StdReturn : 0.0
Eval_MaxReturn : -83.53679656982422
Eval_MinReturn : -83.53679656982422
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -61.17820739746094
Train_StdReturn : 9.66120719909668
Train_MaxReturn : -51.51700210571289
Train_MinReturn : -70.83941650390625
Train_AverageEpLen : 1000.0
Actor Loss : -1027.760498046875
Baseline Loss : 72.7409439086914
Train_EnvstepsSoFar : 235677
TimeSinceStart : 559.1790156364441

********** Iteration 108 ************
Eval_AverageReturn : -8.866706848144531
Eval_StdReturn : 0.0
Eval_MaxReturn : -8.866706848144531
Eval_MinReturn : -8.866706848144531
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -35.56590270996094
Train_StdReturn : 11.29454231262207
Train_MaxReturn : -24.271358489990234
Train_MinReturn : -46.860443115234375
Train_AverageEpLen : 1000.0
Actor Loss : -156.84405517578125
Baseline Loss : 88.96385955810547
Train_EnvstepsSoFar : 237677
TimeSinceStart : 566.5105013847351

********** Iteration 109 ************
Eval_AverageReturn : -36.60014724731445
Eval_StdReturn : 0.0
Eval_MaxReturn : -36.60014724731445
Eval_MinReturn : -36.60014724731445
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -24.41086196899414
Train_StdReturn : 27.391857147216797
Train_MaxReturn : 2.9809951782226562
Train_MinReturn : -51.80271911621094
Train_AverageEpLen : 1000.0
Actor Loss : -229.081298828125
Baseline Loss : 181.89413452148438
Train_EnvstepsSoFar : 239677
TimeSinceStart : 573.8470077514648

********** Iteration 110 ************
Eval_AverageReturn : -30.700410842895508
Eval_StdReturn : 0.0
Eval_MaxReturn : -30.700410842895508
Eval_MinReturn : -30.700410842895508
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -64.64054107666016
Train_StdReturn : 29.989763259887695
Train_MaxReturn : -31.45465850830078
Train_MinReturn : -104.10490417480469
Train_AverageEpLen : 973.6666666666666
Actor Loss : -1778.939208984375
Baseline Loss : 165.15872192382812
Train_EnvstepsSoFar : 242598
TimeSinceStart : 581.808602809906

********** Iteration 111 ************
Eval_AverageReturn : -86.9582748413086
Eval_StdReturn : 0.0
Eval_MaxReturn : -86.9582748413086
Eval_MinReturn : -86.9582748413086
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -34.390960693359375
Train_StdReturn : 18.137428283691406
Train_MaxReturn : -16.25353240966797
Train_MinReturn : -52.52838897705078
Train_AverageEpLen : 1000.0
Actor Loss : -952.464111328125
Baseline Loss : 102.5297622680664
Train_EnvstepsSoFar : 244598
TimeSinceStart : 588.5256769657135

********** Iteration 112 ************
Eval_AverageReturn : -52.120872497558594
Eval_StdReturn : 0.0
Eval_MaxReturn : -52.120872497558594
Eval_MinReturn : -52.120872497558594
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -67.47048950195312
Train_StdReturn : 22.776466369628906
Train_MaxReturn : -44.69402313232422
Train_MinReturn : -90.24695587158203
Train_AverageEpLen : 1000.0
Actor Loss : -1532.4263916015625
Baseline Loss : 55.7666015625
Train_EnvstepsSoFar : 246598
TimeSinceStart : 594.7326366901398

********** Iteration 113 ************
Eval_AverageReturn : -100.95072174072266
Eval_StdReturn : 0.0
Eval_MaxReturn : -100.95072174072266
Eval_MinReturn : -100.95072174072266
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -85.03609466552734
Train_StdReturn : 1.8112945556640625
Train_MaxReturn : -83.22480010986328
Train_MinReturn : -86.8473892211914
Train_AverageEpLen : 1000.0
Actor Loss : -1363.71533203125
Baseline Loss : 88.91578674316406
Train_EnvstepsSoFar : 248598
TimeSinceStart : 601.4598255157471

********** Iteration 114 ************
Eval_AverageReturn : -132.656005859375
Eval_StdReturn : 0.0
Eval_MaxReturn : -132.656005859375
Eval_MinReturn : -132.656005859375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -97.94610595703125
Train_StdReturn : 38.50136947631836
Train_MaxReturn : -59.444740295410156
Train_MinReturn : -136.44747924804688
Train_AverageEpLen : 1000.0
Actor Loss : -1956.1038818359375
Baseline Loss : 106.34764099121094
Train_EnvstepsSoFar : 250598
TimeSinceStart : 608.2395794391632

********** Iteration 115 ************
Eval_AverageReturn : -70.84957122802734
Eval_StdReturn : 0.0
Eval_MaxReturn : -70.84957122802734
Eval_MinReturn : -70.84957122802734
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -69.96975708007812
Train_StdReturn : 21.957181930541992
Train_MaxReturn : -48.012577056884766
Train_MinReturn : -91.92694091796875
Train_AverageEpLen : 1000.0
Actor Loss : -1050.8428955078125
Baseline Loss : 102.96357727050781
Train_EnvstepsSoFar : 252598
TimeSinceStart : 615.7797470092773

********** Iteration 116 ************
Eval_AverageReturn : -108.9579849243164
Eval_StdReturn : 0.0
Eval_MaxReturn : -108.9579849243164
Eval_MinReturn : -108.9579849243164
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -118.1922836303711
Train_StdReturn : 15.206001281738281
Train_MaxReturn : -102.98628234863281
Train_MinReturn : -133.39828491210938
Train_AverageEpLen : 1000.0
Actor Loss : -1672.8721923828125
Baseline Loss : 90.77275085449219
Train_EnvstepsSoFar : 254598
TimeSinceStart : 622.7895443439484

********** Iteration 117 ************
Eval_AverageReturn : -59.45206832885742
Eval_StdReturn : 0.0
Eval_MaxReturn : -59.45206832885742
Eval_MinReturn : -59.45206832885742
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -105.03953552246094
Train_StdReturn : 14.450397491455078
Train_MaxReturn : -90.5891342163086
Train_MinReturn : -119.48992919921875
Train_AverageEpLen : 1000.0
Actor Loss : -984.9696655273438
Baseline Loss : 166.4728546142578
Train_EnvstepsSoFar : 256598
TimeSinceStart : 629.6451878547668

********** Iteration 118 ************
Eval_AverageReturn : -86.72657775878906
Eval_StdReturn : 0.0
Eval_MaxReturn : -86.72657775878906
Eval_MinReturn : -86.72657775878906
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -94.62641906738281
Train_StdReturn : 4.72308349609375
Train_MaxReturn : -89.90333557128906
Train_MinReturn : -99.34950256347656
Train_AverageEpLen : 1000.0
Actor Loss : -1303.3402099609375
Baseline Loss : 85.50938415527344
Train_EnvstepsSoFar : 258598
TimeSinceStart : 635.7469725608826

********** Iteration 119 ************
Eval_AverageReturn : -84.20770263671875
Eval_StdReturn : 0.0
Eval_MaxReturn : -84.20770263671875
Eval_MinReturn : -84.20770263671875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -91.62528991699219
Train_StdReturn : 0.37774658203125
Train_MaxReturn : -91.24754333496094
Train_MinReturn : -92.00303649902344
Train_AverageEpLen : 1000.0
Actor Loss : -509.6050720214844
Baseline Loss : 47.618019104003906
Train_EnvstepsSoFar : 260598
TimeSinceStart : 641.555347442627

********** Iteration 120 ************
Eval_AverageReturn : -21.784944534301758
Eval_StdReturn : 0.0
Eval_MaxReturn : -21.784944534301758
Eval_MinReturn : -21.784944534301758
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 3.7204179763793945
Train_StdReturn : 4.472949028015137
Train_MaxReturn : 8.193367004394531
Train_MinReturn : -0.7525310516357422
Train_AverageEpLen : 1000.0
Actor Loss : 1639.6263427734375
Baseline Loss : 245.8267059326172
Train_EnvstepsSoFar : 262598
TimeSinceStart : 647.4273645877838

********** Iteration 121 ************
Eval_AverageReturn : -141.64788818359375
Eval_StdReturn : 0.0
Eval_MaxReturn : -141.64788818359375
Eval_MinReturn : -141.64788818359375
Eval_AverageEpLen : 900.0
Train_AverageReturn : -68.0086898803711
Train_StdReturn : 125.77699279785156
Train_MaxReturn : 104.72360229492188
Train_MinReturn : -191.150390625
Train_AverageEpLen : 871.6666666666666
Actor Loss : -79.32035827636719
Baseline Loss : 904.6136474609375
Train_EnvstepsSoFar : 265213
TimeSinceStart : 654.5903117656708

********** Iteration 122 ************
Eval_AverageReturn : 2.3236465454101562
Eval_StdReturn : 0.0
Eval_MaxReturn : 2.3236465454101562
Eval_MinReturn : 2.3236465454101562
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -21.97105598449707
Train_StdReturn : 69.69664001464844
Train_MaxReturn : 27.977462768554688
Train_MinReturn : -120.53398132324219
Train_AverageEpLen : 858.0
Actor Loss : 2017.1939697265625
Baseline Loss : 665.27490234375
Train_EnvstepsSoFar : 267787
TimeSinceStart : 661.4239587783813

********** Iteration 123 ************
Eval_AverageReturn : 91.5337142944336
Eval_StdReturn : 0.0
Eval_MaxReturn : 91.5337142944336
Eval_MinReturn : 91.5337142944336
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -70.23306274414062
Train_StdReturn : 45.28425216674805
Train_MaxReturn : -30.85608673095703
Train_MinReturn : -133.66038513183594
Train_AverageEpLen : 953.3333333333334
Actor Loss : -133.46792602539062
Baseline Loss : 404.9825744628906
Train_EnvstepsSoFar : 270647
TimeSinceStart : 670.1141312122345

********** Iteration 124 ************
Eval_AverageReturn : -1.7755584716796875
Eval_StdReturn : 0.0
Eval_MaxReturn : -1.7755584716796875
Eval_MinReturn : -1.7755584716796875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -50.515869140625
Train_StdReturn : 88.36131286621094
Train_MaxReturn : 29.009309768676758
Train_MinReturn : -173.75535583496094
Train_AverageEpLen : 960.3333333333334
Actor Loss : 482.6491394042969
Baseline Loss : 434.8585510253906
Train_EnvstepsSoFar : 273528
TimeSinceStart : 677.6168909072876

********** Iteration 125 ************
Eval_AverageReturn : -15.100902557373047
Eval_StdReturn : 0.0
Eval_MaxReturn : -15.100902557373047
Eval_MinReturn : -15.100902557373047
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -43.85811996459961
Train_StdReturn : 1.5845680236816406
Train_MaxReturn : -42.27355194091797
Train_MinReturn : -45.44268798828125
Train_AverageEpLen : 1000.0
Actor Loss : -54.3257942199707
Baseline Loss : 78.37101745605469
Train_EnvstepsSoFar : 275528
TimeSinceStart : 685.0258088111877

********** Iteration 126 ************
Eval_AverageReturn : -41.675777435302734
Eval_StdReturn : 0.0
Eval_MaxReturn : -41.675777435302734
Eval_MinReturn : -41.675777435302734
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -24.305278778076172
Train_StdReturn : 10.554424285888672
Train_MaxReturn : -13.7508544921875
Train_MinReturn : -34.859703063964844
Train_AverageEpLen : 1000.0
Actor Loss : 945.427978515625
Baseline Loss : 146.65585327148438
Train_EnvstepsSoFar : 277528
TimeSinceStart : 692.9522471427917

********** Iteration 127 ************
Eval_AverageReturn : -18.5328369140625
Eval_StdReturn : 0.0
Eval_MaxReturn : -18.5328369140625
Eval_MinReturn : -18.5328369140625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -2.5434112548828125
Train_StdReturn : 14.893791198730469
Train_MaxReturn : 12.350379943847656
Train_MinReturn : -17.43720245361328
Train_AverageEpLen : 1000.0
Actor Loss : 949.97607421875
Baseline Loss : 132.12322998046875
Train_EnvstepsSoFar : 279528
TimeSinceStart : 699.7498469352722

********** Iteration 128 ************
Eval_AverageReturn : -41.915321350097656
Eval_StdReturn : 0.0
Eval_MaxReturn : -41.915321350097656
Eval_MinReturn : -41.915321350097656
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -40.103031158447266
Train_StdReturn : 29.332820892333984
Train_MaxReturn : -10.770210266113281
Train_MinReturn : -69.43585205078125
Train_AverageEpLen : 1000.0
Actor Loss : 199.74314880371094
Baseline Loss : 84.34872436523438
Train_EnvstepsSoFar : 281528
TimeSinceStart : 707.1959707736969

********** Iteration 129 ************
Eval_AverageReturn : -24.946205139160156
Eval_StdReturn : 0.0
Eval_MaxReturn : -24.946205139160156
Eval_MinReturn : -24.946205139160156
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -40.087005615234375
Train_StdReturn : 10.807992935180664
Train_MaxReturn : -29.279010772705078
Train_MinReturn : -50.894996643066406
Train_AverageEpLen : 1000.0
Actor Loss : 55.44388198852539
Baseline Loss : 118.93031311035156
Train_EnvstepsSoFar : 283528
TimeSinceStart : 714.8863997459412

********** Iteration 130 ************
Eval_AverageReturn : -100.3697509765625
Eval_StdReturn : 0.0
Eval_MaxReturn : -100.3697509765625
Eval_MinReturn : -100.3697509765625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -69.20223236083984
Train_StdReturn : 18.800857543945312
Train_MaxReturn : -50.40137481689453
Train_MinReturn : -88.00308990478516
Train_AverageEpLen : 1000.0
Actor Loss : -729.5092163085938
Baseline Loss : 73.90525817871094
Train_EnvstepsSoFar : 285528
TimeSinceStart : 722.1593492031097

********** Iteration 131 ************
Eval_AverageReturn : -62.523921966552734
Eval_StdReturn : 0.0
Eval_MaxReturn : -62.523921966552734
Eval_MinReturn : -62.523921966552734
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -54.357643127441406
Train_StdReturn : 25.882369995117188
Train_MaxReturn : -28.47527313232422
Train_MinReturn : -80.2400131225586
Train_AverageEpLen : 1000.0
Actor Loss : -587.0532836914062
Baseline Loss : 94.6874771118164
Train_EnvstepsSoFar : 287528
TimeSinceStart : 729.432400226593

********** Iteration 132 ************
Eval_AverageReturn : -62.170318603515625
Eval_StdReturn : 0.0
Eval_MaxReturn : -62.170318603515625
Eval_MinReturn : -62.170318603515625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -69.2557373046875
Train_StdReturn : 5.029327392578125
Train_MaxReturn : -64.22640991210938
Train_MinReturn : -74.28506469726562
Train_AverageEpLen : 1000.0
Actor Loss : -1207.0660400390625
Baseline Loss : 35.53952407836914
Train_EnvstepsSoFar : 289528
TimeSinceStart : 736.5952384471893

********** Iteration 133 ************
Eval_AverageReturn : -38.37532043457031
Eval_StdReturn : 0.0
Eval_MaxReturn : -38.37532043457031
Eval_MinReturn : -38.37532043457031
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -56.655555725097656
Train_StdReturn : 11.814094543457031
Train_MaxReturn : -44.841461181640625
Train_MinReturn : -68.46965026855469
Train_AverageEpLen : 1000.0
Actor Loss : -671.235107421875
Baseline Loss : 143.5663604736328
Train_EnvstepsSoFar : 291528
TimeSinceStart : 742.9664380550385

********** Iteration 134 ************
Eval_AverageReturn : -68.29293823242188
Eval_StdReturn : 0.0
Eval_MaxReturn : -68.29293823242188
Eval_MinReturn : -68.29293823242188
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -86.42369842529297
Train_StdReturn : 3.0504379272460938
Train_MaxReturn : -83.37326049804688
Train_MinReturn : -89.47413635253906
Train_AverageEpLen : 1000.0
Actor Loss : -1460.066162109375
Baseline Loss : 100.2452163696289
Train_EnvstepsSoFar : 293528
TimeSinceStart : 751.0338106155396

********** Iteration 135 ************
Eval_AverageReturn : -15.661334991455078
Eval_StdReturn : 0.0
Eval_MaxReturn : -15.661334991455078
Eval_MinReturn : -15.661334991455078
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -66.4127197265625
Train_StdReturn : 4.195102691650391
Train_MaxReturn : -62.217613220214844
Train_MinReturn : -70.60781860351562
Train_AverageEpLen : 1000.0
Actor Loss : -841.5608520507812
Baseline Loss : 129.90386962890625
Train_EnvstepsSoFar : 295528
TimeSinceStart : 758.3259494304657

********** Iteration 136 ************
Eval_AverageReturn : -23.095779418945312
Eval_StdReturn : 0.0
Eval_MaxReturn : -23.095779418945312
Eval_MinReturn : -23.095779418945312
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -75.30877685546875
Train_StdReturn : 21.815311431884766
Train_MaxReturn : -53.49346160888672
Train_MinReturn : -97.12408447265625
Train_AverageEpLen : 1000.0
Actor Loss : -831.3141479492188
Baseline Loss : 98.62004089355469
Train_EnvstepsSoFar : 297528
TimeSinceStart : 765.2441051006317

********** Iteration 137 ************
Eval_AverageReturn : -26.815567016601562
Eval_StdReturn : 0.0
Eval_MaxReturn : -26.815567016601562
Eval_MinReturn : -26.815567016601562
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -61.818878173828125
Train_StdReturn : 24.499359130859375
Train_MaxReturn : -37.31951904296875
Train_MinReturn : -86.3182373046875
Train_AverageEpLen : 1000.0
Actor Loss : -1049.4149169921875
Baseline Loss : 71.370849609375
Train_EnvstepsSoFar : 299528
TimeSinceStart : 772.5549528598785

********** Iteration 138 ************
Eval_AverageReturn : -3.9825096130371094
Eval_StdReturn : 0.0
Eval_MaxReturn : -3.9825096130371094
Eval_MinReturn : -3.9825096130371094
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -30.636056900024414
Train_StdReturn : 10.072160720825195
Train_MaxReturn : -20.56389617919922
Train_MinReturn : -40.70821762084961
Train_AverageEpLen : 1000.0
Actor Loss : 782.7694091796875
Baseline Loss : 153.0187225341797
Train_EnvstepsSoFar : 301528
TimeSinceStart : 779.521623134613

********** Iteration 139 ************
Eval_AverageReturn : -62.62201690673828
Eval_StdReturn : 0.0
Eval_MaxReturn : -62.62201690673828
Eval_MinReturn : -62.62201690673828
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -38.68627166748047
Train_StdReturn : 45.1495246887207
Train_MaxReturn : 6.463253021240234
Train_MinReturn : -83.8357925415039
Train_AverageEpLen : 1000.0
Actor Loss : 222.857177734375
Baseline Loss : 153.35781860351562
Train_EnvstepsSoFar : 303528
TimeSinceStart : 786.437737941742

********** Iteration 140 ************
Eval_AverageReturn : -54.72785186767578
Eval_StdReturn : 0.0
Eval_MaxReturn : -54.72785186767578
Eval_MinReturn : -54.72785186767578
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 5.0536041259765625
Train_StdReturn : 5.968208312988281
Train_MaxReturn : 11.021812438964844
Train_MinReturn : -0.9146041870117188
Train_AverageEpLen : 1000.0
Actor Loss : 1372.4530029296875
Baseline Loss : 338.7065734863281
Train_EnvstepsSoFar : 305528
TimeSinceStart : 792.7124569416046

********** Iteration 141 ************
Eval_AverageReturn : 91.70317840576172
Eval_StdReturn : 0.0
Eval_MaxReturn : 91.70317840576172
Eval_MinReturn : 91.70317840576172
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 23.166858673095703
Train_StdReturn : 67.56707763671875
Train_MaxReturn : 90.73394012451172
Train_MinReturn : -44.40022277832031
Train_AverageEpLen : 1000.0
Actor Loss : 1691.446533203125
Baseline Loss : 251.76168823242188
Train_EnvstepsSoFar : 307528
TimeSinceStart : 799.2426826953888

********** Iteration 142 ************
Eval_AverageReturn : 94.21912384033203
Eval_StdReturn : 0.0
Eval_MaxReturn : 94.21912384033203
Eval_MinReturn : 94.21912384033203
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 80.79399871826172
Train_StdReturn : 17.45054817199707
Train_MaxReturn : 98.24454498291016
Train_MinReturn : 63.343448638916016
Train_AverageEpLen : 1000.0
Actor Loss : 3517.083740234375
Baseline Loss : 355.55194091796875
Train_EnvstepsSoFar : 309528
TimeSinceStart : 805.2109746932983

********** Iteration 143 ************
Eval_AverageReturn : 125.48585510253906
Eval_StdReturn : 0.0
Eval_MaxReturn : 125.48585510253906
Eval_MinReturn : 125.48585510253906
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 64.88159942626953
Train_StdReturn : 31.33333396911621
Train_MaxReturn : 96.21493530273438
Train_MinReturn : 33.54826736450195
Train_AverageEpLen : 1000.0
Actor Loss : 2162.53369140625
Baseline Loss : 182.26869201660156
Train_EnvstepsSoFar : 311528
TimeSinceStart : 812.333758354187

********** Iteration 144 ************
Eval_AverageReturn : 45.90606689453125
Eval_StdReturn : 0.0
Eval_MaxReturn : 45.90606689453125
Eval_MinReturn : 45.90606689453125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 79.69903564453125
Train_StdReturn : 6.8031005859375
Train_MaxReturn : 86.50213623046875
Train_MinReturn : 72.89593505859375
Train_AverageEpLen : 1000.0
Actor Loss : 3102.720703125
Baseline Loss : 227.44607543945312
Train_EnvstepsSoFar : 313528
TimeSinceStart : 819.1843929290771

********** Iteration 145 ************
Eval_AverageReturn : 102.61856079101562
Eval_StdReturn : 0.0
Eval_MaxReturn : 102.61856079101562
Eval_MinReturn : 102.61856079101562
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 102.64219665527344
Train_StdReturn : 23.685787200927734
Train_MaxReturn : 126.3279800415039
Train_MinReturn : 78.95640563964844
Train_AverageEpLen : 1000.0
Actor Loss : 2881.35498046875
Baseline Loss : 259.2235412597656
Train_EnvstepsSoFar : 315528
TimeSinceStart : 825.907918214798

********** Iteration 146 ************
Eval_AverageReturn : 80.16860961914062
Eval_StdReturn : 0.0
Eval_MaxReturn : 80.16860961914062
Eval_MinReturn : 80.16860961914062
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 80.21894836425781
Train_StdReturn : 0.3710746765136719
Train_MaxReturn : 80.59001922607422
Train_MinReturn : 79.84786987304688
Train_AverageEpLen : 1000.0
Actor Loss : 1803.0318603515625
Baseline Loss : 139.77662658691406
Train_EnvstepsSoFar : 317528
TimeSinceStart : 832.2120578289032

********** Iteration 147 ************
Eval_AverageReturn : 75.61182403564453
Eval_StdReturn : 0.0
Eval_MaxReturn : 75.61182403564453
Eval_MinReturn : 75.61182403564453
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 72.8741455078125
Train_StdReturn : 22.452098846435547
Train_MaxReturn : 95.32624816894531
Train_MinReturn : 50.42205047607422
Train_AverageEpLen : 1000.0
Actor Loss : 874.8065795898438
Baseline Loss : 155.29039001464844
Train_EnvstepsSoFar : 319528
TimeSinceStart : 838.7398302555084

********** Iteration 148 ************
Eval_AverageReturn : 42.28569793701172
Eval_StdReturn : 0.0
Eval_MaxReturn : 42.28569793701172
Eval_MinReturn : 42.28569793701172
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 88.87801361083984
Train_StdReturn : 10.555900573730469
Train_MaxReturn : 99.43391418457031
Train_MinReturn : 78.32211303710938
Train_AverageEpLen : 1000.0
Actor Loss : 1646.951416015625
Baseline Loss : 145.4977264404297
Train_EnvstepsSoFar : 321528
TimeSinceStart : 844.686815738678

********** Iteration 149 ************
Eval_AverageReturn : 52.14814758300781
Eval_StdReturn : 0.0
Eval_MaxReturn : 52.14814758300781
Eval_MinReturn : 52.14814758300781
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 49.04018020629883
Train_StdReturn : 56.13454818725586
Train_MaxReturn : 105.17472839355469
Train_MinReturn : -7.094367980957031
Train_AverageEpLen : 1000.0
Actor Loss : -393.8167724609375
Baseline Loss : 162.43319702148438
Train_EnvstepsSoFar : 323528
TimeSinceStart : 852.3186366558075

********** Iteration 150 ************
Eval_AverageReturn : -105.681640625
Eval_StdReturn : 0.0
Eval_MaxReturn : -105.681640625
Eval_MinReturn : -105.681640625
Eval_AverageEpLen : 993.0
Train_AverageReturn : 22.87632942199707
Train_StdReturn : 30.30963706970215
Train_MaxReturn : 53.18596649169922
Train_MinReturn : -7.433307647705078
Train_AverageEpLen : 1000.0
Actor Loss : -1317.1259765625
Baseline Loss : 86.10441589355469
Train_EnvstepsSoFar : 325528
TimeSinceStart : 858.4880936145782

********** Iteration 151 ************
Eval_AverageReturn : 66.16119384765625
Eval_StdReturn : 0.0
Eval_MaxReturn : 66.16119384765625
Eval_MinReturn : 66.16119384765625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 47.34275817871094
Train_StdReturn : 11.636472702026367
Train_MaxReturn : 58.97923278808594
Train_MinReturn : 35.7062873840332
Train_AverageEpLen : 1000.0
Actor Loss : -642.5274047851562
Baseline Loss : 75.88507080078125
Train_EnvstepsSoFar : 327528
TimeSinceStart : 865.5154573917389

********** Iteration 152 ************
Eval_AverageReturn : -23.659709930419922
Eval_StdReturn : 0.0
Eval_MaxReturn : -23.659709930419922
Eval_MinReturn : -23.659709930419922
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 17.10854148864746
Train_StdReturn : 27.373491287231445
Train_MaxReturn : 44.482032775878906
Train_MinReturn : -10.264949798583984
Train_AverageEpLen : 1000.0
Actor Loss : -1883.658447265625
Baseline Loss : 94.5767822265625
Train_EnvstepsSoFar : 329528
TimeSinceStart : 873.8420057296753

********** Iteration 153 ************
Eval_AverageReturn : -25.84493637084961
Eval_StdReturn : 0.0
Eval_MaxReturn : -25.84493637084961
Eval_MinReturn : -25.84493637084961
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 26.598648071289062
Train_StdReturn : 68.21331024169922
Train_MaxReturn : 94.81195831298828
Train_MinReturn : -41.614662170410156
Train_AverageEpLen : 1000.0
Actor Loss : -1109.1009521484375
Baseline Loss : 177.49075317382812
Train_EnvstepsSoFar : 331528
TimeSinceStart : 880.2191696166992

********** Iteration 154 ************
Eval_AverageReturn : -42.533470153808594
Eval_StdReturn : 0.0
Eval_MaxReturn : -42.533470153808594
Eval_MinReturn : -42.533470153808594
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 3.707296371459961
Train_StdReturn : 17.987791061401367
Train_MaxReturn : 21.695087432861328
Train_MinReturn : -14.280494689941406
Train_AverageEpLen : 1000.0
Actor Loss : -2404.287841796875
Baseline Loss : 113.1769790649414
Train_EnvstepsSoFar : 333528
TimeSinceStart : 887.8177037239075

********** Iteration 155 ************
Eval_AverageReturn : 40.56067657470703
Eval_StdReturn : 0.0
Eval_MaxReturn : 40.56067657470703
Eval_MinReturn : 40.56067657470703
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 68.93745422363281
Train_StdReturn : 5.010099411010742
Train_MaxReturn : 73.94755554199219
Train_MinReturn : 63.9273567199707
Train_AverageEpLen : 1000.0
Actor Loss : -15.673325538635254
Baseline Loss : 164.86935424804688
Train_EnvstepsSoFar : 335528
TimeSinceStart : 895.5186059474945

********** Iteration 156 ************
Eval_AverageReturn : 36.90086364746094
Eval_StdReturn : 0.0
Eval_MaxReturn : 36.90086364746094
Eval_MinReturn : 36.90086364746094
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 30.409198760986328
Train_StdReturn : 2.8549718856811523
Train_MaxReturn : 33.2641716003418
Train_MinReturn : 27.554227828979492
Train_AverageEpLen : 1000.0
Actor Loss : -1236.2529296875
Baseline Loss : 74.66978454589844
Train_EnvstepsSoFar : 337528
TimeSinceStart : 902.8307514190674

********** Iteration 157 ************
Eval_AverageReturn : -50.7405891418457
Eval_StdReturn : 0.0
Eval_MaxReturn : -50.7405891418457
Eval_MinReturn : -50.7405891418457
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -33.396907806396484
Train_StdReturn : 54.20295333862305
Train_MaxReturn : 38.21470642089844
Train_MinReturn : -92.88336181640625
Train_AverageEpLen : 725.0
Actor Loss : -3036.7177734375
Baseline Loss : 921.8932495117188
Train_EnvstepsSoFar : 339703
TimeSinceStart : 908.173371553421

********** Iteration 158 ************
Eval_AverageReturn : -27.769527435302734
Eval_StdReturn : 0.0
Eval_MaxReturn : -27.769527435302734
Eval_MinReturn : -27.769527435302734
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -53.393917083740234
Train_StdReturn : 58.3729133605957
Train_MaxReturn : 24.310537338256836
Train_MinReturn : -116.38345336914062
Train_AverageEpLen : 937.0
Actor Loss : -3963.2119140625
Baseline Loss : 332.5755920410156
Train_EnvstepsSoFar : 342514
TimeSinceStart : 916.3275492191315

********** Iteration 159 ************
Eval_AverageReturn : -81.5027084350586
Eval_StdReturn : 0.0
Eval_MaxReturn : -81.5027084350586
Eval_MinReturn : -81.5027084350586
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -64.7686996459961
Train_StdReturn : 12.420816421508789
Train_MaxReturn : -52.34788131713867
Train_MinReturn : -77.18951416015625
Train_AverageEpLen : 1000.0
Actor Loss : -3458.9150390625
Baseline Loss : 126.54969787597656
Train_EnvstepsSoFar : 344514
TimeSinceStart : 923.4256427288055

********** Iteration 160 ************
Eval_AverageReturn : -32.82291030883789
Eval_StdReturn : 0.0
Eval_MaxReturn : -32.82291030883789
Eval_MinReturn : -32.82291030883789
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -30.2745418548584
Train_StdReturn : 5.957487106323242
Train_MaxReturn : -24.317054748535156
Train_MinReturn : -36.23202896118164
Train_AverageEpLen : 1000.0
Actor Loss : -1912.6112060546875
Baseline Loss : 214.1578826904297
Train_EnvstepsSoFar : 346514
TimeSinceStart : 929.3985276222229

********** Iteration 161 ************
Eval_AverageReturn : -99.90318298339844
Eval_StdReturn : 0.0
Eval_MaxReturn : -99.90318298339844
Eval_MinReturn : -99.90318298339844
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -68.48240661621094
Train_StdReturn : 5.499856948852539
Train_MaxReturn : -62.982547760009766
Train_MinReturn : -73.98226165771484
Train_AverageEpLen : 1000.0
Actor Loss : -2445.22900390625
Baseline Loss : 67.07450866699219
Train_EnvstepsSoFar : 348514
TimeSinceStart : 935.867392539978

********** Iteration 162 ************
Eval_AverageReturn : -63.99973678588867
Eval_StdReturn : 0.0
Eval_MaxReturn : -63.99973678588867
Eval_MinReturn : -63.99973678588867
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -62.106529235839844
Train_StdReturn : 25.39543914794922
Train_MaxReturn : -36.711090087890625
Train_MinReturn : -87.50196838378906
Train_AverageEpLen : 1000.0
Actor Loss : -2128.595947265625
Baseline Loss : 140.7095489501953
Train_EnvstepsSoFar : 350514
TimeSinceStart : 942.0615422725677

********** Iteration 163 ************
Eval_AverageReturn : -117.98313903808594
Eval_StdReturn : 0.0
Eval_MaxReturn : -117.98313903808594
Eval_MinReturn : -117.98313903808594
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -101.11083984375
Train_StdReturn : 21.194477081298828
Train_MaxReturn : -79.91636657714844
Train_MinReturn : -122.3053207397461
Train_AverageEpLen : 1000.0
Actor Loss : -2663.900634765625
Baseline Loss : 93.96124267578125
Train_EnvstepsSoFar : 352514
TimeSinceStart : 948.3641691207886

********** Iteration 164 ************
Eval_AverageReturn : -99.41850280761719
Eval_StdReturn : 0.0
Eval_MaxReturn : -99.41850280761719
Eval_MinReturn : -99.41850280761719
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -125.260498046875
Train_StdReturn : 24.25302505493164
Train_MaxReturn : -101.0074691772461
Train_MinReturn : -149.51351928710938
Train_AverageEpLen : 1000.0
Actor Loss : -3170.5771484375
Baseline Loss : 101.67765808105469
Train_EnvstepsSoFar : 354514
TimeSinceStart : 955.3823201656342

********** Iteration 165 ************
Eval_AverageReturn : -77.3038330078125
Eval_StdReturn : 0.0
Eval_MaxReturn : -77.3038330078125
Eval_MinReturn : -77.3038330078125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -85.12303161621094
Train_StdReturn : 3.6252899169921875
Train_MaxReturn : -81.49774169921875
Train_MinReturn : -88.74832153320312
Train_AverageEpLen : 1000.0
Actor Loss : -1204.7493896484375
Baseline Loss : 96.55128479003906
Train_EnvstepsSoFar : 356514
TimeSinceStart : 961.709912776947

********** Iteration 166 ************
Eval_AverageReturn : -103.93370056152344
Eval_StdReturn : 0.0
Eval_MaxReturn : -103.93370056152344
Eval_MinReturn : -103.93370056152344
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -121.3915786743164
Train_StdReturn : 6.472923278808594
Train_MaxReturn : -114.91865539550781
Train_MinReturn : -127.864501953125
Train_AverageEpLen : 1000.0
Actor Loss : -2120.587890625
Baseline Loss : 84.14820861816406
Train_EnvstepsSoFar : 358514
TimeSinceStart : 969.008909702301

********** Iteration 167 ************
Eval_AverageReturn : -94.88676452636719
Eval_StdReturn : 0.0
Eval_MaxReturn : -94.88676452636719
Eval_MinReturn : -94.88676452636719
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -80.29882049560547
Train_StdReturn : 11.748970031738281
Train_MaxReturn : -68.54985046386719
Train_MinReturn : -92.04779052734375
Train_AverageEpLen : 1000.0
Actor Loss : -1196.5899658203125
Baseline Loss : 120.80936431884766
Train_EnvstepsSoFar : 360514
TimeSinceStart : 976.1509864330292

********** Iteration 168 ************
Eval_AverageReturn : -110.00686645507812
Eval_StdReturn : 0.0
Eval_MaxReturn : -110.00686645507812
Eval_MinReturn : -110.00686645507812
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -87.10791015625
Train_StdReturn : 1.13702392578125
Train_MaxReturn : -85.97088623046875
Train_MinReturn : -88.24493408203125
Train_AverageEpLen : 1000.0
Actor Loss : -1533.189453125
Baseline Loss : 39.423667907714844
Train_EnvstepsSoFar : 362514
TimeSinceStart : 984.1213569641113

********** Iteration 169 ************
Eval_AverageReturn : -51.811527252197266
Eval_StdReturn : 0.0
Eval_MaxReturn : -51.811527252197266
Eval_MinReturn : -51.811527252197266
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -78.107177734375
Train_StdReturn : 4.887451171875
Train_MaxReturn : -73.2197265625
Train_MinReturn : -82.99462890625
Train_AverageEpLen : 1000.0
Actor Loss : 61.16627883911133
Baseline Loss : 79.21402740478516
Train_EnvstepsSoFar : 364514
TimeSinceStart : 990.146162033081

********** Iteration 170 ************
Eval_AverageReturn : -66.08163452148438
Eval_StdReturn : 0.0
Eval_MaxReturn : -66.08163452148438
Eval_MinReturn : -66.08163452148438
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -61.54661560058594
Train_StdReturn : 0.3330860137939453
Train_MaxReturn : -61.21352767944336
Train_MinReturn : -61.87969970703125
Train_AverageEpLen : 1000.0
Actor Loss : 82.7385025024414
Baseline Loss : 75.78651428222656
Train_EnvstepsSoFar : 366514
TimeSinceStart : 997.0061995983124

********** Iteration 171 ************
Eval_AverageReturn : -41.613563537597656
Eval_StdReturn : 0.0
Eval_MaxReturn : -41.613563537597656
Eval_MinReturn : -41.613563537597656
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -43.966033935546875
Train_StdReturn : 4.854791641235352
Train_MaxReturn : -39.11124038696289
Train_MinReturn : -48.820823669433594
Train_AverageEpLen : 1000.0
Actor Loss : 1144.601806640625
Baseline Loss : 160.6199951171875
Train_EnvstepsSoFar : 368514
TimeSinceStart : 1002.7592573165894

********** Iteration 172 ************
Eval_AverageReturn : -65.46465301513672
Eval_StdReturn : 0.0
Eval_MaxReturn : -65.46465301513672
Eval_MinReturn : -65.46465301513672
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -65.12550354003906
Train_StdReturn : 5.05218505859375
Train_MaxReturn : -60.07331848144531
Train_MinReturn : -70.17768859863281
Train_AverageEpLen : 1000.0
Actor Loss : 300.5135498046875
Baseline Loss : 65.79358673095703
Train_EnvstepsSoFar : 370514
TimeSinceStart : 1010.2027380466461

********** Iteration 173 ************
Eval_AverageReturn : -48.121917724609375
Eval_StdReturn : 0.0
Eval_MaxReturn : -48.121917724609375
Eval_MinReturn : -48.121917724609375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -48.443321228027344
Train_StdReturn : 4.096900939941406
Train_MaxReturn : -44.34642028808594
Train_MinReturn : -52.54022216796875
Train_AverageEpLen : 1000.0
Actor Loss : 681.2927856445312
Baseline Loss : 136.07431030273438
Train_EnvstepsSoFar : 372514
TimeSinceStart : 1016.713285446167

********** Iteration 174 ************
Eval_AverageReturn : -46.21883010864258
Eval_StdReturn : 0.0
Eval_MaxReturn : -46.21883010864258
Eval_MinReturn : -46.21883010864258
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -25.48916244506836
Train_StdReturn : 6.028697967529297
Train_MaxReturn : -19.460464477539062
Train_MinReturn : -31.517860412597656
Train_AverageEpLen : 1000.0
Actor Loss : 1010.2672729492188
Baseline Loss : 215.55111694335938
Train_EnvstepsSoFar : 374514
TimeSinceStart : 1023.3267590999603

********** Iteration 175 ************
Eval_AverageReturn : -47.66963195800781
Eval_StdReturn : 0.0
Eval_MaxReturn : -47.66963195800781
Eval_MinReturn : -47.66963195800781
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -25.707521438598633
Train_StdReturn : 18.961484909057617
Train_MaxReturn : -6.746036529541016
Train_MinReturn : -44.66900634765625
Train_AverageEpLen : 1000.0
Actor Loss : 1197.6591796875
Baseline Loss : 190.2584686279297
Train_EnvstepsSoFar : 376514
TimeSinceStart : 1031.4661679267883

********** Iteration 176 ************
Eval_AverageReturn : -18.242454528808594
Eval_StdReturn : 0.0
Eval_MaxReturn : -18.242454528808594
Eval_MinReturn : -18.242454528808594
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -17.09020233154297
Train_StdReturn : 12.876956939697266
Train_MaxReturn : -4.213245391845703
Train_MinReturn : -29.967159271240234
Train_AverageEpLen : 1000.0
Actor Loss : 699.1058349609375
Baseline Loss : 143.82345581054688
Train_EnvstepsSoFar : 378514
TimeSinceStart : 1037.7427430152893

********** Iteration 177 ************
Eval_AverageReturn : -29.014102935791016
Eval_StdReturn : 0.0
Eval_MaxReturn : -29.014102935791016
Eval_MinReturn : -29.014102935791016
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 5.010424613952637
Train_StdReturn : 25.692352294921875
Train_MaxReturn : 30.702777862548828
Train_MinReturn : -20.681928634643555
Train_AverageEpLen : 1000.0
Actor Loss : 1163.7286376953125
Baseline Loss : 200.94032287597656
Train_EnvstepsSoFar : 380514
TimeSinceStart : 1043.6717903614044

********** Iteration 178 ************
Eval_AverageReturn : 0.20132064819335938
Eval_StdReturn : 0.0
Eval_MaxReturn : 0.20132064819335938
Eval_MinReturn : 0.20132064819335938
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -23.744426727294922
Train_StdReturn : 24.796855926513672
Train_MaxReturn : 1.05242919921875
Train_MinReturn : -48.541282653808594
Train_AverageEpLen : 1000.0
Actor Loss : 520.3233642578125
Baseline Loss : 159.19821166992188
Train_EnvstepsSoFar : 382514
TimeSinceStart : 1049.1872155666351

********** Iteration 179 ************
Eval_AverageReturn : 1.1363792419433594
Eval_StdReturn : 0.0
Eval_MaxReturn : 1.1363792419433594
Eval_MinReturn : 1.1363792419433594
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -30.276729583740234
Train_StdReturn : 7.047165870666504
Train_MaxReturn : -23.229562759399414
Train_MinReturn : -37.32389450073242
Train_AverageEpLen : 1000.0
Actor Loss : -65.1513900756836
Baseline Loss : 105.04984283447266
Train_EnvstepsSoFar : 384514
TimeSinceStart : 1057.112874031067

********** Iteration 180 ************
Eval_AverageReturn : -27.41632080078125
Eval_StdReturn : 0.0
Eval_MaxReturn : -27.41632080078125
Eval_MinReturn : -27.41632080078125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -31.908418655395508
Train_StdReturn : 11.739599227905273
Train_MaxReturn : -20.168819427490234
Train_MinReturn : -43.64801788330078
Train_AverageEpLen : 1000.0
Actor Loss : -197.16612243652344
Baseline Loss : 127.7831802368164
Train_EnvstepsSoFar : 386514
TimeSinceStart : 1065.2034695148468

********** Iteration 181 ************
Eval_AverageReturn : -36.203163146972656
Eval_StdReturn : 0.0
Eval_MaxReturn : -36.203163146972656
Eval_MinReturn : -36.203163146972656
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -16.213327407836914
Train_StdReturn : 14.893442153930664
Train_MaxReturn : -1.31988525390625
Train_MinReturn : -31.106769561767578
Train_AverageEpLen : 1000.0
Actor Loss : -414.48248291015625
Baseline Loss : 129.56185913085938
Train_EnvstepsSoFar : 388514
TimeSinceStart : 1071.5187420845032

********** Iteration 182 ************
Eval_AverageReturn : -11.712268829345703
Eval_StdReturn : 0.0
Eval_MaxReturn : -11.712268829345703
Eval_MinReturn : -11.712268829345703
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 4.859792709350586
Train_StdReturn : 9.840265274047852
Train_MaxReturn : 14.700057983398438
Train_MinReturn : -4.980472564697266
Train_AverageEpLen : 1000.0
Actor Loss : 503.263671875
Baseline Loss : 195.6329345703125
Train_EnvstepsSoFar : 390514
TimeSinceStart : 1077.6704304218292

********** Iteration 183 ************
Eval_AverageReturn : -31.428077697753906
Eval_StdReturn : 0.0
Eval_MaxReturn : -31.428077697753906
Eval_MinReturn : -31.428077697753906
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -39.488487243652344
Train_StdReturn : 4.291524887084961
Train_MaxReturn : -35.196964263916016
Train_MinReturn : -43.78001403808594
Train_AverageEpLen : 1000.0
Actor Loss : -854.059814453125
Baseline Loss : 61.00947189331055
Train_EnvstepsSoFar : 392514
TimeSinceStart : 1084.698067188263

********** Iteration 184 ************
Eval_AverageReturn : -24.989280700683594
Eval_StdReturn : 0.0
Eval_MaxReturn : -24.989280700683594
Eval_MinReturn : -24.989280700683594
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -25.718063354492188
Train_StdReturn : 21.45325469970703
Train_MaxReturn : -4.264808654785156
Train_MinReturn : -47.17131805419922
Train_AverageEpLen : 1000.0
Actor Loss : -980.7637939453125
Baseline Loss : 80.08946228027344
Train_EnvstepsSoFar : 394514
TimeSinceStart : 1091.9592823982239

********** Iteration 185 ************
Eval_AverageReturn : -13.215129852294922
Eval_StdReturn : 0.0
Eval_MaxReturn : -13.215129852294922
Eval_MinReturn : -13.215129852294922
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -13.032894134521484
Train_StdReturn : 25.574138641357422
Train_MaxReturn : 12.541244506835938
Train_MinReturn : -38.607032775878906
Train_AverageEpLen : 1000.0
Actor Loss : -359.2470397949219
Baseline Loss : 165.76858520507812
Train_EnvstepsSoFar : 396514
TimeSinceStart : 1098.826515674591

********** Iteration 186 ************
Eval_AverageReturn : -7.662017822265625
Eval_StdReturn : 0.0
Eval_MaxReturn : -7.662017822265625
Eval_MinReturn : -7.662017822265625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -42.3951416015625
Train_StdReturn : 20.649280548095703
Train_MaxReturn : -21.745859146118164
Train_MinReturn : -63.0444221496582
Train_AverageEpLen : 1000.0
Actor Loss : -1140.51806640625
Baseline Loss : 50.6271858215332
Train_EnvstepsSoFar : 398514
TimeSinceStart : 1105.4134850502014

********** Iteration 187 ************
Eval_AverageReturn : -50.14366912841797
Eval_StdReturn : 0.0
Eval_MaxReturn : -50.14366912841797
Eval_MinReturn : -50.14366912841797
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -23.26992416381836
Train_StdReturn : 13.25290298461914
Train_MaxReturn : -10.017021179199219
Train_MinReturn : -36.5228271484375
Train_AverageEpLen : 1000.0
Actor Loss : -740.1173706054688
Baseline Loss : 118.46773529052734
Train_EnvstepsSoFar : 400514
TimeSinceStart : 1111.2298781871796

********** Iteration 188 ************
Eval_AverageReturn : -60.024173736572266
Eval_StdReturn : 0.0
Eval_MaxReturn : -60.024173736572266
Eval_MinReturn : -60.024173736572266
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -61.00999450683594
Train_StdReturn : 5.9710540771484375
Train_MaxReturn : -55.0389404296875
Train_MinReturn : -66.98104858398438
Train_AverageEpLen : 1000.0
Actor Loss : -1611.28271484375
Baseline Loss : 73.59658813476562
Train_EnvstepsSoFar : 402514
TimeSinceStart : 1117.8336577415466

********** Iteration 189 ************
Eval_AverageReturn : -40.559967041015625
Eval_StdReturn : 0.0
Eval_MaxReturn : -40.559967041015625
Eval_MinReturn : -40.559967041015625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -47.90116882324219
Train_StdReturn : 5.96198844909668
Train_MaxReturn : -41.93918228149414
Train_MinReturn : -53.8631591796875
Train_AverageEpLen : 1000.0
Actor Loss : -959.8128662109375
Baseline Loss : 68.69291687011719
Train_EnvstepsSoFar : 404514
TimeSinceStart : 1124.6717290878296

********** Iteration 190 ************
Eval_AverageReturn : -128.72825622558594
Eval_StdReturn : 0.0
Eval_MaxReturn : -128.72825622558594
Eval_MinReturn : -128.72825622558594
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -106.16995239257812
Train_StdReturn : 13.961605072021484
Train_MaxReturn : -92.2083511352539
Train_MinReturn : -120.13156127929688
Train_AverageEpLen : 1000.0
Actor Loss : -2500.24755859375
Baseline Loss : 64.34568786621094
Train_EnvstepsSoFar : 406514
TimeSinceStart : 1130.7414112091064

********** Iteration 191 ************
Eval_AverageReturn : -114.52780151367188
Eval_StdReturn : 0.0
Eval_MaxReturn : -114.52780151367188
Eval_MinReturn : -114.52780151367188
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -38.138648986816406
Train_StdReturn : 4.876153945922852
Train_MaxReturn : -33.26249313354492
Train_MinReturn : -43.014801025390625
Train_AverageEpLen : 1000.0
Actor Loss : -60.95030212402344
Baseline Loss : 120.3531265258789
Train_EnvstepsSoFar : 408514
TimeSinceStart : 1136.9711451530457

********** Iteration 192 ************
Eval_AverageReturn : -87.70258331298828
Eval_StdReturn : 0.0
Eval_MaxReturn : -87.70258331298828
Eval_MinReturn : -87.70258331298828
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -93.9391860961914
Train_StdReturn : 23.70146942138672
Train_MaxReturn : -70.23771667480469
Train_MinReturn : -117.64065551757812
Train_AverageEpLen : 1000.0
Actor Loss : -1727.344970703125
Baseline Loss : 60.619110107421875
Train_EnvstepsSoFar : 410514
TimeSinceStart : 1142.3368589878082

********** Iteration 193 ************
Eval_AverageReturn : -134.0561981201172
Eval_StdReturn : 0.0
Eval_MaxReturn : -134.0561981201172
Eval_MinReturn : -134.0561981201172
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -87.22325134277344
Train_StdReturn : 4.3182220458984375
Train_MaxReturn : -82.905029296875
Train_MinReturn : -91.54147338867188
Train_AverageEpLen : 1000.0
Actor Loss : -995.7869262695312
Baseline Loss : 70.24751281738281
Train_EnvstepsSoFar : 412514
TimeSinceStart : 1147.6783175468445

********** Iteration 194 ************
Eval_AverageReturn : -106.12901306152344
Eval_StdReturn : 0.0
Eval_MaxReturn : -106.12901306152344
Eval_MinReturn : -106.12901306152344
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -77.45977783203125
Train_StdReturn : 24.64450454711914
Train_MaxReturn : -52.81527328491211
Train_MinReturn : -102.10427856445312
Train_AverageEpLen : 1000.0
Actor Loss : -1350.803466796875
Baseline Loss : 143.8597869873047
Train_EnvstepsSoFar : 414514
TimeSinceStart : 1153.2954030036926

********** Iteration 195 ************
Eval_AverageReturn : -89.32760620117188
Eval_StdReturn : 0.0
Eval_MaxReturn : -89.32760620117188
Eval_MinReturn : -89.32760620117188
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -129.7040252685547
Train_StdReturn : 18.645702362060547
Train_MaxReturn : -111.0583267211914
Train_MinReturn : -148.3497314453125
Train_AverageEpLen : 1000.0
Actor Loss : -2330.913818359375
Baseline Loss : 61.25927734375
Train_EnvstepsSoFar : 416514
TimeSinceStart : 1158.9777867794037

********** Iteration 196 ************
Eval_AverageReturn : -95.77291107177734
Eval_StdReturn : 0.0
Eval_MaxReturn : -95.77291107177734
Eval_MinReturn : -95.77291107177734
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -108.94227600097656
Train_StdReturn : 4.736602783203125
Train_MaxReturn : -104.20567321777344
Train_MinReturn : -113.67887878417969
Train_AverageEpLen : 1000.0
Actor Loss : -1352.5494384765625
Baseline Loss : 58.815025329589844
Train_EnvstepsSoFar : 418514
TimeSinceStart : 1163.8275256156921

********** Iteration 197 ************
Eval_AverageReturn : -96.65061950683594
Eval_StdReturn : 0.0
Eval_MaxReturn : -96.65061950683594
Eval_MinReturn : -96.65061950683594
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -95.00732421875
Train_StdReturn : 20.41183853149414
Train_MaxReturn : -74.59548950195312
Train_MinReturn : -115.4191665649414
Train_AverageEpLen : 1000.0
Actor Loss : -346.4661865234375
Baseline Loss : 54.014892578125
Train_EnvstepsSoFar : 420514
TimeSinceStart : 1169.8239150047302

********** Iteration 198 ************
Eval_AverageReturn : -97.29383850097656
Eval_StdReturn : 0.0
Eval_MaxReturn : -97.29383850097656
Eval_MinReturn : -97.29383850097656
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -113.60746765136719
Train_StdReturn : 18.007614135742188
Train_MaxReturn : -95.599853515625
Train_MinReturn : -131.61508178710938
Train_AverageEpLen : 1000.0
Actor Loss : -919.297119140625
Baseline Loss : 37.70830535888672
Train_EnvstepsSoFar : 422514
TimeSinceStart : 1175.9634637832642

********** Iteration 199 ************
Eval_AverageReturn : -63.38993835449219
Eval_StdReturn : 0.0
Eval_MaxReturn : -63.38993835449219
Eval_MinReturn : -63.38993835449219
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -86.46354675292969
Train_StdReturn : 13.523773193359375
Train_MaxReturn : -72.93977355957031
Train_MinReturn : -99.98731994628906
Train_AverageEpLen : 1000.0
Actor Loss : -751.1220092773438
Baseline Loss : 37.9375
Train_EnvstepsSoFar : 424514
TimeSinceStart : 1181.9508893489838

********** Iteration 200 ************
Eval_AverageReturn : -95.89511108398438
Eval_StdReturn : 0.0
Eval_MaxReturn : -95.89511108398438
Eval_MinReturn : -95.89511108398438
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -65.09676361083984
Train_StdReturn : 16.99562644958496
Train_MaxReturn : -48.101139068603516
Train_MinReturn : -82.09239196777344
Train_AverageEpLen : 1000.0
Actor Loss : 521.1491088867188
Baseline Loss : 87.16304779052734
Train_EnvstepsSoFar : 426514
TimeSinceStart : 1187.063580751419

********** Iteration 201 ************
Eval_AverageReturn : -121.09908294677734
Eval_StdReturn : 0.0
Eval_MaxReturn : -121.09908294677734
Eval_MinReturn : -121.09908294677734
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -110.68649291992188
Train_StdReturn : 10.80258560180664
Train_MaxReturn : -99.8839111328125
Train_MinReturn : -121.48908233642578
Train_AverageEpLen : 1000.0
Actor Loss : -684.4871215820312
Baseline Loss : 41.13642120361328
Train_EnvstepsSoFar : 428514
TimeSinceStart : 1192.356591463089

********** Iteration 202 ************
Eval_AverageReturn : -125.8374252319336
Eval_StdReturn : 0.0
Eval_MaxReturn : -125.8374252319336
Eval_MinReturn : -125.8374252319336
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -150.63992309570312
Train_StdReturn : 24.50423812866211
Train_MaxReturn : -126.13568878173828
Train_MinReturn : -175.1441650390625
Train_AverageEpLen : 1000.0
Actor Loss : -1643.1846923828125
Baseline Loss : 69.18901062011719
Train_EnvstepsSoFar : 430514
TimeSinceStart : 1199.0561826229095

********** Iteration 203 ************
Eval_AverageReturn : -95.29988861083984
Eval_StdReturn : 0.0
Eval_MaxReturn : -95.29988861083984
Eval_MinReturn : -95.29988861083984
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -112.24849700927734
Train_StdReturn : 22.420143127441406
Train_MaxReturn : -89.82835388183594
Train_MinReturn : -134.66864013671875
Train_AverageEpLen : 1000.0
Actor Loss : -218.62693786621094
Baseline Loss : 63.921783447265625
Train_EnvstepsSoFar : 432514
TimeSinceStart : 1205.1740052700043

********** Iteration 204 ************
Eval_AverageReturn : -28.094451904296875
Eval_StdReturn : 0.0
Eval_MaxReturn : -28.094451904296875
Eval_MinReturn : -28.094451904296875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -83.27877807617188
Train_StdReturn : 1.6918487548828125
Train_MaxReturn : -81.58692932128906
Train_MinReturn : -84.97062683105469
Train_AverageEpLen : 1000.0
Actor Loss : 365.6664123535156
Baseline Loss : 56.57624053955078
Train_EnvstepsSoFar : 434514
TimeSinceStart : 1210.5873546600342

********** Iteration 205 ************
Eval_AverageReturn : -95.82054138183594
Eval_StdReturn : 0.0
Eval_MaxReturn : -95.82054138183594
Eval_MinReturn : -95.82054138183594
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -83.53463745117188
Train_StdReturn : 4.366924285888672
Train_MaxReturn : -79.16770935058594
Train_MinReturn : -87.90155792236328
Train_AverageEpLen : 1000.0
Actor Loss : 254.35592651367188
Baseline Loss : 48.11626434326172
Train_EnvstepsSoFar : 436514
TimeSinceStart : 1214.711595773697

********** Iteration 206 ************
Eval_AverageReturn : -21.408794403076172
Eval_StdReturn : 0.0
Eval_MaxReturn : -21.408794403076172
Eval_MinReturn : -21.408794403076172
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -67.65975952148438
Train_StdReturn : 22.049137115478516
Train_MaxReturn : -45.610626220703125
Train_MinReturn : -89.70890045166016
Train_AverageEpLen : 1000.0
Actor Loss : 547.6260375976562
Baseline Loss : 50.475120544433594
Train_EnvstepsSoFar : 438514
TimeSinceStart : 1221.2695236206055

********** Iteration 207 ************
Eval_AverageReturn : -32.86729431152344
Eval_StdReturn : 0.0
Eval_MaxReturn : -32.86729431152344
Eval_MinReturn : -32.86729431152344
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -14.428688049316406
Train_StdReturn : 11.382686614990234
Train_MaxReturn : -3.046001434326172
Train_MinReturn : -25.81137466430664
Train_AverageEpLen : 1000.0
Actor Loss : 1937.55029296875
Baseline Loss : 184.3924102783203
Train_EnvstepsSoFar : 440514
TimeSinceStart : 1226.249409198761

********** Iteration 208 ************
Eval_AverageReturn : -16.388946533203125
Eval_StdReturn : 0.0
Eval_MaxReturn : -16.388946533203125
Eval_MinReturn : -16.388946533203125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -36.51853942871094
Train_StdReturn : 3.313844680786133
Train_MaxReturn : -33.20469284057617
Train_MinReturn : -39.83238220214844
Train_AverageEpLen : 1000.0
Actor Loss : 1211.467529296875
Baseline Loss : 71.85404205322266
Train_EnvstepsSoFar : 442514
TimeSinceStart : 1231.7883639335632

********** Iteration 209 ************
Eval_AverageReturn : -31.077878952026367
Eval_StdReturn : 0.0
Eval_MaxReturn : -31.077878952026367
Eval_MinReturn : -31.077878952026367
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -66.97620391845703
Train_StdReturn : 6.112401962280273
Train_MaxReturn : -60.86380386352539
Train_MinReturn : -73.08860778808594
Train_AverageEpLen : 1000.0
Actor Loss : 64.50041961669922
Baseline Loss : 41.81075668334961
Train_EnvstepsSoFar : 444514
TimeSinceStart : 1236.5918598175049

********** Iteration 210 ************
Eval_AverageReturn : 8.51053237915039
Eval_StdReturn : 0.0
Eval_MaxReturn : 8.51053237915039
Eval_MinReturn : 8.51053237915039
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -60.48887634277344
Train_StdReturn : 11.753984451293945
Train_MaxReturn : -48.73488998413086
Train_MinReturn : -72.24285888671875
Train_AverageEpLen : 1000.0
Actor Loss : -178.83163452148438
Baseline Loss : 47.487430572509766
Train_EnvstepsSoFar : 446514
TimeSinceStart : 1242.5273926258087

********** Iteration 211 ************
Eval_AverageReturn : -15.585891723632812
Eval_StdReturn : 0.0
Eval_MaxReturn : -15.585891723632812
Eval_MinReturn : -15.585891723632812
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -36.62868881225586
Train_StdReturn : 9.904415130615234
Train_MaxReturn : -26.724273681640625
Train_MinReturn : -46.533103942871094
Train_AverageEpLen : 1000.0
Actor Loss : -108.91105651855469
Baseline Loss : 59.970458984375
Train_EnvstepsSoFar : 448514
TimeSinceStart : 1248.4239432811737

********** Iteration 212 ************
Eval_AverageReturn : 11.26999282836914
Eval_StdReturn : 0.0
Eval_MaxReturn : 11.26999282836914
Eval_MinReturn : 11.26999282836914
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -63.339576721191406
Train_StdReturn : 3.844024658203125
Train_MaxReturn : -59.49555206298828
Train_MinReturn : -67.18360137939453
Train_AverageEpLen : 1000.0
Actor Loss : -793.2968139648438
Baseline Loss : 28.758153915405273
Train_EnvstepsSoFar : 450514
TimeSinceStart : 1253.6793644428253

********** Iteration 213 ************
Eval_AverageReturn : 0.09070968627929688
Eval_StdReturn : 0.0
Eval_MaxReturn : 0.09070968627929688
Eval_MinReturn : 0.09070968627929688
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 33.4499397277832
Train_StdReturn : 27.865022659301758
Train_MaxReturn : 61.31496047973633
Train_MinReturn : 5.584917068481445
Train_AverageEpLen : 1000.0
Actor Loss : 1620.06787109375
Baseline Loss : 138.39732360839844
Train_EnvstepsSoFar : 452514
TimeSinceStart : 1260.4007105827332

********** Iteration 214 ************
Eval_AverageReturn : -10.646900177001953
Eval_StdReturn : 0.0
Eval_MaxReturn : -10.646900177001953
Eval_MinReturn : -10.646900177001953
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -13.28188705444336
Train_StdReturn : 21.804821014404297
Train_MaxReturn : 8.522933959960938
Train_MinReturn : -35.086708068847656
Train_AverageEpLen : 1000.0
Actor Loss : 310.1786193847656
Baseline Loss : 96.69222259521484
Train_EnvstepsSoFar : 454514
TimeSinceStart : 1266.3262045383453

********** Iteration 215 ************
Eval_AverageReturn : -52.016693115234375
Eval_StdReturn : 0.0
Eval_MaxReturn : -52.016693115234375
Eval_MinReturn : -52.016693115234375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 0.09378433227539062
Train_StdReturn : 29.92041778564453
Train_MaxReturn : 30.014202117919922
Train_MinReturn : -29.82663345336914
Train_AverageEpLen : 1000.0
Actor Loss : 464.7979431152344
Baseline Loss : 124.90071105957031
Train_EnvstepsSoFar : 456514
TimeSinceStart : 1273.343183040619

********** Iteration 216 ************
Eval_AverageReturn : -43.8565673828125
Eval_StdReturn : 0.0
Eval_MaxReturn : -43.8565673828125
Eval_MinReturn : -43.8565673828125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -24.531076431274414
Train_StdReturn : 8.354448318481445
Train_MaxReturn : -16.17662811279297
Train_MinReturn : -32.88552474975586
Train_AverageEpLen : 1000.0
Actor Loss : -1084.5489501953125
Baseline Loss : 45.347068786621094
Train_EnvstepsSoFar : 458514
TimeSinceStart : 1280.0694744586945

********** Iteration 217 ************
Eval_AverageReturn : -21.117061614990234
Eval_StdReturn : 0.0
Eval_MaxReturn : -21.117061614990234
Eval_MinReturn : -21.117061614990234
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -8.89191722869873
Train_StdReturn : 0.1449880599975586
Train_MaxReturn : -8.746929168701172
Train_MinReturn : -9.036905288696289
Train_AverageEpLen : 1000.0
Actor Loss : -791.96630859375
Baseline Loss : 75.73509979248047
Train_EnvstepsSoFar : 460514
TimeSinceStart : 1285.7105774879456

********** Iteration 218 ************
Eval_AverageReturn : -10.424636840820312
Eval_StdReturn : 0.0
Eval_MaxReturn : -10.424636840820312
Eval_MinReturn : -10.424636840820312
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -35.59975814819336
Train_StdReturn : 8.406546592712402
Train_MaxReturn : -27.193212509155273
Train_MinReturn : -44.00630569458008
Train_AverageEpLen : 1000.0
Actor Loss : -1372.5186767578125
Baseline Loss : 65.12821197509766
Train_EnvstepsSoFar : 462514
TimeSinceStart : 1291.1557681560516

********** Iteration 219 ************
Eval_AverageReturn : -53.3332405090332
Eval_StdReturn : 0.0
Eval_MaxReturn : -53.3332405090332
Eval_MinReturn : -53.3332405090332
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -10.366462707519531
Train_StdReturn : 7.963554382324219
Train_MaxReturn : -2.4029083251953125
Train_MinReturn : -18.33001708984375
Train_AverageEpLen : 1000.0
Actor Loss : -268.709228515625
Baseline Loss : 161.4253692626953
Train_EnvstepsSoFar : 464514
TimeSinceStart : 1296.8318948745728

********** Iteration 220 ************
Eval_AverageReturn : -72.24494934082031
Eval_StdReturn : 0.0
Eval_MaxReturn : -72.24494934082031
Eval_MinReturn : -72.24494934082031
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -36.63060760498047
Train_StdReturn : 35.244197845458984
Train_MaxReturn : -1.3864097595214844
Train_MinReturn : -71.87480926513672
Train_AverageEpLen : 1000.0
Actor Loss : -910.9675903320312
Baseline Loss : 127.3436279296875
Train_EnvstepsSoFar : 466514
TimeSinceStart : 1302.305377483368

********** Iteration 221 ************
Eval_AverageReturn : -78.01751708984375
Eval_StdReturn : 0.0
Eval_MaxReturn : -78.01751708984375
Eval_MinReturn : -78.01751708984375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -27.4388370513916
Train_StdReturn : 6.603593826293945
Train_MaxReturn : -20.835243225097656
Train_MinReturn : -34.04243087768555
Train_AverageEpLen : 1000.0
Actor Loss : -602.167724609375
Baseline Loss : 137.69789123535156
Train_EnvstepsSoFar : 468514
TimeSinceStart : 1308.9604761600494

********** Iteration 222 ************
Eval_AverageReturn : -50.003135681152344
Eval_StdReturn : 0.0
Eval_MaxReturn : -50.003135681152344
Eval_MinReturn : -50.003135681152344
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -75.84132385253906
Train_StdReturn : 2.500812530517578
Train_MaxReturn : -73.34050750732422
Train_MinReturn : -78.34213256835938
Train_AverageEpLen : 1000.0
Actor Loss : -2144.7880859375
Baseline Loss : 63.339561462402344
Train_EnvstepsSoFar : 470514
TimeSinceStart : 1315.5668451786041

********** Iteration 223 ************
Eval_AverageReturn : -84.49463653564453
Eval_StdReturn : 0.0
Eval_MaxReturn : -84.49463653564453
Eval_MinReturn : -84.49463653564453
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -50.34220886230469
Train_StdReturn : 36.27085876464844
Train_MaxReturn : -14.071346282958984
Train_MinReturn : -86.61306762695312
Train_AverageEpLen : 1000.0
Actor Loss : -1145.7308349609375
Baseline Loss : 116.0319595336914
Train_EnvstepsSoFar : 472514
TimeSinceStart : 1322.6098413467407

********** Iteration 224 ************
Eval_AverageReturn : -91.73098754882812
Eval_StdReturn : 0.0
Eval_MaxReturn : -91.73098754882812
Eval_MinReturn : -91.73098754882812
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -92.56533813476562
Train_StdReturn : 4.401699066162109
Train_MaxReturn : -88.16364288330078
Train_MinReturn : -96.967041015625
Train_AverageEpLen : 1000.0
Actor Loss : -2244.46484375
Baseline Loss : 108.3185043334961
Train_EnvstepsSoFar : 474514
TimeSinceStart : 1328.2903950214386

********** Iteration 225 ************
Eval_AverageReturn : -108.49970245361328
Eval_StdReturn : 0.0
Eval_MaxReturn : -108.49970245361328
Eval_MinReturn : -108.49970245361328
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -79.8040771484375
Train_StdReturn : 4.636028289794922
Train_MaxReturn : -75.16804504394531
Train_MinReturn : -84.44010162353516
Train_AverageEpLen : 1000.0
Actor Loss : -1653.7056884765625
Baseline Loss : 95.64969635009766
Train_EnvstepsSoFar : 476514
TimeSinceStart : 1333.3200809955597

********** Iteration 226 ************
Eval_AverageReturn : -127.62488555908203
Eval_StdReturn : 0.0
Eval_MaxReturn : -127.62488555908203
Eval_MinReturn : -127.62488555908203
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -118.49535369873047
Train_StdReturn : 12.813880920410156
Train_MaxReturn : -105.68147277832031
Train_MinReturn : -131.30923461914062
Train_AverageEpLen : 1000.0
Actor Loss : -1993.830810546875
Baseline Loss : 66.25804901123047
Train_EnvstepsSoFar : 478514
TimeSinceStart : 1339.2729926109314

********** Iteration 227 ************
Eval_AverageReturn : -124.72058868408203
Eval_StdReturn : 0.0
Eval_MaxReturn : -124.72058868408203
Eval_MinReturn : -124.72058868408203
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -142.08563232421875
Train_StdReturn : 26.52849578857422
Train_MaxReturn : -115.55712890625
Train_MinReturn : -168.61412048339844
Train_AverageEpLen : 1000.0
Actor Loss : -2083.0419921875
Baseline Loss : 66.9676742553711
Train_EnvstepsSoFar : 480514
TimeSinceStart : 1345.4310534000397

********** Iteration 228 ************
Eval_AverageReturn : -96.75462341308594
Eval_StdReturn : 0.0
Eval_MaxReturn : -96.75462341308594
Eval_MinReturn : -96.75462341308594
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -138.04489135742188
Train_StdReturn : 12.021812438964844
Train_MaxReturn : -126.02308654785156
Train_MinReturn : -150.06671142578125
Train_AverageEpLen : 1000.0
Actor Loss : -1706.139404296875
Baseline Loss : 59.50707244873047
Train_EnvstepsSoFar : 482514
TimeSinceStart : 1351.582849264145

********** Iteration 229 ************
Eval_AverageReturn : -87.94217681884766
Eval_StdReturn : 0.0
Eval_MaxReturn : -87.94217681884766
Eval_MinReturn : -87.94217681884766
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -100.22663879394531
Train_StdReturn : 12.402305603027344
Train_MaxReturn : -87.82433319091797
Train_MinReturn : -112.62894439697266
Train_AverageEpLen : 1000.0
Actor Loss : -334.3238220214844
Baseline Loss : 45.56474685668945
Train_EnvstepsSoFar : 484514
TimeSinceStart : 1357.5908551216125

********** Iteration 230 ************
Eval_AverageReturn : -103.51585388183594
Eval_StdReturn : 0.0
Eval_MaxReturn : -103.51585388183594
Eval_MinReturn : -103.51585388183594
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -111.4809799194336
Train_StdReturn : 14.084251403808594
Train_MaxReturn : -97.396728515625
Train_MinReturn : -125.56523132324219
Train_AverageEpLen : 1000.0
Actor Loss : -791.3422241210938
Baseline Loss : 30.084680557250977
Train_EnvstepsSoFar : 486514
TimeSinceStart : 1363.5962409973145

********** Iteration 231 ************
Eval_AverageReturn : -51.02946090698242
Eval_StdReturn : 0.0
Eval_MaxReturn : -51.02946090698242
Eval_MinReturn : -51.02946090698242
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -62.564292907714844
Train_StdReturn : 5.5925750732421875
Train_MaxReturn : -56.971717834472656
Train_MinReturn : -68.15686798095703
Train_AverageEpLen : 1000.0
Actor Loss : 771.5827026367188
Baseline Loss : 75.3302993774414
Train_EnvstepsSoFar : 488514
TimeSinceStart : 1370.1535758972168

********** Iteration 232 ************
Eval_AverageReturn : -89.00617980957031
Eval_StdReturn : 0.0
Eval_MaxReturn : -89.00617980957031
Eval_MinReturn : -89.00617980957031
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -78.45946502685547
Train_StdReturn : 15.739725112915039
Train_MaxReturn : -62.7197380065918
Train_MinReturn : -94.19918823242188
Train_AverageEpLen : 1000.0
Actor Loss : 591.9501953125
Baseline Loss : 50.509239196777344
Train_EnvstepsSoFar : 490514
TimeSinceStart : 1375.3041484355927

********** Iteration 233 ************
Eval_AverageReturn : -47.82923126220703
Eval_StdReturn : 0.0
Eval_MaxReturn : -47.82923126220703
Eval_MinReturn : -47.82923126220703
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -92.83709716796875
Train_StdReturn : 7.652690887451172
Train_MaxReturn : -85.18441009521484
Train_MinReturn : -100.48979187011719
Train_AverageEpLen : 1000.0
Actor Loss : 76.11253356933594
Baseline Loss : 39.51081085205078
Train_EnvstepsSoFar : 492514
TimeSinceStart : 1381.944754600525

********** Iteration 234 ************
Eval_AverageReturn : -22.13823699951172
Eval_StdReturn : 0.0
Eval_MaxReturn : -22.13823699951172
Eval_MinReturn : -22.13823699951172
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -72.61604309082031
Train_StdReturn : 10.07070541381836
Train_MaxReturn : -62.54534149169922
Train_MinReturn : -82.68675231933594
Train_AverageEpLen : 1000.0
Actor Loss : 234.69052124023438
Baseline Loss : 40.59087371826172
Train_EnvstepsSoFar : 494514
TimeSinceStart : 1387.091407775879

********** Iteration 235 ************
Eval_AverageReturn : -24.594985961914062
Eval_StdReturn : 0.0
Eval_MaxReturn : -24.594985961914062
Eval_MinReturn : -24.594985961914062
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -53.960693359375
Train_StdReturn : 6.406036376953125
Train_MaxReturn : -47.554656982421875
Train_MinReturn : -60.366729736328125
Train_AverageEpLen : 1000.0
Actor Loss : 572.4747924804688
Baseline Loss : 63.73480987548828
Train_EnvstepsSoFar : 496514
TimeSinceStart : 1393.2377905845642

********** Iteration 236 ************
Eval_AverageReturn : -25.193500518798828
Eval_StdReturn : 0.0
Eval_MaxReturn : -25.193500518798828
Eval_MinReturn : -25.193500518798828
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -42.189781188964844
Train_StdReturn : 3.4625473022460938
Train_MaxReturn : -38.72723388671875
Train_MinReturn : -45.65232849121094
Train_AverageEpLen : 1000.0
Actor Loss : 415.9131774902344
Baseline Loss : 95.9258041381836
Train_EnvstepsSoFar : 498514
TimeSinceStart : 1398.9328038692474

********** Iteration 237 ************
Eval_AverageReturn : -10.910774230957031
Eval_StdReturn : 0.0
Eval_MaxReturn : -10.910774230957031
Eval_MinReturn : -10.910774230957031
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -42.056060791015625
Train_StdReturn : 15.478405952453613
Train_MaxReturn : -25.303619384765625
Train_MinReturn : -62.63426208496094
Train_AverageEpLen : 896.3333333333334
Actor Loss : -63.90774917602539
Baseline Loss : 322.8811950683594
Train_EnvstepsSoFar : 501203
TimeSinceStart : 1405.9944140911102

********** Iteration 238 ************
Eval_AverageReturn : -39.59189224243164
Eval_StdReturn : 0.0
Eval_MaxReturn : -39.59189224243164
Eval_MinReturn : -39.59189224243164
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -29.478649139404297
Train_StdReturn : 0.9314308166503906
Train_MaxReturn : -28.547218322753906
Train_MinReturn : -30.410079956054688
Train_AverageEpLen : 1000.0
Actor Loss : 603.2359008789062
Baseline Loss : 73.1352767944336
Train_EnvstepsSoFar : 503203
TimeSinceStart : 1413.2998600006104

********** Iteration 239 ************
Eval_AverageReturn : -48.56636047363281
Eval_StdReturn : 0.0
Eval_MaxReturn : -48.56636047363281
Eval_MinReturn : -48.56636047363281
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -65.52729797363281
Train_StdReturn : 18.242359161376953
Train_MaxReturn : -47.284934997558594
Train_MinReturn : -83.7696533203125
Train_AverageEpLen : 1000.0
Actor Loss : -636.2310791015625
Baseline Loss : 93.13789367675781
Train_EnvstepsSoFar : 505203
TimeSinceStart : 1418.3770008087158

********** Iteration 240 ************
Eval_AverageReturn : -38.573631286621094
Eval_StdReturn : 0.0
Eval_MaxReturn : -38.573631286621094
Eval_MinReturn : -38.573631286621094
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -45.01917266845703
Train_StdReturn : 21.65630340576172
Train_MaxReturn : -23.362869262695312
Train_MinReturn : -66.67547607421875
Train_AverageEpLen : 1000.0
Actor Loss : -104.89014434814453
Baseline Loss : 98.78526306152344
Train_EnvstepsSoFar : 507203
TimeSinceStart : 1424.4213926792145

********** Iteration 241 ************
Eval_AverageReturn : -56.18859100341797
Eval_StdReturn : 0.0
Eval_MaxReturn : -56.18859100341797
Eval_MinReturn : -56.18859100341797
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -49.60590362548828
Train_StdReturn : 23.850547790527344
Train_MaxReturn : -25.755355834960938
Train_MinReturn : -73.45645141601562
Train_AverageEpLen : 1000.0
Actor Loss : -77.63912963867188
Baseline Loss : 116.98457336425781
Train_EnvstepsSoFar : 509203
TimeSinceStart : 1431.3236846923828

********** Iteration 242 ************
Eval_AverageReturn : -62.10871124267578
Eval_StdReturn : 0.0
Eval_MaxReturn : -62.10871124267578
Eval_MinReturn : -62.10871124267578
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -52.65735626220703
Train_StdReturn : 19.512487411499023
Train_MaxReturn : -33.14487075805664
Train_MinReturn : -72.16984558105469
Train_AverageEpLen : 1000.0
Actor Loss : -606.3663330078125
Baseline Loss : 69.23350524902344
Train_EnvstepsSoFar : 511203
TimeSinceStart : 1436.9770147800446

********** Iteration 243 ************
Eval_AverageReturn : -47.129119873046875
Eval_StdReturn : 0.0
Eval_MaxReturn : -47.129119873046875
Eval_MinReturn : -47.129119873046875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -34.40558624267578
Train_StdReturn : 0.3574390411376953
Train_MaxReturn : -34.04814910888672
Train_MinReturn : -34.76302719116211
Train_AverageEpLen : 1000.0
Actor Loss : -44.68375778198242
Baseline Loss : 75.86354064941406
Train_EnvstepsSoFar : 513203
TimeSinceStart : 1441.793116569519

********** Iteration 244 ************
Eval_AverageReturn : -15.241371154785156
Eval_StdReturn : 0.0
Eval_MaxReturn : -15.241371154785156
Eval_MinReturn : -15.241371154785156
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -46.876625061035156
Train_StdReturn : 0.1498279571533203
Train_MaxReturn : -46.72679901123047
Train_MinReturn : -47.02645492553711
Train_AverageEpLen : 1000.0
Actor Loss : -366.0420227050781
Baseline Loss : 48.67812728881836
Train_EnvstepsSoFar : 515203
TimeSinceStart : 1445.9063830375671

********** Iteration 245 ************
Eval_AverageReturn : -86.92009735107422
Eval_StdReturn : 0.0
Eval_MaxReturn : -86.92009735107422
Eval_MinReturn : -86.92009735107422
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -19.782323837280273
Train_StdReturn : 4.902082443237305
Train_MaxReturn : -14.880241394042969
Train_MinReturn : -24.684406280517578
Train_AverageEpLen : 1000.0
Actor Loss : 74.0764389038086
Baseline Loss : 207.06344604492188
Train_EnvstepsSoFar : 517203
TimeSinceStart : 1449.7168462276459

********** Iteration 246 ************
Eval_AverageReturn : -79.22628784179688
Eval_StdReturn : 0.0
Eval_MaxReturn : -79.22628784179688
Eval_MinReturn : -79.22628784179688
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -41.17608642578125
Train_StdReturn : 0.6046218872070312
Train_MaxReturn : -40.57146453857422
Train_MinReturn : -41.78070831298828
Train_AverageEpLen : 1000.0
Actor Loss : -284.9707946777344
Baseline Loss : 83.71701049804688
Train_EnvstepsSoFar : 519203
TimeSinceStart : 1453.1091313362122

********** Iteration 247 ************
Eval_AverageReturn : -15.160594940185547
Eval_StdReturn : 0.0
Eval_MaxReturn : -15.160594940185547
Eval_MinReturn : -15.160594940185547
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -79.86211395263672
Train_StdReturn : 16.19891357421875
Train_MaxReturn : -63.66320037841797
Train_MinReturn : -96.06102752685547
Train_AverageEpLen : 1000.0
Actor Loss : -1500.8656005859375
Baseline Loss : 93.38702392578125
Train_EnvstepsSoFar : 521203
TimeSinceStart : 1458.2563846111298

********** Iteration 248 ************
Eval_AverageReturn : -74.03984832763672
Eval_StdReturn : 0.0
Eval_MaxReturn : -74.03984832763672
Eval_MinReturn : -74.03984832763672
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -54.65757751464844
Train_StdReturn : 21.341947555541992
Train_MaxReturn : -33.31563186645508
Train_MinReturn : -75.99952697753906
Train_AverageEpLen : 1000.0
Actor Loss : -731.0453491210938
Baseline Loss : 65.59500122070312
Train_EnvstepsSoFar : 523203
TimeSinceStart : 1462.7052631378174

********** Iteration 249 ************
Eval_AverageReturn : -40.533241271972656
Eval_StdReturn : 0.0
Eval_MaxReturn : -40.533241271972656
Eval_MinReturn : -40.533241271972656
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -55.1566047668457
Train_StdReturn : 15.613529205322266
Train_MaxReturn : -39.54307556152344
Train_MinReturn : -70.77013397216797
Train_AverageEpLen : 1000.0
Actor Loss : -835.5450439453125
Baseline Loss : 75.64244079589844
Train_EnvstepsSoFar : 525203
TimeSinceStart : 1467.4746968746185

********** Iteration 250 ************
Eval_AverageReturn : -14.337272644042969
Eval_StdReturn : 0.0
Eval_MaxReturn : -14.337272644042969
Eval_MinReturn : -14.337272644042969
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -60.360984802246094
Train_StdReturn : 3.2736740112304688
Train_MaxReturn : -57.087310791015625
Train_MinReturn : -63.63465881347656
Train_AverageEpLen : 1000.0
Actor Loss : -964.7618408203125
Baseline Loss : 64.8374252319336
Train_EnvstepsSoFar : 527203
TimeSinceStart : 1472.876400232315

********** Iteration 251 ************
Eval_AverageReturn : -26.956336975097656
Eval_StdReturn : 0.0
Eval_MaxReturn : -26.956336975097656
Eval_MinReturn : -26.956336975097656
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -54.29501724243164
Train_StdReturn : 36.105384826660156
Train_MaxReturn : -18.18963050842285
Train_MinReturn : -90.40040588378906
Train_AverageEpLen : 1000.0
Actor Loss : -431.17498779296875
Baseline Loss : 84.79927825927734
Train_EnvstepsSoFar : 529203
TimeSinceStart : 1476.698081254959

********** Iteration 252 ************
Eval_AverageReturn : -81.8655014038086
Eval_StdReturn : 0.0
Eval_MaxReturn : -81.8655014038086
Eval_MinReturn : -81.8655014038086
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -49.49164581298828
Train_StdReturn : 9.514673233032227
Train_MaxReturn : -39.97697448730469
Train_MinReturn : -59.00632095336914
Train_AverageEpLen : 1000.0
Actor Loss : -782.9270629882812
Baseline Loss : 64.02299499511719
Train_EnvstepsSoFar : 531203
TimeSinceStart : 1481.564064502716

********** Iteration 253 ************
Eval_AverageReturn : -99.72193908691406
Eval_StdReturn : 0.0
Eval_MaxReturn : -99.72193908691406
Eval_MinReturn : -99.72193908691406
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -59.70077133178711
Train_StdReturn : 8.311786651611328
Train_MaxReturn : -51.38898468017578
Train_MinReturn : -68.01255798339844
Train_AverageEpLen : 1000.0
Actor Loss : -798.371826171875
Baseline Loss : 106.85041809082031
Train_EnvstepsSoFar : 533203
TimeSinceStart : 1484.9697864055634

********** Iteration 254 ************
Eval_AverageReturn : -88.34561157226562
Eval_StdReturn : 0.0
Eval_MaxReturn : -88.34561157226562
Eval_MinReturn : -88.34561157226562
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -22.55797004699707
Train_StdReturn : 0.5870952606201172
Train_MaxReturn : -21.970874786376953
Train_MinReturn : -23.145065307617188
Train_AverageEpLen : 1000.0
Actor Loss : 378.1387939453125
Baseline Loss : 172.9696807861328
Train_EnvstepsSoFar : 535203
TimeSinceStart : 1489.0429632663727

********** Iteration 255 ************
Eval_AverageReturn : -81.75353240966797
Eval_StdReturn : 0.0
Eval_MaxReturn : -81.75353240966797
Eval_MinReturn : -81.75353240966797
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -49.14247131347656
Train_StdReturn : 18.934906005859375
Train_MaxReturn : -30.207565307617188
Train_MinReturn : -68.07737731933594
Train_AverageEpLen : 1000.0
Actor Loss : -135.0693359375
Baseline Loss : 171.18637084960938
Train_EnvstepsSoFar : 537203
TimeSinceStart : 1492.4544684886932

********** Iteration 256 ************
Eval_AverageReturn : -12.083232879638672
Eval_StdReturn : 0.0
Eval_MaxReturn : -12.083232879638672
Eval_MinReturn : -12.083232879638672
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -94.04080200195312
Train_StdReturn : 17.659366607666016
Train_MaxReturn : -76.38143157958984
Train_MinReturn : -111.70016479492188
Train_AverageEpLen : 1000.0
Actor Loss : -2114.55078125
Baseline Loss : 48.10860061645508
Train_EnvstepsSoFar : 539203
TimeSinceStart : 1496.5546100139618

********** Iteration 257 ************
Eval_AverageReturn : -64.97027587890625
Eval_StdReturn : 0.0
Eval_MaxReturn : -64.97027587890625
Eval_MinReturn : -64.97027587890625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -48.723976135253906
Train_StdReturn : 30.14928436279297
Train_MaxReturn : -18.574691772460938
Train_MinReturn : -78.87326049804688
Train_AverageEpLen : 1000.0
Actor Loss : -690.424072265625
Baseline Loss : 105.31700134277344
Train_EnvstepsSoFar : 541203
TimeSinceStart : 1500.2104485034943

********** Iteration 258 ************
Eval_AverageReturn : -76.11577606201172
Eval_StdReturn : 0.0
Eval_MaxReturn : -76.11577606201172
Eval_MinReturn : -76.11577606201172
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -51.08091735839844
Train_StdReturn : 17.27430534362793
Train_MaxReturn : -33.80661392211914
Train_MinReturn : -68.355224609375
Train_AverageEpLen : 1000.0
Actor Loss : -336.5032043457031
Baseline Loss : 91.87027740478516
Train_EnvstepsSoFar : 543203
TimeSinceStart : 1503.6193890571594

********** Iteration 259 ************
Eval_AverageReturn : -32.85740661621094
Eval_StdReturn : 0.0
Eval_MaxReturn : -32.85740661621094
Eval_MinReturn : -32.85740661621094
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -58.952110290527344
Train_StdReturn : 6.693397521972656
Train_MaxReturn : -52.25871276855469
Train_MinReturn : -65.6455078125
Train_AverageEpLen : 1000.0
Actor Loss : -832.7431640625
Baseline Loss : 61.685142517089844
Train_EnvstepsSoFar : 545203
TimeSinceStart : 1507.3002095222473

********** Iteration 260 ************
Eval_AverageReturn : -88.9976806640625
Eval_StdReturn : 0.0
Eval_MaxReturn : -88.9976806640625
Eval_MinReturn : -88.9976806640625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -53.07767868041992
Train_StdReturn : 6.011760711669922
Train_MaxReturn : -47.06591796875
Train_MinReturn : -59.089439392089844
Train_AverageEpLen : 1000.0
Actor Loss : -244.77288818359375
Baseline Loss : 52.10334014892578
Train_EnvstepsSoFar : 547203
TimeSinceStart : 1512.2881438732147

********** Iteration 261 ************
Eval_AverageReturn : -58.097938537597656
Eval_StdReturn : 0.0
Eval_MaxReturn : -58.097938537597656
Eval_MinReturn : -58.097938537597656
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -36.05942153930664
Train_StdReturn : 16.428791046142578
Train_MaxReturn : -19.630630493164062
Train_MinReturn : -52.48821258544922
Train_AverageEpLen : 1000.0
Actor Loss : 270.86358642578125
Baseline Loss : 87.40772247314453
Train_EnvstepsSoFar : 549203
TimeSinceStart : 1515.4621605873108

********** Iteration 262 ************
Eval_AverageReturn : -28.726234436035156
Eval_StdReturn : 0.0
Eval_MaxReturn : -28.726234436035156
Eval_MinReturn : -28.726234436035156
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -43.859161376953125
Train_StdReturn : 15.797117233276367
Train_MaxReturn : -28.06204605102539
Train_MinReturn : -59.656280517578125
Train_AverageEpLen : 1000.0
Actor Loss : 182.0502166748047
Baseline Loss : 87.25923156738281
Train_EnvstepsSoFar : 551203
TimeSinceStart : 1519.0391926765442

********** Iteration 263 ************
Eval_AverageReturn : -60.18141555786133
Eval_StdReturn : 0.0
Eval_MaxReturn : -60.18141555786133
Eval_MinReturn : -60.18141555786133
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -62.0612907409668
Train_StdReturn : 0.7837562561035156
Train_MaxReturn : -61.27753448486328
Train_MinReturn : -62.84504699707031
Train_AverageEpLen : 1000.0
Actor Loss : -745.8924560546875
Baseline Loss : 51.91753387451172
Train_EnvstepsSoFar : 553203
TimeSinceStart : 1522.398334980011

********** Iteration 264 ************
Eval_AverageReturn : -26.714244842529297
Eval_StdReturn : 0.0
Eval_MaxReturn : -26.714244842529297
Eval_MinReturn : -26.714244842529297
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -53.48956298828125
Train_StdReturn : 15.182249069213867
Train_MaxReturn : -38.307315826416016
Train_MinReturn : -68.67181396484375
Train_AverageEpLen : 1000.0
Actor Loss : -137.603759765625
Baseline Loss : 73.05787658691406
Train_EnvstepsSoFar : 555203
TimeSinceStart : 1526.0725631713867

********** Iteration 265 ************
Eval_AverageReturn : -56.177207946777344
Eval_StdReturn : 0.0
Eval_MaxReturn : -56.177207946777344
Eval_MinReturn : -56.177207946777344
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -49.1063117980957
Train_StdReturn : 3.5722084045410156
Train_MaxReturn : -45.53410339355469
Train_MinReturn : -52.67852020263672
Train_AverageEpLen : 1000.0
Actor Loss : -401.3156433105469
Baseline Loss : 81.62882232666016
Train_EnvstepsSoFar : 557203
TimeSinceStart : 1529.5528984069824

********** Iteration 266 ************
Eval_AverageReturn : -25.119651794433594
Eval_StdReturn : 0.0
Eval_MaxReturn : -25.119651794433594
Eval_MinReturn : -25.119651794433594
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -102.7962646484375
Train_StdReturn : 38.72683334350586
Train_MaxReturn : -58.94561004638672
Train_MinReturn : -153.1379852294922
Train_AverageEpLen : 941.0
Actor Loss : -3099.30322265625
Baseline Loss : 292.31243896484375
Train_EnvstepsSoFar : 560026
TimeSinceStart : 1533.1197152137756

********** Iteration 267 ************
Eval_AverageReturn : -73.65550231933594
Eval_StdReturn : 0.0
Eval_MaxReturn : -73.65550231933594
Eval_MinReturn : -73.65550231933594
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -44.050819396972656
Train_StdReturn : 29.90961265563965
Train_MaxReturn : -14.14120864868164
Train_MinReturn : -73.96043395996094
Train_AverageEpLen : 1000.0
Actor Loss : -150.7756805419922
Baseline Loss : 111.8772201538086
Train_EnvstepsSoFar : 562026
TimeSinceStart : 1536.5036706924438

********** Iteration 268 ************
Eval_AverageReturn : -32.529415130615234
Eval_StdReturn : 0.0
Eval_MaxReturn : -32.529415130615234
Eval_MinReturn : -32.529415130615234
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -70.1461181640625
Train_StdReturn : 17.37911033630371
Train_MaxReturn : -52.76700973510742
Train_MinReturn : -87.52523040771484
Train_AverageEpLen : 1000.0
Actor Loss : -689.7310791015625
Baseline Loss : 48.85948944091797
Train_EnvstepsSoFar : 564026
TimeSinceStart : 1540.6834526062012

********** Iteration 269 ************
Eval_AverageReturn : -49.07701110839844
Eval_StdReturn : 0.0
Eval_MaxReturn : -49.07701110839844
Eval_MinReturn : -49.07701110839844
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -53.86314392089844
Train_StdReturn : 28.28299903869629
Train_MaxReturn : -25.580142974853516
Train_MinReturn : -82.1461410522461
Train_AverageEpLen : 1000.0
Actor Loss : 9.933425903320312
Baseline Loss : 121.01991271972656
Train_EnvstepsSoFar : 566026
TimeSinceStart : 1544.2445316314697

********** Iteration 270 ************
Eval_AverageReturn : -73.73178100585938
Eval_StdReturn : 0.0
Eval_MaxReturn : -73.73178100585938
Eval_MinReturn : -73.73178100585938
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -58.36259841918945
Train_StdReturn : 30.254474639892578
Train_MaxReturn : -24.19805908203125
Train_MinReturn : -97.75154876708984
Train_AverageEpLen : 775.3333333333334
Actor Loss : -935.155517578125
Baseline Loss : 337.9361267089844
Train_EnvstepsSoFar : 568352
TimeSinceStart : 1548.251633644104

********** Iteration 271 ************
Eval_AverageReturn : -60.63541793823242
Eval_StdReturn : 0.0
Eval_MaxReturn : -60.63541793823242
Eval_MinReturn : -60.63541793823242
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -44.577266693115234
Train_StdReturn : 11.07534408569336
Train_MaxReturn : -33.501922607421875
Train_MinReturn : -55.652610778808594
Train_AverageEpLen : 1000.0
Actor Loss : -134.053955078125
Baseline Loss : 177.01438903808594
Train_EnvstepsSoFar : 570352
TimeSinceStart : 1551.766152381897

********** Iteration 272 ************
Eval_AverageReturn : -52.465980529785156
Eval_StdReturn : 0.0
Eval_MaxReturn : -52.465980529785156
Eval_MinReturn : -52.465980529785156
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -106.8912353515625
Train_StdReturn : 36.92094802856445
Train_MaxReturn : -67.32473754882812
Train_MinReturn : -156.18048095703125
Train_AverageEpLen : 986.0
Actor Loss : -2499.043701171875
Baseline Loss : 247.0503692626953
Train_EnvstepsSoFar : 573310
TimeSinceStart : 1555.8137917518616

********** Iteration 273 ************
Eval_AverageReturn : -88.29135131835938
Eval_StdReturn : 0.0
Eval_MaxReturn : -88.29135131835938
Eval_MinReturn : -88.29135131835938
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -65.92999267578125
Train_StdReturn : 20.780258178710938
Train_MaxReturn : -45.14973449707031
Train_MinReturn : -86.71025085449219
Train_AverageEpLen : 1000.0
Actor Loss : -314.95703125
Baseline Loss : 137.32875061035156
Train_EnvstepsSoFar : 575310
TimeSinceStart : 1559.020686864853

********** Iteration 274 ************
Eval_AverageReturn : -168.334228515625
Eval_StdReturn : 0.0
Eval_MaxReturn : -168.334228515625
Eval_MinReturn : -168.334228515625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -161.80596923828125
Train_StdReturn : 0.12189483642578125
Train_MaxReturn : -161.68408203125
Train_MinReturn : -161.92787170410156
Train_AverageEpLen : 1000.0
Actor Loss : -2413.36376953125
Baseline Loss : 113.0428695678711
Train_EnvstepsSoFar : 577310
TimeSinceStart : 1561.8101024627686

********** Iteration 275 ************
Eval_AverageReturn : -81.14422607421875
Eval_StdReturn : 0.0
Eval_MaxReturn : -81.14422607421875
Eval_MinReturn : -81.14422607421875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -147.7473602294922
Train_StdReturn : 12.435226440429688
Train_MaxReturn : -135.3121337890625
Train_MinReturn : -160.18258666992188
Train_AverageEpLen : 1000.0
Actor Loss : -1780.120849609375
Baseline Loss : 111.9602279663086
Train_EnvstepsSoFar : 579310
TimeSinceStart : 1565.0458252429962

********** Iteration 276 ************
Eval_AverageReturn : -112.818603515625
Eval_StdReturn : 0.0
Eval_MaxReturn : -112.818603515625
Eval_MinReturn : -112.818603515625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -122.16736602783203
Train_StdReturn : 15.309577941894531
Train_MaxReturn : -106.8577880859375
Train_MinReturn : -137.47694396972656
Train_AverageEpLen : 1000.0
Actor Loss : -1270.332763671875
Baseline Loss : 45.981319427490234
Train_EnvstepsSoFar : 581310
TimeSinceStart : 1568.7136404514313

********** Iteration 277 ************
Eval_AverageReturn : -131.47879028320312
Eval_StdReturn : 0.0
Eval_MaxReturn : -131.47879028320312
Eval_MinReturn : -131.47879028320312
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -137.97869873046875
Train_StdReturn : 59.52149963378906
Train_MaxReturn : -62.90379333496094
Train_MinReturn : -208.486328125
Train_AverageEpLen : 838.3333333333334
Actor Loss : -3146.725830078125
Baseline Loss : 582.1924438476562
Train_EnvstepsSoFar : 583825
TimeSinceStart : 1572.3535161018372

********** Iteration 278 ************
Eval_AverageReturn : -107.97477722167969
Eval_StdReturn : 0.0
Eval_MaxReturn : -107.97477722167969
Eval_MinReturn : -107.97477722167969
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -91.14557647705078
Train_StdReturn : 64.91227722167969
Train_MaxReturn : -44.797637939453125
Train_MinReturn : -182.94393920898438
Train_AverageEpLen : 901.0
Actor Loss : 546.5236206054688
Baseline Loss : 319.1195373535156
Train_EnvstepsSoFar : 586528
TimeSinceStart : 1576.049814939499

********** Iteration 279 ************
Eval_AverageReturn : -113.7223129272461
Eval_StdReturn : 0.0
Eval_MaxReturn : -113.7223129272461
Eval_MinReturn : -113.7223129272461
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -121.60797119140625
Train_StdReturn : 9.478485107421875
Train_MaxReturn : -112.12948608398438
Train_MinReturn : -131.08645629882812
Train_AverageEpLen : 1000.0
Actor Loss : 221.99667358398438
Baseline Loss : 53.995086669921875
Train_EnvstepsSoFar : 588528
TimeSinceStart : 1580.7140312194824

********** Iteration 280 ************
Eval_AverageReturn : -93.58651733398438
Eval_StdReturn : 0.0
Eval_MaxReturn : -93.58651733398438
Eval_MinReturn : -93.58651733398438
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -77.68461608886719
Train_StdReturn : 6.4647064208984375
Train_MaxReturn : -71.21990966796875
Train_MinReturn : -84.14932250976562
Train_AverageEpLen : 1000.0
Actor Loss : 1763.9871826171875
Baseline Loss : 160.0425567626953
Train_EnvstepsSoFar : 590528
TimeSinceStart : 1584.2155685424805

********** Iteration 281 ************
Eval_AverageReturn : -110.4516372680664
Eval_StdReturn : 0.0
Eval_MaxReturn : -110.4516372680664
Eval_MinReturn : -110.4516372680664
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -99.0545425415039
Train_StdReturn : 11.078544616699219
Train_MaxReturn : -87.97599792480469
Train_MinReturn : -110.13308715820312
Train_AverageEpLen : 1000.0
Actor Loss : 906.0186767578125
Baseline Loss : 85.2661361694336
Train_EnvstepsSoFar : 592528
TimeSinceStart : 1587.7801780700684

********** Iteration 282 ************
Eval_AverageReturn : -72.59026336669922
Eval_StdReturn : 0.0
Eval_MaxReturn : -72.59026336669922
Eval_MinReturn : -72.59026336669922
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -84.56118774414062
Train_StdReturn : 0.2180328369140625
Train_MaxReturn : -84.34315490722656
Train_MinReturn : -84.77922058105469
Train_AverageEpLen : 1000.0
Actor Loss : 948.9725952148438
Baseline Loss : 101.67081451416016
Train_EnvstepsSoFar : 594528
TimeSinceStart : 1591.4627468585968

********** Iteration 283 ************
Eval_AverageReturn : -118.97344970703125
Eval_StdReturn : 0.0
Eval_MaxReturn : -118.97344970703125
Eval_MinReturn : -118.97344970703125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -91.27044677734375
Train_StdReturn : 0.4087257385253906
Train_MaxReturn : -90.86172485351562
Train_MinReturn : -91.6791763305664
Train_AverageEpLen : 1000.0
Actor Loss : -394.63580322265625
Baseline Loss : 40.33222961425781
Train_EnvstepsSoFar : 596528
TimeSinceStart : 1594.8675153255463

********** Iteration 284 ************
Eval_AverageReturn : -96.09150695800781
Eval_StdReturn : 0.0
Eval_MaxReturn : -96.09150695800781
Eval_MinReturn : -96.09150695800781
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -90.80477142333984
Train_StdReturn : 22.823768615722656
Train_MaxReturn : -67.98100280761719
Train_MinReturn : -113.6285400390625
Train_AverageEpLen : 1000.0
Actor Loss : 475.529052734375
Baseline Loss : 63.07537841796875
Train_EnvstepsSoFar : 598528
TimeSinceStart : 1598.8031136989594

********** Iteration 285 ************
Eval_AverageReturn : -93.91345977783203
Eval_StdReturn : 0.0
Eval_MaxReturn : -93.91345977783203
Eval_MinReturn : -93.91345977783203
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -75.69322204589844
Train_StdReturn : 30.315921783447266
Train_MaxReturn : -45.377296447753906
Train_MinReturn : -106.00914001464844
Train_AverageEpLen : 1000.0
Actor Loss : 325.4759521484375
Baseline Loss : 77.33992767333984
Train_EnvstepsSoFar : 600528
TimeSinceStart : 1601.9783737659454

********** Iteration 286 ************
Eval_AverageReturn : -66.75682830810547
Eval_StdReturn : 0.0
Eval_MaxReturn : -66.75682830810547
Eval_MinReturn : -66.75682830810547
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -82.12899780273438
Train_StdReturn : 36.64773941040039
Train_MaxReturn : -45.48125457763672
Train_MinReturn : -118.7767333984375
Train_AverageEpLen : 1000.0
Actor Loss : 156.467041015625
Baseline Loss : 61.6252326965332
Train_EnvstepsSoFar : 602528
TimeSinceStart : 1605.7129402160645

********** Iteration 287 ************
Eval_AverageReturn : -24.277812957763672
Eval_StdReturn : 0.0
Eval_MaxReturn : -24.277812957763672
Eval_MinReturn : -24.277812957763672
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -82.93510437011719
Train_StdReturn : 8.870967864990234
Train_MaxReturn : -74.06413269042969
Train_MinReturn : -91.80606842041016
Train_AverageEpLen : 1000.0
Actor Loss : -294.31536865234375
Baseline Loss : 29.488632202148438
Train_EnvstepsSoFar : 604528
TimeSinceStart : 1609.6453614234924

********** Iteration 288 ************
Eval_AverageReturn : -42.186302185058594
Eval_StdReturn : 0.0
Eval_MaxReturn : -42.186302185058594
Eval_MinReturn : -42.186302185058594
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -80.65289306640625
Train_StdReturn : 6.281284809112549
Train_MaxReturn : -74.37161254882812
Train_MinReturn : -86.9341812133789
Train_AverageEpLen : 1000.0
Actor Loss : -533.5293579101562
Baseline Loss : 50.73290252685547
Train_EnvstepsSoFar : 606528
TimeSinceStart : 1613.3353388309479

********** Iteration 289 ************
Eval_AverageReturn : -72.94465637207031
Eval_StdReturn : 0.0
Eval_MaxReturn : -72.94465637207031
Eval_MinReturn : -72.94465637207031
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -30.299497604370117
Train_StdReturn : 10.722299575805664
Train_MaxReturn : -19.577198028564453
Train_MinReturn : -41.02179718017578
Train_AverageEpLen : 1000.0
Actor Loss : 899.8568115234375
Baseline Loss : 153.7771453857422
Train_EnvstepsSoFar : 608528
TimeSinceStart : 1616.782029390335

********** Iteration 290 ************
Eval_AverageReturn : -47.528831481933594
Eval_StdReturn : 0.0
Eval_MaxReturn : -47.528831481933594
Eval_MinReturn : -47.528831481933594
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -49.518463134765625
Train_StdReturn : 8.029333114624023
Train_MaxReturn : -41.48912811279297
Train_MinReturn : -57.547794342041016
Train_AverageEpLen : 1000.0
Actor Loss : 426.67523193359375
Baseline Loss : 121.60688781738281
Train_EnvstepsSoFar : 610528
TimeSinceStart : 1619.5953640937805

********** Iteration 291 ************
Eval_AverageReturn : -50.73125457763672
Eval_StdReturn : 0.0
Eval_MaxReturn : -50.73125457763672
Eval_MinReturn : -50.73125457763672
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -67.49664306640625
Train_StdReturn : 0.002803805051371455
Train_MaxReturn : -67.49384307861328
Train_MinReturn : -67.49945068359375
Train_AverageEpLen : 1000.0
Actor Loss : -500.7093505859375
Baseline Loss : 42.45484161376953
Train_EnvstepsSoFar : 612528
TimeSinceStart : 1623.2681810855865

********** Iteration 292 ************
Eval_AverageReturn : -35.48912048339844
Eval_StdReturn : 0.0
Eval_MaxReturn : -35.48912048339844
Eval_MinReturn : -35.48912048339844
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -54.47368621826172
Train_StdReturn : 11.219720840454102
Train_MaxReturn : -43.253963470458984
Train_MinReturn : -65.69340515136719
Train_AverageEpLen : 1000.0
Actor Loss : 47.24939727783203
Baseline Loss : 59.72174835205078
Train_EnvstepsSoFar : 614528
TimeSinceStart : 1627.384203195572

********** Iteration 293 ************
Eval_AverageReturn : -3.8387451171875
Eval_StdReturn : 0.0
Eval_MaxReturn : -3.8387451171875
Eval_MinReturn : -3.8387451171875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -23.981040954589844
Train_StdReturn : 28.443180084228516
Train_MaxReturn : 4.462139129638672
Train_MinReturn : -52.42422103881836
Train_AverageEpLen : 1000.0
Actor Loss : 304.6517333984375
Baseline Loss : 93.06468200683594
Train_EnvstepsSoFar : 616528
TimeSinceStart : 1630.3875641822815

********** Iteration 294 ************
Eval_AverageReturn : 11.096824645996094
Eval_StdReturn : 0.0
Eval_MaxReturn : 11.096824645996094
Eval_MinReturn : 11.096824645996094
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -21.82069206237793
Train_StdReturn : 12.574914932250977
Train_MaxReturn : -9.245777130126953
Train_MinReturn : -34.395606994628906
Train_AverageEpLen : 1000.0
Actor Loss : 519.4732666015625
Baseline Loss : 85.25070190429688
Train_EnvstepsSoFar : 618528
TimeSinceStart : 1633.4876985549927

********** Iteration 295 ************
Eval_AverageReturn : -16.588031768798828
Eval_StdReturn : 0.0
Eval_MaxReturn : -16.588031768798828
Eval_MinReturn : -16.588031768798828
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -33.646766662597656
Train_StdReturn : 12.799504280090332
Train_MaxReturn : -20.847261428833008
Train_MinReturn : -46.44626998901367
Train_AverageEpLen : 1000.0
Actor Loss : -406.08905029296875
Baseline Loss : 41.600852966308594
Train_EnvstepsSoFar : 620528
TimeSinceStart : 1637.7076511383057

********** Iteration 296 ************
Eval_AverageReturn : -19.950984954833984
Eval_StdReturn : 0.0
Eval_MaxReturn : -19.950984954833984
Eval_MinReturn : -19.950984954833984
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -26.112886428833008
Train_StdReturn : 14.100820541381836
Train_MaxReturn : -12.012065887451172
Train_MinReturn : -40.213706970214844
Train_AverageEpLen : 1000.0
Actor Loss : -436.67156982421875
Baseline Loss : 89.10923767089844
Train_EnvstepsSoFar : 622528
TimeSinceStart : 1641.420231103897

********** Iteration 297 ************
Eval_AverageReturn : -8.64566421508789
Eval_StdReturn : 0.0
Eval_MaxReturn : -8.64566421508789
Eval_MinReturn : -8.64566421508789
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -3.723597526550293
Train_StdReturn : 17.262287139892578
Train_MaxReturn : 13.538690567016602
Train_MinReturn : -20.985885620117188
Train_AverageEpLen : 1000.0
Actor Loss : 439.4689025878906
Baseline Loss : 129.93603515625
Train_EnvstepsSoFar : 624528
TimeSinceStart : 1644.1316504478455

********** Iteration 298 ************
Eval_AverageReturn : -30.579788208007812
Eval_StdReturn : 0.0
Eval_MaxReturn : -30.579788208007812
Eval_MinReturn : -30.579788208007812
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -51.348052978515625
Train_StdReturn : 15.461030960083008
Train_MaxReturn : -35.887020111083984
Train_MinReturn : -66.80908203125
Train_AverageEpLen : 1000.0
Actor Loss : -1725.4781494140625
Baseline Loss : 29.094757080078125
Train_EnvstepsSoFar : 626528
TimeSinceStart : 1648.113075017929

********** Iteration 299 ************
Eval_AverageReturn : -54.98744201660156
Eval_StdReturn : 0.0
Eval_MaxReturn : -54.98744201660156
Eval_MinReturn : -54.98744201660156
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -62.18138885498047
Train_StdReturn : 17.85615348815918
Train_MaxReturn : -44.32523727416992
Train_MinReturn : -80.03754425048828
Train_AverageEpLen : 1000.0
Actor Loss : -1505.13134765625
Baseline Loss : 44.198997497558594
Train_EnvstepsSoFar : 628528
TimeSinceStart : 1651.721736907959

Process finished with exit code 0
