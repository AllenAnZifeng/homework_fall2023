C:\My_Project\ALLEN_Python\homework_fall2023\venv\Scripts\python.exe C:\My_Project\ALLEN_Python\homework_fall2023\hw2\cs285\scripts\run_hw2.py --env_name CartPole-v0 -n 100 -b 4000 -rtg --exp_name cartpole_lb_rtg
########################
logging outputs to  C:\My_Project\ALLEN_Python\homework_fall2023\hw2\cs285\scripts\../../data\q2_pg_cartpole_lb_rtg_CartPole-v0_25-09-2023_20-53-22
########################
Using CPU.

********** Iteration 0 ************
C:\My_Project\ALLEN_Python\homework_fall2023\venv\lib\site-packages\gym\envs\registration.py:593: UserWarning: WARN: The environment CartPole-v0 is out of date. You should consider upgrading to version `v1`.
  logger.warn(
C:\My_Project\ALLEN_Python\homework_fall2023\venv\lib\site-packages\gym\core.py:317: DeprecationWarning: WARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.
  deprecation(
C:\My_Project\ALLEN_Python\homework_fall2023\venv\lib\site-packages\gym\wrappers\step_api_compatibility.py:39: DeprecationWarning: WARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.
  deprecation(
C:\My_Project\ALLEN_Python\homework_fall2023\venv\lib\site-packages\gym\utils\passive_env_checker.py:241: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
Eval_AverageReturn : 38.181819915771484
Eval_StdReturn : 16.672340393066406
Eval_MaxReturn : 71.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 38.18181818181818
Train_AverageReturn : 23.745561599731445
Train_StdReturn : 13.925003051757812
Train_MaxReturn : 99.0
Train_MinReturn : 9.0
Train_AverageEpLen : 23.745562130177515
Actor Loss : 45357.9921875
Train_EnvstepsSoFar : 4013
TimeSinceStart : 1.2637622356414795
Initial_DataCollection_AverageReturn : 23.745561599731445

********** Iteration 1 ************
C:\My_Project\ALLEN_Python\homework_fall2023\venv\lib\site-packages\tensorboardX\summary.py:153: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)
  scalar = float(scalar)
Eval_AverageReturn : 56.5
Eval_StdReturn : 33.14739990234375
Eval_MaxReturn : 111.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 56.5
Train_AverageReturn : 32.055999755859375
Train_StdReturn : 17.092363357543945
Train_MaxReturn : 86.0
Train_MinReturn : 11.0
Train_AverageEpLen : 32.056
Actor Loss : 55850.09765625
Train_EnvstepsSoFar : 8020
TimeSinceStart : 2.4766933917999268

********** Iteration 2 ************
Eval_AverageReturn : 51.0
Eval_StdReturn : 18.61450958251953
Eval_MaxReturn : 84.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 51.0
Train_AverageReturn : 40.767677307128906
Train_StdReturn : 19.606651306152344
Train_MaxReturn : 107.0
Train_MinReturn : 12.0
Train_AverageEpLen : 40.76767676767677
Actor Loss : 65873.921875
Train_EnvstepsSoFar : 12056
TimeSinceStart : 3.689155340194702

********** Iteration 3 ************
Eval_AverageReturn : 107.25
Eval_StdReturn : 57.119937896728516
Eval_MaxReturn : 200.0
Eval_MinReturn : 44.0
Eval_AverageEpLen : 107.25
Train_AverageReturn : 55.095890045166016
Train_StdReturn : 26.85841178894043
Train_MaxReturn : 154.0
Train_MinReturn : 10.0
Train_AverageEpLen : 55.0958904109589
Actor Loss : 85637.953125
Train_EnvstepsSoFar : 16078
TimeSinceStart : 4.9271252155303955

********** Iteration 4 ************
Eval_AverageReturn : 90.19999694824219
Eval_StdReturn : 36.94536590576172
Eval_MaxReturn : 160.0
Eval_MinReturn : 54.0
Eval_AverageEpLen : 90.2
Train_AverageReturn : 64.7741928100586
Train_StdReturn : 31.01166343688965
Train_MaxReturn : 163.0
Train_MinReturn : 20.0
Train_AverageEpLen : 64.7741935483871
Actor Loss : 97659.359375
Train_EnvstepsSoFar : 20094
TimeSinceStart : 6.183553695678711

********** Iteration 5 ************
Eval_AverageReturn : 63.28571319580078
Eval_StdReturn : 19.69564437866211
Eval_MaxReturn : 103.0
Eval_MinReturn : 36.0
Eval_AverageEpLen : 63.285714285714285
Train_AverageReturn : 65.12903594970703
Train_StdReturn : 28.613374710083008
Train_MaxReturn : 134.0
Train_MinReturn : 20.0
Train_AverageEpLen : 65.12903225806451
Actor Loss : 91899.4140625
Train_EnvstepsSoFar : 24132
TimeSinceStart : 7.454845428466797

********** Iteration 6 ************
Eval_AverageReturn : 86.0
Eval_StdReturn : 21.232051849365234
Eval_MaxReturn : 113.0
Eval_MinReturn : 60.0
Eval_AverageEpLen : 86.0
Train_AverageReturn : 82.04081726074219
Train_StdReturn : 41.09370040893555
Train_MaxReturn : 200.0
Train_MinReturn : 35.0
Train_AverageEpLen : 82.04081632653062
Actor Loss : 119534.6484375
Train_EnvstepsSoFar : 28152
TimeSinceStart : 8.694446086883545

********** Iteration 7 ************
Eval_AverageReturn : 134.6666717529297
Eval_StdReturn : 23.58436393737793
Eval_MaxReturn : 168.0
Eval_MinReturn : 117.0
Eval_AverageEpLen : 134.66666666666666
Train_AverageReturn : 94.97674560546875
Train_StdReturn : 25.985225677490234
Train_MaxReturn : 167.0
Train_MinReturn : 41.0
Train_AverageEpLen : 94.97674418604652
Actor Loss : 115650.1171875
Train_EnvstepsSoFar : 32236
TimeSinceStart : 9.945748567581177

********** Iteration 8 ************
Eval_AverageReturn : 132.75
Eval_StdReturn : 55.47690963745117
Eval_MaxReturn : 200.0
Eval_MinReturn : 76.0
Eval_AverageEpLen : 132.75
Train_AverageReturn : 124.2727279663086
Train_StdReturn : 42.68863296508789
Train_MaxReturn : 200.0
Train_MinReturn : 53.0
Train_AverageEpLen : 124.27272727272727
Actor Loss : 157025.109375
Train_EnvstepsSoFar : 36337
TimeSinceStart : 11.253389596939087

********** Iteration 9 ************
Eval_AverageReturn : 188.6666717529297
Eval_StdReturn : 16.027753829956055
Eval_MaxReturn : 200.0
Eval_MinReturn : 166.0
Eval_AverageEpLen : 188.66666666666666
Train_AverageReturn : 136.43333435058594
Train_StdReturn : 43.46162033081055
Train_MaxReturn : 200.0
Train_MinReturn : 45.0
Train_AverageEpLen : 136.43333333333334
Actor Loss : 166042.546875
Train_EnvstepsSoFar : 40430
TimeSinceStart : 12.533409833908081

********** Iteration 10 ************
Eval_AverageReturn : 107.5
Eval_StdReturn : 43.31570053100586
Eval_MaxReturn : 162.0
Eval_MinReturn : 49.0
Eval_AverageEpLen : 107.5
Train_AverageReturn : 150.77777099609375
Train_StdReturn : 32.21379089355469
Train_MaxReturn : 200.0
Train_MinReturn : 95.0
Train_AverageEpLen : 150.77777777777777
Actor Loss : 172289.328125
Train_EnvstepsSoFar : 44501
TimeSinceStart : 13.780426979064941

********** Iteration 11 ************
Eval_AverageReturn : 137.3333282470703
Eval_StdReturn : 19.48218536376953
Eval_MaxReturn : 164.0
Eval_MinReturn : 118.0
Eval_AverageEpLen : 137.33333333333334
Train_AverageReturn : 140.89654541015625
Train_StdReturn : 46.70697021484375
Train_MaxReturn : 200.0
Train_MinReturn : 44.0
Train_AverageEpLen : 140.89655172413794
Actor Loss : 167687.03125
Train_EnvstepsSoFar : 48587
TimeSinceStart : 15.004334688186646

********** Iteration 12 ************
Eval_AverageReturn : 161.0
Eval_StdReturn : 31.968734741210938
Eval_MaxReturn : 198.0
Eval_MinReturn : 120.0
Eval_AverageEpLen : 161.0
Train_AverageReturn : 158.03846740722656
Train_StdReturn : 34.68593215942383
Train_MaxReturn : 200.0
Train_MinReturn : 97.0
Train_AverageEpLen : 158.03846153846155
Actor Loss : 178525.59375
Train_EnvstepsSoFar : 52696
TimeSinceStart : 16.345849752426147

********** Iteration 13 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 168.2916717529297
Train_StdReturn : 37.66129684448242
Train_MaxReturn : 200.0
Train_MinReturn : 93.0
Train_AverageEpLen : 168.29166666666666
Actor Loss : 183961.71875
Train_EnvstepsSoFar : 56735
TimeSinceStart : 17.5559823513031

********** Iteration 14 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 175.47825622558594
Train_StdReturn : 34.5855827331543
Train_MaxReturn : 200.0
Train_MinReturn : 93.0
Train_AverageEpLen : 175.47826086956522
Actor Loss : 186511.140625
Train_EnvstepsSoFar : 60771
TimeSinceStart : 18.755992650985718

********** Iteration 15 ************
Eval_AverageReturn : 160.6666717529297
Eval_StdReturn : 7.3635735511779785
Eval_MaxReturn : 170.0
Eval_MinReturn : 152.0
Eval_AverageEpLen : 160.66666666666666
Train_AverageReturn : 176.30435180664062
Train_StdReturn : 33.328975677490234
Train_MaxReturn : 200.0
Train_MinReturn : 111.0
Train_AverageEpLen : 176.30434782608697
Actor Loss : 188442.625
Train_EnvstepsSoFar : 64826
TimeSinceStart : 19.98424983024597

********** Iteration 16 ************
Eval_AverageReturn : 151.6666717529297
Eval_StdReturn : 34.47060012817383
Eval_MaxReturn : 200.0
Eval_MinReturn : 122.0
Eval_AverageEpLen : 151.66666666666666
Train_AverageReturn : 182.31817626953125
Train_StdReturn : 26.746938705444336
Train_MaxReturn : 200.0
Train_MinReturn : 111.0
Train_AverageEpLen : 182.3181818181818
Actor Loss : 187516.484375
Train_EnvstepsSoFar : 68837
TimeSinceStart : 21.219247341156006

********** Iteration 17 ************
Eval_AverageReturn : 162.3333282470703
Eval_StdReturn : 26.787227630615234
Eval_MaxReturn : 200.0
Eval_MinReturn : 140.0
Eval_AverageEpLen : 162.33333333333334
Train_AverageReturn : 172.0
Train_StdReturn : 31.240999221801758
Train_MaxReturn : 200.0
Train_MinReturn : 105.0
Train_AverageEpLen : 172.0
Actor Loss : 183987.15625
Train_EnvstepsSoFar : 72965
TimeSinceStart : 22.481747150421143

********** Iteration 18 ************
Eval_AverageReturn : 116.0
Eval_StdReturn : 16.07793426513672
Eval_MaxReturn : 141.0
Eval_MinReturn : 98.0
Eval_AverageEpLen : 116.0
Train_AverageReturn : 131.90322875976562
Train_StdReturn : 21.341093063354492
Train_MaxReturn : 200.0
Train_MinReturn : 108.0
Train_AverageEpLen : 131.90322580645162
Actor Loss : 133401.921875
Train_EnvstepsSoFar : 77054
TimeSinceStart : 23.72378182411194

********** Iteration 19 ************
Eval_AverageReturn : 103.25
Eval_StdReturn : 17.583728790283203
Eval_MaxReturn : 123.0
Eval_MinReturn : 75.0
Eval_AverageEpLen : 103.25
Train_AverageReturn : 100.6500015258789
Train_StdReturn : 27.741260528564453
Train_MaxReturn : 134.0
Train_MinReturn : 36.0
Train_AverageEpLen : 100.65
Actor Loss : 103569.4609375
Train_EnvstepsSoFar : 81080
TimeSinceStart : 24.93266725540161

********** Iteration 20 ************
Eval_AverageReturn : 107.5
Eval_StdReturn : 3.2015621662139893
Eval_MaxReturn : 112.0
Eval_MinReturn : 104.0
Eval_AverageEpLen : 107.5
Train_AverageReturn : 92.7727279663086
Train_StdReturn : 28.783567428588867
Train_MaxReturn : 124.0
Train_MinReturn : 28.0
Train_AverageEpLen : 92.77272727272727
Actor Loss : 94960.1875
Train_EnvstepsSoFar : 85162
TimeSinceStart : 26.19401526451111

********** Iteration 21 ************
Eval_AverageReturn : 112.5
Eval_StdReturn : 8.958236694335938
Eval_MaxReturn : 122.0
Eval_MinReturn : 98.0
Eval_AverageEpLen : 112.5
Train_AverageReturn : 91.88636016845703
Train_StdReturn : 28.986059188842773
Train_MaxReturn : 132.0
Train_MinReturn : 38.0
Train_AverageEpLen : 91.88636363636364
Actor Loss : 96606.0390625
Train_EnvstepsSoFar : 89205
TimeSinceStart : 27.41665267944336

********** Iteration 22 ************
Eval_AverageReturn : 122.5
Eval_StdReturn : 10.781929016113281
Eval_MaxReturn : 141.0
Eval_MinReturn : 114.0
Eval_AverageEpLen : 122.5
Train_AverageReturn : 100.4749984741211
Train_StdReturn : 28.450822830200195
Train_MaxReturn : 135.0
Train_MinReturn : 26.0
Train_AverageEpLen : 100.475
Actor Loss : 100821.6328125
Train_EnvstepsSoFar : 93224
TimeSinceStart : 28.656742811203003

********** Iteration 23 ************
Eval_AverageReturn : 119.5
Eval_StdReturn : 11.258330345153809
Eval_MaxReturn : 138.0
Eval_MinReturn : 108.0
Eval_AverageEpLen : 119.5
Train_AverageReturn : 113.52777862548828
Train_StdReturn : 14.207756042480469
Train_MaxReturn : 138.0
Train_MinReturn : 49.0
Train_AverageEpLen : 113.52777777777777
Actor Loss : 107358.9140625
Train_EnvstepsSoFar : 97311
TimeSinceStart : 29.882741689682007

********** Iteration 24 ************
Eval_AverageReturn : 137.0
Eval_StdReturn : 12.027746200561523
Eval_MaxReturn : 150.0
Eval_MinReturn : 121.0
Eval_AverageEpLen : 137.0
Train_AverageReturn : 120.35294342041016
Train_StdReturn : 16.424304962158203
Train_MaxReturn : 155.0
Train_MinReturn : 53.0
Train_AverageEpLen : 120.3529411764706
Actor Loss : 114042.609375
Train_EnvstepsSoFar : 101403
TimeSinceStart : 31.099918603897095

********** Iteration 25 ************
Eval_AverageReturn : 143.6666717529297
Eval_StdReturn : 7.717224597930908
Eval_MaxReturn : 151.0
Eval_MinReturn : 133.0
Eval_AverageEpLen : 143.66666666666666
Train_AverageReturn : 132.06451416015625
Train_StdReturn : 14.895194053649902
Train_MaxReturn : 166.0
Train_MinReturn : 104.0
Train_AverageEpLen : 132.06451612903226
Actor Loss : 120992.1640625
Train_EnvstepsSoFar : 105497
TimeSinceStart : 32.32589888572693

********** Iteration 26 ************
Eval_AverageReturn : 162.0
Eval_StdReturn : 5.099019527435303
Eval_MaxReturn : 167.0
Eval_MinReturn : 155.0
Eval_AverageEpLen : 162.0
Train_AverageReturn : 142.13792419433594
Train_StdReturn : 19.283233642578125
Train_MaxReturn : 186.0
Train_MinReturn : 120.0
Train_AverageEpLen : 142.13793103448276
Actor Loss : 131553.359375
Train_EnvstepsSoFar : 109619
TimeSinceStart : 33.5737030506134

********** Iteration 27 ************
Eval_AverageReturn : 184.3333282470703
Eval_StdReturn : 17.441967010498047
Eval_MaxReturn : 200.0
Eval_MinReturn : 160.0
Eval_AverageEpLen : 184.33333333333334
Train_AverageReturn : 158.57691955566406
Train_StdReturn : 20.422786712646484
Train_MaxReturn : 200.0
Train_MinReturn : 121.0
Train_AverageEpLen : 158.57692307692307
Actor Loss : 140480.34375
Train_EnvstepsSoFar : 113742
TimeSinceStart : 34.852824449539185

********** Iteration 28 ************
Eval_AverageReturn : 193.0
Eval_StdReturn : 7.874007701873779
Eval_MaxReturn : 200.0
Eval_MinReturn : 182.0
Eval_AverageEpLen : 193.0
Train_AverageReturn : 181.90908813476562
Train_StdReturn : 17.979557037353516
Train_MaxReturn : 200.0
Train_MinReturn : 142.0
Train_AverageEpLen : 181.9090909090909
Actor Loss : 158253.28125
Train_EnvstepsSoFar : 117744
TimeSinceStart : 36.13530230522156

********** Iteration 29 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 184.81817626953125
Train_StdReturn : 20.078563690185547
Train_MaxReturn : 200.0
Train_MinReturn : 133.0
Train_AverageEpLen : 184.8181818181818
Actor Loss : 163123.046875
Train_EnvstepsSoFar : 121810
TimeSinceStart : 37.33317279815674

********** Iteration 30 ************
Eval_AverageReturn : 169.3333282470703
Eval_StdReturn : 19.669490814208984
Eval_MaxReturn : 197.0
Eval_MinReturn : 153.0
Eval_AverageEpLen : 169.33333333333334
Train_AverageReturn : 187.90908813476562
Train_StdReturn : 14.314356803894043
Train_MaxReturn : 200.0
Train_MinReturn : 156.0
Train_AverageEpLen : 187.9090909090909
Actor Loss : 163732.359375
Train_EnvstepsSoFar : 125944
TimeSinceStart : 38.62014651298523

********** Iteration 31 ************
Eval_AverageReturn : 179.3333282470703
Eval_StdReturn : 20.885934829711914
Eval_MaxReturn : 197.0
Eval_MinReturn : 150.0
Eval_AverageEpLen : 179.33333333333334
Train_AverageReturn : 185.90908813476562
Train_StdReturn : 20.328907012939453
Train_MaxReturn : 200.0
Train_MinReturn : 137.0
Train_AverageEpLen : 185.9090909090909
Actor Loss : 159966.640625
Train_EnvstepsSoFar : 130034
TimeSinceStart : 39.89584541320801

********** Iteration 32 ************
Eval_AverageReturn : 157.3333282470703
Eval_StdReturn : 19.136934280395508
Eval_MaxReturn : 184.0
Eval_MinReturn : 140.0
Eval_AverageEpLen : 157.33333333333334
Train_AverageReturn : 179.86956787109375
Train_StdReturn : 16.477399826049805
Train_MaxReturn : 200.0
Train_MinReturn : 151.0
Train_AverageEpLen : 179.8695652173913
Actor Loss : 153230.53125
Train_EnvstepsSoFar : 134171
TimeSinceStart : 41.13841724395752

********** Iteration 33 ************
Eval_AverageReturn : 178.0
Eval_StdReturn : 9.092121124267578
Eval_MaxReturn : 190.0
Eval_MinReturn : 168.0
Eval_AverageEpLen : 178.0
Train_AverageReturn : 160.23077392578125
Train_StdReturn : 18.56238555908203
Train_MaxReturn : 200.0
Train_MinReturn : 134.0
Train_AverageEpLen : 160.23076923076923
Actor Loss : 138945.390625
Train_EnvstepsSoFar : 138337
TimeSinceStart : 42.4370539188385

********** Iteration 34 ************
Eval_AverageReturn : 169.0
Eval_StdReturn : 22.105806350708008
Eval_MaxReturn : 200.0
Eval_MinReturn : 150.0
Eval_AverageEpLen : 169.0
Train_AverageReturn : 165.75999450683594
Train_StdReturn : 20.578203201293945
Train_MaxReturn : 200.0
Train_MinReturn : 138.0
Train_AverageEpLen : 165.76
Actor Loss : 140284.515625
Train_EnvstepsSoFar : 142481
TimeSinceStart : 43.806957960128784

********** Iteration 35 ************
Eval_AverageReturn : 161.6666717529297
Eval_StdReturn : 2.8674418926239014
Eval_MaxReturn : 165.0
Eval_MinReturn : 158.0
Eval_AverageEpLen : 161.66666666666666
Train_AverageReturn : 162.1199951171875
Train_StdReturn : 21.109846115112305
Train_MaxReturn : 200.0
Train_MinReturn : 124.0
Train_AverageEpLen : 162.12
Actor Loss : 137471.34375
Train_EnvstepsSoFar : 146534
TimeSinceStart : 45.061829805374146

********** Iteration 36 ************
Eval_AverageReturn : 197.6666717529297
Eval_StdReturn : 3.2998316287994385
Eval_MaxReturn : 200.0
Eval_MinReturn : 193.0
Eval_AverageEpLen : 197.66666666666666
Train_AverageReturn : 174.2916717529297
Train_StdReturn : 19.62668228149414
Train_MaxReturn : 200.0
Train_MinReturn : 135.0
Train_AverageEpLen : 174.29166666666666
Actor Loss : 144888.03125
Train_EnvstepsSoFar : 150717
TimeSinceStart : 46.36277890205383

********** Iteration 37 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 188.0454559326172
Train_StdReturn : 14.965042114257812
Train_MaxReturn : 200.0
Train_MinReturn : 153.0
Train_AverageEpLen : 188.04545454545453
Actor Loss : 155789.75
Train_EnvstepsSoFar : 154854
TimeSinceStart : 47.59232521057129

********** Iteration 38 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 195.3333282470703
Train_StdReturn : 8.481539726257324
Train_MaxReturn : 200.0
Train_MinReturn : 171.0
Train_AverageEpLen : 195.33333333333334
Actor Loss : 158203.109375
Train_EnvstepsSoFar : 158956
TimeSinceStart : 48.8136420249939

********** Iteration 39 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 197.85714721679688
Train_StdReturn : 5.717855453491211
Train_MaxReturn : 200.0
Train_MinReturn : 177.0
Train_AverageEpLen : 197.85714285714286
Actor Loss : 166107.1875
Train_EnvstepsSoFar : 163111
TimeSinceStart : 50.02714562416077

********** Iteration 40 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 197.23809814453125
Train_StdReturn : 6.209860324859619
Train_MaxReturn : 200.0
Train_MinReturn : 179.0
Train_AverageEpLen : 197.23809523809524
Actor Loss : 160024.390625
Train_EnvstepsSoFar : 167253
TimeSinceStart : 51.24482011795044

********** Iteration 41 ************
Eval_AverageReturn : 187.6666717529297
Eval_StdReturn : 17.441967010498047
Eval_MaxReturn : 200.0
Eval_MinReturn : 163.0
Eval_AverageEpLen : 187.66666666666666
Train_AverageReturn : 194.4761962890625
Train_StdReturn : 10.196260452270508
Train_MaxReturn : 200.0
Train_MinReturn : 166.0
Train_AverageEpLen : 194.47619047619048
Actor Loss : 154311.671875
Train_EnvstepsSoFar : 171337
TimeSinceStart : 52.4922821521759

********** Iteration 42 ************
Eval_AverageReturn : 189.6666717529297
Eval_StdReturn : 7.586537837982178
Eval_MaxReturn : 200.0
Eval_MinReturn : 182.0
Eval_AverageEpLen : 189.66666666666666
Train_AverageReturn : 193.2857208251953
Train_StdReturn : 10.845857620239258
Train_MaxReturn : 200.0
Train_MinReturn : 164.0
Train_AverageEpLen : 193.28571428571428
Actor Loss : 163489.09375
Train_EnvstepsSoFar : 175396
TimeSinceStart : 53.75796127319336

********** Iteration 43 ************
Eval_AverageReturn : 160.6666717529297
Eval_StdReturn : 13.59738540649414
Eval_MaxReturn : 174.0
Eval_MinReturn : 142.0
Eval_AverageEpLen : 160.66666666666666
Train_AverageReturn : 175.21739196777344
Train_StdReturn : 20.250511169433594
Train_MaxReturn : 200.0
Train_MinReturn : 146.0
Train_AverageEpLen : 175.2173913043478
Actor Loss : 139380.5
Train_EnvstepsSoFar : 179426
TimeSinceStart : 54.96060562133789

********** Iteration 44 ************
Eval_AverageReturn : 147.6666717529297
Eval_StdReturn : 14.659089088439941
Eval_MaxReturn : 168.0
Eval_MinReturn : 134.0
Eval_AverageEpLen : 147.66666666666666
Train_AverageReturn : 163.47999572753906
Train_StdReturn : 19.538925170898438
Train_MaxReturn : 200.0
Train_MinReturn : 133.0
Train_AverageEpLen : 163.48
Actor Loss : 139709.078125
Train_EnvstepsSoFar : 183513
TimeSinceStart : 56.178875207901

********** Iteration 45 ************
Eval_AverageReturn : 136.5
Eval_StdReturn : 14.115593910217285
Eval_MaxReturn : 155.0
Eval_MinReturn : 120.0
Eval_AverageEpLen : 136.5
Train_AverageReturn : 149.88888549804688
Train_StdReturn : 13.177796363830566
Train_MaxReturn : 174.0
Train_MinReturn : 128.0
Train_AverageEpLen : 149.88888888888889
Actor Loss : 119792.765625
Train_EnvstepsSoFar : 187560
TimeSinceStart : 57.4423942565918

********** Iteration 46 ************
Eval_AverageReturn : 137.6666717529297
Eval_StdReturn : 11.841547012329102
Eval_MaxReturn : 152.0
Eval_MinReturn : 123.0
Eval_AverageEpLen : 137.66666666666666
Train_AverageReturn : 143.07142639160156
Train_StdReturn : 14.215003967285156
Train_MaxReturn : 178.0
Train_MinReturn : 111.0
Train_AverageEpLen : 143.07142857142858
Actor Loss : 121422.6484375
Train_EnvstepsSoFar : 191566
TimeSinceStart : 58.62607765197754

********** Iteration 47 ************
Eval_AverageReturn : 135.5
Eval_StdReturn : 13.275918006896973
Eval_MaxReturn : 157.0
Eval_MinReturn : 124.0
Eval_AverageEpLen : 135.5
Train_AverageReturn : 137.8000030517578
Train_StdReturn : 11.335490226745605
Train_MaxReturn : 172.0
Train_MinReturn : 119.0
Train_AverageEpLen : 137.8
Actor Loss : 116932.1484375
Train_EnvstepsSoFar : 195700
TimeSinceStart : 59.88721323013306

********** Iteration 48 ************
Eval_AverageReturn : 135.6666717529297
Eval_StdReturn : 10.208929061889648
Eval_MaxReturn : 148.0
Eval_MinReturn : 123.0
Eval_AverageEpLen : 135.66666666666666
Train_AverageReturn : 135.8000030517578
Train_StdReturn : 11.838918685913086
Train_MaxReturn : 157.0
Train_MinReturn : 117.0
Train_AverageEpLen : 135.8
Actor Loss : 117526.6484375
Train_EnvstepsSoFar : 199774
TimeSinceStart : 61.07385492324829

********** Iteration 49 ************
Eval_AverageReturn : 130.25
Eval_StdReturn : 5.117372512817383
Eval_MaxReturn : 136.0
Eval_MinReturn : 122.0
Eval_AverageEpLen : 130.25
Train_AverageReturn : 135.96665954589844
Train_StdReturn : 10.762537956237793
Train_MaxReturn : 154.0
Train_MinReturn : 115.0
Train_AverageEpLen : 135.96666666666667
Actor Loss : 117265.421875
Train_EnvstepsSoFar : 203853
TimeSinceStart : 62.31984066963196

********** Iteration 50 ************
Eval_AverageReturn : 134.5
Eval_StdReturn : 6.72681188583374
Eval_MaxReturn : 144.0
Eval_MinReturn : 125.0
Eval_AverageEpLen : 134.5
Train_AverageReturn : 138.72413635253906
Train_StdReturn : 13.229790687561035
Train_MaxReturn : 166.0
Train_MinReturn : 119.0
Train_AverageEpLen : 138.72413793103448
Actor Loss : 121571.5390625
Train_EnvstepsSoFar : 207876
TimeSinceStart : 63.56270170211792

********** Iteration 51 ************
Eval_AverageReturn : 135.0
Eval_StdReturn : 4.898979663848877
Eval_MaxReturn : 141.0
Eval_MinReturn : 129.0
Eval_AverageEpLen : 135.0
Train_AverageReturn : 142.72413635253906
Train_StdReturn : 12.059898376464844
Train_MaxReturn : 174.0
Train_MinReturn : 123.0
Train_AverageEpLen : 142.72413793103448
Actor Loss : 128989.8515625
Train_EnvstepsSoFar : 212015
TimeSinceStart : 64.78376626968384

********** Iteration 52 ************
Eval_AverageReturn : 153.0
Eval_StdReturn : 9.201449394226074
Eval_MaxReturn : 160.0
Eval_MinReturn : 140.0
Eval_AverageEpLen : 153.0
Train_AverageReturn : 149.6666717529297
Train_StdReturn : 11.969096183776855
Train_MaxReturn : 170.0
Train_MinReturn : 120.0
Train_AverageEpLen : 149.66666666666666
Actor Loss : 131745.390625
Train_EnvstepsSoFar : 216056
TimeSinceStart : 66.05022692680359

********** Iteration 53 ************
Eval_AverageReturn : 183.3333282470703
Eval_StdReturn : 8.379870414733887
Eval_MaxReturn : 192.0
Eval_MinReturn : 172.0
Eval_AverageEpLen : 183.33333333333334
Train_AverageReturn : 155.61538696289062
Train_StdReturn : 11.354689598083496
Train_MaxReturn : 179.0
Train_MinReturn : 135.0
Train_AverageEpLen : 155.6153846153846
Actor Loss : 138876.96875
Train_EnvstepsSoFar : 220102
TimeSinceStart : 67.31628727912903

********** Iteration 54 ************
Eval_AverageReturn : 179.3333282470703
Eval_StdReturn : 13.474255561828613
Eval_MaxReturn : 193.0
Eval_MinReturn : 161.0
Eval_AverageEpLen : 179.33333333333334
Train_AverageReturn : 167.1666717529297
Train_StdReturn : 11.319845199584961
Train_MaxReturn : 190.0
Train_MinReturn : 145.0
Train_AverageEpLen : 167.16666666666666
Actor Loss : 147885.109375
Train_EnvstepsSoFar : 224114
TimeSinceStart : 68.55514883995056

********** Iteration 55 ************
Eval_AverageReturn : 190.0
Eval_StdReturn : 3.265986442565918
Eval_MaxReturn : 194.0
Eval_MinReturn : 186.0
Eval_AverageEpLen : 190.0
Train_AverageReturn : 177.82608032226562
Train_StdReturn : 14.991744041442871
Train_MaxReturn : 200.0
Train_MinReturn : 151.0
Train_AverageEpLen : 177.82608695652175
Actor Loss : 165755.328125
Train_EnvstepsSoFar : 228204
TimeSinceStart : 69.8434898853302

********** Iteration 56 ************
Eval_AverageReturn : 194.6666717529297
Eval_StdReturn : 7.542471885681152
Eval_MaxReturn : 200.0
Eval_MinReturn : 184.0
Eval_AverageEpLen : 194.66666666666666
Train_AverageReturn : 189.77272033691406
Train_StdReturn : 11.75481128692627
Train_MaxReturn : 200.0
Train_MinReturn : 161.0
Train_AverageEpLen : 189.77272727272728
Actor Loss : 180946.59375
Train_EnvstepsSoFar : 232379
TimeSinceStart : 71.19153165817261

********** Iteration 57 ************
Eval_AverageReturn : 191.6666717529297
Eval_StdReturn : 1.247219204902649
Eval_MaxReturn : 193.0
Eval_MinReturn : 190.0
Eval_AverageEpLen : 191.66666666666666
Train_AverageReturn : 194.14285278320312
Train_StdReturn : 7.093160152435303
Train_MaxReturn : 200.0
Train_MinReturn : 178.0
Train_AverageEpLen : 194.14285714285714
Actor Loss : 179092.546875
Train_EnvstepsSoFar : 236456
TimeSinceStart : 72.47637724876404

********** Iteration 58 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 198.23809814453125
Train_StdReturn : 4.081371784210205
Train_MaxReturn : 200.0
Train_MinReturn : 183.0
Train_AverageEpLen : 198.23809523809524
Actor Loss : 190949.953125
Train_EnvstepsSoFar : 240619
TimeSinceStart : 73.71130585670471

********** Iteration 59 ************
Eval_AverageReturn : 198.0
Eval_StdReturn : 2.8284270763397217
Eval_MaxReturn : 200.0
Eval_MinReturn : 194.0
Eval_AverageEpLen : 198.0
Train_AverageReturn : 198.8095245361328
Train_StdReturn : 2.9539167881011963
Train_MaxReturn : 200.0
Train_MinReturn : 188.0
Train_AverageEpLen : 198.8095238095238
Actor Loss : 192131.375
Train_EnvstepsSoFar : 244794
TimeSinceStart : 75.02637958526611

********** Iteration 60 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 199.6666717529297
Train_StdReturn : 1.4907118082046509
Train_MaxReturn : 200.0
Train_MinReturn : 193.0
Train_AverageEpLen : 199.66666666666666
Actor Loss : 195929.734375
Train_EnvstepsSoFar : 248987
TimeSinceStart : 76.27349257469177

********** Iteration 61 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 186681.71875
Train_EnvstepsSoFar : 252987
TimeSinceStart : 77.4837076663971

********** Iteration 62 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 188266.171875
Train_EnvstepsSoFar : 256987
TimeSinceStart : 78.65601587295532

********** Iteration 63 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 191474.390625
Train_EnvstepsSoFar : 260987
TimeSinceStart : 79.83598446846008

********** Iteration 64 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 191201.625
Train_EnvstepsSoFar : 264987
TimeSinceStart : 81.02506566047668

********** Iteration 65 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 189993.796875
Train_EnvstepsSoFar : 268987
TimeSinceStart : 82.1971492767334

********** Iteration 66 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 192060.90625
Train_EnvstepsSoFar : 272987
TimeSinceStart : 83.39261198043823

********** Iteration 67 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 194111.765625
Train_EnvstepsSoFar : 276987
TimeSinceStart : 84.57396936416626

********** Iteration 68 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 195606.96875
Train_EnvstepsSoFar : 280987
TimeSinceStart : 85.760178565979

********** Iteration 69 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 195793.59375
Train_EnvstepsSoFar : 284987
TimeSinceStart : 86.923992395401

********** Iteration 70 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 195720.6875
Train_EnvstepsSoFar : 288987
TimeSinceStart : 88.10412383079529

********** Iteration 71 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 201230.90625
Train_EnvstepsSoFar : 292987
TimeSinceStart : 89.27490448951721

********** Iteration 72 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 197758.03125
Train_EnvstepsSoFar : 296987
TimeSinceStart : 90.46084094047546

********** Iteration 73 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 202285.734375
Train_EnvstepsSoFar : 300987
TimeSinceStart : 91.66253614425659

********** Iteration 74 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 201935.53125
Train_EnvstepsSoFar : 304987
TimeSinceStart : 92.8548891544342

********** Iteration 75 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 199727.25
Train_EnvstepsSoFar : 308987
TimeSinceStart : 94.04076313972473

********** Iteration 76 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 201589.28125
Train_EnvstepsSoFar : 312987
TimeSinceStart : 95.21349692344666

********** Iteration 77 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 202314.8125
Train_EnvstepsSoFar : 316987
TimeSinceStart : 96.38944363594055

********** Iteration 78 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 203350.15625
Train_EnvstepsSoFar : 320987
TimeSinceStart : 97.55609059333801

********** Iteration 79 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 199.85714721679688
Train_StdReturn : 0.6388765573501587
Train_MaxReturn : 200.0
Train_MinReturn : 197.0
Train_AverageEpLen : 199.85714285714286
Actor Loss : 213491.625
Train_EnvstepsSoFar : 325184
TimeSinceStart : 98.80316877365112

********** Iteration 80 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 191.42857360839844
Train_StdReturn : 38.33259201049805
Train_MaxReturn : 200.0
Train_MinReturn : 20.0
Train_AverageEpLen : 191.42857142857142
Actor Loss : 207134.71875
Train_EnvstepsSoFar : 329204
TimeSinceStart : 99.98398685455322

********** Iteration 81 ************
Eval_AverageReturn : 139.0
Eval_StdReturn : 86.26702880859375
Eval_MaxReturn : 200.0
Eval_MinReturn : 17.0
Eval_AverageEpLen : 139.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 207782.25
Train_EnvstepsSoFar : 333204
TimeSinceStart : 101.16851449012756

********** Iteration 82 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 206704.6875
Train_EnvstepsSoFar : 337204
TimeSinceStart : 102.33796048164368

********** Iteration 83 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 166.63999938964844
Train_StdReturn : 66.81430053710938
Train_MaxReturn : 200.0
Train_MinReturn : 13.0
Train_AverageEpLen : 166.64
Actor Loss : 207142.390625
Train_EnvstepsSoFar : 341370
TimeSinceStart : 103.55760049819946

********** Iteration 84 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 186.18182373046875
Train_StdReturn : 43.713565826416016
Train_MaxReturn : 200.0
Train_MinReturn : 44.0
Train_AverageEpLen : 186.1818181818182
Actor Loss : 205906.25
Train_EnvstepsSoFar : 345466
TimeSinceStart : 104.78335356712341

********** Iteration 85 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 179.3478240966797
Train_StdReturn : 54.679786682128906
Train_MaxReturn : 200.0
Train_MinReturn : 16.0
Train_AverageEpLen : 179.34782608695653
Actor Loss : 204461.359375
Train_EnvstepsSoFar : 349591
TimeSinceStart : 105.99633479118347

********** Iteration 86 ************
Eval_AverageReturn : 187.6666717529297
Eval_StdReturn : 4.9888763427734375
Eval_MaxReturn : 193.0
Eval_MinReturn : 181.0
Eval_AverageEpLen : 187.66666666666666
Train_AverageReturn : 151.48147583007812
Train_StdReturn : 79.30315399169922
Train_MaxReturn : 200.0
Train_MinReturn : 13.0
Train_AverageEpLen : 151.4814814814815
Actor Loss : 197845.515625
Train_EnvstepsSoFar : 353681
TimeSinceStart : 107.24029684066772

********** Iteration 87 ************
Eval_AverageReturn : 174.6666717529297
Eval_StdReturn : 3.0912060737609863
Eval_MaxReturn : 179.0
Eval_MinReturn : 172.0
Eval_AverageEpLen : 174.66666666666666
Train_AverageReturn : 149.8518524169922
Train_StdReturn : 70.13040924072266
Train_MaxReturn : 200.0
Train_MinReturn : 16.0
Train_AverageEpLen : 149.85185185185185
Actor Loss : 186707.6875
Train_EnvstepsSoFar : 357727
TimeSinceStart : 108.4550096988678

********** Iteration 88 ************
Eval_AverageReturn : 89.33333587646484
Eval_StdReturn : 69.71051025390625
Eval_MaxReturn : 168.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 89.33333333333333
Train_AverageReturn : 116.17142486572266
Train_StdReturn : 72.24461364746094
Train_MaxReturn : 187.0
Train_MinReturn : 15.0
Train_AverageEpLen : 116.17142857142858
Actor Loss : 161235.53125
Train_EnvstepsSoFar : 361793
TimeSinceStart : 109.68037009239197

********** Iteration 89 ************
Eval_AverageReturn : 119.0
Eval_StdReturn : 58.89397430419922
Eval_MaxReturn : 154.0
Eval_MinReturn : 17.0
Eval_AverageEpLen : 119.0
Train_AverageReturn : 124.0
Train_StdReturn : 59.91408157348633
Train_MaxReturn : 177.0
Train_MinReturn : 17.0
Train_AverageEpLen : 124.0
Actor Loss : 154554.234375
Train_EnvstepsSoFar : 365885
TimeSinceStart : 110.91339039802551

********** Iteration 90 ************
Eval_AverageReturn : 154.0
Eval_StdReturn : 11.518101692199707
Eval_MaxReturn : 169.0
Eval_MinReturn : 141.0
Eval_AverageEpLen : 154.0
Train_AverageReturn : 137.56666564941406
Train_StdReturn : 40.551761627197266
Train_MaxReturn : 169.0
Train_MinReturn : 18.0
Train_AverageEpLen : 137.56666666666666
Actor Loss : 146377.1875
Train_EnvstepsSoFar : 370012
TimeSinceStart : 112.1441707611084

********** Iteration 91 ************
Eval_AverageReturn : 152.6666717529297
Eval_StdReturn : 3.0912060737609863
Eval_MaxReturn : 157.0
Eval_MinReturn : 150.0
Eval_AverageEpLen : 152.66666666666666
Train_AverageReturn : 152.70370483398438
Train_StdReturn : 6.294116973876953
Train_MaxReturn : 174.0
Train_MinReturn : 142.0
Train_AverageEpLen : 152.7037037037037
Actor Loss : 150443.90625
Train_EnvstepsSoFar : 374135
TimeSinceStart : 113.3823447227478

********** Iteration 92 ************
Eval_AverageReturn : 154.6666717529297
Eval_StdReturn : 5.792715549468994
Eval_MaxReturn : 161.0
Eval_MinReturn : 147.0
Eval_AverageEpLen : 154.66666666666666
Train_AverageReturn : 146.35714721679688
Train_StdReturn : 25.26462173461914
Train_MaxReturn : 167.0
Train_MinReturn : 19.0
Train_AverageEpLen : 146.35714285714286
Actor Loss : 146372.75
Train_EnvstepsSoFar : 378233
TimeSinceStart : 114.6052827835083

********** Iteration 93 ************
Eval_AverageReturn : 154.6666717529297
Eval_StdReturn : 7.408703327178955
Eval_MaxReturn : 163.0
Eval_MinReturn : 145.0
Eval_AverageEpLen : 154.66666666666666
Train_AverageReturn : 146.42857360839844
Train_StdReturn : 26.137588500976562
Train_MaxReturn : 167.0
Train_MinReturn : 16.0
Train_AverageEpLen : 146.42857142857142
Actor Loss : 149294.203125
Train_EnvstepsSoFar : 382333
TimeSinceStart : 115.81839990615845

********** Iteration 94 ************
Eval_AverageReturn : 156.3333282470703
Eval_StdReturn : 7.586537837982178
Eval_MaxReturn : 167.0
Eval_MinReturn : 150.0
Eval_AverageEpLen : 156.33333333333334
Train_AverageReturn : 152.88888549804688
Train_StdReturn : 7.728415012359619
Train_MaxReturn : 167.0
Train_MinReturn : 140.0
Train_AverageEpLen : 152.88888888888889
Actor Loss : 152489.546875
Train_EnvstepsSoFar : 386461
TimeSinceStart : 117.03798604011536

********** Iteration 95 ************
Eval_AverageReturn : 154.3333282470703
Eval_StdReturn : 0.471404492855072
Eval_MaxReturn : 155.0
Eval_MinReturn : 154.0
Eval_AverageEpLen : 154.33333333333334
Train_AverageReturn : 152.8518524169922
Train_StdReturn : 7.599725723266602
Train_MaxReturn : 167.0
Train_MinReturn : 140.0
Train_AverageEpLen : 152.85185185185185
Actor Loss : 153675.421875
Train_EnvstepsSoFar : 390588
TimeSinceStart : 118.2478518486023

********** Iteration 96 ************
Eval_AverageReturn : 164.6666717529297
Eval_StdReturn : 2.054804801940918
Eval_MaxReturn : 167.0
Eval_MinReturn : 162.0
Eval_AverageEpLen : 164.66666666666666
Train_AverageReturn : 151.11111450195312
Train_StdReturn : 27.451417922973633
Train_MaxReturn : 170.0
Train_MinReturn : 16.0
Train_AverageEpLen : 151.11111111111111
Actor Loss : 152660.46875
Train_EnvstepsSoFar : 394668
TimeSinceStart : 119.50639915466309

********** Iteration 97 ************
Eval_AverageReturn : 173.6666717529297
Eval_StdReturn : 7.7602972984313965
Eval_MaxReturn : 183.0
Eval_MinReturn : 164.0
Eval_AverageEpLen : 173.66666666666666
Train_AverageReturn : 160.55999755859375
Train_StdReturn : 8.227174758911133
Train_MaxReturn : 183.0
Train_MinReturn : 149.0
Train_AverageEpLen : 160.56
Actor Loss : 155683.8125
Train_EnvstepsSoFar : 398682
TimeSinceStart : 120.7831289768219

********** Iteration 98 ************
Eval_AverageReturn : 168.0
Eval_StdReturn : 8.164965629577637
Eval_MaxReturn : 178.0
Eval_MinReturn : 158.0
Eval_AverageEpLen : 168.0
Train_AverageReturn : 164.8800048828125
Train_StdReturn : 6.677245140075684
Train_MaxReturn : 182.0
Train_MinReturn : 152.0
Train_AverageEpLen : 164.88
Actor Loss : 164946.828125
Train_EnvstepsSoFar : 402804
TimeSinceStart : 121.97939038276672

********** Iteration 99 ************
Eval_AverageReturn : 183.6666717529297
Eval_StdReturn : 4.109609127044678
Eval_MaxReturn : 189.0
Eval_MinReturn : 179.0
Eval_AverageEpLen : 183.66666666666666
Train_AverageReturn : 174.17391967773438
Train_StdReturn : 7.269065856933594
Train_MaxReturn : 190.0
Train_MinReturn : 158.0
Train_AverageEpLen : 174.17391304347825
Actor Loss : 171854.71875
Train_EnvstepsSoFar : 406810
TimeSinceStart : 123.15778708457947

Process finished with exit code 0
