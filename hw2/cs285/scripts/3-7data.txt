C:\My_Project\ALLEN_Python\homework_fall2023\venv\Scripts\python.exe C:\My_Project\ALLEN_Python\homework_fall2023\hw2\cs285\scripts\run_hw2.py --env_name CartPole-v0 -n 100 -b 4000 -na --exp_name cartpole_lb_na
########################
logging outputs to  C:\My_Project\ALLEN_Python\homework_fall2023\hw2\cs285\scripts\../../data\q2_pg_cartpole_lb_na_CartPole-v0_25-09-2023_20-37-31
########################
Using CPU.

********** Iteration 0 ************
C:\My_Project\ALLEN_Python\homework_fall2023\venv\lib\site-packages\gym\envs\registration.py:593: UserWarning: WARN: The environment CartPole-v0 is out of date. You should consider upgrading to version `v1`.
  logger.warn(
C:\My_Project\ALLEN_Python\homework_fall2023\venv\lib\site-packages\gym\core.py:317: DeprecationWarning: WARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.
  deprecation(
C:\My_Project\ALLEN_Python\homework_fall2023\venv\lib\site-packages\gym\wrappers\step_api_compatibility.py:39: DeprecationWarning: WARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.
  deprecation(
C:\My_Project\ALLEN_Python\homework_fall2023\venv\lib\site-packages\gym\utils\passive_env_checker.py:241: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
C:\My_Project\ALLEN_Python\homework_fall2023\venv\lib\site-packages\tensorboardX\summary.py:153: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)
  scalar = float(scalar)
Eval_AverageReturn : 37.08333206176758
Eval_StdReturn : 17.12920570373535
Eval_MaxReturn : 65.0
Eval_MinReturn : 12.0
Eval_AverageEpLen : 37.083333333333336
Train_AverageReturn : 24.26060676574707
Train_StdReturn : 13.744376182556152
Train_MaxReturn : 99.0
Train_MinReturn : 9.0
Train_AverageEpLen : 24.26060606060606
Actor Loss : -10.082426071166992
Train_EnvstepsSoFar : 4003
TimeSinceStart : 1.3278601169586182
Initial_DataCollection_AverageReturn : 24.26060676574707

********** Iteration 1 ************
Eval_AverageReturn : 45.0
Eval_StdReturn : 16.44992446899414
Eval_MaxReturn : 77.0
Eval_MinReturn : 12.0
Eval_AverageEpLen : 45.0
Train_AverageReturn : 32.74796676635742
Train_StdReturn : 18.59696388244629
Train_MaxReturn : 100.0
Train_MinReturn : 10.0
Train_AverageEpLen : 32.7479674796748
Actor Loss : -46.577476501464844
Train_EnvstepsSoFar : 8031
TimeSinceStart : 2.626950740814209

********** Iteration 2 ************
Eval_AverageReturn : 58.0
Eval_StdReturn : 20.560884475708008
Eval_MaxReturn : 93.0
Eval_MinReturn : 26.0
Eval_AverageEpLen : 58.0
Train_AverageReturn : 39.77450942993164
Train_StdReturn : 18.734420776367188
Train_MaxReturn : 91.0
Train_MinReturn : 9.0
Train_AverageEpLen : 39.77450980392157
Actor Loss : -61.443878173828125
Train_EnvstepsSoFar : 12088
TimeSinceStart : 4.138798236846924

********** Iteration 3 ************
Eval_AverageReturn : 79.33333587646484
Eval_StdReturn : 33.15452194213867
Eval_MaxReturn : 149.0
Eval_MinReturn : 50.0
Eval_AverageEpLen : 79.33333333333333
Train_AverageReturn : 53.746665954589844
Train_StdReturn : 28.8804874420166
Train_MaxReturn : 154.0
Train_MinReturn : 20.0
Train_AverageEpLen : 53.74666666666667
Actor Loss : -17.532817840576172
Train_EnvstepsSoFar : 16119
TimeSinceStart : 5.540771722793579

********** Iteration 4 ************
Eval_AverageReturn : 75.5
Eval_StdReturn : 34.14064025878906
Eval_MaxReturn : 139.0
Eval_MinReturn : 37.0
Eval_AverageEpLen : 75.5
Train_AverageReturn : 57.42856979370117
Train_StdReturn : 23.612689971923828
Train_MaxReturn : 123.0
Train_MinReturn : 18.0
Train_AverageEpLen : 57.42857142857143
Actor Loss : -43.14259338378906
Train_EnvstepsSoFar : 20139
TimeSinceStart : 6.914638042449951

********** Iteration 5 ************
Eval_AverageReturn : 65.28571319580078
Eval_StdReturn : 15.21009349822998
Eval_MaxReturn : 94.0
Eval_MinReturn : 43.0
Eval_AverageEpLen : 65.28571428571429
Train_AverageReturn : 70.40351104736328
Train_StdReturn : 29.80984115600586
Train_MaxReturn : 133.0
Train_MinReturn : 19.0
Train_AverageEpLen : 70.40350877192982
Actor Loss : -44.604156494140625
Train_EnvstepsSoFar : 24152
TimeSinceStart : 8.482237815856934

********** Iteration 6 ************
Eval_AverageReturn : 111.75
Eval_StdReturn : 27.426036834716797
Eval_MaxReturn : 159.0
Eval_MinReturn : 92.0
Eval_AverageEpLen : 111.75
Train_AverageReturn : 88.06521606445312
Train_StdReturn : 40.1472282409668
Train_MaxReturn : 200.0
Train_MinReturn : 37.0
Train_AverageEpLen : 88.06521739130434
Actor Loss : -19.74896812438965
Train_EnvstepsSoFar : 28203
TimeSinceStart : 9.85664963722229

********** Iteration 7 ************
Eval_AverageReturn : 68.14286041259766
Eval_StdReturn : 18.87120819091797
Eval_MaxReturn : 97.0
Eval_MinReturn : 49.0
Eval_AverageEpLen : 68.14285714285714
Train_AverageReturn : 103.07691955566406
Train_StdReturn : 34.59463882446289
Train_MaxReturn : 200.0
Train_MinReturn : 42.0
Train_AverageEpLen : 103.07692307692308
Actor Loss : -25.22596549987793
Train_EnvstepsSoFar : 32223
TimeSinceStart : 11.259360074996948

********** Iteration 8 ************
Eval_AverageReturn : 86.19999694824219
Eval_StdReturn : 18.977882385253906
Eval_MaxReturn : 123.0
Eval_MinReturn : 70.0
Eval_AverageEpLen : 86.2
Train_AverageReturn : 86.38298034667969
Train_StdReturn : 37.21161651611328
Train_MaxReturn : 200.0
Train_MinReturn : 35.0
Train_AverageEpLen : 86.38297872340425
Actor Loss : -12.600332260131836
Train_EnvstepsSoFar : 36283
TimeSinceStart : 12.635133981704712

********** Iteration 9 ************
Eval_AverageReturn : 151.0
Eval_StdReturn : 47.3356819152832
Eval_MaxReturn : 200.0
Eval_MinReturn : 87.0
Eval_AverageEpLen : 151.0
Train_AverageReturn : 105.66666412353516
Train_StdReturn : 39.76297378540039
Train_MaxReturn : 200.0
Train_MinReturn : 35.0
Train_AverageEpLen : 105.66666666666667
Actor Loss : -9.033340454101562
Train_EnvstepsSoFar : 40404
TimeSinceStart : 14.015836954116821

********** Iteration 10 ************
Eval_AverageReturn : 150.0
Eval_StdReturn : 12.569805145263672
Eval_MaxReturn : 163.0
Eval_MinReturn : 133.0
Eval_AverageEpLen : 150.0
Train_AverageReturn : 140.7586212158203
Train_StdReturn : 47.89979553222656
Train_MaxReturn : 200.0
Train_MinReturn : 58.0
Train_AverageEpLen : 140.75862068965517
Actor Loss : -54.95158767700195
Train_EnvstepsSoFar : 44486
TimeSinceStart : 15.400508642196655

********** Iteration 11 ************
Eval_AverageReturn : 185.6666717529297
Eval_StdReturn : 11.841547012329102
Eval_MaxReturn : 200.0
Eval_MinReturn : 171.0
Eval_AverageEpLen : 185.66666666666666
Train_AverageReturn : 169.25
Train_StdReturn : 30.205202102661133
Train_MaxReturn : 200.0
Train_MinReturn : 86.0
Train_AverageEpLen : 169.25
Actor Loss : -46.59601593017578
Train_EnvstepsSoFar : 48548
TimeSinceStart : 16.81695318222046

********** Iteration 12 ************
Eval_AverageReturn : 196.0
Eval_StdReturn : 4.966554641723633
Eval_MaxReturn : 200.0
Eval_MinReturn : 189.0
Eval_AverageEpLen : 196.0
Train_AverageReturn : 167.9583282470703
Train_StdReturn : 27.51284408569336
Train_MaxReturn : 200.0
Train_MinReturn : 106.0
Train_AverageEpLen : 167.95833333333334
Actor Loss : -50.4727668762207
Train_EnvstepsSoFar : 52579
TimeSinceStart : 18.194807052612305

********** Iteration 13 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 178.82608032226562
Train_StdReturn : 24.36614227294922
Train_MaxReturn : 200.0
Train_MinReturn : 127.0
Train_AverageEpLen : 178.82608695652175
Actor Loss : -36.94813537597656
Train_EnvstepsSoFar : 56692
TimeSinceStart : 19.55009651184082

********** Iteration 14 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 184.63636779785156
Train_StdReturn : 25.82906150817871
Train_MaxReturn : 200.0
Train_MinReturn : 120.0
Train_AverageEpLen : 184.63636363636363
Actor Loss : -53.33363723754883
Train_EnvstepsSoFar : 60754
TimeSinceStart : 20.909456253051758

********** Iteration 15 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 199.1904754638672
Train_StdReturn : 3.620300769805908
Train_MaxReturn : 200.0
Train_MinReturn : 183.0
Train_AverageEpLen : 199.1904761904762
Actor Loss : 10.355718612670898
Train_EnvstepsSoFar : 64937
TimeSinceStart : 22.28642511367798

********** Iteration 16 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 190.13636779785156
Train_StdReturn : 23.96075439453125
Train_MaxReturn : 200.0
Train_MinReturn : 111.0
Train_AverageEpLen : 190.13636363636363
Actor Loss : -13.512980461120605
Train_EnvstepsSoFar : 69120
TimeSinceStart : 23.672932624816895

********** Iteration 17 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 199.1904754638672
Train_StdReturn : 3.620300769805908
Train_MaxReturn : 200.0
Train_MinReturn : 183.0
Train_AverageEpLen : 199.1904761904762
Actor Loss : 38.98219680786133
Train_EnvstepsSoFar : 73303
TimeSinceStart : 25.079023361206055

********** Iteration 18 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -0.0
Train_EnvstepsSoFar : 77303
TimeSinceStart : 26.492603540420532

********** Iteration 19 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -0.0
Train_EnvstepsSoFar : 81303
TimeSinceStart : 27.979370832443237

********** Iteration 20 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -0.0
Train_EnvstepsSoFar : 85303
TimeSinceStart : 29.385549545288086

********** Iteration 21 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 198.38095092773438
Train_StdReturn : 7.240601539611816
Train_MaxReturn : 200.0
Train_MinReturn : 166.0
Train_AverageEpLen : 198.38095238095238
Actor Loss : -49.111900329589844
Train_EnvstepsSoFar : 89469
TimeSinceStart : 30.773892641067505

********** Iteration 22 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -0.0
Train_EnvstepsSoFar : 93469
TimeSinceStart : 32.086101055145264

********** Iteration 23 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 195.2857208251953
Train_StdReturn : 21.082927703857422
Train_MaxReturn : 200.0
Train_MinReturn : 101.0
Train_AverageEpLen : 195.28571428571428
Actor Loss : -56.188560485839844
Train_EnvstepsSoFar : 97570
TimeSinceStart : 33.49767541885376

********** Iteration 24 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -0.0
Train_EnvstepsSoFar : 101570
TimeSinceStart : 34.84149241447449

********** Iteration 25 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -0.0
Train_EnvstepsSoFar : 105570
TimeSinceStart : 36.21495985984802

********** Iteration 26 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -0.0
Train_EnvstepsSoFar : 109570
TimeSinceStart : 37.52828598022461

********** Iteration 27 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -0.0
Train_EnvstepsSoFar : 113570
TimeSinceStart : 38.892178535461426

********** Iteration 28 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -0.0
Train_EnvstepsSoFar : 117570
TimeSinceStart : 40.1631965637207

********** Iteration 29 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -0.0
Train_EnvstepsSoFar : 121570
TimeSinceStart : 41.48077917098999

********** Iteration 30 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -0.0
Train_EnvstepsSoFar : 125570
TimeSinceStart : 42.856995582580566

********** Iteration 31 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -0.0
Train_EnvstepsSoFar : 129570
TimeSinceStart : 44.146636962890625

********** Iteration 32 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -0.0
Train_EnvstepsSoFar : 133570
TimeSinceStart : 45.48793959617615

********** Iteration 33 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -0.0
Train_EnvstepsSoFar : 137570
TimeSinceStart : 46.79596281051636

********** Iteration 34 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -0.0
Train_EnvstepsSoFar : 141570
TimeSinceStart : 48.13956308364868

********** Iteration 35 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -0.0
Train_EnvstepsSoFar : 145570
TimeSinceStart : 49.47956347465515

********** Iteration 36 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -0.0
Train_EnvstepsSoFar : 149570
TimeSinceStart : 50.80686664581299

********** Iteration 37 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -0.0
Train_EnvstepsSoFar : 153570
TimeSinceStart : 52.14072847366333

********** Iteration 38 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -0.0
Train_EnvstepsSoFar : 157570
TimeSinceStart : 53.53743505477905

********** Iteration 39 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -0.0
Train_EnvstepsSoFar : 161570
TimeSinceStart : 54.86335468292236

********** Iteration 40 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -0.0
Train_EnvstepsSoFar : 165570
TimeSinceStart : 56.249021768569946

********** Iteration 41 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -0.0
Train_EnvstepsSoFar : 169570
TimeSinceStart : 57.588048696517944

********** Iteration 42 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -0.0
Train_EnvstepsSoFar : 173570
TimeSinceStart : 58.91083288192749

********** Iteration 43 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -0.0
Train_EnvstepsSoFar : 177570
TimeSinceStart : 60.42723846435547

********** Iteration 44 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -0.0
Train_EnvstepsSoFar : 181570
TimeSinceStart : 61.77917146682739

********** Iteration 45 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -0.0
Train_EnvstepsSoFar : 185570
TimeSinceStart : 63.10988736152649

********** Iteration 46 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -0.0
Train_EnvstepsSoFar : 189570
TimeSinceStart : 64.47452402114868

********** Iteration 47 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -0.0
Train_EnvstepsSoFar : 193570
TimeSinceStart : 65.87116503715515

********** Iteration 48 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -0.0
Train_EnvstepsSoFar : 197570
TimeSinceStart : 67.35239553451538

********** Iteration 49 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -0.0
Train_EnvstepsSoFar : 201570
TimeSinceStart : 68.72968530654907

********** Iteration 50 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -0.0
Train_EnvstepsSoFar : 205570
TimeSinceStart : 70.20020246505737

********** Iteration 51 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -0.0
Train_EnvstepsSoFar : 209570
TimeSinceStart : 71.55955648422241

********** Iteration 52 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -0.0
Train_EnvstepsSoFar : 213570
TimeSinceStart : 73.1850209236145

********** Iteration 53 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -0.0
Train_EnvstepsSoFar : 217570
TimeSinceStart : 74.563472032547

********** Iteration 54 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -0.0
Train_EnvstepsSoFar : 221570
TimeSinceStart : 75.98641848564148

********** Iteration 55 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -0.0
Train_EnvstepsSoFar : 225570
TimeSinceStart : 77.33526539802551

********** Iteration 56 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -0.0
Train_EnvstepsSoFar : 229570
TimeSinceStart : 78.84766221046448

********** Iteration 57 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -0.0
Train_EnvstepsSoFar : 233570
TimeSinceStart : 80.25249648094177

********** Iteration 58 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -0.0
Train_EnvstepsSoFar : 237570
TimeSinceStart : 81.62130069732666

********** Iteration 59 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -0.0
Train_EnvstepsSoFar : 241570
TimeSinceStart : 83.19774508476257

********** Iteration 60 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -0.0
Train_EnvstepsSoFar : 245570
TimeSinceStart : 84.50076484680176

********** Iteration 61 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -0.0
Train_EnvstepsSoFar : 249570
TimeSinceStart : 85.94562315940857

********** Iteration 62 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -0.0
Train_EnvstepsSoFar : 253570
TimeSinceStart : 87.28160309791565

********** Iteration 63 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -0.0
Train_EnvstepsSoFar : 257570
TimeSinceStart : 88.57434630393982

********** Iteration 64 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -0.0
Train_EnvstepsSoFar : 261570
TimeSinceStart : 89.88564252853394

********** Iteration 65 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -0.0
Train_EnvstepsSoFar : 265570
TimeSinceStart : 91.2350332736969

********** Iteration 66 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -0.0
Train_EnvstepsSoFar : 269570
TimeSinceStart : 92.53648114204407

********** Iteration 67 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -0.0
Train_EnvstepsSoFar : 273570
TimeSinceStart : 93.84143257141113

********** Iteration 68 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -0.0
Train_EnvstepsSoFar : 277570
TimeSinceStart : 95.22436094284058

********** Iteration 69 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -0.0
Train_EnvstepsSoFar : 281570
TimeSinceStart : 96.54587030410767

********** Iteration 70 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -0.0
Train_EnvstepsSoFar : 285570
TimeSinceStart : 97.87317204475403

********** Iteration 71 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -0.0
Train_EnvstepsSoFar : 289570
TimeSinceStart : 99.22967195510864

********** Iteration 72 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -0.0
Train_EnvstepsSoFar : 293570
TimeSinceStart : 100.64500904083252

********** Iteration 73 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -0.0
Train_EnvstepsSoFar : 297570
TimeSinceStart : 101.96782374382019

********** Iteration 74 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -0.0
Train_EnvstepsSoFar : 301570
TimeSinceStart : 103.26073837280273

********** Iteration 75 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -0.0
Train_EnvstepsSoFar : 305570
TimeSinceStart : 104.55053186416626

********** Iteration 76 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -0.0
Train_EnvstepsSoFar : 309570
TimeSinceStart : 105.88547778129578

********** Iteration 77 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -0.0
Train_EnvstepsSoFar : 313570
TimeSinceStart : 107.19405937194824

********** Iteration 78 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -0.0
Train_EnvstepsSoFar : 317570
TimeSinceStart : 108.59676957130432

********** Iteration 79 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -0.0
Train_EnvstepsSoFar : 321570
TimeSinceStart : 110.18602895736694

********** Iteration 80 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -0.0
Train_EnvstepsSoFar : 325570
TimeSinceStart : 111.64580583572388

********** Iteration 81 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -0.0
Train_EnvstepsSoFar : 329570
TimeSinceStart : 112.95538377761841

********** Iteration 82 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -0.0
Train_EnvstepsSoFar : 333570
TimeSinceStart : 114.29405975341797

********** Iteration 83 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -0.0
Train_EnvstepsSoFar : 337570
TimeSinceStart : 115.59111452102661

********** Iteration 84 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -0.0
Train_EnvstepsSoFar : 341570
TimeSinceStart : 116.92762041091919

********** Iteration 85 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -0.0
Train_EnvstepsSoFar : 345570
TimeSinceStart : 118.25224304199219

********** Iteration 86 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -0.0
Train_EnvstepsSoFar : 349570
TimeSinceStart : 119.59551191329956

********** Iteration 87 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -0.0
Train_EnvstepsSoFar : 353570
TimeSinceStart : 120.85264325141907

********** Iteration 88 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -0.0
Train_EnvstepsSoFar : 357570
TimeSinceStart : 122.195232629776

********** Iteration 89 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -0.0
Train_EnvstepsSoFar : 361570
TimeSinceStart : 123.49207639694214

********** Iteration 90 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -0.0
Train_EnvstepsSoFar : 365570
TimeSinceStart : 124.75860071182251

********** Iteration 91 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -0.0
Train_EnvstepsSoFar : 369570
TimeSinceStart : 126.04215288162231

********** Iteration 92 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -0.0
Train_EnvstepsSoFar : 373570
TimeSinceStart : 127.32735896110535

********** Iteration 93 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -0.0
Train_EnvstepsSoFar : 377570
TimeSinceStart : 128.61474537849426

********** Iteration 94 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -0.0
Train_EnvstepsSoFar : 381570
TimeSinceStart : 129.94354796409607

********** Iteration 95 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -0.0
Train_EnvstepsSoFar : 385570
TimeSinceStart : 131.2798376083374

********** Iteration 96 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -0.0
Train_EnvstepsSoFar : 389570
TimeSinceStart : 132.67006540298462

********** Iteration 97 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -0.0
Train_EnvstepsSoFar : 393570
TimeSinceStart : 133.98529648780823

********** Iteration 98 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -0.0
Train_EnvstepsSoFar : 397570
TimeSinceStart : 135.2794165611267

********** Iteration 99 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -0.0
Train_EnvstepsSoFar : 401570
TimeSinceStart : 136.5916075706482

Process finished with exit code 0
