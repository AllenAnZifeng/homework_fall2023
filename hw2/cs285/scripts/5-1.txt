C:\My_Project\ALLEN_Python\homework_fall2023\venv\Scripts\python.exe C:\My_Project\ALLEN_Python\homework_fall2023\hw2\cs285\scripts\run_hw2.py --env_name LunarLander-v2 --ep_len 1000 --discount 0.99 -n 300 -l 3 -s 128 -b 2000 -lr 0.001 --use_reward_to_go --use_baseline --gae_lambda 0 --exp_name lunar_lander_lambda0
########################
logging outputs to  C:\My_Project\ALLEN_Python\homework_fall2023\hw2\cs285\scripts\../../data\q2_pg_lunar_lander_lambda0_LunarLander-v2_25-09-2023_22-12-48
########################
Using CPU.
C:\My_Project\ALLEN_Python\homework_fall2023\venv\lib\site-packages\gym\core.py:317: DeprecationWarning: WARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.
  deprecation(
C:\My_Project\ALLEN_Python\homework_fall2023\venv\lib\site-packages\gym\wrappers\step_api_compatibility.py:39: DeprecationWarning: WARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.
  deprecation(
C:\My_Project\ALLEN_Python\homework_fall2023\venv\lib\site-packages\gym\utils\passive_env_checker.py:241: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):

********** Iteration 0 ************
C:\My_Project\ALLEN_Python\homework_fall2023\venv\lib\site-packages\tensorboardX\summary.py:153: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)
  scalar = float(scalar)
Eval_AverageReturn : -244.43344116210938
Eval_StdReturn : 153.91822814941406
Eval_MaxReturn : -14.662445068359375
Eval_MinReturn : -445.4704284667969
Eval_AverageEpLen : 106.5
Train_AverageReturn : -140.60775756835938
Train_StdReturn : 89.35624694824219
Train_MaxReturn : -20.73697280883789
Train_MinReturn : -377.93231201171875
Train_AverageEpLen : 90.17391304347827
Actor Loss : -4397.84375
Baseline Loss : 7912.7119140625
Train_EnvstepsSoFar : 2074
TimeSinceStart : 1.0515069961547852
Initial_DataCollection_AverageReturn : -140.60775756835938

********** Iteration 1 ************
Eval_AverageReturn : -218.26544189453125
Eval_StdReturn : 142.94972229003906
Eval_MaxReturn : -88.7441177368164
Eval_MinReturn : -453.6536865234375
Eval_AverageEpLen : 112.75
Train_AverageReturn : -134.76593017578125
Train_StdReturn : 65.42898559570312
Train_MaxReturn : 13.050704956054688
Train_MinReturn : -269.8348693847656
Train_AverageEpLen : 101.6
Actor Loss : -3438.158935546875
Baseline Loss : 5429.3720703125
Train_EnvstepsSoFar : 4106
TimeSinceStart : 2.0201334953308105

********** Iteration 2 ************
Eval_AverageReturn : -216.2274627685547
Eval_StdReturn : 173.27493286132812
Eval_MaxReturn : -55.53633499145508
Eval_MinReturn : -483.91387939453125
Eval_AverageEpLen : 89.2
Train_AverageReturn : -153.89422607421875
Train_StdReturn : 61.4701042175293
Train_MaxReturn : -63.88334274291992
Train_MinReturn : -334.3109130859375
Train_AverageEpLen : 102.35
Actor Loss : -3782.7158203125
Baseline Loss : 5886.85107421875
Train_EnvstepsSoFar : 6153
TimeSinceStart : 3.0169060230255127

********** Iteration 3 ************
Eval_AverageReturn : -293.0465087890625
Eval_StdReturn : 103.45245361328125
Eval_MaxReturn : -125.67689514160156
Eval_MinReturn : -399.20556640625
Eval_AverageEpLen : 104.75
Train_AverageReturn : -186.01065063476562
Train_StdReturn : 94.50366973876953
Train_MaxReturn : -82.07005310058594
Train_MinReturn : -412.44293212890625
Train_AverageEpLen : 105.0
Actor Loss : -4457.43701171875
Baseline Loss : 8582.916015625
Train_EnvstepsSoFar : 8253
TimeSinceStart : 4.0278332233428955

********** Iteration 4 ************
Eval_AverageReturn : -309.60955810546875
Eval_StdReturn : 159.84434509277344
Eval_MaxReturn : -74.98686218261719
Eval_MinReturn : -522.772705078125
Eval_AverageEpLen : 134.5
Train_AverageReturn : -169.2277069091797
Train_StdReturn : 111.63861846923828
Train_MaxReturn : 7.291694641113281
Train_MinReturn : -421.6449279785156
Train_AverageEpLen : 106.0
Actor Loss : -3710.015625
Baseline Loss : 8072.90380859375
Train_EnvstepsSoFar : 10267
TimeSinceStart : 5.073144912719727

********** Iteration 5 ************
Eval_AverageReturn : -194.8975372314453
Eval_StdReturn : 91.6907958984375
Eval_MaxReturn : -110.08538055419922
Eval_MinReturn : -322.2505187988281
Eval_AverageEpLen : 136.33333333333334
Train_AverageReturn : -170.12893676757812
Train_StdReturn : 114.0846176147461
Train_MaxReturn : -28.903289794921875
Train_MinReturn : -471.4571228027344
Train_AverageEpLen : 112.55555555555556
Actor Loss : -3173.751708984375
Baseline Loss : 7289.5009765625
Train_EnvstepsSoFar : 12293
TimeSinceStart : 6.064955234527588

********** Iteration 6 ************
Eval_AverageReturn : -216.14987182617188
Eval_StdReturn : 126.50094604492188
Eval_MaxReturn : -105.83784484863281
Eval_MinReturn : -416.23077392578125
Eval_AverageEpLen : 103.5
Train_AverageReturn : -243.2749786376953
Train_StdReturn : 114.4946060180664
Train_MaxReturn : -87.18399047851562
Train_MinReturn : -443.90606689453125
Train_AverageEpLen : 143.53333333333333
Actor Loss : -3627.455078125
Baseline Loss : 9750.525390625
Train_EnvstepsSoFar : 14446
TimeSinceStart : 7.149531602859497

********** Iteration 7 ************
Eval_AverageReturn : -103.08878326416016
Eval_StdReturn : 112.01931762695312
Eval_MaxReturn : -6.6219024658203125
Eval_MinReturn : -260.1482238769531
Eval_AverageEpLen : 138.0
Train_AverageReturn : -249.50689697265625
Train_StdReturn : 153.41590881347656
Train_MaxReturn : -46.533729553222656
Train_MinReturn : -568.239990234375
Train_AverageEpLen : 137.66666666666666
Actor Loss : -3333.8935546875
Baseline Loss : 11692.119140625
Train_EnvstepsSoFar : 16511
TimeSinceStart : 8.225206851959229

********** Iteration 8 ************
Eval_AverageReturn : -269.519287109375
Eval_StdReturn : 145.647216796875
Eval_MaxReturn : -63.144405364990234
Eval_MinReturn : -448.3084411621094
Eval_AverageEpLen : 137.75
Train_AverageReturn : -235.38870239257812
Train_StdReturn : 139.01341247558594
Train_MaxReturn : -41.795936584472656
Train_MinReturn : -493.0319519042969
Train_AverageEpLen : 126.8125
Actor Loss : -3514.723388671875
Baseline Loss : 9760.2490234375
Train_EnvstepsSoFar : 18540
TimeSinceStart : 9.391576051712036

********** Iteration 9 ************
Eval_AverageReturn : -221.1172332763672
Eval_StdReturn : 96.3566665649414
Eval_MaxReturn : -86.92298889160156
Eval_MinReturn : -351.7554626464844
Eval_AverageEpLen : 106.5
Train_AverageReturn : -173.43460083007812
Train_StdReturn : 115.678466796875
Train_MaxReturn : -45.23666763305664
Train_MinReturn : -402.4628601074219
Train_AverageEpLen : 121.94117647058823
Actor Loss : -2796.482421875
Baseline Loss : 5404.35400390625
Train_EnvstepsSoFar : 20613
TimeSinceStart : 10.454932451248169

********** Iteration 10 ************
Eval_AverageReturn : -150.9954071044922
Eval_StdReturn : 107.59807586669922
Eval_MaxReturn : -9.265304565429688
Eval_MinReturn : -269.823486328125
Eval_AverageEpLen : 182.0
Train_AverageReturn : -239.221923828125
Train_StdReturn : 113.04447937011719
Train_MaxReturn : -66.0377197265625
Train_MinReturn : -409.4451904296875
Train_AverageEpLen : 148.42857142857142
Actor Loss : -2589.4560546875
Baseline Loss : 6632.52490234375
Train_EnvstepsSoFar : 22691
TimeSinceStart : 11.604548692703247

********** Iteration 11 ************
Eval_AverageReturn : -313.1725769042969
Eval_StdReturn : 86.04806518554688
Eval_MaxReturn : -194.7704620361328
Eval_MinReturn : -396.7069091796875
Eval_AverageEpLen : 159.66666666666666
Train_AverageReturn : -210.42071533203125
Train_StdReturn : 88.40103149414062
Train_MaxReturn : -62.55545425415039
Train_MinReturn : -342.4517822265625
Train_AverageEpLen : 183.58333333333334
Actor Loss : -1937.98193359375
Baseline Loss : 3763.591796875
Train_EnvstepsSoFar : 24894
TimeSinceStart : 12.984245777130127

********** Iteration 12 ************
Eval_AverageReturn : -145.1462860107422
Eval_StdReturn : 50.1756706237793
Eval_MaxReturn : -94.10851287841797
Eval_MinReturn : -217.69741821289062
Eval_AverageEpLen : 142.25
Train_AverageReturn : -230.6111602783203
Train_StdReturn : 135.5247344970703
Train_MaxReturn : 13.63748550415039
Train_MinReturn : -417.9014587402344
Train_AverageEpLen : 154.57142857142858
Actor Loss : -2472.93017578125
Baseline Loss : 7152.98828125
Train_EnvstepsSoFar : 27058
TimeSinceStart : 14.28530216217041

********** Iteration 13 ************
Eval_AverageReturn : -110.81915283203125
Eval_StdReturn : 35.47037124633789
Eval_MaxReturn : -75.3487777709961
Eval_MinReturn : -146.28952026367188
Eval_AverageEpLen : 210.0
Train_AverageReturn : -154.30535888671875
Train_StdReturn : 165.2101593017578
Train_MaxReturn : 9.1448974609375
Train_MinReturn : -514.4024047851562
Train_AverageEpLen : 241.66666666666666
Actor Loss : -602.14697265625
Baseline Loss : 5289.265625
Train_EnvstepsSoFar : 29233
TimeSinceStart : 15.935179471969604

********** Iteration 14 ************
Eval_AverageReturn : -248.95957946777344
Eval_StdReturn : 24.37759780883789
Eval_MaxReturn : -220.58668518066406
Eval_MinReturn : -280.1058349609375
Eval_AverageEpLen : 203.33333333333334
Train_AverageReturn : -253.765869140625
Train_StdReturn : 142.99276733398438
Train_MaxReturn : -46.05198669433594
Train_MinReturn : -462.93914794921875
Train_AverageEpLen : 186.0909090909091
Actor Loss : -1763.3094482421875
Baseline Loss : 5134.13037109375
Train_EnvstepsSoFar : 31280
TimeSinceStart : 17.246881246566772

********** Iteration 15 ************
Eval_AverageReturn : -262.3063659667969
Eval_StdReturn : 51.21880340576172
Eval_MaxReturn : -198.4423828125
Eval_MinReturn : -323.83721923828125
Eval_AverageEpLen : 210.0
Train_AverageReturn : -223.98080444335938
Train_StdReturn : 151.44740295410156
Train_MaxReturn : -82.03837585449219
Train_MinReturn : -641.9486083984375
Train_AverageEpLen : 182.63636363636363
Actor Loss : -1417.215576171875
Baseline Loss : 4350.10791015625
Train_EnvstepsSoFar : 33289
TimeSinceStart : 18.555038928985596

********** Iteration 16 ************
Eval_AverageReturn : -240.0614776611328
Eval_StdReturn : 119.5792236328125
Eval_MaxReturn : -73.44046783447266
Eval_MinReturn : -348.4092712402344
Eval_AverageEpLen : 177.33333333333334
Train_AverageReturn : -154.39088439941406
Train_StdReturn : 114.84173583984375
Train_MaxReturn : 86.98684692382812
Train_MinReturn : -314.4161376953125
Train_AverageEpLen : 256.0
Actor Loss : -284.4261169433594
Baseline Loss : 3687.38232421875
Train_EnvstepsSoFar : 36105
TimeSinceStart : 21.291395902633667

********** Iteration 17 ************
Eval_AverageReturn : -143.7522735595703
Eval_StdReturn : 120.34257507324219
Eval_MaxReturn : -15.566902160644531
Eval_MinReturn : -304.7979736328125
Eval_AverageEpLen : 137.33333333333334
Train_AverageReturn : -186.4314727783203
Train_StdReturn : 139.9927520751953
Train_MaxReturn : -19.952842712402344
Train_MinReturn : -496.58001708984375
Train_AverageEpLen : 162.46153846153845
Actor Loss : -1773.25732421875
Baseline Loss : 4632.16162109375
Train_EnvstepsSoFar : 38217
TimeSinceStart : 22.815911769866943

********** Iteration 18 ************
Eval_AverageReturn : -292.1943359375
Eval_StdReturn : 57.70133972167969
Eval_MaxReturn : -234.49301147460938
Eval_MinReturn : -349.89569091796875
Eval_AverageEpLen : 219.0
Train_AverageReturn : -137.4447784423828
Train_StdReturn : 113.53800964355469
Train_MaxReturn : 8.457794189453125
Train_MinReturn : -322.60992431640625
Train_AverageEpLen : 137.6
Actor Loss : -1419.70263671875
Baseline Loss : 3330.28955078125
Train_EnvstepsSoFar : 40281
TimeSinceStart : 24.423431158065796

********** Iteration 19 ************
Eval_AverageReturn : -161.4251251220703
Eval_StdReturn : 93.80795288085938
Eval_MaxReturn : -50.592350006103516
Eval_MinReturn : -279.9839782714844
Eval_AverageEpLen : 155.0
Train_AverageReturn : -133.68777465820312
Train_StdReturn : 117.09183502197266
Train_MaxReturn : 81.34244537353516
Train_MinReturn : -249.70330810546875
Train_AverageEpLen : 272.75
Actor Loss : 112.99781799316406
Baseline Loss : 3216.115234375
Train_EnvstepsSoFar : 42463
TimeSinceStart : 26.76473307609558

********** Iteration 20 ************
Eval_AverageReturn : -170.6665802001953
Eval_StdReturn : 100.2056884765625
Eval_MaxReturn : -39.720054626464844
Eval_MinReturn : -283.0602722167969
Eval_AverageEpLen : 172.0
Train_AverageReturn : -67.51085662841797
Train_StdReturn : 99.73738098144531
Train_MaxReturn : 56.801429748535156
Train_MinReturn : -221.6082305908203
Train_AverageEpLen : 231.55555555555554
Actor Loss : 373.41168212890625
Baseline Loss : 3634.039794921875
Train_EnvstepsSoFar : 44547
TimeSinceStart : 29.778748750686646

********** Iteration 21 ************
Eval_AverageReturn : -124.0978012084961
Eval_StdReturn : 118.71560668945312
Eval_MaxReturn : -1.8811378479003906
Eval_MinReturn : -284.8927001953125
Eval_AverageEpLen : 447.0
Train_AverageReturn : -128.93484497070312
Train_StdReturn : 129.95199584960938
Train_MaxReturn : 31.318359375
Train_MinReturn : -359.62042236328125
Train_AverageEpLen : 172.08333333333334
Actor Loss : -554.9647216796875
Baseline Loss : 2675.10205078125
Train_EnvstepsSoFar : 46612
TimeSinceStart : 33.89802432060242

********** Iteration 22 ************
Eval_AverageReturn : -49.01461410522461
Eval_StdReturn : 38.34136199951172
Eval_MaxReturn : -9.326911926269531
Eval_MinReturn : -112.0915756225586
Eval_AverageEpLen : 148.0
Train_AverageReturn : -136.77853393554688
Train_StdReturn : 103.26378631591797
Train_MaxReturn : 50.21778869628906
Train_MinReturn : -335.25469970703125
Train_AverageEpLen : 145.71428571428572
Actor Loss : -1159.758544921875
Baseline Loss : 2954.760986328125
Train_EnvstepsSoFar : 48652
TimeSinceStart : 36.57658410072327

********** Iteration 23 ************
Eval_AverageReturn : -113.5496826171875
Eval_StdReturn : 76.02194213867188
Eval_MaxReturn : -48.79849624633789
Eval_MinReturn : -220.2520294189453
Eval_AverageEpLen : 148.0
Train_AverageReturn : -108.42253875732422
Train_StdReturn : 107.88067626953125
Train_MaxReturn : 21.952972412109375
Train_MinReturn : -286.45648193359375
Train_AverageEpLen : 157.84615384615384
Actor Loss : -1048.362548828125
Baseline Loss : 3409.21337890625
Train_EnvstepsSoFar : 50704
TimeSinceStart : 39.08179187774658

********** Iteration 24 ************
Eval_AverageReturn : -367.9339904785156
Eval_StdReturn : 2.464141845703125
Eval_MaxReturn : -365.4698486328125
Eval_MinReturn : -370.39813232421875
Eval_AverageEpLen : 278.5
Train_AverageReturn : -252.9422149658203
Train_StdReturn : 143.9751434326172
Train_MaxReturn : -87.828125
Train_MinReturn : -629.5618896484375
Train_AverageEpLen : 216.5
Actor Loss : -1516.193603515625
Baseline Loss : 3621.891845703125
Train_EnvstepsSoFar : 52869
TimeSinceStart : 42.0098512172699

********** Iteration 25 ************
Eval_AverageReturn : -229.10321044921875
Eval_StdReturn : 80.2448959350586
Eval_MaxReturn : -148.8583221435547
Eval_MinReturn : -309.3481140136719
Eval_AverageEpLen : 240.0
Train_AverageReturn : -276.0621643066406
Train_StdReturn : 143.1217041015625
Train_MaxReturn : -97.617919921875
Train_MinReturn : -580.3873291015625
Train_AverageEpLen : 256.0
Actor Loss : -1006.634033203125
Baseline Loss : 2670.38134765625
Train_EnvstepsSoFar : 54917
TimeSinceStart : 44.784900188446045

********** Iteration 26 ************
Eval_AverageReturn : 57.451576232910156
Eval_StdReturn : 0.0
Eval_MaxReturn : 57.451576232910156
Eval_MinReturn : 57.451576232910156
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -201.26902770996094
Train_StdReturn : 181.888916015625
Train_MaxReturn : 62.669708251953125
Train_MinReturn : -548.9718017578125
Train_AverageEpLen : 191.25
Actor Loss : -1157.4027099609375
Baseline Loss : 4074.913330078125
Train_EnvstepsSoFar : 57212
TimeSinceStart : 49.41326189041138

********** Iteration 27 ************
Eval_AverageReturn : -58.46600341796875
Eval_StdReturn : 109.59276580810547
Eval_MaxReturn : 26.330604553222656
Eval_MinReturn : -213.21649169921875
Eval_AverageEpLen : 143.0
Train_AverageReturn : -261.7580871582031
Train_StdReturn : 142.71873474121094
Train_MaxReturn : -46.40087890625
Train_MinReturn : -529.3516235351562
Train_AverageEpLen : 266.625
Actor Loss : -1060.5965576171875
Baseline Loss : 3735.98291015625
Train_EnvstepsSoFar : 59345
TimeSinceStart : 52.54024052619934

********** Iteration 28 ************
Eval_AverageReturn : -157.8247528076172
Eval_StdReturn : 11.85675048828125
Eval_MaxReturn : -145.96800231933594
Eval_MinReturn : -169.68150329589844
Eval_AverageEpLen : 260.0
Train_AverageReturn : -160.02902221679688
Train_StdReturn : 80.38988494873047
Train_MaxReturn : -41.16552734375
Train_MinReturn : -287.4374694824219
Train_AverageEpLen : 184.1818181818182
Actor Loss : -860.3385009765625
Baseline Loss : 2037.0260009765625
Train_EnvstepsSoFar : 61371
TimeSinceStart : 55.45137166976929

********** Iteration 29 ************
Eval_AverageReturn : -93.6181869506836
Eval_StdReturn : 135.5880126953125
Eval_MaxReturn : 6.736839294433594
Eval_MinReturn : -285.2976989746094
Eval_AverageEpLen : 153.0
Train_AverageReturn : -144.27186584472656
Train_StdReturn : 60.76356506347656
Train_MaxReturn : -16.57178497314453
Train_MinReturn : -203.44747924804688
Train_AverageEpLen : 160.15384615384616
Actor Loss : -1084.2003173828125
Baseline Loss : 2087.546142578125
Train_EnvstepsSoFar : 63453
TimeSinceStart : 58.135924339294434

********** Iteration 30 ************
Eval_AverageReturn : -189.32411193847656
Eval_StdReturn : 172.9524688720703
Eval_MaxReturn : -16.37163543701172
Eval_MinReturn : -362.2765808105469
Eval_AverageEpLen : 249.5
Train_AverageReturn : -137.11155700683594
Train_StdReturn : 91.01014709472656
Train_MaxReturn : -6.778404235839844
Train_MinReturn : -297.5541687011719
Train_AverageEpLen : 273.9
Actor Loss : -72.63128662109375
Baseline Loss : 2546.44384765625
Train_EnvstepsSoFar : 66192
TimeSinceStart : 62.817272424697876

********** Iteration 31 ************
Eval_AverageReturn : -43.28337478637695
Eval_StdReturn : 0.0
Eval_MaxReturn : -43.28337478637695
Eval_MinReturn : -43.28337478637695
Eval_AverageEpLen : 548.0
Train_AverageReturn : -117.0013427734375
Train_StdReturn : 85.054931640625
Train_MaxReturn : 24.26447296142578
Train_MinReturn : -238.49874877929688
Train_AverageEpLen : 222.55555555555554
Actor Loss : -135.87608337402344
Baseline Loss : 2850.63671875
Train_EnvstepsSoFar : 68195
TimeSinceStart : 65.70648455619812

********** Iteration 32 ************
Eval_AverageReturn : -114.75529479980469
Eval_StdReturn : 8.82000732421875
Eval_MaxReturn : -105.93528747558594
Eval_MinReturn : -123.57530212402344
Eval_AverageEpLen : 363.5
Train_AverageReturn : -192.26780700683594
Train_StdReturn : 94.9163589477539
Train_MaxReturn : -4.687705993652344
Train_MinReturn : -270.42218017578125
Train_AverageEpLen : 292.57142857142856
Actor Loss : 147.04510498046875
Baseline Loss : 2167.414306640625
Train_EnvstepsSoFar : 70243
TimeSinceStart : 69.34461164474487

********** Iteration 33 ************
Eval_AverageReturn : -272.09130859375
Eval_StdReturn : 0.0
Eval_MaxReturn : -272.09130859375
Eval_MinReturn : -272.09130859375
Eval_AverageEpLen : 681.0
Train_AverageReturn : -108.40486145019531
Train_StdReturn : 81.35855102539062
Train_MaxReturn : -16.262876510620117
Train_MinReturn : -256.9326171875
Train_AverageEpLen : 249.33333333333334
Actor Loss : 186.8042449951172
Baseline Loss : 3007.51953125
Train_EnvstepsSoFar : 72487
TimeSinceStart : 73.46882939338684

********** Iteration 34 ************
Eval_AverageReturn : -88.07421112060547
Eval_StdReturn : 37.406768798828125
Eval_MaxReturn : -50.667442321777344
Eval_MinReturn : -125.4809799194336
Eval_AverageEpLen : 555.0
Train_AverageReturn : -125.56156158447266
Train_StdReturn : 99.50654602050781
Train_MaxReturn : -2.794586181640625
Train_MinReturn : -277.8827819824219
Train_AverageEpLen : 271.375
Actor Loss : 30.74065399169922
Baseline Loss : 2173.629638671875
Train_EnvstepsSoFar : 74658
TimeSinceStart : 77.9809558391571

********** Iteration 35 ************
Eval_AverageReturn : -143.627197265625
Eval_StdReturn : 73.69203186035156
Eval_MaxReturn : -40.35253143310547
Eval_MinReturn : -207.36953735351562
Eval_AverageEpLen : 179.66666666666666
Train_AverageReturn : -160.2932586669922
Train_StdReturn : 101.42369079589844
Train_MaxReturn : 64.60122680664062
Train_MinReturn : -264.9654541015625
Train_AverageEpLen : 253.0
Actor Loss : 114.54400634765625
Baseline Loss : 2586.69482421875
Train_EnvstepsSoFar : 76682
TimeSinceStart : 80.83132672309875

********** Iteration 36 ************
Eval_AverageReturn : -263.5635986328125
Eval_StdReturn : 34.94432830810547
Eval_MaxReturn : -228.61927795410156
Eval_MinReturn : -298.5079345703125
Eval_AverageEpLen : 297.5
Train_AverageReturn : -184.3775177001953
Train_StdReturn : 98.70706939697266
Train_MaxReturn : -56.75236511230469
Train_MinReturn : -354.4061279296875
Train_AverageEpLen : 334.1666666666667
Actor Loss : 186.6188507080078
Baseline Loss : 3019.105712890625
Train_EnvstepsSoFar : 78687
TimeSinceStart : 83.96432995796204

********** Iteration 37 ************
Eval_AverageReturn : -245.116455078125
Eval_StdReturn : 36.10101318359375
Eval_MaxReturn : -209.01544189453125
Eval_MinReturn : -281.21746826171875
Eval_AverageEpLen : 360.0
Train_AverageReturn : -98.10899353027344
Train_StdReturn : 57.41184616088867
Train_MaxReturn : -16.73999786376953
Train_MinReturn : -171.3837127685547
Train_AverageEpLen : 228.77777777777777
Actor Loss : -3.629283905029297
Baseline Loss : 2149.16552734375
Train_EnvstepsSoFar : 80746
TimeSinceStart : 87.41335558891296

********** Iteration 38 ************
Eval_AverageReturn : -120.65718841552734
Eval_StdReturn : 100.06289672851562
Eval_MaxReturn : 20.727489471435547
Eval_MinReturn : -196.51258850097656
Eval_AverageEpLen : 192.66666666666666
Train_AverageReturn : -136.04087829589844
Train_StdReturn : 83.19648742675781
Train_MaxReturn : -23.70037078857422
Train_MinReturn : -269.30743408203125
Train_AverageEpLen : 352.6666666666667
Actor Loss : 110.66111755371094
Baseline Loss : 3237.9873046875
Train_EnvstepsSoFar : 82862
TimeSinceStart : 91.35395216941833

********** Iteration 39 ************
Eval_AverageReturn : -141.5288543701172
Eval_StdReturn : 51.06656265258789
Eval_MaxReturn : -90.46228790283203
Eval_MinReturn : -192.5954132080078
Eval_AverageEpLen : 212.0
Train_AverageReturn : -142.9284210205078
Train_StdReturn : 111.01608276367188
Train_MaxReturn : -4.556235313415527
Train_MinReturn : -288.74462890625
Train_AverageEpLen : 473.8
Actor Loss : 148.72869873046875
Baseline Loss : 2191.40283203125
Train_EnvstepsSoFar : 85231
TimeSinceStart : 95.77352166175842

********** Iteration 40 ************
Eval_AverageReturn : -56.88698196411133
Eval_StdReturn : 28.172121047973633
Eval_MaxReturn : -17.985952377319336
Eval_MinReturn : -83.78968811035156
Eval_AverageEpLen : 242.66666666666666
Train_AverageReturn : -118.74525451660156
Train_StdReturn : 99.04358673095703
Train_MaxReturn : 77.04315185546875
Train_MinReturn : -296.9308776855469
Train_AverageEpLen : 269.44444444444446
Actor Loss : -69.69905853271484
Baseline Loss : 2947.24560546875
Train_EnvstepsSoFar : 87656
TimeSinceStart : 99.84175705909729

********** Iteration 41 ************
Eval_AverageReturn : -248.9666748046875
Eval_StdReturn : 42.419395446777344
Eval_MaxReturn : -206.5472869873047
Eval_MinReturn : -291.3860778808594
Eval_AverageEpLen : 341.0
Train_AverageReturn : -117.0522232055664
Train_StdReturn : 83.95895385742188
Train_MaxReturn : -2.5141754150390625
Train_MinReturn : -246.2139129638672
Train_AverageEpLen : 287.375
Actor Loss : -211.28359985351562
Baseline Loss : 2844.184814453125
Train_EnvstepsSoFar : 89955
TimeSinceStart : 103.97176384925842

********** Iteration 42 ************
Eval_AverageReturn : -100.84683990478516
Eval_StdReturn : 73.9632339477539
Eval_MaxReturn : -26.883607864379883
Eval_MinReturn : -174.81007385253906
Eval_AverageEpLen : 204.5
Train_AverageReturn : -149.34536743164062
Train_StdReturn : 72.21563720703125
Train_MaxReturn : 14.251014709472656
Train_MinReturn : -240.81118774414062
Train_AverageEpLen : 204.2
Actor Loss : -579.7207641601562
Baseline Loss : 2902.58056640625
Train_EnvstepsSoFar : 91997
TimeSinceStart : 106.81284809112549

********** Iteration 43 ************
Eval_AverageReturn : -99.06340789794922
Eval_StdReturn : 61.35222625732422
Eval_MaxReturn : -37.711185455322266
Eval_MinReturn : -160.41563415527344
Eval_AverageEpLen : 216.5
Train_AverageReturn : -50.58120346069336
Train_StdReturn : 46.695919036865234
Train_MaxReturn : -7.759613037109375
Train_MinReturn : -126.36526489257812
Train_AverageEpLen : 589.5
Actor Loss : 696.1144409179688
Baseline Loss : 3075.80029296875
Train_EnvstepsSoFar : 94355
TimeSinceStart : 112.21460342407227

********** Iteration 44 ************
Eval_AverageReturn : -82.72515869140625
Eval_StdReturn : 11.534435272216797
Eval_MaxReturn : -71.19072723388672
Eval_MinReturn : -94.25959777832031
Eval_AverageEpLen : 315.5
Train_AverageReturn : -135.58067321777344
Train_StdReturn : 94.3903579711914
Train_MaxReturn : -7.533346176147461
Train_MinReturn : -251.58541870117188
Train_AverageEpLen : 252.125
Actor Loss : -191.0127410888672
Baseline Loss : 2010.5413818359375
Train_EnvstepsSoFar : 96372
TimeSinceStart : 115.42507743835449

********** Iteration 45 ************
Eval_AverageReturn : -121.62490844726562
Eval_StdReturn : 82.55569458007812
Eval_MaxReturn : -39.069217681884766
Eval_MinReturn : -204.18060302734375
Eval_AverageEpLen : 220.0
Train_AverageReturn : -126.52915954589844
Train_StdReturn : 77.72682189941406
Train_MaxReturn : 0.3364715576171875
Train_MinReturn : -218.09774780273438
Train_AverageEpLen : 249.33333333333334
Actor Loss : -95.44403076171875
Baseline Loss : 3154.026611328125
Train_EnvstepsSoFar : 98616
TimeSinceStart : 118.94612121582031

********** Iteration 46 ************
Eval_AverageReturn : -121.05848693847656
Eval_StdReturn : 1.7617683410644531
Eval_MaxReturn : -119.29671478271484
Eval_MinReturn : -122.82025146484375
Eval_AverageEpLen : 251.0
Train_AverageReturn : -152.3286590576172
Train_StdReturn : 72.84317016601562
Train_MaxReturn : -38.36516571044922
Train_MinReturn : -254.82330322265625
Train_AverageEpLen : 341.8333333333333
Actor Loss : -116.3614273071289
Baseline Loss : 2914.96533203125
Train_EnvstepsSoFar : 100667
TimeSinceStart : 123.05112552642822

********** Iteration 47 ************
Eval_AverageReturn : -154.6849365234375
Eval_StdReturn : 0.0
Eval_MaxReturn : -154.6849365234375
Eval_MinReturn : -154.6849365234375
Eval_AverageEpLen : 418.0
Train_AverageReturn : -122.2215805053711
Train_StdReturn : 96.33753967285156
Train_MaxReturn : 25.47576904296875
Train_MinReturn : -277.21466064453125
Train_AverageEpLen : 263.8
Actor Loss : 10.797609329223633
Baseline Loss : 2640.86767578125
Train_EnvstepsSoFar : 103305
TimeSinceStart : 127.13617444038391

********** Iteration 48 ************
Eval_AverageReturn : -88.86799621582031
Eval_StdReturn : 25.15835189819336
Eval_MaxReturn : -63.70964050292969
Eval_MinReturn : -114.0263442993164
Eval_AverageEpLen : 210.5
Train_AverageReturn : -98.9177474975586
Train_StdReturn : 94.55879974365234
Train_MaxReturn : 32.53923034667969
Train_MinReturn : -233.83660888671875
Train_AverageEpLen : 344.2857142857143
Actor Loss : -42.47856903076172
Baseline Loss : 3047.81591796875
Train_EnvstepsSoFar : 105715
TimeSinceStart : 131.60701274871826

********** Iteration 49 ************
Eval_AverageReturn : -179.8116912841797
Eval_StdReturn : 33.395103454589844
Eval_MaxReturn : -134.5357666015625
Eval_MinReturn : -214.0865478515625
Eval_AverageEpLen : 243.33333333333334
Train_AverageReturn : -156.8942108154297
Train_StdReturn : 72.4636459350586
Train_MaxReturn : -48.959632873535156
Train_MinReturn : -252.79638671875
Train_AverageEpLen : 359.5
Actor Loss : -34.51298141479492
Baseline Loss : 2471.91943359375
Train_EnvstepsSoFar : 107872
TimeSinceStart : 136.60871958732605

********** Iteration 50 ************
Eval_AverageReturn : -129.64434814453125
Eval_StdReturn : 69.92003631591797
Eval_MaxReturn : -34.903560638427734
Eval_MinReturn : -201.5372772216797
Eval_AverageEpLen : 161.0
Train_AverageReturn : -145.02870178222656
Train_StdReturn : 74.57868194580078
Train_MaxReturn : -35.54130172729492
Train_MinReturn : -259.8941650390625
Train_AverageEpLen : 370.8333333333333
Actor Loss : -361.25042724609375
Baseline Loss : 2159.138671875
Train_EnvstepsSoFar : 110097
TimeSinceStart : 140.68611645698547

********** Iteration 51 ************
Eval_AverageReturn : -159.68719482421875
Eval_StdReturn : 59.89820098876953
Eval_MaxReturn : -99.78898620605469
Eval_MinReturn : -219.58538818359375
Eval_AverageEpLen : 212.0
Train_AverageReturn : -147.7326202392578
Train_StdReturn : 77.45787048339844
Train_MaxReturn : -75.8125991821289
Train_MinReturn : -290.84381103515625
Train_AverageEpLen : 341.8333333333333
Actor Loss : -234.74151611328125
Baseline Loss : 1211.440185546875
Train_EnvstepsSoFar : 112148
TimeSinceStart : 144.27564096450806

********** Iteration 52 ************
Eval_AverageReturn : -185.9888153076172
Eval_StdReturn : 11.039077758789062
Eval_MaxReturn : -174.94973754882812
Eval_MinReturn : -197.02789306640625
Eval_AverageEpLen : 200.5
Train_AverageReturn : -108.87834167480469
Train_StdReturn : 80.33931732177734
Train_MaxReturn : 3.3270339965820312
Train_MinReturn : -215.15399169921875
Train_AverageEpLen : 187.54545454545453
Actor Loss : -557.197021484375
Baseline Loss : 1898.4202880859375
Train_EnvstepsSoFar : 114211
TimeSinceStart : 147.17488884925842

********** Iteration 53 ************
Eval_AverageReturn : -119.81475830078125
Eval_StdReturn : 27.6120548248291
Eval_MaxReturn : -99.42121887207031
Eval_MinReturn : -158.85101318359375
Eval_AverageEpLen : 161.66666666666666
Train_AverageReturn : -127.01797485351562
Train_StdReturn : 70.9520034790039
Train_MaxReturn : -39.76313018798828
Train_MinReturn : -242.56593322753906
Train_AverageEpLen : 259.75
Actor Loss : -529.8722534179688
Baseline Loss : 1523.6607666015625
Train_EnvstepsSoFar : 116289
TimeSinceStart : 150.2629599571228

********** Iteration 54 ************
Eval_AverageReturn : -102.4865951538086
Eval_StdReturn : 42.936546325683594
Eval_MaxReturn : -59.550048828125
Eval_MinReturn : -145.4231414794922
Eval_AverageEpLen : 227.0
Train_AverageReturn : -102.1250991821289
Train_StdReturn : 126.42926025390625
Train_MaxReturn : 78.211181640625
Train_MinReturn : -330.6055908203125
Train_AverageEpLen : 359.5
Actor Loss : -9.25271987915039
Baseline Loss : 2533.405517578125
Train_EnvstepsSoFar : 118446
TimeSinceStart : 154.10327124595642

********** Iteration 55 ************
Eval_AverageReturn : -60.907470703125
Eval_StdReturn : 13.47871208190918
Eval_MaxReturn : -47.42876052856445
Eval_MinReturn : -74.38618469238281
Eval_AverageEpLen : 203.0
Train_AverageReturn : -135.52142333984375
Train_StdReturn : 125.86649322509766
Train_MaxReturn : 92.11209869384766
Train_MinReturn : -294.42431640625
Train_AverageEpLen : 350.42857142857144
Actor Loss : 52.41659164428711
Baseline Loss : 2856.45263671875
Train_EnvstepsSoFar : 120899
TimeSinceStart : 158.32966256141663

********** Iteration 56 ************
Eval_AverageReturn : -61.05006790161133
Eval_StdReturn : 186.68954467773438
Eval_MaxReturn : 160.37939453125
Eval_MinReturn : -296.2887878417969
Eval_AverageEpLen : 456.6666666666667
Train_AverageReturn : -126.55632019042969
Train_StdReturn : 107.58641815185547
Train_MaxReturn : 66.6480712890625
Train_MinReturn : -317.763671875
Train_AverageEpLen : 216.5
Actor Loss : -480.6048889160156
Baseline Loss : 2526.55322265625
Train_EnvstepsSoFar : 123064
TimeSinceStart : 163.21707320213318

********** Iteration 57 ************
Eval_AverageReturn : -106.56920623779297
Eval_StdReturn : 75.54257202148438
Eval_MaxReturn : -51.515403747558594
Eval_MinReturn : -213.38563537597656
Eval_AverageEpLen : 190.0
Train_AverageReturn : -179.36865234375
Train_StdReturn : 99.50907135009766
Train_MaxReturn : -26.994848251342773
Train_MinReturn : -321.9781188964844
Train_AverageEpLen : 252.55555555555554
Actor Loss : -524.45458984375
Baseline Loss : 2179.775634765625
Train_EnvstepsSoFar : 125337
TimeSinceStart : 166.7880117893219

********** Iteration 58 ************
Eval_AverageReturn : -272.01385498046875
Eval_StdReturn : 43.955787658691406
Eval_MaxReturn : -228.0580596923828
Eval_MinReturn : -315.9696350097656
Eval_AverageEpLen : 218.5
Train_AverageReturn : -151.32009887695312
Train_StdReturn : 96.63374328613281
Train_MaxReturn : 42.71617126464844
Train_MinReturn : -241.0204315185547
Train_AverageEpLen : 247.44444444444446
Actor Loss : -409.01385498046875
Baseline Loss : 2627.03857421875
Train_EnvstepsSoFar : 127564
TimeSinceStart : 170.44892954826355

********** Iteration 59 ************
Eval_AverageReturn : -187.8356170654297
Eval_StdReturn : 34.4593620300293
Eval_MaxReturn : -157.31756591796875
Eval_MinReturn : -235.9984130859375
Eval_AverageEpLen : 215.0
Train_AverageReturn : -112.64501953125
Train_StdReturn : 153.65394592285156
Train_MaxReturn : 179.7703399658203
Train_MinReturn : -277.1772766113281
Train_AverageEpLen : 364.5
Actor Loss : 280.62799072265625
Baseline Loss : 3412.116455078125
Train_EnvstepsSoFar : 129751
TimeSinceStart : 174.35305786132812

********** Iteration 60 ************
Eval_AverageReturn : -178.79971313476562
Eval_StdReturn : 96.9865493774414
Eval_MaxReturn : -81.81315612792969
Eval_MinReturn : -275.7862548828125
Eval_AverageEpLen : 238.0
Train_AverageReturn : -144.03192138671875
Train_StdReturn : 67.40636444091797
Train_MaxReturn : -29.016422271728516
Train_MinReturn : -246.07553100585938
Train_AverageEpLen : 228.0
Actor Loss : -733.5797729492188
Baseline Loss : 2178.78271484375
Train_EnvstepsSoFar : 131803
TimeSinceStart : 177.74804997444153

********** Iteration 61 ************
Eval_AverageReturn : -237.55633544921875
Eval_StdReturn : 65.4764175415039
Eval_MaxReturn : -172.0799102783203
Eval_MinReturn : -303.0327453613281
Eval_AverageEpLen : 274.0
Train_AverageReturn : -137.08340454101562
Train_StdReturn : 76.28071594238281
Train_MaxReturn : -49.44230651855469
Train_MinReturn : -298.5107421875
Train_AverageEpLen : 204.3
Actor Loss : -483.105712890625
Baseline Loss : 1792.400390625
Train_EnvstepsSoFar : 133846
TimeSinceStart : 180.80498695373535

********** Iteration 62 ************
Eval_AverageReturn : -144.9661865234375
Eval_StdReturn : 80.27503204345703
Eval_MaxReturn : -64.69114685058594
Eval_MinReturn : -225.2412109375
Eval_AverageEpLen : 265.0
Train_AverageReturn : -118.41249084472656
Train_StdReturn : 80.05875396728516
Train_MaxReturn : -3.0572547912597656
Train_MinReturn : -241.27102661132812
Train_AverageEpLen : 252.5
Actor Loss : -186.24716186523438
Baseline Loss : 1563.2652587890625
Train_EnvstepsSoFar : 135866
TimeSinceStart : 184.19417715072632

********** Iteration 63 ************
Eval_AverageReturn : -152.02540588378906
Eval_StdReturn : 103.24807739257812
Eval_MaxReturn : -48.77732849121094
Eval_MinReturn : -255.2734832763672
Eval_AverageEpLen : 271.0
Train_AverageReturn : -126.5174560546875
Train_StdReturn : 82.08809661865234
Train_MaxReturn : -7.784480094909668
Train_MinReturn : -266.24383544921875
Train_AverageEpLen : 250.375
Actor Loss : -276.93621826171875
Baseline Loss : 2144.052001953125
Train_EnvstepsSoFar : 137869
TimeSinceStart : 187.60184001922607

********** Iteration 64 ************
Eval_AverageReturn : 27.87298583984375
Eval_StdReturn : 39.71281433105469
Eval_MaxReturn : 67.58580017089844
Eval_MinReturn : -11.839828491210938
Eval_AverageEpLen : 607.0
Train_AverageReturn : -62.89430618286133
Train_StdReturn : 113.31839752197266
Train_MaxReturn : 184.7262725830078
Train_MinReturn : -184.94972229003906
Train_AverageEpLen : 296.3333333333333
Actor Loss : 301.9975891113281
Baseline Loss : 3263.249755859375
Train_EnvstepsSoFar : 140536
TimeSinceStart : 194.2919955253601

********** Iteration 65 ************
Eval_AverageReturn : -200.20355224609375
Eval_StdReturn : 39.239906311035156
Eval_MaxReturn : -160.96363830566406
Eval_MinReturn : -239.44345092773438
Eval_AverageEpLen : 287.0
Train_AverageReturn : -157.43972778320312
Train_StdReturn : 57.51093673706055
Train_MaxReturn : -37.48685836791992
Train_MinReturn : -245.42855834960938
Train_AverageEpLen : 231.44444444444446
Actor Loss : -67.50265502929688
Baseline Loss : 2315.85009765625
Train_EnvstepsSoFar : 142619
TimeSinceStart : 197.73968195915222

********** Iteration 66 ************
Eval_AverageReturn : -97.51919555664062
Eval_StdReturn : 102.99573516845703
Eval_MaxReturn : 5.476539611816406
Eval_MinReturn : -200.51492309570312
Eval_AverageEpLen : 271.0
Train_AverageReturn : -69.66969299316406
Train_StdReturn : 111.15851593017578
Train_MaxReturn : 124.87091827392578
Train_MinReturn : -203.44740295410156
Train_AverageEpLen : 354.6666666666667
Actor Loss : 332.7960205078125
Baseline Loss : 3081.63720703125
Train_EnvstepsSoFar : 144747
TimeSinceStart : 201.9407069683075

********** Iteration 67 ************
Eval_AverageReturn : -146.60031127929688
Eval_StdReturn : 69.8679428100586
Eval_MaxReturn : -76.73236846923828
Eval_MinReturn : -216.46826171875
Eval_AverageEpLen : 218.0
Train_AverageReturn : -158.31341552734375
Train_StdReturn : 93.96527099609375
Train_MaxReturn : 14.423710823059082
Train_MinReturn : -242.92276000976562
Train_AverageEpLen : 265.375
Actor Loss : 12.57868766784668
Baseline Loss : 2014.8079833984375
Train_EnvstepsSoFar : 146870
TimeSinceStart : 205.3793613910675

********** Iteration 68 ************
Eval_AverageReturn : -175.11434936523438
Eval_StdReturn : 5.595664978027344
Eval_MaxReturn : -169.5186767578125
Eval_MinReturn : -180.7100067138672
Eval_AverageEpLen : 243.0
Train_AverageReturn : -140.50775146484375
Train_StdReturn : 74.99311828613281
Train_MaxReturn : -23.525516510009766
Train_MinReturn : -231.09942626953125
Train_AverageEpLen : 235.66666666666666
Actor Loss : -395.8329162597656
Baseline Loss : 2351.393798828125
Train_EnvstepsSoFar : 148991
TimeSinceStart : 208.7243869304657

********** Iteration 69 ************
Eval_AverageReturn : -197.5204620361328
Eval_StdReturn : 107.37882232666016
Eval_MaxReturn : -46.634246826171875
Eval_MinReturn : -287.80712890625
Eval_AverageEpLen : 193.33333333333334
Train_AverageReturn : -127.24848175048828
Train_StdReturn : 90.55271911621094
Train_MaxReturn : 58.85111999511719
Train_MinReturn : -264.1752624511719
Train_AverageEpLen : 252.77777777777777
Actor Loss : -43.004661560058594
Baseline Loss : 2074.623291015625
Train_EnvstepsSoFar : 151266
TimeSinceStart : 212.56700205802917

********** Iteration 70 ************
Eval_AverageReturn : -139.06134033203125
Eval_StdReturn : 13.017738342285156
Eval_MaxReturn : -126.04360961914062
Eval_MinReturn : -152.07908630371094
Eval_AverageEpLen : 284.0
Train_AverageReturn : -155.07650756835938
Train_StdReturn : 74.65412139892578
Train_MaxReturn : -42.68043518066406
Train_MinReturn : -263.69964599609375
Train_AverageEpLen : 238.66666666666666
Actor Loss : -176.6670684814453
Baseline Loss : 2054.29736328125
Train_EnvstepsSoFar : 153414
TimeSinceStart : 216.25842452049255

********** Iteration 71 ************
Eval_AverageReturn : -48.25699996948242
Eval_StdReturn : 9.335758209228516
Eval_MaxReturn : -38.921241760253906
Eval_MinReturn : -57.59275817871094
Eval_AverageEpLen : 233.0
Train_AverageReturn : -44.94575119018555
Train_StdReturn : 107.9891128540039
Train_MaxReturn : 125.97727966308594
Train_MinReturn : -236.6141357421875
Train_AverageEpLen : 352.6666666666667
Actor Loss : 119.3566665649414
Baseline Loss : 2556.08056640625
Train_EnvstepsSoFar : 155530
TimeSinceStart : 219.9914288520813

********** Iteration 72 ************
Eval_AverageReturn : -156.680419921875
Eval_StdReturn : 82.0595932006836
Eval_MaxReturn : -74.62083435058594
Eval_MinReturn : -238.74002075195312
Eval_AverageEpLen : 209.5
Train_AverageReturn : -120.50228118896484
Train_StdReturn : 106.77175903320312
Train_MaxReturn : 33.93129348754883
Train_MinReturn : -296.50787353515625
Train_AverageEpLen : 224.88888888888889
Actor Loss : -263.92047119140625
Baseline Loss : 2759.268310546875
Train_EnvstepsSoFar : 157554
TimeSinceStart : 223.1710867881775

********** Iteration 73 ************
Eval_AverageReturn : -128.572265625
Eval_StdReturn : 58.94569778442383
Eval_MaxReturn : -64.22742462158203
Eval_MinReturn : -206.6434783935547
Eval_AverageEpLen : 213.0
Train_AverageReturn : -25.18852996826172
Train_StdReturn : 187.57611083984375
Train_MaxReturn : 163.739501953125
Train_MinReturn : -220.430419921875
Train_AverageEpLen : 577.5
Actor Loss : 784.6857299804688
Baseline Loss : 3803.25390625
Train_EnvstepsSoFar : 159864
TimeSinceStart : 227.6617431640625

********** Iteration 74 ************
Eval_AverageReturn : -184.12754821777344
Eval_StdReturn : 32.37489318847656
Eval_MaxReturn : -151.75265502929688
Eval_MinReturn : -216.50244140625
Eval_AverageEpLen : 225.5
Train_AverageReturn : -105.42765808105469
Train_StdReturn : 109.04359436035156
Train_MaxReturn : 102.18281555175781
Train_MinReturn : -234.71881103515625
Train_AverageEpLen : 365.14285714285717
Actor Loss : 218.02346801757812
Baseline Loss : 2672.26416015625
Train_EnvstepsSoFar : 162420
TimeSinceStart : 232.07619619369507

********** Iteration 75 ************
Eval_AverageReturn : -201.84596252441406
Eval_StdReturn : 9.873886108398438
Eval_MaxReturn : -191.97207641601562
Eval_MinReturn : -211.7198486328125
Eval_AverageEpLen : 243.5
Train_AverageReturn : -108.16017150878906
Train_StdReturn : 125.84062957763672
Train_MaxReturn : 96.68533325195312
Train_MinReturn : -242.09555053710938
Train_AverageEpLen : 323.77777777777777
Actor Loss : -219.88357543945312
Baseline Loss : 3298.126220703125
Train_EnvstepsSoFar : 165334
TimeSinceStart : 236.74947881698608

********** Iteration 76 ************
Eval_AverageReturn : -149.44781494140625
Eval_StdReturn : 42.73493194580078
Eval_MaxReturn : -106.712890625
Eval_MinReturn : -192.18275451660156
Eval_AverageEpLen : 286.0
Train_AverageReturn : -98.57281494140625
Train_StdReturn : 115.66000366210938
Train_MaxReturn : 134.7412872314453
Train_MinReturn : -191.36874389648438
Train_AverageEpLen : 340.1666666666667
Actor Loss : 87.0084228515625
Baseline Loss : 2882.630126953125
Train_EnvstepsSoFar : 167375
TimeSinceStart : 240.5577085018158

********** Iteration 77 ************
Eval_AverageReturn : -164.63319396972656
Eval_StdReturn : 31.556747436523438
Eval_MaxReturn : -133.07644653320312
Eval_MinReturn : -196.18994140625
Eval_AverageEpLen : 235.5
Train_AverageReturn : -243.36886596679688
Train_StdReturn : 57.08183288574219
Train_MaxReturn : -120.84563446044922
Train_MinReturn : -317.0085144042969
Train_AverageEpLen : 276.5
Actor Loss : -369.17095947265625
Baseline Loss : 3575.84423828125
Train_EnvstepsSoFar : 169587
TimeSinceStart : 244.35578393936157

********** Iteration 78 ************
Eval_AverageReturn : -77.56792449951172
Eval_StdReturn : 50.37587356567383
Eval_MaxReturn : -27.19205093383789
Eval_MinReturn : -127.94380187988281
Eval_AverageEpLen : 215.0
Train_AverageReturn : -87.25450897216797
Train_StdReturn : 129.10836791992188
Train_MaxReturn : 119.8416748046875
Train_MinReturn : -299.2154541015625
Train_AverageEpLen : 363.6666666666667
Actor Loss : 252.06710815429688
Baseline Loss : 2612.974609375
Train_EnvstepsSoFar : 171769
TimeSinceStart : 248.36837315559387

********** Iteration 79 ************
Eval_AverageReturn : -253.79241943359375
Eval_StdReturn : 13.618682861328125
Eval_MaxReturn : -240.17373657226562
Eval_MinReturn : -267.4111022949219
Eval_AverageEpLen : 248.5
Train_AverageReturn : -131.87091064453125
Train_StdReturn : 107.97970581054688
Train_MaxReturn : -0.5981321334838867
Train_MinReturn : -314.2674865722656
Train_AverageEpLen : 242.88888888888889
Actor Loss : -447.59722900390625
Baseline Loss : 2569.3876953125
Train_EnvstepsSoFar : 173955
TimeSinceStart : 252.07657098770142

********** Iteration 80 ************
Eval_AverageReturn : -74.82982635498047
Eval_StdReturn : 102.85826873779297
Eval_MaxReturn : 14.118236541748047
Eval_MinReturn : -218.98294067382812
Eval_AverageEpLen : 187.33333333333334
Train_AverageReturn : -113.86842346191406
Train_StdReturn : 104.63436889648438
Train_MaxReturn : 24.184223175048828
Train_MinReturn : -254.84213256835938
Train_AverageEpLen : 237.11111111111111
Actor Loss : -257.93798828125
Baseline Loss : 2900.599609375
Train_EnvstepsSoFar : 176089
TimeSinceStart : 255.3729326725006

********** Iteration 81 ************
Eval_AverageReturn : -32.5534553527832
Eval_StdReturn : 41.905452728271484
Eval_MaxReturn : 9.351997375488281
Eval_MinReturn : -74.45890808105469
Eval_AverageEpLen : 204.0
Train_AverageReturn : -93.64273834228516
Train_StdReturn : 88.73524475097656
Train_MaxReturn : 20.26146697998047
Train_MinReturn : -235.13587951660156
Train_AverageEpLen : 222.55555555555554
Actor Loss : -247.0047607421875
Baseline Loss : 2010.2564697265625
Train_EnvstepsSoFar : 178092
TimeSinceStart : 258.4426281452179

********** Iteration 82 ************
Eval_AverageReturn : -190.8141632080078
Eval_StdReturn : 52.94313430786133
Eval_MaxReturn : -125.13571166992188
Eval_MinReturn : -254.78567504882812
Eval_AverageEpLen : 241.33333333333334
Train_AverageReturn : -39.71707534790039
Train_StdReturn : 135.63433837890625
Train_MaxReturn : 247.67648315429688
Train_MinReturn : -202.61241149902344
Train_AverageEpLen : 289.0
Actor Loss : 63.57709503173828
Baseline Loss : 3359.6953125
Train_EnvstepsSoFar : 180115
TimeSinceStart : 262.32374835014343

********** Iteration 83 ************
Eval_AverageReturn : -6.475624084472656
Eval_StdReturn : 63.10301971435547
Eval_MaxReturn : 56.62739562988281
Eval_MinReturn : -69.57864379882812
Eval_AverageEpLen : 252.5
Train_AverageReturn : -132.7714080810547
Train_StdReturn : 88.68964385986328
Train_MaxReturn : -6.159664154052734
Train_MinReturn : -236.6185302734375
Train_AverageEpLen : 235.33333333333334
Actor Loss : -105.49864196777344
Baseline Loss : 2805.47998046875
Train_EnvstepsSoFar : 182233
TimeSinceStart : 265.7739541530609

********** Iteration 84 ************
Eval_AverageReturn : 54.533870697021484
Eval_StdReturn : 0.0
Eval_MaxReturn : 54.533870697021484
Eval_MinReturn : 54.533870697021484
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -110.29456329345703
Train_StdReturn : 91.16515350341797
Train_MaxReturn : 48.35887908935547
Train_MinReturn : -190.82789611816406
Train_AverageEpLen : 346.3333333333333
Actor Loss : 27.028606414794922
Baseline Loss : 2988.87451171875
Train_EnvstepsSoFar : 184311
TimeSinceStart : 271.1104860305786

********** Iteration 85 ************
Eval_AverageReturn : -139.91827392578125
Eval_StdReturn : 56.59861755371094
Eval_MaxReturn : -83.31965637207031
Eval_MinReturn : -196.5168914794922
Eval_AverageEpLen : 256.0
Train_AverageReturn : -87.0508804321289
Train_StdReturn : 91.34593963623047
Train_MaxReturn : 22.09974479675293
Train_MinReturn : -268.3312683105469
Train_AverageEpLen : 211.3
Actor Loss : -260.1845397949219
Baseline Loss : 2199.19873046875
Train_EnvstepsSoFar : 186424
TimeSinceStart : 274.27907705307007

********** Iteration 86 ************
Eval_AverageReturn : -238.91159057617188
Eval_StdReturn : 1.4752424955368042
Eval_MaxReturn : -237.43634033203125
Eval_MinReturn : -240.38682556152344
Eval_AverageEpLen : 292.0
Train_AverageReturn : -42.54777908325195
Train_StdReturn : 100.55856323242188
Train_MaxReturn : 132.61756896972656
Train_MinReturn : -196.05213928222656
Train_AverageEpLen : 368.8333333333333
Actor Loss : 334.15020751953125
Baseline Loss : 2417.8251953125
Train_EnvstepsSoFar : 188637
TimeSinceStart : 278.7424097061157

********** Iteration 87 ************
Eval_AverageReturn : -174.60934448242188
Eval_StdReturn : 8.574058532714844
Eval_MaxReturn : -166.0352783203125
Eval_MinReturn : -183.1833953857422
Eval_AverageEpLen : 216.5
Train_AverageReturn : -97.50633239746094
Train_StdReturn : 131.03831481933594
Train_MaxReturn : 144.46310424804688
Train_MinReturn : -268.70806884765625
Train_AverageEpLen : 355.75
Actor Loss : 177.68057250976562
Baseline Loss : 2659.52294921875
Train_EnvstepsSoFar : 191483
TimeSinceStart : 283.7228796482086

********** Iteration 88 ************
Eval_AverageReturn : -165.14938354492188
Eval_StdReturn : 30.82898712158203
Eval_MaxReturn : -134.32040405273438
Eval_MinReturn : -195.97837829589844
Eval_AverageEpLen : 209.5
Train_AverageReturn : -158.7840576171875
Train_StdReturn : 138.18374633789062
Train_MaxReturn : 149.7059326171875
Train_MinReturn : -230.26113891601562
Train_AverageEpLen : 356.8333333333333
Actor Loss : 145.67909240722656
Baseline Loss : 3628.553955078125
Train_EnvstepsSoFar : 193624
TimeSinceStart : 287.4344148635864

********** Iteration 89 ************
Eval_AverageReturn : -225.1454315185547
Eval_StdReturn : 27.88641357421875
Eval_MaxReturn : -197.25901794433594
Eval_MinReturn : -253.03184509277344
Eval_AverageEpLen : 259.5
Train_AverageReturn : -19.11715316772461
Train_StdReturn : 64.09510040283203
Train_MaxReturn : 89.11156463623047
Train_MinReturn : -78.09193420410156
Train_AverageEpLen : 521.25
Actor Loss : 367.0455627441406
Baseline Loss : 2570.640869140625
Train_EnvstepsSoFar : 195709
TimeSinceStart : 291.94128036499023

********** Iteration 90 ************
Eval_AverageReturn : 8.561408996582031
Eval_StdReturn : 68.84549713134766
Eval_MaxReturn : 77.40690612792969
Eval_MinReturn : -60.284088134765625
Eval_AverageEpLen : 634.0
Train_AverageReturn : -67.43113708496094
Train_StdReturn : 68.56114959716797
Train_MaxReturn : 16.85540199279785
Train_MinReturn : -207.79432678222656
Train_AverageEpLen : 230.77777777777777
Actor Loss : -29.397186279296875
Baseline Loss : 1657.1865234375
Train_EnvstepsSoFar : 197786
TimeSinceStart : 296.2782757282257

********** Iteration 91 ************
Eval_AverageReturn : -174.18240356445312
Eval_StdReturn : 26.97876739501953
Eval_MaxReturn : -147.20364379882812
Eval_MinReturn : -201.1611785888672
Eval_AverageEpLen : 232.0
Train_AverageReturn : -145.6371612548828
Train_StdReturn : 150.2526092529297
Train_MaxReturn : 123.9046630859375
Train_MinReturn : -274.80712890625
Train_AverageEpLen : 402.6666666666667
Actor Loss : 193.3743438720703
Baseline Loss : 2835.177978515625
Train_EnvstepsSoFar : 200202
TimeSinceStart : 300.3131115436554

********** Iteration 92 ************
Eval_AverageReturn : -113.48493194580078
Eval_StdReturn : 135.87820434570312
Eval_MaxReturn : 22.393266677856445
Eval_MinReturn : -249.36312866210938
Eval_AverageEpLen : 212.5
Train_AverageReturn : -127.09795379638672
Train_StdReturn : 78.65370178222656
Train_MaxReturn : -30.741920471191406
Train_MinReturn : -253.49195861816406
Train_AverageEpLen : 260.75
Actor Loss : -573.2918701171875
Baseline Loss : 2598.32177734375
Train_EnvstepsSoFar : 202288
TimeSinceStart : 303.44688630104065

********** Iteration 93 ************
Eval_AverageReturn : -124.848876953125
Eval_StdReturn : 104.0792236328125
Eval_MaxReturn : -20.7696590423584
Eval_MinReturn : -228.9281005859375
Eval_AverageEpLen : 276.0
Train_AverageReturn : -122.83902740478516
Train_StdReturn : 104.56867980957031
Train_MaxReturn : 28.93524169921875
Train_MinReturn : -270.54766845703125
Train_AverageEpLen : 223.22222222222223
Actor Loss : 62.19036102294922
Baseline Loss : 3630.91796875
Train_EnvstepsSoFar : 204297
TimeSinceStart : 306.62259888648987

********** Iteration 94 ************
Eval_AverageReturn : -154.890869140625
Eval_StdReturn : 84.6901626586914
Eval_MaxReturn : -70.20071411132812
Eval_MinReturn : -239.58103942871094
Eval_AverageEpLen : 248.5
Train_AverageReturn : 29.659006118774414
Train_StdReturn : 119.65623474121094
Train_MaxReturn : 227.51388549804688
Train_MinReturn : -84.2928466796875
Train_AverageEpLen : 518.4
Actor Loss : 147.67140197753906
Baseline Loss : 2150.671630859375
Train_EnvstepsSoFar : 206889
TimeSinceStart : 311.54303193092346

********** Iteration 95 ************
Eval_AverageReturn : -68.19548797607422
Eval_StdReturn : 93.12625885009766
Eval_MaxReturn : 24.93076515197754
Eval_MinReturn : -161.32174682617188
Eval_AverageEpLen : 241.0
Train_AverageReturn : -85.52857208251953
Train_StdReturn : 115.09234619140625
Train_MaxReturn : 152.7142791748047
Train_MinReturn : -179.59890747070312
Train_AverageEpLen : 346.0
Actor Loss : 271.2391662597656
Baseline Loss : 2820.393798828125
Train_EnvstepsSoFar : 208965
TimeSinceStart : 315.3620080947876

********** Iteration 96 ************
Eval_AverageReturn : -35.091312408447266
Eval_StdReturn : 84.26210021972656
Eval_MaxReturn : 49.17079162597656
Eval_MinReturn : -119.3534164428711
Eval_AverageEpLen : 591.0
Train_AverageReturn : -174.2788848876953
Train_StdReturn : 121.0501937866211
Train_MaxReturn : 83.51522827148438
Train_MinReturn : -280.3984375
Train_AverageEpLen : 369.1666666666667
Actor Loss : -109.71832275390625
Baseline Loss : 3813.79345703125
Train_EnvstepsSoFar : 211180
TimeSinceStart : 320.47424030303955

********** Iteration 97 ************
Eval_AverageReturn : -48.168914794921875
Eval_StdReturn : 4.81553840637207
Eval_MaxReturn : -43.35337448120117
Eval_MinReturn : -52.98445129394531
Eval_AverageEpLen : 219.0
Train_AverageReturn : -66.60123443603516
Train_StdReturn : 78.94051361083984
Train_MaxReturn : 67.86881256103516
Train_MinReturn : -187.3736572265625
Train_AverageEpLen : 354.6666666666667
Actor Loss : -88.05204772949219
Baseline Loss : 2522.69091796875
Train_EnvstepsSoFar : 213308
TimeSinceStart : 324.26918601989746

********** Iteration 98 ************
Eval_AverageReturn : -119.91957092285156
Eval_StdReturn : 0.0
Eval_MaxReturn : -119.91957092285156
Eval_MinReturn : -119.91957092285156
Eval_AverageEpLen : 436.0
Train_AverageReturn : -70.75536346435547
Train_StdReturn : 96.64315795898438
Train_MaxReturn : 102.99581146240234
Train_MinReturn : -172.6013946533203
Train_AverageEpLen : 331.2857142857143
Actor Loss : 40.646888732910156
Baseline Loss : 2780.52099609375
Train_EnvstepsSoFar : 215627
TimeSinceStart : 328.32171750068665

********** Iteration 99 ************
Eval_AverageReturn : -86.94510650634766
Eval_StdReturn : 75.04293823242188
Eval_MaxReturn : -20.654052734375
Eval_MinReturn : -191.86309814453125
Eval_AverageEpLen : 218.0
Train_AverageReturn : 2.2212367057800293
Train_StdReturn : 74.56261444091797
Train_MaxReturn : 130.81698608398438
Train_MinReturn : -93.36822509765625
Train_AverageEpLen : 503.6
Actor Loss : 15.389142990112305
Baseline Loss : 1720.3421630859375
Train_EnvstepsSoFar : 218145
TimeSinceStart : 333.5949718952179

********** Iteration 100 ************
Eval_AverageReturn : -130.59829711914062
Eval_StdReturn : 47.14838409423828
Eval_MaxReturn : -83.44990539550781
Eval_MinReturn : -177.74667358398438
Eval_AverageEpLen : 218.5
Train_AverageReturn : -131.68165588378906
Train_StdReturn : 79.88533020019531
Train_MaxReturn : -41.81016540527344
Train_MinReturn : -278.40869140625
Train_AverageEpLen : 259.77777777777777
Actor Loss : -14.219533920288086
Baseline Loss : 1696.990966796875
Train_EnvstepsSoFar : 220483
TimeSinceStart : 337.2299997806549

********** Iteration 101 ************
Eval_AverageReturn : -236.822509765625
Eval_StdReturn : 0.0
Eval_MaxReturn : -236.822509765625
Eval_MinReturn : -236.822509765625
Eval_AverageEpLen : 409.0
Train_AverageReturn : -95.2286376953125
Train_StdReturn : 109.7944107055664
Train_MaxReturn : 20.402816772460938
Train_MinReturn : -285.70361328125
Train_AverageEpLen : 250.125
Actor Loss : -185.22438049316406
Baseline Loss : 3165.033935546875
Train_EnvstepsSoFar : 222484
TimeSinceStart : 340.4063403606415

********** Iteration 102 ************
Eval_AverageReturn : -22.061979293823242
Eval_StdReturn : 63.525787353515625
Eval_MaxReturn : 41.463809967041016
Eval_MinReturn : -85.5877685546875
Eval_AverageEpLen : 612.5
Train_AverageReturn : -66.05499267578125
Train_StdReturn : 112.51952362060547
Train_MaxReturn : 110.0405502319336
Train_MinReturn : -241.0889129638672
Train_AverageEpLen : 435.0
Actor Loss : -143.18084716796875
Baseline Loss : 1580.819580078125
Train_EnvstepsSoFar : 224659
TimeSinceStart : 346.0588791370392

********** Iteration 103 ************
Eval_AverageReturn : -188.73780822753906
Eval_StdReturn : 25.71234130859375
Eval_MaxReturn : -163.0254669189453
Eval_MinReturn : -214.4501495361328
Eval_AverageEpLen : 225.0
Train_AverageReturn : -135.56752014160156
Train_StdReturn : 75.4259033203125
Train_MaxReturn : -7.283572196960449
Train_MinReturn : -247.82130432128906
Train_AverageEpLen : 245.33333333333334
Actor Loss : -358.6941223144531
Baseline Loss : 2874.69970703125
Train_EnvstepsSoFar : 226867
TimeSinceStart : 349.6222701072693

********** Iteration 104 ************
Eval_AverageReturn : -52.99654769897461
Eval_StdReturn : 119.20609283447266
Eval_MaxReturn : 84.99726867675781
Eval_MinReturn : -205.8589324951172
Eval_AverageEpLen : 465.0
Train_AverageReturn : -91.44452667236328
Train_StdReturn : 76.8662109375
Train_MaxReturn : -2.9767370223999023
Train_MinReturn : -208.0100555419922
Train_AverageEpLen : 256.25
Actor Loss : -240.2977752685547
Baseline Loss : 1736.317626953125
Train_EnvstepsSoFar : 228917
TimeSinceStart : 354.89193511009216

********** Iteration 105 ************
Eval_AverageReturn : -208.1172637939453
Eval_StdReturn : 4.763763427734375
Eval_MaxReturn : -203.35350036621094
Eval_MinReturn : -212.8810272216797
Eval_AverageEpLen : 223.5
Train_AverageReturn : -106.99159240722656
Train_StdReturn : 99.17955017089844
Train_MaxReturn : 29.106307983398438
Train_MinReturn : -244.0382080078125
Train_AverageEpLen : 252.125
Actor Loss : 66.53485107421875
Baseline Loss : 2523.2001953125
Train_EnvstepsSoFar : 230934
TimeSinceStart : 358.19575023651123

********** Iteration 106 ************
Eval_AverageReturn : -115.70108795166016
Eval_StdReturn : 20.52123260498047
Eval_MaxReturn : -95.17985534667969
Eval_MinReturn : -136.22232055664062
Eval_AverageEpLen : 290.5
Train_AverageReturn : -73.52546691894531
Train_StdReturn : 123.6912841796875
Train_MaxReturn : 128.64422607421875
Train_MinReturn : -213.86587524414062
Train_AverageEpLen : 402.4
Actor Loss : -107.57174682617188
Baseline Loss : 2117.25
Train_EnvstepsSoFar : 232946
TimeSinceStart : 362.51502752304077

********** Iteration 107 ************
Eval_AverageReturn : -111.0053482055664
Eval_StdReturn : 90.19416046142578
Eval_MaxReturn : -20.811193466186523
Eval_MinReturn : -201.1995086669922
Eval_AverageEpLen : 242.0
Train_AverageReturn : -137.64340209960938
Train_StdReturn : 95.7999267578125
Train_MaxReturn : -25.03652572631836
Train_MinReturn : -252.5978240966797
Train_AverageEpLen : 303.85714285714283
Actor Loss : 36.2778434753418
Baseline Loss : 2030.4453125
Train_EnvstepsSoFar : 235073
TimeSinceStart : 366.21051120758057

********** Iteration 108 ************
Eval_AverageReturn : -117.86685180664062
Eval_StdReturn : 34.624114990234375
Eval_MaxReturn : -83.24273681640625
Eval_MinReturn : -152.490966796875
Eval_AverageEpLen : 274.5
Train_AverageReturn : -161.87806701660156
Train_StdReturn : 65.1253662109375
Train_MaxReturn : -32.8157958984375
Train_MinReturn : -241.17042541503906
Train_AverageEpLen : 287.14285714285717
Actor Loss : 153.627197265625
Baseline Loss : 2458.526123046875
Train_EnvstepsSoFar : 237083
TimeSinceStart : 369.7145040035248

********** Iteration 109 ************
Eval_AverageReturn : 55.842384338378906
Eval_StdReturn : 92.79007720947266
Eval_MaxReturn : 148.63246154785156
Eval_MinReturn : -36.94769287109375
Eval_AverageEpLen : 619.5
Train_AverageReturn : -63.131019592285156
Train_StdReturn : 112.45201873779297
Train_MaxReturn : 98.79595947265625
Train_MinReturn : -194.7197265625
Train_AverageEpLen : 402.8
Actor Loss : 251.98130798339844
Baseline Loss : 2512.359619140625
Train_EnvstepsSoFar : 239097
TimeSinceStart : 375.36544036865234

********** Iteration 110 ************
Eval_AverageReturn : -207.518310546875
Eval_StdReturn : 0.0
Eval_MaxReturn : -207.518310546875
Eval_MinReturn : -207.518310546875
Eval_AverageEpLen : 443.0
Train_AverageReturn : -106.13258361816406
Train_StdReturn : 81.96660614013672
Train_MaxReturn : 27.12205696105957
Train_MinReturn : -260.2959289550781
Train_AverageEpLen : 263.75
Actor Loss : -147.74288940429688
Baseline Loss : 2323.26318359375
Train_EnvstepsSoFar : 241207
TimeSinceStart : 379.1829454898834

********** Iteration 111 ************
Eval_AverageReturn : -220.04339599609375
Eval_StdReturn : 6.403419494628906
Eval_MaxReturn : -213.63998413085938
Eval_MinReturn : -226.4468231201172
Eval_AverageEpLen : 241.5
Train_AverageReturn : -81.6495590209961
Train_StdReturn : 124.2265396118164
Train_MaxReturn : 114.76305389404297
Train_MinReturn : -246.5260009765625
Train_AverageEpLen : 362.85714285714283
Actor Loss : 47.75102615356445
Baseline Loss : 2778.90478515625
Train_EnvstepsSoFar : 243747
TimeSinceStart : 384.0484735965729

********** Iteration 112 ************
Eval_AverageReturn : -117.54689025878906
Eval_StdReturn : 64.99404907226562
Eval_MaxReturn : -52.55284881591797
Eval_MinReturn : -182.5409393310547
Eval_AverageEpLen : 226.0
Train_AverageReturn : -134.1919403076172
Train_StdReturn : 60.3807258605957
Train_MaxReturn : -47.710548400878906
Train_MinReturn : -210.33688354492188
Train_AverageEpLen : 252.0
Actor Loss : 71.10258483886719
Baseline Loss : 2472.26220703125
Train_EnvstepsSoFar : 245763
TimeSinceStart : 387.3447895050049

********** Iteration 113 ************
Eval_AverageReturn : -146.34555053710938
Eval_StdReturn : 30.693695068359375
Eval_MaxReturn : -115.65185546875
Eval_MinReturn : -177.03924560546875
Eval_AverageEpLen : 231.0
Train_AverageReturn : -138.58700561523438
Train_StdReturn : 60.50979995727539
Train_MaxReturn : -35.82807922363281
Train_MinReturn : -188.3834686279297
Train_AverageEpLen : 407.4
Actor Loss : 37.32878112792969
Baseline Loss : 2586.679931640625
Train_EnvstepsSoFar : 247800
TimeSinceStart : 391.074059009552

********** Iteration 114 ************
Eval_AverageReturn : -166.77801513671875
Eval_StdReturn : 39.4583740234375
Eval_MaxReturn : -127.31964111328125
Eval_MinReturn : -206.23638916015625
Eval_AverageEpLen : 278.5
Train_AverageReturn : -172.35621643066406
Train_StdReturn : 81.6741714477539
Train_MaxReturn : -42.46984100341797
Train_MinReturn : -262.223388671875
Train_AverageEpLen : 251.625
Actor Loss : -368.9832458496094
Baseline Loss : 3002.874267578125
Train_EnvstepsSoFar : 249813
TimeSinceStart : 394.6089816093445

********** Iteration 115 ************
Eval_AverageReturn : -114.51016998291016
Eval_StdReturn : 71.85494232177734
Eval_MaxReturn : -42.65522766113281
Eval_MinReturn : -186.3651123046875
Eval_AverageEpLen : 282.5
Train_AverageReturn : -71.42230987548828
Train_StdReturn : 117.32011413574219
Train_MaxReturn : 106.10440826416016
Train_MinReturn : -208.48171997070312
Train_AverageEpLen : 402.0
Actor Loss : 203.28802490234375
Baseline Loss : 2440.791259765625
Train_EnvstepsSoFar : 251823
TimeSinceStart : 398.5742700099945

********** Iteration 116 ************
Eval_AverageReturn : -145.93783569335938
Eval_StdReturn : 94.8227310180664
Eval_MaxReturn : -51.1151123046875
Eval_MinReturn : -240.7605743408203
Eval_AverageEpLen : 306.5
Train_AverageReturn : -76.71127319335938
Train_StdReturn : 93.6316146850586
Train_MaxReturn : 60.70143508911133
Train_MinReturn : -254.61105346679688
Train_AverageEpLen : 228.66666666666666
Actor Loss : 177.5501251220703
Baseline Loss : 2914.02490234375
Train_EnvstepsSoFar : 253881
TimeSinceStart : 402.0594356060028

********** Iteration 117 ************
Eval_AverageReturn : -81.45089721679688
Eval_StdReturn : 110.99423217773438
Eval_MaxReturn : 29.543336868286133
Eval_MinReturn : -192.44512939453125
Eval_AverageEpLen : 252.0
Train_AverageReturn : -131.2902069091797
Train_StdReturn : 86.94324493408203
Train_MaxReturn : -36.31890869140625
Train_MinReturn : -260.306396484375
Train_AverageEpLen : 233.88888888888889
Actor Loss : -83.41373443603516
Baseline Loss : 2496.201416015625
Train_EnvstepsSoFar : 255986
TimeSinceStart : 405.36939692497253

********** Iteration 118 ************
Eval_AverageReturn : 20.430648803710938
Eval_StdReturn : 72.41948699951172
Eval_MaxReturn : 92.85013580322266
Eval_MinReturn : -51.98883819580078
Eval_AverageEpLen : 613.0
Train_AverageReturn : -146.31533813476562
Train_StdReturn : 77.23894500732422
Train_MaxReturn : -31.273767471313477
Train_MinReturn : -231.98643493652344
Train_AverageEpLen : 232.22222222222223
Actor Loss : -222.95774841308594
Baseline Loss : 2723.906005859375
Train_EnvstepsSoFar : 258076
TimeSinceStart : 409.86422872543335

********** Iteration 119 ************
Eval_AverageReturn : -155.84567260742188
Eval_StdReturn : 82.13459014892578
Eval_MaxReturn : -73.7110824584961
Eval_MinReturn : -237.98025512695312
Eval_AverageEpLen : 255.0
Train_AverageReturn : -127.40730285644531
Train_StdReturn : 117.0986099243164
Train_MaxReturn : 72.54273223876953
Train_MinReturn : -244.27069091796875
Train_AverageEpLen : 435.0
Actor Loss : 225.45359802246094
Baseline Loss : 2655.14208984375
Train_EnvstepsSoFar : 260251
TimeSinceStart : 414.2627110481262

********** Iteration 120 ************
Eval_AverageReturn : -135.8561553955078
Eval_StdReturn : 104.6520767211914
Eval_MaxReturn : -31.20407485961914
Eval_MinReturn : -240.5082244873047
Eval_AverageEpLen : 292.0
Train_AverageReturn : -181.13986206054688
Train_StdReturn : 84.02891540527344
Train_MaxReturn : -13.4366455078125
Train_MinReturn : -241.8941650390625
Train_AverageEpLen : 245.66666666666666
Actor Loss : -443.504150390625
Baseline Loss : 2822.760986328125
Train_EnvstepsSoFar : 262462
TimeSinceStart : 417.93321228027344

********** Iteration 121 ************
Eval_AverageReturn : -91.11241149902344
Eval_StdReturn : 56.71598434448242
Eval_MaxReturn : -34.39643096923828
Eval_MinReturn : -147.82839965820312
Eval_AverageEpLen : 218.5
Train_AverageReturn : -192.66232299804688
Train_StdReturn : 76.21664428710938
Train_MaxReturn : -27.843069076538086
Train_MinReturn : -311.334716796875
Train_AverageEpLen : 234.44444444444446
Actor Loss : -221.47242736816406
Baseline Loss : 3595.335205078125
Train_EnvstepsSoFar : 264572
TimeSinceStart : 421.3653390407562

********** Iteration 122 ************
Eval_AverageReturn : 47.802738189697266
Eval_StdReturn : 106.49617004394531
Eval_MaxReturn : 154.2989044189453
Eval_MinReturn : -58.69342803955078
Eval_AverageEpLen : 622.5
Train_AverageReturn : -166.37628173828125
Train_StdReturn : 86.3132553100586
Train_MaxReturn : -24.683761596679688
Train_MinReturn : -264.521484375
Train_AverageEpLen : 245.11111111111111
Actor Loss : -101.43033599853516
Baseline Loss : 3173.35498046875
Train_EnvstepsSoFar : 266778
TimeSinceStart : 426.15552830696106

********** Iteration 123 ************
Eval_AverageReturn : -206.06658935546875
Eval_StdReturn : 1.2285919189453125
Eval_MaxReturn : -204.83799743652344
Eval_MinReturn : -207.29518127441406
Eval_AverageEpLen : 265.5
Train_AverageReturn : -105.82186889648438
Train_StdReturn : 133.4481658935547
Train_MaxReturn : 148.35714721679688
Train_MinReturn : -246.0242919921875
Train_AverageEpLen : 363.8333333333333
Actor Loss : 227.28366088867188
Baseline Loss : 3033.181640625
Train_EnvstepsSoFar : 268961
TimeSinceStart : 430.26649808883667

********** Iteration 124 ************
Eval_AverageReturn : -39.42031478881836
Eval_StdReturn : 7.212985992431641
Eval_MaxReturn : -32.20732879638672
Eval_MinReturn : -46.63330078125
Eval_AverageEpLen : 200.5
Train_AverageReturn : -144.49557495117188
Train_StdReturn : 93.76290893554688
Train_MaxReturn : 13.393228530883789
Train_MinReturn : -251.8811492919922
Train_AverageEpLen : 215.4
Actor Loss : -83.01069641113281
Baseline Loss : 3033.594482421875
Train_EnvstepsSoFar : 271115
TimeSinceStart : 433.41927695274353

********** Iteration 125 ************
Eval_AverageReturn : 77.52589416503906
Eval_StdReturn : 129.6126708984375
Eval_MaxReturn : 207.13856506347656
Eval_MinReturn : -52.08678436279297
Eval_AverageEpLen : 630.0
Train_AverageReturn : -125.38846588134766
Train_StdReturn : 85.89436340332031
Train_MaxReturn : -8.326662063598633
Train_MinReturn : -220.8883819580078
Train_AverageEpLen : 225.33333333333334
Actor Loss : -51.282936096191406
Baseline Loss : 2878.10986328125
Train_EnvstepsSoFar : 273143
TimeSinceStart : 437.7489802837372

********** Iteration 126 ************
Eval_AverageReturn : -128.5811309814453
Eval_StdReturn : 69.81128692626953
Eval_MaxReturn : -58.76984405517578
Eval_MinReturn : -198.39242553710938
Eval_AverageEpLen : 201.0
Train_AverageReturn : -130.2538299560547
Train_StdReturn : 73.35225677490234
Train_MaxReturn : 3.7533164024353027
Train_MinReturn : -195.08087158203125
Train_AverageEpLen : 243.88888888888889
Actor Loss : -74.30443572998047
Baseline Loss : 2209.01220703125
Train_EnvstepsSoFar : 275338
TimeSinceStart : 441.0334494113922

********** Iteration 127 ************
Eval_AverageReturn : -47.62763214111328
Eval_StdReturn : 23.2105712890625
Eval_MaxReturn : -24.41706085205078
Eval_MinReturn : -70.83820343017578
Eval_AverageEpLen : 271.5
Train_AverageReturn : -146.2417449951172
Train_StdReturn : 92.32759094238281
Train_MaxReturn : -11.602344512939453
Train_MinReturn : -268.7823486328125
Train_AverageEpLen : 231.0
Actor Loss : -655.6475219726562
Baseline Loss : 2847.311767578125
Train_EnvstepsSoFar : 277417
TimeSinceStart : 444.38452649116516

********** Iteration 128 ************
Eval_AverageReturn : 32.68457794189453
Eval_StdReturn : 0.0
Eval_MaxReturn : 32.68457794189453
Eval_MinReturn : 32.68457794189453
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -46.850379943847656
Train_StdReturn : 99.268798828125
Train_MaxReturn : 106.84974670410156
Train_MinReturn : -200.0987548828125
Train_AverageEpLen : 403.2
Actor Loss : 415.93475341796875
Baseline Loss : 3126.88330078125
Train_EnvstepsSoFar : 279433
TimeSinceStart : 449.39385962486267

********** Iteration 129 ************
Eval_AverageReturn : -54.358154296875
Eval_StdReturn : 41.80420684814453
Eval_MaxReturn : -12.553945541381836
Eval_MinReturn : -96.16236114501953
Eval_AverageEpLen : 270.5
Train_AverageReturn : 17.407215118408203
Train_StdReturn : 138.5114288330078
Train_MaxReturn : 127.09170532226562
Train_MinReturn : -217.00054931640625
Train_AverageEpLen : 587.0
Actor Loss : 709.95068359375
Baseline Loss : 4543.87353515625
Train_EnvstepsSoFar : 281781
TimeSinceStart : 454.0947217941284

********** Iteration 130 ************
Eval_AverageReturn : -147.3380889892578
Eval_StdReturn : 6.3098297119140625
Eval_MaxReturn : -141.02825927734375
Eval_MinReturn : -153.64791870117188
Eval_AverageEpLen : 221.5
Train_AverageReturn : -97.2577896118164
Train_StdReturn : 142.4536895751953
Train_MaxReturn : 130.4697265625
Train_MinReturn : -298.2274169921875
Train_AverageEpLen : 423.5
Actor Loss : 341.9004821777344
Baseline Loss : 2307.55126953125
Train_EnvstepsSoFar : 284322
TimeSinceStart : 458.33162474632263

********** Iteration 131 ************
Eval_AverageReturn : -21.39704132080078
Eval_StdReturn : 161.71844482421875
Eval_MaxReturn : 140.32139587402344
Eval_MinReturn : -183.115478515625
Eval_AverageEpLen : 633.0
Train_AverageReturn : -80.13069915771484
Train_StdReturn : 119.02783203125
Train_MaxReturn : 93.64879608154297
Train_MinReturn : -235.92840576171875
Train_AverageEpLen : 377.42857142857144
Actor Loss : 455.50372314453125
Baseline Loss : 2547.793701171875
Train_EnvstepsSoFar : 286964
TimeSinceStart : 464.55691838264465

********** Iteration 132 ************
Eval_AverageReturn : -108.29737854003906
Eval_StdReturn : 49.27719497680664
Eval_MaxReturn : -59.020179748535156
Eval_MinReturn : -157.57456970214844
Eval_AverageEpLen : 296.5
Train_AverageReturn : -115.97541809082031
Train_StdReturn : 132.48910522460938
Train_MaxReturn : 99.26087951660156
Train_MinReturn : -253.60704040527344
Train_AverageEpLen : 412.8
Actor Loss : 147.37339782714844
Baseline Loss : 2898.56396484375
Train_EnvstepsSoFar : 289028
TimeSinceStart : 468.5165195465088

********** Iteration 133 ************
Eval_AverageReturn : -102.29583740234375
Eval_StdReturn : 57.83087158203125
Eval_MaxReturn : -44.464962005615234
Eval_MinReturn : -160.126708984375
Eval_AverageEpLen : 231.5
Train_AverageReturn : -112.95561981201172
Train_StdReturn : 81.93119812011719
Train_MaxReturn : -7.854240417480469
Train_MinReturn : -238.13818359375
Train_AverageEpLen : 263.25
Actor Loss : 62.52702713012695
Baseline Loss : 2099.56005859375
Train_EnvstepsSoFar : 291134
TimeSinceStart : 471.86216950416565

********** Iteration 134 ************
Eval_AverageReturn : -188.14617919921875
Eval_StdReturn : 58.70056915283203
Eval_MaxReturn : -129.44561767578125
Eval_MinReturn : -246.8467559814453
Eval_AverageEpLen : 224.0
Train_AverageReturn : -48.3067626953125
Train_StdReturn : 132.66177368164062
Train_MaxReturn : 158.3225555419922
Train_MinReturn : -240.04844665527344
Train_AverageEpLen : 364.0
Actor Loss : 217.80357360839844
Baseline Loss : 2919.25146484375
Train_EnvstepsSoFar : 293318
TimeSinceStart : 475.3939595222473

********** Iteration 135 ************
Eval_AverageReturn : -80.01502227783203
Eval_StdReturn : 38.27940368652344
Eval_MaxReturn : -41.735618591308594
Eval_MinReturn : -118.29442596435547
Eval_AverageEpLen : 299.0
Train_AverageReturn : -72.14752197265625
Train_StdReturn : 82.27228546142578
Train_MaxReturn : -1.3406448364257812
Train_MinReturn : -242.3738250732422
Train_AverageEpLen : 254.25
Actor Loss : -248.62538146972656
Baseline Loss : 1586.7047119140625
Train_EnvstepsSoFar : 295352
TimeSinceStart : 478.88619661331177

********** Iteration 136 ************
Eval_AverageReturn : -158.58766174316406
Eval_StdReturn : 97.86589813232422
Eval_MaxReturn : -60.721763610839844
Eval_MinReturn : -256.45355224609375
Eval_AverageEpLen : 325.5
Train_AverageReturn : -70.28739166259766
Train_StdReturn : 148.85292053222656
Train_MaxReturn : 194.4293212890625
Train_MinReturn : -260.0499267578125
Train_AverageEpLen : 322.57142857142856
Actor Loss : 253.1354217529297
Baseline Loss : 2470.352294921875
Train_EnvstepsSoFar : 297610
TimeSinceStart : 483.0195860862732

********** Iteration 137 ************
Eval_AverageReturn : -201.16958618164062
Eval_StdReturn : 50.6546630859375
Eval_MaxReturn : -150.51492309570312
Eval_MinReturn : -251.82424926757812
Eval_AverageEpLen : 285.5
Train_AverageReturn : -76.72420501708984
Train_StdReturn : 149.4334259033203
Train_MaxReturn : 94.30585479736328
Train_MinReturn : -270.0059814453125
Train_AverageEpLen : 413.8
Actor Loss : 308.44049072265625
Baseline Loss : 2557.39990234375
Train_EnvstepsSoFar : 299679
TimeSinceStart : 486.8803632259369

********** Iteration 138 ************
Eval_AverageReturn : 138.44140625
Eval_StdReturn : 0.0
Eval_MaxReturn : 138.44140625
Eval_MinReturn : 138.44140625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -94.50963592529297
Train_StdReturn : 93.87811279296875
Train_MaxReturn : 13.526687622070312
Train_MinReturn : -253.44036865234375
Train_AverageEpLen : 343.57142857142856
Actor Loss : 117.10824584960938
Baseline Loss : 1772.306640625
Train_EnvstepsSoFar : 302084
TimeSinceStart : 492.0308246612549

********** Iteration 139 ************
Eval_AverageReturn : -66.90980529785156
Eval_StdReturn : 115.52568054199219
Eval_MaxReturn : 48.615875244140625
Eval_MinReturn : -182.43548583984375
Eval_AverageEpLen : 280.0
Train_AverageReturn : -107.7874755859375
Train_StdReturn : 63.8731803894043
Train_MaxReturn : -31.918962478637695
Train_MinReturn : -217.45632934570312
Train_AverageEpLen : 252.0
Actor Loss : 58.88739013671875
Baseline Loss : 2186.993408203125
Train_EnvstepsSoFar : 304100
TimeSinceStart : 495.3647975921631

********** Iteration 140 ************
Eval_AverageReturn : -147.20236206054688
Eval_StdReturn : 75.6132583618164
Eval_MaxReturn : -71.58909606933594
Eval_MinReturn : -222.81561279296875
Eval_AverageEpLen : 236.5
Train_AverageReturn : -126.84449768066406
Train_StdReturn : 135.0797119140625
Train_MaxReturn : 82.19945526123047
Train_MinReturn : -282.69122314453125
Train_AverageEpLen : 382.0
Actor Loss : 69.95396423339844
Baseline Loss : 3071.680419921875
Train_EnvstepsSoFar : 306774
TimeSinceStart : 499.9466350078583

********** Iteration 141 ************
Eval_AverageReturn : -127.81674194335938
Eval_StdReturn : 99.799072265625
Eval_MaxReturn : -28.017663955688477
Eval_MinReturn : -227.61581420898438
Eval_AverageEpLen : 228.5
Train_AverageReturn : -110.58128356933594
Train_StdReturn : 65.23802947998047
Train_MaxReturn : -20.279476165771484
Train_MinReturn : -192.00616455078125
Train_AverageEpLen : 239.44444444444446
Actor Loss : -269.9433288574219
Baseline Loss : 2638.1962890625
Train_EnvstepsSoFar : 308929
TimeSinceStart : 503.504585981369

********** Iteration 142 ************
Eval_AverageReturn : -62.31810760498047
Eval_StdReturn : 32.00718307495117
Eval_MaxReturn : -30.310924530029297
Eval_MinReturn : -94.3252944946289
Eval_AverageEpLen : 259.5
Train_AverageReturn : -120.36045837402344
Train_StdReturn : 150.60812377929688
Train_MaxReturn : 221.72604370117188
Train_MinReturn : -234.88377380371094
Train_AverageEpLen : 256.375
Actor Loss : 235.56854248046875
Baseline Loss : 5111.22607421875
Train_EnvstepsSoFar : 310980
TimeSinceStart : 506.85703229904175

********** Iteration 143 ************
Eval_AverageReturn : -222.36306762695312
Eval_StdReturn : 31.442474365234375
Eval_MaxReturn : -190.92059326171875
Eval_MinReturn : -253.8055419921875
Eval_AverageEpLen : 287.0
Train_AverageReturn : 10.494860649108887
Train_StdReturn : 160.26463317871094
Train_MaxReturn : 135.3607177734375
Train_MinReturn : -215.74746704101562
Train_AverageEpLen : 745.6666666666666
Actor Loss : 363.9959716796875
Baseline Loss : 2753.431884765625
Train_EnvstepsSoFar : 313217
TimeSinceStart : 511.33442759513855

********** Iteration 144 ************
Eval_AverageReturn : -175.00840759277344
Eval_StdReturn : 39.65861511230469
Eval_MaxReturn : -135.34979248046875
Eval_MinReturn : -214.66702270507812
Eval_AverageEpLen : 264.0
Train_AverageReturn : -38.081642150878906
Train_StdReturn : 126.17123413085938
Train_MaxReturn : 141.5783233642578
Train_MinReturn : -229.95469665527344
Train_AverageEpLen : 483.1666666666667
Actor Loss : 268.3332824707031
Baseline Loss : 2872.61962890625
Train_EnvstepsSoFar : 316116
TimeSinceStart : 516.8571062088013

********** Iteration 145 ************
Eval_AverageReturn : -60.37238311767578
Eval_StdReturn : 11.633674621582031
Eval_MaxReturn : -48.73870849609375
Eval_MinReturn : -72.00605773925781
Eval_AverageEpLen : 247.5
Train_AverageReturn : -128.0343475341797
Train_StdReturn : 113.9305648803711
Train_MaxReturn : 92.02671813964844
Train_MinReturn : -269.7425231933594
Train_AverageEpLen : 358.125
Actor Loss : -79.00324249267578
Baseline Loss : 2712.97119140625
Train_EnvstepsSoFar : 318981
TimeSinceStart : 522.2919826507568

********** Iteration 146 ************
Eval_AverageReturn : -84.55315399169922
Eval_StdReturn : 61.37628936767578
Eval_MaxReturn : -25.10577964782715
Eval_MinReturn : -169.04983520507812
Eval_AverageEpLen : 189.66666666666666
Train_AverageReturn : -151.6367950439453
Train_StdReturn : 82.09235382080078
Train_MaxReturn : -32.201576232910156
Train_MinReturn : -275.3854064941406
Train_AverageEpLen : 244.11111111111111
Actor Loss : -187.3999481201172
Baseline Loss : 3356.956298828125
Train_EnvstepsSoFar : 321178
TimeSinceStart : 525.9292376041412

********** Iteration 147 ************
Eval_AverageReturn : -125.50205993652344
Eval_StdReturn : 61.75633239746094
Eval_MaxReturn : -63.7457275390625
Eval_MinReturn : -187.25839233398438
Eval_AverageEpLen : 434.0
Train_AverageReturn : -108.671875
Train_StdReturn : 138.8152618408203
Train_MaxReturn : 155.57144165039062
Train_MinReturn : -244.71177673339844
Train_AverageEpLen : 372.1666666666667
Actor Loss : 76.90569305419922
Baseline Loss : 3196.39794921875
Train_EnvstepsSoFar : 323411
TimeSinceStart : 530.7593102455139

********** Iteration 148 ************
Eval_AverageReturn : -89.68986511230469
Eval_StdReturn : 74.78825378417969
Eval_MaxReturn : -14.901611328125
Eval_MinReturn : -164.47811889648438
Eval_AverageEpLen : 636.0
Train_AverageReturn : -62.697265625
Train_StdReturn : 123.458984375
Train_MaxReturn : 132.17059326171875
Train_MinReturn : -214.68614196777344
Train_AverageEpLen : 410.4
Actor Loss : 3.6269664764404297
Baseline Loss : 2893.359619140625
Train_EnvstepsSoFar : 325463
TimeSinceStart : 536.02192902565

********** Iteration 149 ************
Eval_AverageReturn : -49.874515533447266
Eval_StdReturn : 30.170955657958984
Eval_MaxReturn : -19.70355796813965
Eval_MinReturn : -80.04547119140625
Eval_AverageEpLen : 289.5
Train_AverageReturn : -148.88128662109375
Train_StdReturn : 80.20487976074219
Train_MaxReturn : -36.97416687011719
Train_MinReturn : -256.4287109375
Train_AverageEpLen : 235.66666666666666
Actor Loss : -35.223602294921875
Baseline Loss : 3242.98388671875
Train_EnvstepsSoFar : 327584
TimeSinceStart : 539.5022139549255

********** Iteration 150 ************
Eval_AverageReturn : -97.69952392578125
Eval_StdReturn : 111.12879943847656
Eval_MaxReturn : 13.429267883300781
Eval_MinReturn : -208.8283233642578
Eval_AverageEpLen : 240.0
Train_AverageReturn : -50.29404830932617
Train_StdReturn : 163.0124969482422
Train_MaxReturn : 223.38641357421875
Train_MinReturn : -259.9453125
Train_AverageEpLen : 354.5
Actor Loss : -101.58453369140625
Baseline Loss : 3299.596923828125
Train_EnvstepsSoFar : 329711
TimeSinceStart : 543.5474808216095

********** Iteration 151 ************
Eval_AverageReturn : -100.75209045410156
Eval_StdReturn : 13.55002212524414
Eval_MaxReturn : -87.20207214355469
Eval_MinReturn : -114.30211639404297
Eval_AverageEpLen : 306.5
Train_AverageReturn : -190.3241729736328
Train_StdReturn : 70.25035095214844
Train_MaxReturn : -69.43250274658203
Train_MinReturn : -291.8699645996094
Train_AverageEpLen : 264.125
Actor Loss : -157.40960693359375
Baseline Loss : 3108.792236328125
Train_EnvstepsSoFar : 331824
TimeSinceStart : 547.2937784194946

********** Iteration 152 ************
Eval_AverageReturn : -113.61927795410156
Eval_StdReturn : 63.0953483581543
Eval_MaxReturn : -50.52393341064453
Eval_MinReturn : -176.71463012695312
Eval_AverageEpLen : 285.0
Train_AverageReturn : -146.10797119140625
Train_StdReturn : 75.44695281982422
Train_MaxReturn : -25.345947265625
Train_MinReturn : -215.07186889648438
Train_AverageEpLen : 275.125
Actor Loss : 1.7130680084228516
Baseline Loss : 2835.63525390625
Train_EnvstepsSoFar : 334025
TimeSinceStart : 551.0420722961426

********** Iteration 153 ************
Eval_AverageReturn : -131.42312622070312
Eval_StdReturn : 68.74298858642578
Eval_MaxReturn : -62.68013381958008
Eval_MinReturn : -200.16610717773438
Eval_AverageEpLen : 301.5
Train_AverageReturn : -162.85226440429688
Train_StdReturn : 70.43379211425781
Train_MaxReturn : -36.86431884765625
Train_MinReturn : -249.14381408691406
Train_AverageEpLen : 266.5
Actor Loss : -165.71783447265625
Baseline Loss : 2551.981201171875
Train_EnvstepsSoFar : 336157
TimeSinceStart : 554.8999302387238

********** Iteration 154 ************
Eval_AverageReturn : 126.36906433105469
Eval_StdReturn : 119.20118713378906
Eval_MaxReturn : 245.57025146484375
Eval_MinReturn : 7.167869567871094
Eval_AverageEpLen : 360.0
Train_AverageReturn : -51.99326705932617
Train_StdReturn : 174.62130737304688
Train_MaxReturn : 227.228759765625
Train_MinReturn : -244.72390747070312
Train_AverageEpLen : 471.6666666666667
Actor Loss : 300.3538818359375
Baseline Loss : 3499.462890625
Train_EnvstepsSoFar : 338987
TimeSinceStart : 560.4018688201904

********** Iteration 155 ************
Eval_AverageReturn : -75.16206359863281
Eval_StdReturn : 0.0
Eval_MaxReturn : -75.16206359863281
Eval_MinReturn : -75.16206359863281
Eval_AverageEpLen : 409.0
Train_AverageReturn : -103.43201446533203
Train_StdReturn : 120.22694396972656
Train_MaxReturn : 108.81473541259766
Train_MinReturn : -240.60501098632812
Train_AverageEpLen : 378.1666666666667
Actor Loss : -269.96136474609375
Baseline Loss : 2942.595947265625
Train_EnvstepsSoFar : 341256
TimeSinceStart : 564.7262709140778

********** Iteration 156 ************
Eval_AverageReturn : 21.579662322998047
Eval_StdReturn : 62.271175384521484
Eval_MaxReturn : 83.85083770751953
Eval_MinReturn : -40.69151306152344
Eval_AverageEpLen : 209.5
Train_AverageReturn : 25.8570556640625
Train_StdReturn : 80.41033935546875
Train_MaxReturn : 132.1102294921875
Train_MinReturn : -47.665382385253906
Train_AverageEpLen : 554.0
Actor Loss : 406.5943298339844
Baseline Loss : 2095.38232421875
Train_EnvstepsSoFar : 344026
TimeSinceStart : 570.6498799324036

********** Iteration 157 ************
Eval_AverageReturn : -93.60841369628906
Eval_StdReturn : 75.16397857666016
Eval_MaxReturn : -18.444435119628906
Eval_MinReturn : -168.77239990234375
Eval_AverageEpLen : 202.5
Train_AverageReturn : -37.567108154296875
Train_StdReturn : 153.6649169921875
Train_MaxReturn : 157.01150512695312
Train_MinReturn : -192.1991424560547
Train_AverageEpLen : 506.5
Actor Loss : 150.64334106445312
Baseline Loss : 3047.735107421875
Train_EnvstepsSoFar : 346052
TimeSinceStart : 575.0739748477936

********** Iteration 158 ************
Eval_AverageReturn : -144.5120849609375
Eval_StdReturn : 112.70110321044922
Eval_MaxReturn : -31.810985565185547
Eval_MinReturn : -257.21319580078125
Eval_AverageEpLen : 342.5
Train_AverageReturn : -45.50033950805664
Train_StdReturn : 106.18704223632812
Train_MaxReturn : 140.06484985351562
Train_MinReturn : -252.07821655273438
Train_AverageEpLen : 369.14285714285717
Actor Loss : 126.66744995117188
Baseline Loss : 1842.9241943359375
Train_EnvstepsSoFar : 348636
TimeSinceStart : 580.2070391178131

********** Iteration 159 ************
Eval_AverageReturn : 100.00277709960938
Eval_StdReturn : 0.0
Eval_MaxReturn : 100.00277709960938
Eval_MinReturn : 100.00277709960938
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -13.571617126464844
Train_StdReturn : 168.37217712402344
Train_MaxReturn : 235.7751922607422
Train_MinReturn : -176.85739135742188
Train_AverageEpLen : 435.6666666666667
Actor Loss : 138.52032470703125
Baseline Loss : 3713.98388671875
Train_EnvstepsSoFar : 351250
TimeSinceStart : 586.5593295097351

********** Iteration 160 ************
Eval_AverageReturn : -81.88720703125
Eval_StdReturn : 109.31072998046875
Eval_MaxReturn : 27.42351531982422
Eval_MinReturn : -191.19793701171875
Eval_AverageEpLen : 241.5
Train_AverageReturn : -51.01337814331055
Train_StdReturn : 147.0530242919922
Train_MaxReturn : 86.47860717773438
Train_MinReturn : -254.88470458984375
Train_AverageEpLen : 798.0
Actor Loss : 108.32832336425781
Baseline Loss : 2088.310546875
Train_EnvstepsSoFar : 353644
TimeSinceStart : 592.004921913147

********** Iteration 161 ************
Eval_AverageReturn : -116.31504821777344
Eval_StdReturn : 133.90966796875
Eval_MaxReturn : 17.59461212158203
Eval_MinReturn : -250.22471618652344
Eval_AverageEpLen : 232.5
Train_AverageReturn : -32.471351623535156
Train_StdReturn : 137.27012634277344
Train_MaxReturn : 260.3529968261719
Train_MinReturn : -196.82272338867188
Train_AverageEpLen : 294.85714285714283
Actor Loss : 36.965328216552734
Baseline Loss : 2901.11279296875
Train_EnvstepsSoFar : 355708
TimeSinceStart : 595.5797252655029

********** Iteration 162 ************
Eval_AverageReturn : -154.69113159179688
Eval_StdReturn : 22.155303955078125
Eval_MaxReturn : -132.53582763671875
Eval_MinReturn : -176.846435546875
Eval_AverageEpLen : 202.0
Train_AverageReturn : -12.829055786132812
Train_StdReturn : 67.1573257446289
Train_MaxReturn : 115.75662994384766
Train_MinReturn : -63.48969650268555
Train_AverageEpLen : 405.8
Actor Loss : 134.2999267578125
Baseline Loss : 1013.9650268554688
Train_EnvstepsSoFar : 357737
TimeSinceStart : 599.5690007209778

********** Iteration 163 ************
Eval_AverageReturn : -88.83277893066406
Eval_StdReturn : 151.34671020507812
Eval_MaxReturn : 62.51392364501953
Eval_MinReturn : -240.1794891357422
Eval_AverageEpLen : 658.5
Train_AverageReturn : -113.02351379394531
Train_StdReturn : 126.27762603759766
Train_MaxReturn : 67.12261962890625
Train_MinReturn : -267.76654052734375
Train_AverageEpLen : 419.0
Actor Loss : 248.25506591796875
Baseline Loss : 2698.23193359375
Train_EnvstepsSoFar : 359832
TimeSinceStart : 605.5209226608276

********** Iteration 164 ************
Eval_AverageReturn : -78.02430725097656
Eval_StdReturn : 89.22802734375
Eval_MaxReturn : 11.20372200012207
Eval_MinReturn : -167.25233459472656
Eval_AverageEpLen : 254.5
Train_AverageReturn : -147.87937927246094
Train_StdReturn : 92.4806900024414
Train_MaxReturn : -24.024127960205078
Train_MinReturn : -272.7538146972656
Train_AverageEpLen : 307.0
Actor Loss : -181.93792724609375
Baseline Loss : 2959.7353515625
Train_EnvstepsSoFar : 361981
TimeSinceStart : 609.2819051742554

********** Iteration 165 ************
Eval_AverageReturn : 248.95367431640625
Eval_StdReturn : 0.0
Eval_MaxReturn : 248.95367431640625
Eval_MinReturn : 248.95367431640625
Eval_AverageEpLen : 801.0
Train_AverageReturn : -163.74542236328125
Train_StdReturn : 89.17660522460938
Train_MaxReturn : -30.33620834350586
Train_MinReturn : -252.1805877685547
Train_AverageEpLen : 265.375
Actor Loss : -321.2151184082031
Baseline Loss : 3714.48779296875
Train_EnvstepsSoFar : 364104
TimeSinceStart : 613.4014322757721

********** Iteration 166 ************
Eval_AverageReturn : -258.90081787109375
Eval_StdReturn : 0.0
Eval_MaxReturn : -258.90081787109375
Eval_MinReturn : -258.90081787109375
Eval_AverageEpLen : 444.0
Train_AverageReturn : -67.44966888427734
Train_StdReturn : 114.00574493408203
Train_MaxReturn : 113.10986328125
Train_MinReturn : -200.90696716308594
Train_AverageEpLen : 338.85714285714283
Actor Loss : -144.80381774902344
Baseline Loss : 2488.114501953125
Train_EnvstepsSoFar : 366476
TimeSinceStart : 617.5444061756134

********** Iteration 167 ************
Eval_AverageReturn : -44.8977165222168
Eval_StdReturn : 22.734804153442383
Eval_MaxReturn : -22.162912368774414
Eval_MinReturn : -67.63252258300781
Eval_AverageEpLen : 224.0
Train_AverageReturn : -36.961021423339844
Train_StdReturn : 131.458251953125
Train_MaxReturn : 231.75741577148438
Train_MinReturn : -222.21487426757812
Train_AverageEpLen : 295.0
Actor Loss : -84.0072250366211
Baseline Loss : 2827.188720703125
Train_EnvstepsSoFar : 368836
TimeSinceStart : 621.2786314487457

********** Iteration 168 ************
Eval_AverageReturn : -53.66828918457031
Eval_StdReturn : 21.578392028808594
Eval_MaxReturn : -32.08989715576172
Eval_MinReturn : -75.2466812133789
Eval_AverageEpLen : 264.5
Train_AverageReturn : -130.37347412109375
Train_StdReturn : 89.19898223876953
Train_MaxReturn : -21.431772232055664
Train_MinReturn : -239.8973388671875
Train_AverageEpLen : 227.22222222222223
Actor Loss : -309.2936096191406
Baseline Loss : 3464.667236328125
Train_EnvstepsSoFar : 370881
TimeSinceStart : 624.6694543361664

********** Iteration 169 ************
Eval_AverageReturn : -63.916419982910156
Eval_StdReturn : 16.71111297607422
Eval_MaxReturn : -47.20530700683594
Eval_MinReturn : -80.62753295898438
Eval_AverageEpLen : 236.0
Train_AverageReturn : -114.08475494384766
Train_StdReturn : 160.05101013183594
Train_MaxReturn : 241.7491455078125
Train_MinReturn : -226.7750244140625
Train_AverageEpLen : 288.14285714285717
Actor Loss : -514.6171875
Baseline Loss : 4368.4228515625
Train_EnvstepsSoFar : 372898
TimeSinceStart : 628.2148950099945

********** Iteration 170 ************
Eval_AverageReturn : -209.7980499267578
Eval_StdReturn : 12.466049194335938
Eval_MaxReturn : -197.33200073242188
Eval_MinReturn : -222.26409912109375
Eval_AverageEpLen : 269.0
Train_AverageReturn : -54.650386810302734
Train_StdReturn : 164.63873291015625
Train_MaxReturn : 126.56041717529297
Train_MinReturn : -242.09628295898438
Train_AverageEpLen : 603.25
Actor Loss : 60.90375518798828
Baseline Loss : 2451.04736328125
Train_EnvstepsSoFar : 375311
TimeSinceStart : 632.7986106872559

********** Iteration 171 ************
Eval_AverageReturn : 15.45367431640625
Eval_StdReturn : 185.93942260742188
Eval_MaxReturn : 201.39309692382812
Eval_MinReturn : -170.48574829101562
Eval_AverageEpLen : 292.5
Train_AverageReturn : -52.900936126708984
Train_StdReturn : 198.58871459960938
Train_MaxReturn : 235.14036560058594
Train_MinReturn : -277.7652587890625
Train_AverageEpLen : 520.75
Actor Loss : 60.093936920166016
Baseline Loss : 3506.774658203125
Train_EnvstepsSoFar : 377394
TimeSinceStart : 636.9100794792175

********** Iteration 172 ************
Eval_AverageReturn : -153.43955993652344
Eval_StdReturn : 36.5397834777832
Eval_MaxReturn : -116.89977264404297
Eval_MinReturn : -189.97933959960938
Eval_AverageEpLen : 234.5
Train_AverageReturn : -118.85106658935547
Train_StdReturn : 130.8589324951172
Train_MaxReturn : 137.61944580078125
Train_MinReturn : -238.16946411132812
Train_AverageEpLen : 349.5
Actor Loss : -88.76065063476562
Baseline Loss : 3130.522216796875
Train_EnvstepsSoFar : 379491
TimeSinceStart : 640.7943086624146

********** Iteration 173 ************
Eval_AverageReturn : -218.538330078125
Eval_StdReturn : 8.856712341308594
Eval_MaxReturn : -209.68162536621094
Eval_MinReturn : -227.39505004882812
Eval_AverageEpLen : 243.0
Train_AverageReturn : -129.9180145263672
Train_StdReturn : 154.34600830078125
Train_MaxReturn : 265.927490234375
Train_MinReturn : -255.6101531982422
Train_AverageEpLen : 316.44444444444446
Actor Loss : -297.5999755859375
Baseline Loss : 3772.49853515625
Train_EnvstepsSoFar : 382339
TimeSinceStart : 645.2934656143188

********** Iteration 174 ************
Eval_AverageReturn : -207.49200439453125
Eval_StdReturn : 40.535484313964844
Eval_MaxReturn : -166.95652770996094
Eval_MinReturn : -248.02749633789062
Eval_AverageEpLen : 286.5
Train_AverageReturn : -175.0064697265625
Train_StdReturn : 78.75843811035156
Train_MaxReturn : 12.866352081298828
Train_MinReturn : -258.98480224609375
Train_AverageEpLen : 211.8
Actor Loss : -288.0023498535156
Baseline Loss : 4366.0087890625
Train_EnvstepsSoFar : 384457
TimeSinceStart : 648.482691526413

********** Iteration 175 ************
Eval_AverageReturn : -130.28663635253906
Eval_StdReturn : 19.719181060791016
Eval_MaxReturn : -110.56745147705078
Eval_MinReturn : -150.0058135986328
Eval_AverageEpLen : 240.5
Train_AverageReturn : -47.62380599975586
Train_StdReturn : 166.62570190429688
Train_MaxReturn : 211.6981201171875
Train_MinReturn : -238.27772521972656
Train_AverageEpLen : 332.85714285714283
Actor Loss : 64.6139144897461
Baseline Loss : 3965.84814453125
Train_EnvstepsSoFar : 386787
TimeSinceStart : 652.4830226898193

********** Iteration 176 ************
Eval_AverageReturn : -122.47650146484375
Eval_StdReturn : 97.01136779785156
Eval_MaxReturn : -25.465133666992188
Eval_MinReturn : -219.4878692626953
Eval_AverageEpLen : 226.0
Train_AverageReturn : -75.60546112060547
Train_StdReturn : 131.18724060058594
Train_MaxReturn : 209.0526580810547
Train_MinReturn : -208.03150939941406
Train_AverageEpLen : 257.375
Actor Loss : 7.387855529785156
Baseline Loss : 3453.770751953125
Train_EnvstepsSoFar : 388846
TimeSinceStart : 655.7493197917938

********** Iteration 177 ************
Eval_AverageReturn : -122.0914306640625
Eval_StdReturn : 107.29955291748047
Eval_MaxReturn : -14.791877746582031
Eval_MinReturn : -229.39097595214844
Eval_AverageEpLen : 232.5
Train_AverageReturn : -125.66278839111328
Train_StdReturn : 104.49116516113281
Train_MaxReturn : 36.02021789550781
Train_MinReturn : -238.01708984375
Train_AverageEpLen : 241.11111111111111
Actor Loss : 160.77166748046875
Baseline Loss : 3259.78466796875
Train_EnvstepsSoFar : 391016
TimeSinceStart : 658.9587640762329

********** Iteration 178 ************
Eval_AverageReturn : 70.17198181152344
Eval_StdReturn : 111.08049011230469
Eval_MaxReturn : 181.25247192382812
Eval_MinReturn : -40.90850830078125
Eval_AverageEpLen : 304.0
Train_AverageReturn : 16.291412353515625
Train_StdReturn : 147.45083618164062
Train_MaxReturn : 206.69839477539062
Train_MinReturn : -212.11883544921875
Train_AverageEpLen : 522.6
Actor Loss : 289.439697265625
Baseline Loss : 3330.32470703125
Train_EnvstepsSoFar : 393629
TimeSinceStart : 663.8640620708466

********** Iteration 179 ************
Eval_AverageReturn : -136.82554626464844
Eval_StdReturn : 90.78254699707031
Eval_MaxReturn : -46.04299545288086
Eval_MinReturn : -227.60809326171875
Eval_AverageEpLen : 229.5
Train_AverageReturn : -52.93414306640625
Train_StdReturn : 66.75502014160156
Train_MaxReturn : 17.86736297607422
Train_MinReturn : -174.27076721191406
Train_AverageEpLen : 246.55555555555554
Actor Loss : -25.316871643066406
Baseline Loss : 1986.5892333984375
Train_EnvstepsSoFar : 395848
TimeSinceStart : 666.7454929351807

********** Iteration 180 ************
Eval_AverageReturn : -1.7167816162109375
Eval_StdReturn : 255.9661407470703
Eval_MaxReturn : 254.24935913085938
Eval_MinReturn : -257.68292236328125
Eval_AverageEpLen : 475.5
Train_AverageReturn : 36.41521072387695
Train_StdReturn : 155.93048095703125
Train_MaxReturn : 278.5949401855469
Train_MinReturn : -172.06759643554688
Train_AverageEpLen : 298.2857142857143
Actor Loss : 114.93061065673828
Baseline Loss : 4576.14404296875
Train_EnvstepsSoFar : 397936
TimeSinceStart : 670.8852295875549

********** Iteration 181 ************
Eval_AverageReturn : -73.22635650634766
Eval_StdReturn : 59.30406951904297
Eval_MaxReturn : -13.922286987304688
Eval_MinReturn : -132.53042602539062
Eval_AverageEpLen : 231.5
Train_AverageReturn : -83.56226348876953
Train_StdReturn : 141.9795379638672
Train_MaxReturn : 242.51722717285156
Train_MinReturn : -231.7333984375
Train_AverageEpLen : 278.125
Actor Loss : -471.4774169921875
Baseline Loss : 3628.447998046875
Train_EnvstepsSoFar : 400161
TimeSinceStart : 674.2726171016693

********** Iteration 182 ************
Eval_AverageReturn : 276.6603088378906
Eval_StdReturn : 0.0
Eval_MaxReturn : 276.6603088378906
Eval_MinReturn : 276.6603088378906
Eval_AverageEpLen : 468.0
Train_AverageReturn : -89.96968078613281
Train_StdReturn : 156.26133728027344
Train_MaxReturn : 225.61416625976562
Train_MinReturn : -246.14309692382812
Train_AverageEpLen : 364.0
Actor Loss : 203.24871826171875
Baseline Loss : 3027.2958984375
Train_EnvstepsSoFar : 403073
TimeSinceStart : 679.208615064621

********** Iteration 183 ************
Eval_AverageReturn : -115.55152893066406
Eval_StdReturn : 114.63264465332031
Eval_MaxReturn : -0.9188871383666992
Eval_MinReturn : -230.18417358398438
Eval_AverageEpLen : 333.0
Train_AverageReturn : -163.75282287597656
Train_StdReturn : 88.11412811279297
Train_MaxReturn : -8.976966857910156
Train_MinReturn : -229.10433959960938
Train_AverageEpLen : 275.0
Actor Loss : -164.184814453125
Baseline Loss : 3311.072998046875
Train_EnvstepsSoFar : 405273
TimeSinceStart : 682.9913642406464

********** Iteration 184 ************
Eval_AverageReturn : -114.83352661132812
Eval_StdReturn : 74.31835174560547
Eval_MaxReturn : -40.515174865722656
Eval_MinReturn : -189.15188598632812
Eval_AverageEpLen : 268.5
Train_AverageReturn : -140.12164306640625
Train_StdReturn : 158.2682647705078
Train_MaxReturn : 209.66738891601562
Train_MinReturn : -234.22361755371094
Train_AverageEpLen : 339.6666666666667
Actor Loss : 13.360429763793945
Baseline Loss : 4015.79541015625
Train_EnvstepsSoFar : 407311
TimeSinceStart : 686.651177406311

********** Iteration 185 ************
Eval_AverageReturn : -206.73226928710938
Eval_StdReturn : 13.268211364746094
Eval_MaxReturn : -193.4640655517578
Eval_MinReturn : -220.00048828125
Eval_AverageEpLen : 219.5
Train_AverageReturn : -95.45565795898438
Train_StdReturn : 159.79225158691406
Train_MaxReturn : 282.42236328125
Train_MinReturn : -239.03457641601562
Train_AverageEpLen : 298.75
Actor Loss : -123.6197509765625
Baseline Loss : 3337.882080078125
Train_EnvstepsSoFar : 409701
TimeSinceStart : 690.3448255062103

********** Iteration 186 ************
Eval_AverageReturn : 24.21558380126953
Eval_StdReturn : 181.6129150390625
Eval_MaxReturn : 205.8284912109375
Eval_MinReturn : -157.39732360839844
Eval_AverageEpLen : 332.5
Train_AverageReturn : -10.337072372436523
Train_StdReturn : 170.7517852783203
Train_MaxReturn : 263.05059814453125
Train_MinReturn : -213.2023162841797
Train_AverageEpLen : 281.5
Actor Loss : 382.6231689453125
Baseline Loss : 5379.44189453125
Train_EnvstepsSoFar : 411953
TimeSinceStart : 694.3233060836792

********** Iteration 187 ************
Eval_AverageReturn : 20.44432830810547
Eval_StdReturn : 170.24667358398438
Eval_MaxReturn : 190.69100952148438
Eval_MinReturn : -149.80235290527344
Eval_AverageEpLen : 514.5
Train_AverageReturn : 33.23961639404297
Train_StdReturn : 112.14208984375
Train_MaxReturn : 257.47662353515625
Train_MinReturn : -67.28695678710938
Train_AverageEpLen : 363.57142857142856
Actor Loss : 392.41656494140625
Baseline Loss : 2245.53955078125
Train_EnvstepsSoFar : 414498
TimeSinceStart : 700.2733759880066

********** Iteration 188 ************
Eval_AverageReturn : 18.387489318847656
Eval_StdReturn : 226.28591918945312
Eval_MaxReturn : 244.6734161376953
Eval_MinReturn : -207.8984375
Eval_AverageEpLen : 353.5
Train_AverageReturn : -70.39519500732422
Train_StdReturn : 136.94198608398438
Train_MaxReturn : 174.00445556640625
Train_MinReturn : -251.5865478515625
Train_AverageEpLen : 369.0
Actor Loss : -62.91057586669922
Baseline Loss : 2593.094970703125
Train_EnvstepsSoFar : 416712
TimeSinceStart : 704.6080105304718

********** Iteration 189 ************
Eval_AverageReturn : 230.49891662597656
Eval_StdReturn : 0.0
Eval_MaxReturn : 230.49891662597656
Eval_MinReturn : 230.49891662597656
Eval_AverageEpLen : 501.0
Train_AverageReturn : 43.321842193603516
Train_StdReturn : 145.5284881591797
Train_MaxReturn : 235.12322998046875
Train_MinReturn : -199.58804321289062
Train_AverageEpLen : 369.5
Actor Loss : -215.99017333984375
Baseline Loss : 3056.53466796875
Train_EnvstepsSoFar : 418929
TimeSinceStart : 708.6205317974091

********** Iteration 190 ************
Eval_AverageReturn : -144.17080688476562
Eval_StdReturn : 22.514488220214844
Eval_MaxReturn : -121.65632629394531
Eval_MinReturn : -166.685302734375
Eval_AverageEpLen : 249.5
Train_AverageReturn : 40.548316955566406
Train_StdReturn : 126.58999633789062
Train_MaxReturn : 264.1796875
Train_MinReturn : -88.40986633300781
Train_AverageEpLen : 314.85714285714283
Actor Loss : -234.27981567382812
Baseline Loss : 3226.09033203125
Train_EnvstepsSoFar : 421133
TimeSinceStart : 712.2542004585266

********** Iteration 191 ************
Eval_AverageReturn : -22.926467895507812
Eval_StdReturn : 47.58917236328125
Eval_MaxReturn : 24.662704467773438
Eval_MinReturn : -70.51564025878906
Eval_AverageEpLen : 259.0
Train_AverageReturn : 64.21814727783203
Train_StdReturn : 202.84039306640625
Train_MaxReturn : 257.0533447265625
Train_MinReturn : -206.91812133789062
Train_AverageEpLen : 456.4
Actor Loss : 145.12753295898438
Baseline Loss : 4852.6728515625
Train_EnvstepsSoFar : 423415
TimeSinceStart : 716.8721857070923

********** Iteration 192 ************
Eval_AverageReturn : -28.103618621826172
Eval_StdReturn : 140.407958984375
Eval_MaxReturn : 112.3043441772461
Eval_MinReturn : -168.51158142089844
Eval_AverageEpLen : 610.5
Train_AverageReturn : -56.62327194213867
Train_StdReturn : 102.66346740722656
Train_MaxReturn : 121.08983612060547
Train_MinReturn : -180.8873748779297
Train_AverageEpLen : 364.5
Actor Loss : -63.395816802978516
Baseline Loss : 1832.340087890625
Train_EnvstepsSoFar : 425602
TimeSinceStart : 722.0177464485168

********** Iteration 193 ************
Eval_AverageReturn : -46.689476013183594
Eval_StdReturn : 9.137519836425781
Eval_MaxReturn : -37.55195617675781
Eval_MinReturn : -55.826995849609375
Eval_AverageEpLen : 203.5
Train_AverageReturn : -91.24632263183594
Train_StdReturn : 131.39462280273438
Train_MaxReturn : 153.310546875
Train_MinReturn : -240.09974670410156
Train_AverageEpLen : 276.125
Actor Loss : -274.94793701171875
Baseline Loss : 4077.096923828125
Train_EnvstepsSoFar : 427811
TimeSinceStart : 725.4611132144928

********** Iteration 194 ************
Eval_AverageReturn : -50.11846923828125
Eval_StdReturn : 173.14459228515625
Eval_MaxReturn : 123.026123046875
Eval_MinReturn : -223.2630615234375
Eval_AverageEpLen : 623.5
Train_AverageReturn : -66.47665405273438
Train_StdReturn : 157.7787322998047
Train_MaxReturn : 273.451904296875
Train_MinReturn : -263.4090270996094
Train_AverageEpLen : 273.625
Actor Loss : -526.2523193359375
Baseline Loss : 3708.80224609375
Train_EnvstepsSoFar : 430000
TimeSinceStart : 730.2995364665985

********** Iteration 195 ************
Eval_AverageReturn : -252.86285400390625
Eval_StdReturn : 10.696563720703125
Eval_MaxReturn : -242.16629028320312
Eval_MinReturn : -263.5594177246094
Eval_AverageEpLen : 252.0
Train_AverageReturn : -49.47025680541992
Train_StdReturn : 139.4044647216797
Train_MaxReturn : 276.8489990234375
Train_MinReturn : -232.56149291992188
Train_AverageEpLen : 282.75
Actor Loss : -215.60040283203125
Baseline Loss : 3072.151611328125
Train_EnvstepsSoFar : 432262
TimeSinceStart : 734.1722319126129

********** Iteration 196 ************
Eval_AverageReturn : 188.9952392578125
Eval_StdReturn : 0.0
Eval_MaxReturn : 188.9952392578125
Eval_MinReturn : 188.9952392578125
Eval_AverageEpLen : 808.0
Train_AverageReturn : -55.198814392089844
Train_StdReturn : 131.9470672607422
Train_MaxReturn : 227.91058349609375
Train_MinReturn : -251.35267639160156
Train_AverageEpLen : 263.75
Actor Loss : -44.708984375
Baseline Loss : 3652.35546875
Train_EnvstepsSoFar : 434372
TimeSinceStart : 738.5953896045685

********** Iteration 197 ************
Eval_AverageReturn : -116.7247085571289
Eval_StdReturn : 72.96392059326172
Eval_MaxReturn : -43.76078796386719
Eval_MinReturn : -189.68862915039062
Eval_AverageEpLen : 230.5
Train_AverageReturn : -134.3796844482422
Train_StdReturn : 120.46874237060547
Train_MaxReturn : 78.25846862792969
Train_MinReturn : -268.7484130859375
Train_AverageEpLen : 373.1666666666667
Actor Loss : -136.48924255371094
Baseline Loss : 3462.690185546875
Train_EnvstepsSoFar : 436611
TimeSinceStart : 742.5513501167297

********** Iteration 198 ************
Eval_AverageReturn : -235.0670166015625
Eval_StdReturn : 4.202995300292969
Eval_MaxReturn : -230.86402893066406
Eval_MinReturn : -239.27001953125
Eval_AverageEpLen : 321.0
Train_AverageReturn : -115.2962875366211
Train_StdReturn : 177.79539489746094
Train_MaxReturn : 245.87921142578125
Train_MinReturn : -295.53228759765625
Train_AverageEpLen : 386.6666666666667
Actor Loss : -169.71707153320312
Baseline Loss : 3655.536376953125
Train_EnvstepsSoFar : 438931
TimeSinceStart : 746.8247570991516

********** Iteration 199 ************
Eval_AverageReturn : 237.8756561279297
Eval_StdReturn : 0.0
Eval_MaxReturn : 237.8756561279297
Eval_MinReturn : 237.8756561279297
Eval_AverageEpLen : 842.0
Train_AverageReturn : -80.2269287109375
Train_StdReturn : 66.41313171386719
Train_MaxReturn : -0.022739410400390625
Train_MinReturn : -201.64234924316406
Train_AverageEpLen : 268.25
Actor Loss : 156.2008056640625
Baseline Loss : 2000.8060302734375
Train_EnvstepsSoFar : 441077
TimeSinceStart : 751.0871016979218

********** Iteration 200 ************
Eval_AverageReturn : -5.391845703125
Eval_StdReturn : 10.274105072021484
Eval_MaxReturn : 4.882259368896484
Eval_MinReturn : -15.665950775146484
Eval_AverageEpLen : 236.5
Train_AverageReturn : -86.95082092285156
Train_StdReturn : 95.9360580444336
Train_MaxReturn : 23.956024169921875
Train_MinReturn : -213.52218627929688
Train_AverageEpLen : 257.0
Actor Loss : -330.1129455566406
Baseline Loss : 2542.150634765625
Train_EnvstepsSoFar : 443133
TimeSinceStart : 754.429562330246

********** Iteration 201 ************
Eval_AverageReturn : 224.48728942871094
Eval_StdReturn : 0.0
Eval_MaxReturn : 224.48728942871094
Eval_MinReturn : 224.48728942871094
Eval_AverageEpLen : 420.0
Train_AverageReturn : -47.615638732910156
Train_StdReturn : 187.08412170410156
Train_MaxReturn : 254.5380859375
Train_MinReturn : -215.38739013671875
Train_AverageEpLen : 268.625
Actor Loss : -269.7375183105469
Baseline Loss : 5402.2294921875
Train_EnvstepsSoFar : 445282
TimeSinceStart : 757.9385807514191

********** Iteration 202 ************
Eval_AverageReturn : -174.1738739013672
Eval_StdReturn : 10.034698486328125
Eval_MaxReturn : -164.13917541503906
Eval_MinReturn : -184.2085723876953
Eval_AverageEpLen : 291.0
Train_AverageReturn : -74.45941162109375
Train_StdReturn : 113.23187255859375
Train_MaxReturn : 119.60820770263672
Train_MinReturn : -205.48117065429688
Train_AverageEpLen : 364.5
Actor Loss : -240.31878662109375
Baseline Loss : 2572.4443359375
Train_EnvstepsSoFar : 447469
TimeSinceStart : 762.4846274852753

********** Iteration 203 ************
Eval_AverageReturn : -36.75859069824219
Eval_StdReturn : 28.814001083374023
Eval_MaxReturn : 1.11602783203125
Eval_MinReturn : -68.7153091430664
Eval_AverageEpLen : 184.33333333333334
Train_AverageReturn : -106.33729553222656
Train_StdReturn : 90.71373748779297
Train_MaxReturn : 4.584506988525391
Train_MinReturn : -264.0292053222656
Train_AverageEpLen : 264.125
Actor Loss : 38.512813568115234
Baseline Loss : 3006.984375
Train_EnvstepsSoFar : 449582
TimeSinceStart : 766.1082468032837

********** Iteration 204 ************
Eval_AverageReturn : -78.49549865722656
Eval_StdReturn : 30.932174682617188
Eval_MaxReturn : -47.563323974609375
Eval_MinReturn : -109.42767333984375
Eval_AverageEpLen : 202.5
Train_AverageReturn : -65.47373962402344
Train_StdReturn : 213.3302764892578
Train_MaxReturn : 269.429931640625
Train_MinReturn : -279.37799072265625
Train_AverageEpLen : 467.0
Actor Loss : 295.447998046875
Baseline Loss : 4043.20703125
Train_EnvstepsSoFar : 451917
TimeSinceStart : 770.3479492664337

********** Iteration 205 ************
Eval_AverageReturn : 241.87930297851562
Eval_StdReturn : 0.0
Eval_MaxReturn : 241.87930297851562
Eval_MinReturn : 241.87930297851562
Eval_AverageEpLen : 465.0
Train_AverageReturn : -73.1927719116211
Train_StdReturn : 118.56939697265625
Train_MaxReturn : 90.09381103515625
Train_MinReturn : -210.78123474121094
Train_AverageEpLen : 418.8
Actor Loss : 202.0792694091797
Baseline Loss : 2142.720458984375
Train_EnvstepsSoFar : 454011
TimeSinceStart : 774.2849767208099

********** Iteration 206 ************
Eval_AverageReturn : -192.0320281982422
Eval_StdReturn : 15.366287231445312
Eval_MaxReturn : -176.66574096679688
Eval_MinReturn : -207.3983154296875
Eval_AverageEpLen : 220.0
Train_AverageReturn : -124.26408386230469
Train_StdReturn : 156.43284606933594
Train_MaxReturn : 243.18453979492188
Train_MinReturn : -245.60076904296875
Train_AverageEpLen : 290.42857142857144
Actor Loss : -107.52902221679688
Baseline Loss : 3968.123046875
Train_EnvstepsSoFar : 456044
TimeSinceStart : 777.6358091831207

********** Iteration 207 ************
Eval_AverageReturn : -23.58081817626953
Eval_StdReturn : 215.25430297851562
Eval_MaxReturn : 191.67349243164062
Eval_MinReturn : -238.8351287841797
Eval_AverageEpLen : 318.5
Train_AverageReturn : 9.827010154724121
Train_StdReturn : 154.1929168701172
Train_MaxReturn : 199.94403076171875
Train_MinReturn : -219.65057373046875
Train_AverageEpLen : 528.5
Actor Loss : 128.29559326171875
Baseline Loss : 2708.921142578125
Train_EnvstepsSoFar : 458158
TimeSinceStart : 782.576655626297

********** Iteration 208 ************
Eval_AverageReturn : 192.6318359375
Eval_StdReturn : 0.0
Eval_MaxReturn : 192.6318359375
Eval_MinReturn : 192.6318359375
Eval_AverageEpLen : 689.0
Train_AverageReturn : -111.01968383789062
Train_StdReturn : 98.44603729248047
Train_MaxReturn : -1.867767333984375
Train_MinReturn : -241.14102172851562
Train_AverageEpLen : 235.0
Actor Loss : -710.8364868164062
Baseline Loss : 3383.989501953125
Train_EnvstepsSoFar : 460273
TimeSinceStart : 786.2952389717102

********** Iteration 209 ************
Eval_AverageReturn : -109.75738525390625
Eval_StdReturn : 65.93767547607422
Eval_MaxReturn : -43.81970977783203
Eval_MinReturn : -175.695068359375
Eval_AverageEpLen : 256.0
Train_AverageReturn : -91.38629150390625
Train_StdReturn : 107.74126434326172
Train_MaxReturn : 91.82637786865234
Train_MinReturn : -205.52874755859375
Train_AverageEpLen : 343.3333333333333
Actor Loss : -262.4906005859375
Baseline Loss : 2364.987548828125
Train_EnvstepsSoFar : 462333
TimeSinceStart : 790.0249769687653

********** Iteration 210 ************
Eval_AverageReturn : -102.63845825195312
Eval_StdReturn : 118.2234878540039
Eval_MaxReturn : 15.585029602050781
Eval_MinReturn : -220.86195373535156
Eval_AverageEpLen : 258.5
Train_AverageReturn : -119.3051986694336
Train_StdReturn : 89.81990051269531
Train_MaxReturn : 35.37967300415039
Train_MinReturn : -198.78909301757812
Train_AverageEpLen : 350.8333333333333
Actor Loss : -137.1473388671875
Baseline Loss : 3163.49658203125
Train_EnvstepsSoFar : 464438
TimeSinceStart : 794.2260148525238

********** Iteration 211 ************
Eval_AverageReturn : 27.39368438720703
Eval_StdReturn : 219.96270751953125
Eval_MaxReturn : 247.3563995361328
Eval_MinReturn : -192.56903076171875
Eval_AverageEpLen : 339.0
Train_AverageReturn : -124.14402770996094
Train_StdReturn : 139.69915771484375
Train_MaxReturn : 250.82907104492188
Train_MinReturn : -204.46200561523438
Train_AverageEpLen : 237.88888888888889
Actor Loss : 93.42949676513672
Baseline Loss : 5458.3662109375
Train_EnvstepsSoFar : 466579
TimeSinceStart : 797.8766658306122

********** Iteration 212 ************
Eval_AverageReturn : -116.31349182128906
Eval_StdReturn : 21.055835723876953
Eval_MaxReturn : -95.25765228271484
Eval_MinReturn : -137.36932373046875
Eval_AverageEpLen : 233.5
Train_AverageReturn : -69.30634307861328
Train_StdReturn : 145.7765655517578
Train_MaxReturn : 228.28341674804688
Train_MinReturn : -217.51260375976562
Train_AverageEpLen : 302.85714285714283
Actor Loss : -4.2095794677734375
Baseline Loss : 3195.61865234375
Train_EnvstepsSoFar : 468699
TimeSinceStart : 801.669349193573

********** Iteration 213 ************
Eval_AverageReturn : 104.75899505615234
Eval_StdReturn : 172.09994506835938
Eval_MaxReturn : 276.85894775390625
Eval_MinReturn : -67.34095764160156
Eval_AverageEpLen : 321.0
Train_AverageReturn : -36.04774856567383
Train_StdReturn : 173.51364135742188
Train_MaxReturn : 238.29754638671875
Train_MinReturn : -245.6097412109375
Train_AverageEpLen : 306.14285714285717
Actor Loss : -131.77291870117188
Baseline Loss : 5213.0087890625
Train_EnvstepsSoFar : 470842
TimeSinceStart : 805.4835290908813

********** Iteration 214 ************
Eval_AverageReturn : 99.29122924804688
Eval_StdReturn : 133.8455352783203
Eval_MaxReturn : 233.1367645263672
Eval_MinReturn : -34.55431365966797
Eval_AverageEpLen : 364.0
Train_AverageReturn : -138.7891845703125
Train_StdReturn : 91.93205261230469
Train_MaxReturn : 9.698373794555664
Train_MinReturn : -252.65634155273438
Train_AverageEpLen : 269.625
Actor Loss : -276.4258117675781
Baseline Loss : 3029.276123046875
Train_EnvstepsSoFar : 472999
TimeSinceStart : 809.4821379184723

********** Iteration 215 ************
Eval_AverageReturn : -66.13972473144531
Eval_StdReturn : 4.263507843017578
Eval_MaxReturn : -61.87621307373047
Eval_MinReturn : -70.40322875976562
Eval_AverageEpLen : 253.0
Train_AverageReturn : 23.926025390625
Train_StdReturn : 143.3465576171875
Train_MaxReturn : 250.7755126953125
Train_MinReturn : -175.04779052734375
Train_AverageEpLen : 422.0
Actor Loss : 194.26882934570312
Baseline Loss : 3853.32861328125
Train_EnvstepsSoFar : 475109
TimeSinceStart : 813.2754323482513

********** Iteration 216 ************
Eval_AverageReturn : -38.31965637207031
Eval_StdReturn : 125.84519958496094
Eval_MaxReturn : 87.52554321289062
Eval_MinReturn : -164.16485595703125
Eval_AverageEpLen : 579.5
Train_AverageReturn : -95.52113342285156
Train_StdReturn : 83.63439178466797
Train_MaxReturn : -10.814125061035156
Train_MinReturn : -223.60455322265625
Train_AverageEpLen : 238.0
Actor Loss : -44.080238342285156
Baseline Loss : 2444.98388671875
Train_EnvstepsSoFar : 477251
TimeSinceStart : 818.0561029911041

********** Iteration 217 ************
Eval_AverageReturn : -35.844970703125
Eval_StdReturn : 84.65995788574219
Eval_MaxReturn : 36.635887145996094
Eval_MinReturn : -154.61331176757812
Eval_AverageEpLen : 197.66666666666666
Train_AverageReturn : -63.49164581298828
Train_StdReturn : 122.99132537841797
Train_MaxReturn : 155.2346649169922
Train_MinReturn : -201.00794982910156
Train_AverageEpLen : 326.2857142857143
Actor Loss : 166.7361297607422
Baseline Loss : 2801.341064453125
Train_EnvstepsSoFar : 479535
TimeSinceStart : 822.0545125007629

********** Iteration 218 ************
Eval_AverageReturn : -12.162191390991211
Eval_StdReturn : 37.823890686035156
Eval_MaxReturn : 25.661697387695312
Eval_MinReturn : -49.986080169677734
Eval_AverageEpLen : 211.5
Train_AverageReturn : 53.3362922668457
Train_StdReturn : 159.00790405273438
Train_MaxReturn : 257.8992919921875
Train_MinReturn : -200.6713409423828
Train_AverageEpLen : 354.5
Actor Loss : -111.28059387207031
Baseline Loss : 3808.022705078125
Train_EnvstepsSoFar : 481662
TimeSinceStart : 825.5987091064453

********** Iteration 219 ************
Eval_AverageReturn : 219.7837371826172
Eval_StdReturn : 0.0
Eval_MaxReturn : 219.7837371826172
Eval_MinReturn : 219.7837371826172
Eval_AverageEpLen : 838.0
Train_AverageReturn : 75.50711822509766
Train_StdReturn : 194.10049438476562
Train_MaxReturn : 269.676513671875
Train_MinReturn : -224.38720703125
Train_AverageEpLen : 490.8
Actor Loss : -121.434814453125
Baseline Loss : 4170.32080078125
Train_EnvstepsSoFar : 484116
TimeSinceStart : 830.7393968105316

********** Iteration 220 ************
Eval_AverageReturn : -44.670406341552734
Eval_StdReturn : 29.24312973022461
Eval_MaxReturn : -15.427276611328125
Eval_MinReturn : -73.91353607177734
Eval_AverageEpLen : 300.0
Train_AverageReturn : 31.320505142211914
Train_StdReturn : 170.8837432861328
Train_MaxReturn : 260.095458984375
Train_MinReturn : -190.67803955078125
Train_AverageEpLen : 315.57142857142856
Actor Loss : 425.7779541015625
Baseline Loss : 4273.79296875
Train_EnvstepsSoFar : 486325
TimeSinceStart : 834.654956817627

********** Iteration 221 ************
Eval_AverageReturn : -55.71583557128906
Eval_StdReturn : 20.63298225402832
Eval_MaxReturn : -35.08285140991211
Eval_MinReturn : -76.34881591796875
Eval_AverageEpLen : 249.5
Train_AverageReturn : -53.17969512939453
Train_StdReturn : 143.39596557617188
Train_MaxReturn : 278.11944580078125
Train_MinReturn : -215.79315185546875
Train_AverageEpLen : 268.22222222222223
Actor Loss : 55.850006103515625
Baseline Loss : 3203.566162109375
Train_EnvstepsSoFar : 488739
TimeSinceStart : 838.6622154712677

********** Iteration 222 ************
Eval_AverageReturn : -100.77055358886719
Eval_StdReturn : 132.9513702392578
Eval_MaxReturn : 32.180824279785156
Eval_MinReturn : -233.721923828125
Eval_AverageEpLen : 271.5
Train_AverageReturn : -31.81166648864746
Train_StdReturn : 138.31668090820312
Train_MaxReturn : 130.14175415039062
Train_MinReturn : -238.8935546875
Train_AverageEpLen : 630.75
Actor Loss : -116.25792694091797
Baseline Loss : 1952.9769287109375
Train_EnvstepsSoFar : 491262
TimeSinceStart : 843.9804766178131

********** Iteration 223 ************
Eval_AverageReturn : -147.24636840820312
Eval_StdReturn : 111.53710174560547
Eval_MaxReturn : -35.709266662597656
Eval_MinReturn : -258.7834777832031
Eval_AverageEpLen : 217.5
Train_AverageReturn : -78.21453094482422
Train_StdReturn : 136.10362243652344
Train_MaxReturn : 169.61785888671875
Train_MinReturn : -217.94886779785156
Train_AverageEpLen : 373.1666666666667
Actor Loss : -6.962131500244141
Baseline Loss : 2923.4580078125
Train_EnvstepsSoFar : 493501
TimeSinceStart : 847.7284851074219

********** Iteration 224 ************
Eval_AverageReturn : -99.39193725585938
Eval_StdReturn : 164.0196533203125
Eval_MaxReturn : 64.62771606445312
Eval_MinReturn : -263.4115905761719
Eval_AverageEpLen : 281.0
Train_AverageReturn : -110.28185272216797
Train_StdReturn : 143.5343017578125
Train_MaxReturn : 215.5169219970703
Train_MinReturn : -242.9820556640625
Train_AverageEpLen : 305.22222222222223
Actor Loss : -48.284141540527344
Baseline Loss : 4166.24462890625
Train_EnvstepsSoFar : 496248
TimeSinceStart : 852.3912918567657

********** Iteration 225 ************
Eval_AverageReturn : -180.39132690429688
Eval_StdReturn : 8.341529846191406
Eval_MaxReturn : -172.0498046875
Eval_MinReturn : -188.7328643798828
Eval_AverageEpLen : 225.5
Train_AverageReturn : -82.03466033935547
Train_StdReturn : 117.708251953125
Train_MaxReturn : 111.45429992675781
Train_MinReturn : -226.24874877929688
Train_AverageEpLen : 398.0
Actor Loss : -205.00936889648438
Baseline Loss : 2487.73291015625
Train_EnvstepsSoFar : 498636
TimeSinceStart : 856.9564681053162

********** Iteration 226 ************
Eval_AverageReturn : 28.21904754638672
Eval_StdReturn : 234.18231201171875
Eval_MaxReturn : 262.4013671875
Eval_MinReturn : -205.96327209472656
Eval_AverageEpLen : 371.5
Train_AverageReturn : -74.20645141601562
Train_StdReturn : 72.28258514404297
Train_MaxReturn : 18.201297760009766
Train_MinReturn : -188.7560272216797
Train_AverageEpLen : 280.375
Actor Loss : -348.40185546875
Baseline Loss : 2155.86376953125
Train_EnvstepsSoFar : 500879
TimeSinceStart : 861.1648099422455

********** Iteration 227 ************
Eval_AverageReturn : -63.7640266418457
Eval_StdReturn : 109.79598999023438
Eval_MaxReturn : 46.031959533691406
Eval_MinReturn : -173.5600128173828
Eval_AverageEpLen : 609.5
Train_AverageReturn : 14.634994506835938
Train_StdReturn : 205.65342712402344
Train_MaxReturn : 265.6031188964844
Train_MinReturn : -221.80752563476562
Train_AverageEpLen : 417.8
Actor Loss : 36.029457092285156
Baseline Loss : 3374.67333984375
Train_EnvstepsSoFar : 502968
TimeSinceStart : 866.5197796821594

********** Iteration 228 ************
Eval_AverageReturn : -222.7110595703125
Eval_StdReturn : 12.30645751953125
Eval_MaxReturn : -210.40460205078125
Eval_MinReturn : -235.01751708984375
Eval_AverageEpLen : 309.0
Train_AverageReturn : -108.066650390625
Train_StdReturn : 91.38672637939453
Train_MaxReturn : 27.681396484375
Train_MinReturn : -218.71023559570312
Train_AverageEpLen : 434.4
Actor Loss : 12.421612739562988
Baseline Loss : 2475.19482421875
Train_EnvstepsSoFar : 505140
TimeSinceStart : 870.811041355133

********** Iteration 229 ************
Eval_AverageReturn : 38.35942840576172
Eval_StdReturn : 100.22228240966797
Eval_MaxReturn : 138.5817108154297
Eval_MinReturn : -61.86285400390625
Eval_AverageEpLen : 634.0
Train_AverageReturn : 46.53007125854492
Train_StdReturn : 187.11294555664062
Train_MaxReturn : 251.16952514648438
Train_MinReturn : -191.5507049560547
Train_AverageEpLen : 377.3333333333333
Actor Loss : 153.32069396972656
Baseline Loss : 4700.9931640625
Train_EnvstepsSoFar : 507404
TimeSinceStart : 876.2412886619568

********** Iteration 230 ************
Eval_AverageReturn : -109.55937957763672
Eval_StdReturn : 93.67387390136719
Eval_MaxReturn : -15.885509490966797
Eval_MinReturn : -203.23324584960938
Eval_AverageEpLen : 248.0
Train_AverageReturn : -3.4685134887695312
Train_StdReturn : 159.1710968017578
Train_MaxReturn : 238.97305297851562
Train_MinReturn : -222.33279418945312
Train_AverageEpLen : 408.3333333333333
Actor Loss : -5.686361312866211
Baseline Loss : 3376.494873046875
Train_EnvstepsSoFar : 509854
TimeSinceStart : 880.7313330173492

********** Iteration 231 ************
Eval_AverageReturn : 17.012832641601562
Eval_StdReturn : 3.7933921813964844
Eval_MaxReturn : 20.806224822998047
Eval_MinReturn : 13.219440460205078
Eval_AverageEpLen : 221.0
Train_AverageReturn : 32.26948547363281
Train_StdReturn : 164.30709838867188
Train_MaxReturn : 243.4119110107422
Train_MinReturn : -184.46633911132812
Train_AverageEpLen : 518.25
Actor Loss : 33.262901306152344
Baseline Loss : 1953.2099609375
Train_EnvstepsSoFar : 511927
TimeSinceStart : 884.5615036487579

********** Iteration 232 ************
Eval_AverageReturn : -109.99226379394531
Eval_StdReturn : 107.09117126464844
Eval_MaxReturn : -2.901092529296875
Eval_MinReturn : -217.08343505859375
Eval_AverageEpLen : 354.0
Train_AverageReturn : -74.50399017333984
Train_StdReturn : 146.22731018066406
Train_MaxReturn : 250.10079956054688
Train_MinReturn : -258.2721252441406
Train_AverageEpLen : 267.25
Actor Loss : -193.6290283203125
Baseline Loss : 4205.41552734375
Train_EnvstepsSoFar : 514065
TimeSinceStart : 888.713073015213

********** Iteration 233 ************
Eval_AverageReturn : -42.79173278808594
Eval_StdReturn : 0.0
Eval_MaxReturn : -42.79173278808594
Eval_MinReturn : -42.79173278808594
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 65.28473663330078
Train_StdReturn : 127.20899963378906
Train_MaxReturn : 263.1214294433594
Train_MinReturn : -72.53741455078125
Train_AverageEpLen : 502.5
Actor Loss : -209.24423217773438
Baseline Loss : 1558.9075927734375
Train_EnvstepsSoFar : 516075
TimeSinceStart : 894.5497403144836

********** Iteration 234 ************
Eval_AverageReturn : 200.6775665283203
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.6775665283203
Eval_MinReturn : 200.6775665283203
Eval_AverageEpLen : 484.0
Train_AverageReturn : -106.0917739868164
Train_StdReturn : 141.81394958496094
Train_MaxReturn : 101.41193389892578
Train_MinReturn : -282.55267333984375
Train_AverageEpLen : 436.6
Actor Loss : -174.40728759765625
Baseline Loss : 2986.33837890625
Train_EnvstepsSoFar : 518258
TimeSinceStart : 898.6759638786316

********** Iteration 235 ************
Eval_AverageReturn : -144.73583984375
Eval_StdReturn : 105.68460083007812
Eval_MaxReturn : -39.051239013671875
Eval_MinReturn : -250.42044067382812
Eval_AverageEpLen : 262.0
Train_AverageReturn : -38.02104949951172
Train_StdReturn : 159.61883544921875
Train_MaxReturn : 236.23434448242188
Train_MinReturn : -242.7989501953125
Train_AverageEpLen : 382.85714285714283
Actor Loss : -289.3563232421875
Baseline Loss : 2641.41455078125
Train_EnvstepsSoFar : 520938
TimeSinceStart : 904.1212713718414

********** Iteration 236 ************
Eval_AverageReturn : -117.96603393554688
Eval_StdReturn : 80.33659362792969
Eval_MaxReturn : -37.629432678222656
Eval_MinReturn : -198.30262756347656
Eval_AverageEpLen : 233.5
Train_AverageReturn : -111.6240234375
Train_StdReturn : 85.14915466308594
Train_MaxReturn : -7.157197952270508
Train_MinReturn : -246.14752197265625
Train_AverageEpLen : 251.25
Actor Loss : -342.0560607910156
Baseline Loss : 3074.96435546875
Train_EnvstepsSoFar : 522948
TimeSinceStart : 907.4559581279755

********** Iteration 237 ************
Eval_AverageReturn : -111.45934295654297
Eval_StdReturn : 21.213905334472656
Eval_MaxReturn : -90.24543762207031
Eval_MinReturn : -132.67324829101562
Eval_AverageEpLen : 302.5
Train_AverageReturn : -116.20146179199219
Train_StdReturn : 70.68046569824219
Train_MaxReturn : -5.87786865234375
Train_MinReturn : -192.68521118164062
Train_AverageEpLen : 262.375
Actor Loss : -317.39593505859375
Baseline Loss : 3283.874267578125
Train_EnvstepsSoFar : 525047
TimeSinceStart : 911.1431119441986

********** Iteration 238 ************
Eval_AverageReturn : 196.55667114257812
Eval_StdReturn : 0.0
Eval_MaxReturn : 196.55667114257812
Eval_MinReturn : 196.55667114257812
Eval_AverageEpLen : 554.0
Train_AverageReturn : -114.145263671875
Train_StdReturn : 138.8291015625
Train_MaxReturn : 213.19625854492188
Train_MinReturn : -226.6141357421875
Train_AverageEpLen : 285.85714285714283
Actor Loss : -352.5538635253906
Baseline Loss : 3322.58837890625
Train_EnvstepsSoFar : 527048
TimeSinceStart : 914.924512386322

********** Iteration 239 ************
Eval_AverageReturn : -104.23053741455078
Eval_StdReturn : 50.02503204345703
Eval_MaxReturn : -54.20550537109375
Eval_MinReturn : -154.2555694580078
Eval_AverageEpLen : 241.5
Train_AverageReturn : -31.043638229370117
Train_StdReturn : 219.7466278076172
Train_MaxReturn : 265.42962646484375
Train_MinReturn : -298.706298828125
Train_AverageEpLen : 352.6666666666667
Actor Loss : -65.2415771484375
Baseline Loss : 5208.6884765625
Train_EnvstepsSoFar : 529164
TimeSinceStart : 918.8327577114105

********** Iteration 240 ************
Eval_AverageReturn : -217.03866577148438
Eval_StdReturn : 18.962928771972656
Eval_MaxReturn : -198.07574462890625
Eval_MinReturn : -236.00160217285156
Eval_AverageEpLen : 330.5
Train_AverageReturn : 43.4439582824707
Train_StdReturn : 152.676513671875
Train_MaxReturn : 224.5688934326172
Train_MinReturn : -143.94537353515625
Train_AverageEpLen : 569.25
Actor Loss : -176.0935821533203
Baseline Loss : 2309.117919921875
Train_EnvstepsSoFar : 531441
TimeSinceStart : 923.5506217479706

********** Iteration 241 ************
Eval_AverageReturn : -117.48094940185547
Eval_StdReturn : 112.8687973022461
Eval_MaxReturn : -4.612147808074951
Eval_MinReturn : -230.34974670410156
Eval_AverageEpLen : 249.0
Train_AverageReturn : -133.07998657226562
Train_StdReturn : 99.97258758544922
Train_MaxReturn : 12.219478607177734
Train_MinReturn : -244.8060302734375
Train_AverageEpLen : 264.875
Actor Loss : -552.1213989257812
Baseline Loss : 2807.284423828125
Train_EnvstepsSoFar : 533560
TimeSinceStart : 926.9790751934052

********** Iteration 242 ************
Eval_AverageReturn : -24.08428382873535
Eval_StdReturn : 26.760183334350586
Eval_MaxReturn : 2.6758995056152344
Eval_MinReturn : -50.84446716308594
Eval_AverageEpLen : 258.0
Train_AverageReturn : -18.908367156982422
Train_StdReturn : 108.50677490234375
Train_MaxReturn : 118.73823547363281
Train_MinReturn : -206.6940460205078
Train_AverageEpLen : 482.0
Actor Loss : -97.7656021118164
Baseline Loss : 1539.837890625
Train_EnvstepsSoFar : 536452
TimeSinceStart : 932.2755768299103

********** Iteration 243 ************
Eval_AverageReturn : 269.1674499511719
Eval_StdReturn : 0.0
Eval_MaxReturn : 269.1674499511719
Eval_MinReturn : 269.1674499511719
Eval_AverageEpLen : 414.0
Train_AverageReturn : 6.0538201332092285
Train_StdReturn : 239.09939575195312
Train_MaxReturn : 264.6876525878906
Train_MinReturn : -242.108154296875
Train_AverageEpLen : 378.5
Actor Loss : -5.690025329589844
Baseline Loss : 5556.1533203125
Train_EnvstepsSoFar : 538723
TimeSinceStart : 936.1978781223297

********** Iteration 244 ************
Eval_AverageReturn : -111.78842163085938
Eval_StdReturn : 105.50289916992188
Eval_MaxReturn : -6.285514831542969
Eval_MinReturn : -217.29132080078125
Eval_AverageEpLen : 346.0
Train_AverageReturn : -63.80579376220703
Train_StdReturn : 133.04440307617188
Train_MaxReturn : 233.68797302246094
Train_MinReturn : -211.50401306152344
Train_AverageEpLen : 244.0
Actor Loss : -31.764217376708984
Baseline Loss : 4401.01708984375
Train_EnvstepsSoFar : 540919
TimeSinceStart : 940.1734571456909

********** Iteration 245 ************
Eval_AverageReturn : -197.75421142578125
Eval_StdReturn : 18.463172912597656
Eval_MaxReturn : -179.29103088378906
Eval_MinReturn : -216.21737670898438
Eval_AverageEpLen : 254.5
Train_AverageReturn : -98.8437271118164
Train_StdReturn : 175.43112182617188
Train_MaxReturn : 298.853271484375
Train_MinReturn : -299.3656005859375
Train_AverageEpLen : 279.625
Actor Loss : -209.5352325439453
Baseline Loss : 4759.67724609375
Train_EnvstepsSoFar : 543156
TimeSinceStart : 943.5162212848663

********** Iteration 246 ************
Eval_AverageReturn : -28.651771545410156
Eval_StdReturn : 144.84759521484375
Eval_MaxReturn : 116.19581604003906
Eval_MinReturn : -173.49935913085938
Eval_AverageEpLen : 634.0
Train_AverageReturn : -124.32762908935547
Train_StdReturn : 103.16268157958984
Train_MaxReturn : 3.280994176864624
Train_MinReturn : -265.716064453125
Train_AverageEpLen : 273.75
Actor Loss : -631.8855590820312
Baseline Loss : 2564.44091796875
Train_EnvstepsSoFar : 545346
TimeSinceStart : 947.6759305000305

********** Iteration 247 ************
Eval_AverageReturn : 90.04227447509766
Eval_StdReturn : 0.0
Eval_MaxReturn : 90.04227447509766
Eval_MinReturn : 90.04227447509766
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -30.861400604248047
Train_StdReturn : 144.3004608154297
Train_MaxReturn : 250.18565368652344
Train_MinReturn : -228.38742065429688
Train_AverageEpLen : 293.42857142857144
Actor Loss : -187.0595703125
Baseline Loss : 3327.13134765625
Train_EnvstepsSoFar : 547400
TimeSinceStart : 952.2874894142151

********** Iteration 248 ************
Eval_AverageReturn : -229.5093536376953
Eval_StdReturn : 11.362747192382812
Eval_MaxReturn : -218.1466064453125
Eval_MinReturn : -240.87210083007812
Eval_AverageEpLen : 258.5
Train_AverageReturn : -110.72270965576172
Train_StdReturn : 143.9034881591797
Train_MaxReturn : 267.41375732421875
Train_MinReturn : -215.26333618164062
Train_AverageEpLen : 245.22222222222223
Actor Loss : -16.614486694335938
Baseline Loss : 4453.45068359375
Train_EnvstepsSoFar : 549607
TimeSinceStart : 955.0818099975586

********** Iteration 249 ************
Eval_AverageReturn : -111.90943145751953
Eval_StdReturn : 125.90706634521484
Eval_MaxReturn : 13.997629165649414
Eval_MinReturn : -237.81649780273438
Eval_AverageEpLen : 213.5
Train_AverageReturn : -116.94252014160156
Train_StdReturn : 76.8238296508789
Train_MaxReturn : -19.247722625732422
Train_MinReturn : -246.3828125
Train_AverageEpLen : 257.25
Actor Loss : -123.81352996826172
Baseline Loss : 2353.041015625
Train_EnvstepsSoFar : 551665
TimeSinceStart : 958.1865034103394

********** Iteration 250 ************
Eval_AverageReturn : -49.12819290161133
Eval_StdReturn : 18.07491683959961
Eval_MaxReturn : -31.05327606201172
Eval_MinReturn : -67.20310974121094
Eval_AverageEpLen : 208.0
Train_AverageReturn : -22.494503021240234
Train_StdReturn : 182.39944458007812
Train_MaxReturn : 265.71514892578125
Train_MinReturn : -240.08053588867188
Train_AverageEpLen : 305.85714285714283
Actor Loss : -139.91030883789062
Baseline Loss : 5020.5595703125
Train_EnvstepsSoFar : 553806
TimeSinceStart : 961.4979236125946

********** Iteration 251 ************
Eval_AverageReturn : -108.72651672363281
Eval_StdReturn : 63.811676025390625
Eval_MaxReturn : -44.91484069824219
Eval_MinReturn : -172.53819274902344
Eval_AverageEpLen : 252.5
Train_AverageReturn : -43.19132614135742
Train_StdReturn : 156.75775146484375
Train_MaxReturn : 244.5425567626953
Train_MinReturn : -221.07928466796875
Train_AverageEpLen : 352.8333333333333
Actor Loss : -153.74899291992188
Baseline Loss : 3178.25732421875
Train_EnvstepsSoFar : 555923
TimeSinceStart : 964.9795489311218

********** Iteration 252 ************
Eval_AverageReturn : 226.42562866210938
Eval_StdReturn : 0.0
Eval_MaxReturn : 226.42562866210938
Eval_MinReturn : 226.42562866210938
Eval_AverageEpLen : 407.0
Train_AverageReturn : -194.80560302734375
Train_StdReturn : 61.33808898925781
Train_MaxReturn : -57.41363525390625
Train_MinReturn : -264.020263671875
Train_AverageEpLen : 274.625
Actor Loss : -823.5026245117188
Baseline Loss : 3520.69189453125
Train_EnvstepsSoFar : 558120
TimeSinceStart : 968.4908618927002

********** Iteration 253 ************
Eval_AverageReturn : -137.1288604736328
Eval_StdReturn : 103.47847747802734
Eval_MaxReturn : -33.65038299560547
Eval_MinReturn : -240.6073455810547
Eval_AverageEpLen : 295.0
Train_AverageReturn : 19.988065719604492
Train_StdReturn : 233.885009765625
Train_MaxReturn : 276.56494140625
Train_MinReturn : -255.2003631591797
Train_AverageEpLen : 349.6666666666667
Actor Loss : 175.40200805664062
Baseline Loss : 7014.9130859375
Train_EnvstepsSoFar : 560218
TimeSinceStart : 972.338623046875

********** Iteration 254 ************
Eval_AverageReturn : 237.65103149414062
Eval_StdReturn : 0.0
Eval_MaxReturn : 237.65103149414062
Eval_MinReturn : 237.65103149414062
Eval_AverageEpLen : 464.0
Train_AverageReturn : -17.066972732543945
Train_StdReturn : 177.93125915527344
Train_MaxReturn : 266.15289306640625
Train_MinReturn : -207.19757080078125
Train_AverageEpLen : 344.57142857142856
Actor Loss : -1.2671470642089844
Baseline Loss : 4313.43115234375
Train_EnvstepsSoFar : 562630
TimeSinceStart : 976.3649845123291

********** Iteration 255 ************
Eval_AverageReturn : -162.53109741210938
Eval_StdReturn : 89.67596435546875
Eval_MaxReturn : -72.85513305664062
Eval_MinReturn : -252.20706176757812
Eval_AverageEpLen : 298.5
Train_AverageReturn : 1.707975149154663
Train_StdReturn : 143.35653686523438
Train_MaxReturn : 235.87303161621094
Train_MinReturn : -239.5264434814453
Train_AverageEpLen : 412.14285714285717
Actor Loss : -188.71627807617188
Baseline Loss : 2836.619140625
Train_EnvstepsSoFar : 565515
TimeSinceStart : 981.4001817703247

********** Iteration 256 ************
Eval_AverageReturn : 20.393295288085938
Eval_StdReturn : 2.9056243896484375
Eval_MaxReturn : 23.298919677734375
Eval_MinReturn : 17.4876708984375
Eval_AverageEpLen : 229.0
Train_AverageReturn : 59.3914909362793
Train_StdReturn : 110.35570526123047
Train_MaxReturn : 237.690185546875
Train_MinReturn : -43.24010467529297
Train_AverageEpLen : 318.0
Actor Loss : 60.6187858581543
Baseline Loss : 3426.28369140625
Train_EnvstepsSoFar : 567741
TimeSinceStart : 984.5669438838959

********** Iteration 257 ************
Eval_AverageReturn : 109.45732116699219
Eval_StdReturn : 0.0
Eval_MaxReturn : 109.45732116699219
Eval_MinReturn : 109.45732116699219
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 8.587688446044922
Train_StdReturn : 144.83541870117188
Train_MaxReturn : 240.6945037841797
Train_MinReturn : -210.95156860351562
Train_AverageEpLen : 253.875
Actor Loss : -46.860374450683594
Baseline Loss : 4301.0546875
Train_EnvstepsSoFar : 569772
TimeSinceStart : 989.0035083293915

********** Iteration 258 ************
Eval_AverageReturn : -215.19802856445312
Eval_StdReturn : 1.144012451171875
Eval_MaxReturn : -214.05401611328125
Eval_MinReturn : -216.342041015625
Eval_AverageEpLen : 262.5
Train_AverageReturn : 45.160606384277344
Train_StdReturn : 196.07127380371094
Train_MaxReturn : 266.501220703125
Train_MinReturn : -251.07058715820312
Train_AverageEpLen : 296.2857142857143
Actor Loss : -130.834716796875
Baseline Loss : 5879.93017578125
Train_EnvstepsSoFar : 571846
TimeSinceStart : 992.5297617912292

********** Iteration 259 ************
Eval_AverageReturn : -51.956966400146484
Eval_StdReturn : 18.939167022705078
Eval_MaxReturn : -33.017799377441406
Eval_MinReturn : -70.89613342285156
Eval_AverageEpLen : 259.5
Train_AverageReturn : -78.6993179321289
Train_StdReturn : 152.59567260742188
Train_MaxReturn : 156.79598999023438
Train_MinReturn : -251.98779296875
Train_AverageEpLen : 370.3333333333333
Actor Loss : -159.13565063476562
Baseline Loss : 3436.204345703125
Train_EnvstepsSoFar : 574068
TimeSinceStart : 996.4699630737305

********** Iteration 260 ************
Eval_AverageReturn : -169.63150024414062
Eval_StdReturn : 2.8900222778320312
Eval_MaxReturn : -166.74147033691406
Eval_MinReturn : -172.52151489257812
Eval_AverageEpLen : 226.5
Train_AverageReturn : -67.58204650878906
Train_StdReturn : 198.95083618164062
Train_MaxReturn : 281.41253662109375
Train_MinReturn : -226.685546875
Train_AverageEpLen : 265.375
Actor Loss : -156.223388671875
Baseline Loss : 5842.5361328125
Train_EnvstepsSoFar : 576191
TimeSinceStart : 999.9876265525818

********** Iteration 261 ************
Eval_AverageReturn : 17.52495574951172
Eval_StdReturn : 242.69390869140625
Eval_MaxReturn : 260.2188720703125
Eval_MinReturn : -225.16896057128906
Eval_AverageEpLen : 308.5
Train_AverageReturn : -175.79104614257812
Train_StdReturn : 49.91371536254883
Train_MaxReturn : -64.28107452392578
Train_MinReturn : -217.94081115722656
Train_AverageEpLen : 247.88888888888889
Actor Loss : -290.3902893066406
Baseline Loss : 5371.4169921875
Train_EnvstepsSoFar : 578422
TimeSinceStart : 1003.8397648334503

********** Iteration 262 ************
Eval_AverageReturn : 51.24170684814453
Eval_StdReturn : 230.7554931640625
Eval_MaxReturn : 281.9971923828125
Eval_MinReturn : -179.51377868652344
Eval_AverageEpLen : 294.0
Train_AverageReturn : 11.360305786132812
Train_StdReturn : 224.04766845703125
Train_MaxReturn : 297.8814392089844
Train_MinReturn : -251.7347412109375
Train_AverageEpLen : 332.57142857142856
Actor Loss : -160.52438354492188
Baseline Loss : 5750.4697265625
Train_EnvstepsSoFar : 580750
TimeSinceStart : 1008.0336985588074

********** Iteration 263 ************
Eval_AverageReturn : -210.60794067382812
Eval_StdReturn : 7.729316711425781
Eval_MaxReturn : -202.87863159179688
Eval_MinReturn : -218.33726501464844
Eval_AverageEpLen : 306.0
Train_AverageReturn : 6.458058834075928
Train_StdReturn : 158.06765747070312
Train_MaxReturn : 219.60195922851562
Train_MinReturn : -212.93515014648438
Train_AverageEpLen : 361.8333333333333
Actor Loss : -232.42880249023438
Baseline Loss : 3140.62451171875
Train_EnvstepsSoFar : 582921
TimeSinceStart : 1012.6984157562256

********** Iteration 264 ************
Eval_AverageReturn : -63.12980651855469
Eval_StdReturn : 102.59431457519531
Eval_MaxReturn : 11.407943725585938
Eval_MinReturn : -208.20166015625
Eval_AverageEpLen : 192.66666666666666
Train_AverageReturn : -140.39324951171875
Train_StdReturn : 89.51448059082031
Train_MaxReturn : 13.75321102142334
Train_MinReturn : -227.62869262695312
Train_AverageEpLen : 250.88888888888889
Actor Loss : -336.7008361816406
Baseline Loss : 3999.18798828125
Train_EnvstepsSoFar : 585179
TimeSinceStart : 1016.2965202331543

********** Iteration 265 ************
Eval_AverageReturn : 94.9323959350586
Eval_StdReturn : 122.7078857421875
Eval_MaxReturn : 217.64027404785156
Eval_MinReturn : -27.775487899780273
Eval_AverageEpLen : 323.0
Train_AverageReturn : -49.768089294433594
Train_StdReturn : 123.23895263671875
Train_MaxReturn : 121.45418548583984
Train_MinReturn : -264.0649108886719
Train_AverageEpLen : 430.6
Actor Loss : -139.95065307617188
Baseline Loss : 1522.142822265625
Train_EnvstepsSoFar : 587332
TimeSinceStart : 1020.3041048049927

********** Iteration 266 ************
Eval_AverageReturn : 97.1473388671875
Eval_StdReturn : 0.0
Eval_MaxReturn : 97.1473388671875
Eval_MinReturn : 97.1473388671875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -112.27212524414062
Train_StdReturn : 150.564208984375
Train_MaxReturn : 255.72207641601562
Train_MinReturn : -247.13690185546875
Train_AverageEpLen : 246.0
Actor Loss : 11.712852478027344
Baseline Loss : 5075.18115234375
Train_EnvstepsSoFar : 589546
TimeSinceStart : 1024.7327857017517

********** Iteration 267 ************
Eval_AverageReturn : -10.584037780761719
Eval_StdReturn : 207.68890380859375
Eval_MaxReturn : 197.1048583984375
Eval_MinReturn : -218.27293395996094
Eval_AverageEpLen : 333.5
Train_AverageReturn : -48.12528610229492
Train_StdReturn : 142.6219940185547
Train_MaxReturn : 265.541259765625
Train_MinReturn : -228.13987731933594
Train_AverageEpLen : 250.11111111111111
Actor Loss : -53.35359573364258
Baseline Loss : 3614.787109375
Train_EnvstepsSoFar : 591797
TimeSinceStart : 1028.6283385753632

********** Iteration 268 ************
Eval_AverageReturn : -131.03952026367188
Eval_StdReturn : 100.0135726928711
Eval_MaxReturn : -31.025951385498047
Eval_MinReturn : -231.0531005859375
Eval_AverageEpLen : 264.0
Train_AverageReturn : -57.97068786621094
Train_StdReturn : 139.23007202148438
Train_MaxReturn : 268.1548156738281
Train_MinReturn : -212.41197204589844
Train_AverageEpLen : 262.0
Actor Loss : -197.07716369628906
Baseline Loss : 3176.2685546875
Train_EnvstepsSoFar : 593893
TimeSinceStart : 1032.1049783229828

********** Iteration 269 ************
Eval_AverageReturn : -93.4691390991211
Eval_StdReturn : 130.31893920898438
Eval_MaxReturn : 36.849796295166016
Eval_MinReturn : -223.78807067871094
Eval_AverageEpLen : 238.0
Train_AverageReturn : 26.768098831176758
Train_StdReturn : 158.0011749267578
Train_MaxReturn : 276.0832214355469
Train_MinReturn : -237.3275146484375
Train_AverageEpLen : 275.0
Actor Loss : 91.22132873535156
Baseline Loss : 4501.18798828125
Train_EnvstepsSoFar : 596093
TimeSinceStart : 1035.5940718650818

********** Iteration 270 ************
Eval_AverageReturn : -138.72586059570312
Eval_StdReturn : 73.0328598022461
Eval_MaxReturn : -65.69300842285156
Eval_MinReturn : -211.75872802734375
Eval_AverageEpLen : 319.0
Train_AverageReturn : -35.20075607299805
Train_StdReturn : 114.58839416503906
Train_MaxReturn : 207.0979766845703
Train_MinReturn : -196.79470825195312
Train_AverageEpLen : 312.7142857142857
Actor Loss : -102.11929321289062
Baseline Loss : 2630.64599609375
Train_EnvstepsSoFar : 598282
TimeSinceStart : 1039.5880739688873

********** Iteration 271 ************
Eval_AverageReturn : 50.970428466796875
Eval_StdReturn : 199.3192138671875
Eval_MaxReturn : 250.28964233398438
Eval_MinReturn : -148.34878540039062
Eval_AverageEpLen : 274.0
Train_AverageReturn : -71.66082000732422
Train_StdReturn : 172.38214111328125
Train_MaxReturn : 237.73489379882812
Train_MinReturn : -285.90557861328125
Train_AverageEpLen : 399.42857142857144
Actor Loss : -41.53662109375
Baseline Loss : 3100.406005859375
Train_EnvstepsSoFar : 601078
TimeSinceStart : 1045.2481036186218

********** Iteration 272 ************
Eval_AverageReturn : -101.66458129882812
Eval_StdReturn : 80.88069152832031
Eval_MaxReturn : -20.78388214111328
Eval_MinReturn : -182.54527282714844
Eval_AverageEpLen : 226.5
Train_AverageReturn : 104.99725341796875
Train_StdReturn : 164.2781219482422
Train_MaxReturn : 269.73760986328125
Train_MinReturn : -174.18800354003906
Train_AverageEpLen : 351.7142857142857
Actor Loss : 185.48753356933594
Baseline Loss : 4914.787109375
Train_EnvstepsSoFar : 603540
TimeSinceStart : 1049.119392156601

********** Iteration 273 ************
Eval_AverageReturn : -178.21603393554688
Eval_StdReturn : 79.14035034179688
Eval_MaxReturn : -99.07568359375
Eval_MinReturn : -257.35638427734375
Eval_AverageEpLen : 300.0
Train_AverageReturn : -17.5026798248291
Train_StdReturn : 196.35348510742188
Train_MaxReturn : 279.29736328125
Train_MinReturn : -245.28244018554688
Train_AverageEpLen : 336.0
Actor Loss : 140.6028289794922
Baseline Loss : 4634.6767578125
Train_EnvstepsSoFar : 605556
TimeSinceStart : 1052.6813428401947

********** Iteration 274 ************
Eval_AverageReturn : -212.39456176757812
Eval_StdReturn : 14.5888671875
Eval_MaxReturn : -197.80569458007812
Eval_MinReturn : -226.98342895507812
Eval_AverageEpLen : 263.0
Train_AverageReturn : 11.111413955688477
Train_StdReturn : 171.95530700683594
Train_MaxReturn : 240.57156372070312
Train_MinReturn : -222.26271057128906
Train_AverageEpLen : 525.75
Actor Loss : 102.93855285644531
Baseline Loss : 2412.184814453125
Train_EnvstepsSoFar : 607659
TimeSinceStart : 1056.7562425136566

********** Iteration 275 ************
Eval_AverageReturn : -94.97850036621094
Eval_StdReturn : 55.80149841308594
Eval_MaxReturn : -39.177001953125
Eval_MinReturn : -150.77999877929688
Eval_AverageEpLen : 201.0
Train_AverageReturn : -120.26762390136719
Train_StdReturn : 153.79644775390625
Train_MaxReturn : 206.0426483154297
Train_MinReturn : -239.74374389648438
Train_AverageEpLen : 294.7142857142857
Actor Loss : -205.8048858642578
Baseline Loss : 4875.248046875
Train_EnvstepsSoFar : 609722
TimeSinceStart : 1059.9236602783203

********** Iteration 276 ************
Eval_AverageReturn : 78.73201751708984
Eval_StdReturn : 0.0
Eval_MaxReturn : 78.73201751708984
Eval_MinReturn : 78.73201751708984
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -77.85406494140625
Train_StdReturn : 94.83976745605469
Train_MaxReturn : 55.069557189941406
Train_MinReturn : -207.92330932617188
Train_AverageEpLen : 361.5
Actor Loss : -181.36264038085938
Baseline Loss : 2223.5380859375
Train_EnvstepsSoFar : 611891
TimeSinceStart : 1064.7715990543365

********** Iteration 277 ************
Eval_AverageReturn : -208.3489532470703
Eval_StdReturn : 9.120590209960938
Eval_MaxReturn : -199.22836303710938
Eval_MinReturn : -217.46954345703125
Eval_AverageEpLen : 319.0
Train_AverageReturn : 11.424839973449707
Train_StdReturn : 161.09300231933594
Train_MaxReturn : 247.63084411621094
Train_MinReturn : -211.01832580566406
Train_AverageEpLen : 311.2857142857143
Actor Loss : -286.62261962890625
Baseline Loss : 3240.91796875
Train_EnvstepsSoFar : 614070
TimeSinceStart : 1068.593379020691

********** Iteration 278 ************
Eval_AverageReturn : -122.73838806152344
Eval_StdReturn : 104.3672866821289
Eval_MaxReturn : -18.37110137939453
Eval_MinReturn : -227.10568237304688
Eval_AverageEpLen : 232.5
Train_AverageReturn : -128.5824737548828
Train_StdReturn : 83.39042663574219
Train_MaxReturn : -23.776981353759766
Train_MinReturn : -221.22528076171875
Train_AverageEpLen : 248.33333333333334
Actor Loss : -521.3623657226562
Baseline Loss : 3602.708984375
Train_EnvstepsSoFar : 616305
TimeSinceStart : 1071.9517815113068

********** Iteration 279 ************
Eval_AverageReturn : -69.99433135986328
Eval_StdReturn : 88.81643676757812
Eval_MaxReturn : 20.356483459472656
Eval_MinReturn : -190.73484802246094
Eval_AverageEpLen : 208.66666666666666
Train_AverageReturn : -82.31059265136719
Train_StdReturn : 117.33448791503906
Train_MaxReturn : 128.91293334960938
Train_MinReturn : -237.66165161132812
Train_AverageEpLen : 337.25
Actor Loss : -324.62408447265625
Baseline Loss : 2346.10888671875
Train_EnvstepsSoFar : 619003
TimeSinceStart : 1076.619077205658

********** Iteration 280 ************
Eval_AverageReturn : -151.12826538085938
Eval_StdReturn : 83.52914428710938
Eval_MaxReturn : -67.59912109375
Eval_MinReturn : -234.65740966796875
Eval_AverageEpLen : 289.0
Train_AverageReturn : 9.343061447143555
Train_StdReturn : 170.56173706054688
Train_MaxReturn : 269.4463195800781
Train_MinReturn : -193.94857788085938
Train_AverageEpLen : 325.0
Actor Loss : -128.35964965820312
Baseline Loss : 3675.50390625
Train_EnvstepsSoFar : 621278
TimeSinceStart : 1080.5643146038055

********** Iteration 281 ************
Eval_AverageReturn : -115.11228942871094
Eval_StdReturn : 103.07969665527344
Eval_MaxReturn : -12.032591819763184
Eval_MinReturn : -218.19198608398438
Eval_AverageEpLen : 204.0
Train_AverageReturn : -54.4363899230957
Train_StdReturn : 111.4466323852539
Train_MaxReturn : 142.6041717529297
Train_MinReturn : -194.0741424560547
Train_AverageEpLen : 368.5
Actor Loss : -31.9228572845459
Baseline Loss : 2184.790283203125
Train_EnvstepsSoFar : 623489
TimeSinceStart : 1084.3191821575165

********** Iteration 282 ************
Eval_AverageReturn : 90.51795959472656
Eval_StdReturn : 125.87355041503906
Eval_MaxReturn : 216.39151000976562
Eval_MinReturn : -35.35559844970703
Eval_AverageEpLen : 413.5
Train_AverageReturn : -92.02003479003906
Train_StdReturn : 109.83441162109375
Train_MaxReturn : 68.97510528564453
Train_MinReturn : -258.2188720703125
Train_AverageEpLen : 426.0
Actor Loss : -261.8942565917969
Baseline Loss : 1790.7855224609375
Train_EnvstepsSoFar : 625619
TimeSinceStart : 1088.6897435188293

********** Iteration 283 ************
Eval_AverageReturn : 193.33526611328125
Eval_StdReturn : 0.0
Eval_MaxReturn : 193.33526611328125
Eval_MinReturn : 193.33526611328125
Eval_AverageEpLen : 692.0
Train_AverageReturn : 56.89442825317383
Train_StdReturn : 118.19808197021484
Train_MaxReturn : 274.5699462890625
Train_MinReturn : -59.100955963134766
Train_AverageEpLen : 309.2857142857143
Actor Loss : -30.91718292236328
Baseline Loss : 3075.544921875
Train_EnvstepsSoFar : 627784
TimeSinceStart : 1092.8622279167175

********** Iteration 284 ************
Eval_AverageReturn : -197.24960327148438
Eval_StdReturn : 10.137214660644531
Eval_MaxReturn : -187.1123809814453
Eval_MinReturn : -207.38681030273438
Eval_AverageEpLen : 280.0
Train_AverageReturn : -28.1655330657959
Train_StdReturn : 176.31629943847656
Train_MaxReturn : 308.1824951171875
Train_MinReturn : -222.01998901367188
Train_AverageEpLen : 360.7142857142857
Actor Loss : -155.14279174804688
Baseline Loss : 3963.595703125
Train_EnvstepsSoFar : 630309
TimeSinceStart : 1097.1406154632568

********** Iteration 285 ************
Eval_AverageReturn : 48.88373947143555
Eval_StdReturn : 76.63909912109375
Eval_MaxReturn : 125.52284240722656
Eval_MinReturn : -27.755361557006836
Eval_AverageEpLen : 647.0
Train_AverageReturn : 19.54593849182129
Train_StdReturn : 175.2305908203125
Train_MaxReturn : 275.3685302734375
Train_MinReturn : -181.25755310058594
Train_AverageEpLen : 453.6
Actor Loss : -3.97515869140625
Baseline Loss : 3514.512939453125
Train_EnvstepsSoFar : 632577
TimeSinceStart : 1101.9661371707916

********** Iteration 286 ************
Eval_AverageReturn : -155.01577758789062
Eval_StdReturn : 13.961700439453125
Eval_MaxReturn : -141.0540771484375
Eval_MinReturn : -168.97747802734375
Eval_AverageEpLen : 221.0
Train_AverageReturn : -38.188697814941406
Train_StdReturn : 130.46861267089844
Train_MaxReturn : 211.82786560058594
Train_MinReturn : -226.4214630126953
Train_AverageEpLen : 310.0
Actor Loss : -541.16552734375
Baseline Loss : 3288.010986328125
Train_EnvstepsSoFar : 634747
TimeSinceStart : 1105.5408353805542

********** Iteration 287 ************
Eval_AverageReturn : 35.19104766845703
Eval_StdReturn : 233.83566284179688
Eval_MaxReturn : 269.0267028808594
Eval_MinReturn : -198.6446075439453
Eval_AverageEpLen : 325.0
Train_AverageReturn : -37.343605041503906
Train_StdReturn : 175.98300170898438
Train_MaxReturn : 258.1772155761719
Train_MinReturn : -222.5625
Train_AverageEpLen : 264.375
Actor Loss : -228.93739318847656
Baseline Loss : 5029.8037109375
Train_EnvstepsSoFar : 636862
TimeSinceStart : 1109.0468571186066

********** Iteration 288 ************
Eval_AverageReturn : -86.41844177246094
Eval_StdReturn : 91.82696533203125
Eval_MaxReturn : 5.408519744873047
Eval_MinReturn : -178.2454071044922
Eval_AverageEpLen : 257.5
Train_AverageReturn : -29.230850219726562
Train_StdReturn : 197.2025604248047
Train_MaxReturn : 267.4532470703125
Train_MinReturn : -250.63748168945312
Train_AverageEpLen : 385.0
Actor Loss : -37.85930252075195
Baseline Loss : 3997.66064453125
Train_EnvstepsSoFar : 639172
TimeSinceStart : 1112.9584412574768

********** Iteration 289 ************
Eval_AverageReturn : -189.9783477783203
Eval_StdReturn : 1.6444854736328125
Eval_MaxReturn : -188.3338623046875
Eval_MinReturn : -191.62283325195312
Eval_AverageEpLen : 290.5
Train_AverageReturn : -14.517084121704102
Train_StdReturn : 170.35699462890625
Train_MaxReturn : 263.62823486328125
Train_MinReturn : -226.26145935058594
Train_AverageEpLen : 286.5
Actor Loss : -62.423213958740234
Baseline Loss : 4597.37939453125
Train_EnvstepsSoFar : 641464
TimeSinceStart : 1116.6754314899445

********** Iteration 290 ************
Eval_AverageReturn : 130.4442596435547
Eval_StdReturn : 138.23683166503906
Eval_MaxReturn : 268.68109130859375
Eval_MinReturn : -7.792572021484375
Eval_AverageEpLen : 251.5
Train_AverageReturn : -123.95710754394531
Train_StdReturn : 105.15618133544922
Train_MaxReturn : 31.14444923400879
Train_MinReturn : -248.71636962890625
Train_AverageEpLen : 254.125
Actor Loss : -129.623779296875
Baseline Loss : 4011.069580078125
Train_EnvstepsSoFar : 643497
TimeSinceStart : 1119.6838359832764

********** Iteration 291 ************
Eval_AverageReturn : 77.97762298583984
Eval_StdReturn : 115.94803619384766
Eval_MaxReturn : 193.9256591796875
Eval_MinReturn : -37.97040939331055
Eval_AverageEpLen : 373.0
Train_AverageReturn : 5.36907434463501
Train_StdReturn : 148.70774841308594
Train_MaxReturn : 218.64199829101562
Train_MinReturn : -208.1279296875
Train_AverageEpLen : 319.0
Actor Loss : -158.58999633789062
Baseline Loss : 3629.49560546875
Train_EnvstepsSoFar : 645730
TimeSinceStart : 1123.9792530536652

********** Iteration 292 ************
Eval_AverageReturn : -208.4332275390625
Eval_StdReturn : 33.28777313232422
Eval_MaxReturn : -175.14544677734375
Eval_MinReturn : -241.7209930419922
Eval_AverageEpLen : 274.5
Train_AverageReturn : 45.17244338989258
Train_StdReturn : 137.90264892578125
Train_MaxReturn : 227.56866455078125
Train_MinReturn : -176.75840759277344
Train_AverageEpLen : 356.5
Actor Loss : -219.74014282226562
Baseline Loss : 2755.66748046875
Train_EnvstepsSoFar : 647869
TimeSinceStart : 1127.9434428215027

********** Iteration 293 ************
Eval_AverageReturn : -119.22650909423828
Eval_StdReturn : 71.42066192626953
Eval_MaxReturn : -47.80584716796875
Eval_MinReturn : -190.6471710205078
Eval_AverageEpLen : 242.5
Train_AverageReturn : -101.06426239013672
Train_StdReturn : 142.13150024414062
Train_MaxReturn : 185.4354248046875
Train_MinReturn : -228.09661865234375
Train_AverageEpLen : 302.42857142857144
Actor Loss : -152.07608032226562
Baseline Loss : 3860.858154296875
Train_EnvstepsSoFar : 649986
TimeSinceStart : 1131.3030381202698

********** Iteration 294 ************
Eval_AverageReturn : -209.3700714111328
Eval_StdReturn : 11.777908325195312
Eval_MaxReturn : -197.5921630859375
Eval_MinReturn : -221.14797973632812
Eval_AverageEpLen : 300.0
Train_AverageReturn : -37.21538543701172
Train_StdReturn : 144.15093994140625
Train_MaxReturn : 264.2628479003906
Train_MinReturn : -174.82176208496094
Train_AverageEpLen : 345.6666666666667
Actor Loss : -372.4881286621094
Baseline Loss : 3787.37158203125
Train_EnvstepsSoFar : 652060
TimeSinceStart : 1135.0368814468384

********** Iteration 295 ************
Eval_AverageReturn : -176.16873168945312
Eval_StdReturn : 111.35809326171875
Eval_MaxReturn : -64.81063842773438
Eval_MinReturn : -287.5268249511719
Eval_AverageEpLen : 305.5
Train_AverageReturn : 78.06201171875
Train_StdReturn : 122.62957000732422
Train_MaxReturn : 236.74131774902344
Train_MinReturn : -63.007240295410156
Train_AverageEpLen : 270.0
Actor Loss : -155.46673583984375
Baseline Loss : 5075.1328125
Train_EnvstepsSoFar : 654220
TimeSinceStart : 1138.5924515724182

********** Iteration 296 ************
Eval_AverageReturn : -25.160274505615234
Eval_StdReturn : 10.534069061279297
Eval_MaxReturn : -14.626205444335938
Eval_MinReturn : -35.69434356689453
Eval_AverageEpLen : 238.0
Train_AverageReturn : -16.816598892211914
Train_StdReturn : 150.29286193847656
Train_MaxReturn : 130.23487854003906
Train_MinReturn : -249.00006103515625
Train_AverageEpLen : 648.25
Actor Loss : -107.9306411743164
Baseline Loss : 1360.2872314453125
Train_EnvstepsSoFar : 656813
TimeSinceStart : 1143.1582589149475

********** Iteration 297 ************
Eval_AverageReturn : -177.57586669921875
Eval_StdReturn : 12.324134826660156
Eval_MaxReturn : -165.25172424316406
Eval_MinReturn : -189.89999389648438
Eval_AverageEpLen : 283.0
Train_AverageReturn : -47.27485275268555
Train_StdReturn : 189.8302459716797
Train_MaxReturn : 205.41888427734375
Train_MinReturn : -255.00357055664062
Train_AverageEpLen : 353.0
Actor Loss : -147.1406707763672
Baseline Loss : 4333.7705078125
Train_EnvstepsSoFar : 658931
TimeSinceStart : 1147.0117115974426

********** Iteration 298 ************
Eval_AverageReturn : -180.89443969726562
Eval_StdReturn : 19.152015686035156
Eval_MaxReturn : -161.742431640625
Eval_MinReturn : -200.0464630126953
Eval_AverageEpLen : 299.0
Train_AverageReturn : -47.87172317504883
Train_StdReturn : 203.01873779296875
Train_MaxReturn : 229.9255828857422
Train_MinReturn : -285.9617919921875
Train_AverageEpLen : 372.6666666666667
Actor Loss : -113.95614624023438
Baseline Loss : 4246.7919921875
Train_EnvstepsSoFar : 661167
TimeSinceStart : 1151.056524515152

********** Iteration 299 ************
Eval_AverageReturn : -42.26770782470703
Eval_StdReturn : 2.8994979858398438
Eval_MaxReturn : -39.36820983886719
Eval_MinReturn : -45.167205810546875
Eval_AverageEpLen : 274.5
Train_AverageReturn : -132.74172973632812
Train_StdReturn : 91.77420043945312
Train_MaxReturn : 13.523263931274414
Train_MinReturn : -231.23208618164062
Train_AverageEpLen : 261.5
Actor Loss : -341.50738525390625
Baseline Loss : 4174.07666015625
Train_EnvstepsSoFar : 663259
TimeSinceStart : 1154.311053276062

Process finished with exit code 0
