C:\My_Project\ALLEN_Python\homework_fall2023\venv\Scripts\python.exe C:\My_Project\ALLEN_Python\homework_fall2023\hw2\cs285\scripts\run_hw2.py --env_name CartPole-v0 -n 100 -b 4000 -rtg -na --exp_name cartpole_lb_rtg_na
########################
logging outputs to  C:\My_Project\ALLEN_Python\homework_fall2023\hw2\cs285\scripts\../../data\q2_pg_cartpole_lb_rtg_na_CartPole-v0_25-09-2023_20-37-33
########################
Using CPU.

********** Iteration 0 ************
C:\My_Project\ALLEN_Python\homework_fall2023\venv\lib\site-packages\gym\envs\registration.py:593: UserWarning: WARN: The environment CartPole-v0 is out of date. You should consider upgrading to version `v1`.
  logger.warn(
C:\My_Project\ALLEN_Python\homework_fall2023\venv\lib\site-packages\gym\core.py:317: DeprecationWarning: WARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.
  deprecation(
C:\My_Project\ALLEN_Python\homework_fall2023\venv\lib\site-packages\gym\wrappers\step_api_compatibility.py:39: DeprecationWarning: WARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.
  deprecation(
C:\My_Project\ALLEN_Python\homework_fall2023\venv\lib\site-packages\gym\utils\passive_env_checker.py:241: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
C:\My_Project\ALLEN_Python\homework_fall2023\venv\lib\site-packages\tensorboardX\summary.py:153: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)
  scalar = float(scalar)
Eval_AverageReturn : 33.75
Eval_StdReturn : 14.21340274810791
Eval_MaxReturn : 58.0
Eval_MinReturn : 11.0
Eval_AverageEpLen : 33.75
Train_AverageReturn : 24.16867446899414
Train_StdReturn : 13.59643840789795
Train_MaxReturn : 73.0
Train_MinReturn : 8.0
Train_AverageEpLen : 24.16867469879518
Actor Loss : -20.44350814819336
Train_EnvstepsSoFar : 4012
TimeSinceStart : 1.4837830066680908
Initial_DataCollection_AverageReturn : 24.16867446899414

********** Iteration 1 ************
Eval_AverageReturn : 42.20000076293945
Eval_StdReturn : 24.93912696838379
Eval_MaxReturn : 107.0
Eval_MinReturn : 20.0
Eval_AverageEpLen : 42.2
Train_AverageReturn : 36.090091705322266
Train_StdReturn : 21.526247024536133
Train_MaxReturn : 114.0
Train_MinReturn : 10.0
Train_AverageEpLen : 36.090090090090094
Actor Loss : -50.19940185546875
Train_EnvstepsSoFar : 8018
TimeSinceStart : 2.8925399780273438

********** Iteration 2 ************
Eval_AverageReturn : 47.22222137451172
Eval_StdReturn : 17.28697395324707
Eval_MaxReturn : 84.0
Eval_MinReturn : 28.0
Eval_AverageEpLen : 47.22222222222222
Train_AverageReturn : 45.6136360168457
Train_StdReturn : 26.28792953491211
Train_MaxReturn : 157.0
Train_MinReturn : 10.0
Train_AverageEpLen : 45.61363636363637
Actor Loss : -56.90595626831055
Train_EnvstepsSoFar : 12032
TimeSinceStart : 4.27449631690979

********** Iteration 3 ************
Eval_AverageReturn : 57.75
Eval_StdReturn : 32.2945442199707
Eval_MaxReturn : 130.0
Eval_MinReturn : 21.0
Eval_AverageEpLen : 57.75
Train_AverageReturn : 52.921051025390625
Train_StdReturn : 28.60150909423828
Train_MaxReturn : 200.0
Train_MinReturn : 12.0
Train_AverageEpLen : 52.921052631578945
Actor Loss : -26.03621482849121
Train_EnvstepsSoFar : 16054
TimeSinceStart : 5.8624279499053955

********** Iteration 4 ************
Eval_AverageReturn : 61.42856979370117
Eval_StdReturn : 20.583330154418945
Eval_MaxReturn : 94.0
Eval_MinReturn : 41.0
Eval_AverageEpLen : 61.42857142857143
Train_AverageReturn : 64.38095092773438
Train_StdReturn : 31.924230575561523
Train_MaxReturn : 200.0
Train_MinReturn : 19.0
Train_AverageEpLen : 64.38095238095238
Actor Loss : -30.63669204711914
Train_EnvstepsSoFar : 20110
TimeSinceStart : 7.2435736656188965

********** Iteration 5 ************
Eval_AverageReturn : 86.0
Eval_StdReturn : 23.1689453125
Eval_MaxReturn : 107.0
Eval_MinReturn : 45.0
Eval_AverageEpLen : 86.0
Train_AverageReturn : 73.14545440673828
Train_StdReturn : 30.68278694152832
Train_MaxReturn : 174.0
Train_MinReturn : 27.0
Train_AverageEpLen : 73.14545454545454
Actor Loss : -34.304386138916016
Train_EnvstepsSoFar : 24133
TimeSinceStart : 8.649311542510986

********** Iteration 6 ************
Eval_AverageReturn : 68.16666412353516
Eval_StdReturn : 22.872228622436523
Eval_MaxReturn : 114.0
Eval_MinReturn : 48.0
Eval_AverageEpLen : 68.16666666666667
Train_AverageReturn : 87.5
Train_StdReturn : 39.13618850708008
Train_MaxReturn : 196.0
Train_MinReturn : 33.0
Train_AverageEpLen : 87.5
Actor Loss : -48.80634307861328
Train_EnvstepsSoFar : 28158
TimeSinceStart : 10.067000150680542

********** Iteration 7 ************
Eval_AverageReturn : 148.6666717529297
Eval_StdReturn : 37.3928108215332
Eval_MaxReturn : 200.0
Eval_MinReturn : 112.0
Eval_AverageEpLen : 148.66666666666666
Train_AverageReturn : 98.1219482421875
Train_StdReturn : 42.553951263427734
Train_MaxReturn : 200.0
Train_MinReturn : 38.0
Train_AverageEpLen : 98.1219512195122
Actor Loss : -17.854942321777344
Train_EnvstepsSoFar : 32181
TimeSinceStart : 11.45263671875

********** Iteration 8 ************
Eval_AverageReturn : 147.3333282470703
Eval_StdReturn : 41.34677505493164
Eval_MaxReturn : 200.0
Eval_MinReturn : 99.0
Eval_AverageEpLen : 147.33333333333334
Train_AverageReturn : 119.0
Train_StdReturn : 40.21632766723633
Train_MaxReturn : 200.0
Train_MinReturn : 43.0
Train_AverageEpLen : 119.0
Actor Loss : -64.38955688476562
Train_EnvstepsSoFar : 36227
TimeSinceStart : 12.856259107589722

********** Iteration 9 ************
Eval_AverageReturn : 175.0
Eval_StdReturn : 17.795129776000977
Eval_MaxReturn : 200.0
Eval_MinReturn : 160.0
Eval_AverageEpLen : 175.0
Train_AverageReturn : 139.10345458984375
Train_StdReturn : 43.18073272705078
Train_MaxReturn : 200.0
Train_MinReturn : 56.0
Train_AverageEpLen : 139.10344827586206
Actor Loss : -34.63597106933594
Train_EnvstepsSoFar : 40261
TimeSinceStart : 14.21481966972351

********** Iteration 10 ************
Eval_AverageReturn : 155.0
Eval_StdReturn : 32.1351318359375
Eval_MaxReturn : 200.0
Eval_MinReturn : 127.0
Eval_AverageEpLen : 155.0
Train_AverageReturn : 156.11538696289062
Train_StdReturn : 32.96306228637695
Train_MaxReturn : 200.0
Train_MinReturn : 103.0
Train_AverageEpLen : 156.1153846153846
Actor Loss : -12.352989196777344
Train_EnvstepsSoFar : 44320
TimeSinceStart : 15.61560606956482

********** Iteration 11 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 171.125
Train_StdReturn : 30.673431396484375
Train_MaxReturn : 200.0
Train_MinReturn : 75.0
Train_AverageEpLen : 171.125
Actor Loss : 2.5186281204223633
Train_EnvstepsSoFar : 48427
TimeSinceStart : 16.971648693084717

********** Iteration 12 ************
Eval_AverageReturn : 172.0
Eval_StdReturn : 26.191600799560547
Eval_MaxReturn : 200.0
Eval_MinReturn : 137.0
Eval_AverageEpLen : 172.0
Train_AverageReturn : 167.6666717529297
Train_StdReturn : 28.490737915039062
Train_MaxReturn : 200.0
Train_MinReturn : 114.0
Train_AverageEpLen : 167.66666666666666
Actor Loss : -44.27157211303711
Train_EnvstepsSoFar : 52451
TimeSinceStart : 18.35708451271057

********** Iteration 13 ************
Eval_AverageReturn : 163.3333282470703
Eval_StdReturn : 25.978622436523438
Eval_MaxReturn : 200.0
Eval_MinReturn : 143.0
Eval_AverageEpLen : 163.33333333333334
Train_AverageReturn : 165.9199981689453
Train_StdReturn : 34.66170120239258
Train_MaxReturn : 200.0
Train_MinReturn : 61.0
Train_AverageEpLen : 165.92
Actor Loss : -85.64268493652344
Train_EnvstepsSoFar : 56599
TimeSinceStart : 19.748772382736206

********** Iteration 14 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 170.4166717529297
Train_StdReturn : 29.49705696105957
Train_MaxReturn : 200.0
Train_MinReturn : 114.0
Train_AverageEpLen : 170.41666666666666
Actor Loss : -69.36670684814453
Train_EnvstepsSoFar : 60689
TimeSinceStart : 21.11882519721985

********** Iteration 15 ************
Eval_AverageReturn : 194.6666717529297
Eval_StdReturn : 7.542471885681152
Eval_MaxReturn : 200.0
Eval_MinReturn : 184.0
Eval_AverageEpLen : 194.66666666666666
Train_AverageReturn : 186.0
Train_StdReturn : 26.679920196533203
Train_MaxReturn : 200.0
Train_MinReturn : 110.0
Train_AverageEpLen : 186.0
Actor Loss : -65.16111755371094
Train_EnvstepsSoFar : 64781
TimeSinceStart : 22.587026119232178

********** Iteration 16 ************
Eval_AverageReturn : 178.6666717529297
Eval_StdReturn : 30.16988754272461
Eval_MaxReturn : 200.0
Eval_MinReturn : 136.0
Eval_AverageEpLen : 178.66666666666666
Train_AverageReturn : 188.0
Train_StdReturn : 22.360679626464844
Train_MaxReturn : 200.0
Train_MinReturn : 133.0
Train_AverageEpLen : 188.0
Actor Loss : -27.65667724609375
Train_EnvstepsSoFar : 68917
TimeSinceStart : 24.018840312957764

********** Iteration 17 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -40.21466064453125
Train_EnvstepsSoFar : 72917
TimeSinceStart : 25.496891260147095

********** Iteration 18 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 195.3333282470703
Train_StdReturn : 18.36490821838379
Train_MaxReturn : 200.0
Train_MinReturn : 114.0
Train_AverageEpLen : 195.33333333333334
Actor Loss : -41.70266342163086
Train_EnvstepsSoFar : 77019
TimeSinceStart : 26.963802099227905

********** Iteration 19 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -48.42236328125
Train_EnvstepsSoFar : 81019
TimeSinceStart : 28.364694356918335

********** Iteration 20 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 198.38095092773438
Train_StdReturn : 7.240601539611816
Train_MaxReturn : 200.0
Train_MinReturn : 166.0
Train_AverageEpLen : 198.38095238095238
Actor Loss : -18.711458206176758
Train_EnvstepsSoFar : 85185
TimeSinceStart : 29.85739278793335

********** Iteration 21 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -18.990936279296875
Train_EnvstepsSoFar : 89185
TimeSinceStart : 31.241766929626465

********** Iteration 22 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 7.498579025268555
Train_EnvstepsSoFar : 93185
TimeSinceStart : 32.61768388748169

********** Iteration 23 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -63.70891571044922
Train_EnvstepsSoFar : 97185
TimeSinceStart : 33.92641520500183

********** Iteration 24 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -33.49799346923828
Train_EnvstepsSoFar : 101185
TimeSinceStart : 35.258429765701294

********** Iteration 25 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -49.447898864746094
Train_EnvstepsSoFar : 105185
TimeSinceStart : 36.6386559009552

********** Iteration 26 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -86.9019775390625
Train_EnvstepsSoFar : 109185
TimeSinceStart : 37.97925901412964

********** Iteration 27 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -43.14361572265625
Train_EnvstepsSoFar : 113185
TimeSinceStart : 39.33784365653992

********** Iteration 28 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -76.434326171875
Train_EnvstepsSoFar : 117185
TimeSinceStart : 40.64337873458862

********** Iteration 29 ************
Eval_AverageReturn : 182.3333282470703
Eval_StdReturn : 6.599663257598877
Eval_MaxReturn : 191.0
Eval_MinReturn : 175.0
Eval_AverageEpLen : 182.33333333333334
Train_AverageReturn : 195.2857208251953
Train_StdReturn : 7.323432922363281
Train_MaxReturn : 200.0
Train_MinReturn : 181.0
Train_AverageEpLen : 195.28571428571428
Actor Loss : -101.09744262695312
Train_EnvstepsSoFar : 121286
TimeSinceStart : 42.09426784515381

********** Iteration 30 ************
Eval_AverageReturn : 165.0
Eval_StdReturn : 4.320493698120117
Eval_MaxReturn : 171.0
Eval_MinReturn : 161.0
Eval_AverageEpLen : 165.0
Train_AverageReturn : 178.6086883544922
Train_StdReturn : 15.689208030700684
Train_MaxReturn : 200.0
Train_MinReturn : 147.0
Train_AverageEpLen : 178.6086956521739
Actor Loss : -108.01353454589844
Train_EnvstepsSoFar : 125394
TimeSinceStart : 43.51973915100098

********** Iteration 31 ************
Eval_AverageReturn : 166.6666717529297
Eval_StdReturn : 6.6499786376953125
Eval_MaxReturn : 176.0
Eval_MinReturn : 161.0
Eval_AverageEpLen : 166.66666666666666
Train_AverageReturn : 174.17391967773438
Train_StdReturn : 12.408454895019531
Train_MaxReturn : 197.0
Train_MinReturn : 145.0
Train_AverageEpLen : 174.17391304347825
Actor Loss : -115.16047668457031
Train_EnvstepsSoFar : 129400
TimeSinceStart : 44.87054085731506

********** Iteration 32 ************
Eval_AverageReturn : 158.3333282470703
Eval_StdReturn : 8.653837203979492
Eval_MaxReturn : 168.0
Eval_MinReturn : 147.0
Eval_AverageEpLen : 158.33333333333334
Train_AverageReturn : 159.46153259277344
Train_StdReturn : 10.419032096862793
Train_MaxReturn : 174.0
Train_MinReturn : 134.0
Train_AverageEpLen : 159.46153846153845
Actor Loss : -112.76904296875
Train_EnvstepsSoFar : 133546
TimeSinceStart : 46.31532144546509

********** Iteration 33 ************
Eval_AverageReturn : 154.3333282470703
Eval_StdReturn : 9.672412872314453
Eval_MaxReturn : 168.0
Eval_MinReturn : 147.0
Eval_AverageEpLen : 154.33333333333334
Train_AverageReturn : 168.2083282470703
Train_StdReturn : 8.286430358886719
Train_MaxReturn : 184.0
Train_MinReturn : 151.0
Train_AverageEpLen : 168.20833333333334
Actor Loss : -113.02287292480469
Train_EnvstepsSoFar : 137583
TimeSinceStart : 47.685425996780396

********** Iteration 34 ************
Eval_AverageReturn : 180.0
Eval_StdReturn : 7.874007701873779
Eval_MaxReturn : 187.0
Eval_MinReturn : 169.0
Eval_AverageEpLen : 180.0
Train_AverageReturn : 159.5
Train_StdReturn : 11.004369735717773
Train_MaxReturn : 186.0
Train_MinReturn : 141.0
Train_AverageEpLen : 159.5
Actor Loss : -104.84332275390625
Train_EnvstepsSoFar : 141730
TimeSinceStart : 49.089810371398926

********** Iteration 35 ************
Eval_AverageReturn : 170.6666717529297
Eval_StdReturn : 8.730534553527832
Eval_MaxReturn : 183.0
Eval_MinReturn : 164.0
Eval_AverageEpLen : 170.66666666666666
Train_AverageReturn : 166.6666717529297
Train_StdReturn : 12.064640998840332
Train_MaxReturn : 193.0
Train_MinReturn : 141.0
Train_AverageEpLen : 166.66666666666666
Actor Loss : -91.73336791992188
Train_EnvstepsSoFar : 145730
TimeSinceStart : 50.49044466018677

********** Iteration 36 ************
Eval_AverageReturn : 159.3333282470703
Eval_StdReturn : 4.109609127044678
Eval_MaxReturn : 164.0
Eval_MinReturn : 154.0
Eval_AverageEpLen : 159.33333333333334
Train_AverageReturn : 166.9199981689453
Train_StdReturn : 11.706134796142578
Train_MaxReturn : 188.0
Train_MinReturn : 146.0
Train_AverageEpLen : 166.92
Actor Loss : -112.30988311767578
Train_EnvstepsSoFar : 149903
TimeSinceStart : 51.94288921356201

********** Iteration 37 ************
Eval_AverageReturn : 179.0
Eval_StdReturn : 9.201449394226074
Eval_MaxReturn : 186.0
Eval_MinReturn : 166.0
Eval_AverageEpLen : 179.0
Train_AverageReturn : 170.625
Train_StdReturn : 10.315088272094727
Train_MaxReturn : 195.0
Train_MinReturn : 152.0
Train_AverageEpLen : 170.625
Actor Loss : -119.14960479736328
Train_EnvstepsSoFar : 153998
TimeSinceStart : 53.4162015914917

********** Iteration 38 ************
Eval_AverageReturn : 191.0
Eval_StdReturn : 7.788880825042725
Eval_MaxReturn : 200.0
Eval_MinReturn : 181.0
Eval_AverageEpLen : 191.0
Train_AverageReturn : 181.13043212890625
Train_StdReturn : 11.997479438781738
Train_MaxReturn : 200.0
Train_MinReturn : 152.0
Train_AverageEpLen : 181.1304347826087
Actor Loss : -77.57149505615234
Train_EnvstepsSoFar : 158164
TimeSinceStart : 54.89691781997681

********** Iteration 39 ************
Eval_AverageReturn : 196.6666717529297
Eval_StdReturn : 3.399346113204956
Eval_MaxReturn : 200.0
Eval_MinReturn : 192.0
Eval_AverageEpLen : 196.66666666666666
Train_AverageReturn : 189.18182373046875
Train_StdReturn : 10.965385437011719
Train_MaxReturn : 200.0
Train_MinReturn : 168.0
Train_AverageEpLen : 189.1818181818182
Actor Loss : -90.21946716308594
Train_EnvstepsSoFar : 162326
TimeSinceStart : 56.37787342071533

********** Iteration 40 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 197.23809814453125
Train_StdReturn : 4.965641975402832
Train_MaxReturn : 200.0
Train_MinReturn : 183.0
Train_AverageEpLen : 197.23809523809524
Actor Loss : -35.78548049926758
Train_EnvstepsSoFar : 166468
TimeSinceStart : 57.94388151168823

********** Iteration 41 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 199.14285278320312
Train_StdReturn : 2.4935290813446045
Train_MaxReturn : 200.0
Train_MinReturn : 191.0
Train_AverageEpLen : 199.14285714285714
Actor Loss : -105.50222778320312
Train_EnvstepsSoFar : 170650
TimeSinceStart : 59.41060996055603

********** Iteration 42 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 196.14285278320312
Train_StdReturn : 6.577636241912842
Train_MaxReturn : 200.0
Train_MinReturn : 175.0
Train_AverageEpLen : 196.14285714285714
Actor Loss : -76.27758026123047
Train_EnvstepsSoFar : 174769
TimeSinceStart : 60.78792691230774

********** Iteration 43 ************
Eval_AverageReturn : 184.6666717529297
Eval_StdReturn : 11.585432052612305
Eval_MaxReturn : 200.0
Eval_MinReturn : 172.0
Eval_AverageEpLen : 184.66666666666666
Train_AverageReturn : 193.61904907226562
Train_StdReturn : 8.665619850158691
Train_MaxReturn : 200.0
Train_MinReturn : 174.0
Train_AverageEpLen : 193.61904761904762
Actor Loss : -76.5169677734375
Train_EnvstepsSoFar : 178835
TimeSinceStart : 62.307525873184204

********** Iteration 44 ************
Eval_AverageReturn : 179.6666717529297
Eval_StdReturn : 13.224556922912598
Eval_MaxReturn : 190.0
Eval_MinReturn : 161.0
Eval_AverageEpLen : 179.66666666666666
Train_AverageReturn : 185.72727966308594
Train_StdReturn : 10.050698280334473
Train_MaxReturn : 200.0
Train_MinReturn : 165.0
Train_AverageEpLen : 185.72727272727272
Actor Loss : -85.8178482055664
Train_EnvstepsSoFar : 182921
TimeSinceStart : 63.712228298187256

********** Iteration 45 ************
Eval_AverageReturn : 170.6666717529297
Eval_StdReturn : 6.9442219734191895
Eval_MaxReturn : 177.0
Eval_MinReturn : 161.0
Eval_AverageEpLen : 170.66666666666666
Train_AverageReturn : 179.78260803222656
Train_StdReturn : 13.210524559020996
Train_MaxReturn : 200.0
Train_MinReturn : 152.0
Train_AverageEpLen : 179.7826086956522
Actor Loss : -66.55393981933594
Train_EnvstepsSoFar : 187056
TimeSinceStart : 65.29702043533325

********** Iteration 46 ************
Eval_AverageReturn : 169.0
Eval_StdReturn : 10.198039054870605
Eval_MaxReturn : 179.0
Eval_MinReturn : 155.0
Eval_AverageEpLen : 169.0
Train_AverageReturn : 173.9583282470703
Train_StdReturn : 14.336664199829102
Train_MaxReturn : 200.0
Train_MinReturn : 146.0
Train_AverageEpLen : 173.95833333333334
Actor Loss : -100.77789306640625
Train_EnvstepsSoFar : 191231
TimeSinceStart : 66.75319051742554

********** Iteration 47 ************
Eval_AverageReturn : 183.3333282470703
Eval_StdReturn : 12.47219181060791
Eval_MaxReturn : 200.0
Eval_MinReturn : 170.0
Eval_AverageEpLen : 183.33333333333334
Train_AverageReturn : 177.43478393554688
Train_StdReturn : 14.358230590820312
Train_MaxReturn : 200.0
Train_MinReturn : 156.0
Train_AverageEpLen : 177.43478260869566
Actor Loss : -91.85220336914062
Train_EnvstepsSoFar : 195312
TimeSinceStart : 68.37041568756104

********** Iteration 48 ************
Eval_AverageReturn : 177.3333282470703
Eval_StdReturn : 11.085526466369629
Eval_MaxReturn : 193.0
Eval_MinReturn : 169.0
Eval_AverageEpLen : 177.33333333333334
Train_AverageReturn : 180.7391357421875
Train_StdReturn : 13.657988548278809
Train_MaxReturn : 200.0
Train_MinReturn : 155.0
Train_AverageEpLen : 180.7391304347826
Actor Loss : -43.854549407958984
Train_EnvstepsSoFar : 199469
TimeSinceStart : 69.86913204193115

********** Iteration 49 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 183.86363220214844
Train_StdReturn : 11.165267944335938
Train_MaxReturn : 200.0
Train_MinReturn : 163.0
Train_AverageEpLen : 183.86363636363637
Actor Loss : -104.8836669921875
Train_EnvstepsSoFar : 203514
TimeSinceStart : 71.55507063865662

********** Iteration 50 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 192.5238037109375
Train_StdReturn : 10.913596153259277
Train_MaxReturn : 200.0
Train_MinReturn : 167.0
Train_AverageEpLen : 192.52380952380952
Actor Loss : -52.66964340209961
Train_EnvstepsSoFar : 207557
TimeSinceStart : 72.95098567008972

********** Iteration 51 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 198.95237731933594
Train_StdReturn : 4.466554641723633
Train_MaxReturn : 200.0
Train_MinReturn : 179.0
Train_AverageEpLen : 198.95238095238096
Actor Loss : -29.434555053710938
Train_EnvstepsSoFar : 211735
TimeSinceStart : 74.40183234214783

********** Iteration 52 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 199.2857208251953
Train_StdReturn : 3.194382667541504
Train_MaxReturn : 200.0
Train_MinReturn : 185.0
Train_AverageEpLen : 199.28571428571428
Actor Loss : -41.106773376464844
Train_EnvstepsSoFar : 215920
TimeSinceStart : 75.99406623840332

********** Iteration 53 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 27.879079818725586
Train_EnvstepsSoFar : 219920
TimeSinceStart : 77.33993029594421

********** Iteration 54 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 198.7142791748047
Train_StdReturn : 3.7434749603271484
Train_MaxReturn : 200.0
Train_MinReturn : 185.0
Train_AverageEpLen : 198.71428571428572
Actor Loss : -11.050291061401367
Train_EnvstepsSoFar : 224093
TimeSinceStart : 78.89172077178955

********** Iteration 55 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -27.501014709472656
Train_EnvstepsSoFar : 228093
TimeSinceStart : 80.26572036743164

********** Iteration 56 ************
Eval_AverageReturn : 190.6666717529297
Eval_StdReturn : 11.145503044128418
Eval_MaxReturn : 200.0
Eval_MinReturn : 175.0
Eval_AverageEpLen : 190.66666666666666
Train_AverageReturn : 197.90475463867188
Train_StdReturn : 5.878976821899414
Train_MaxReturn : 200.0
Train_MinReturn : 176.0
Train_AverageEpLen : 197.9047619047619
Actor Loss : -47.11626434326172
Train_EnvstepsSoFar : 232249
TimeSinceStart : 81.94363641738892

********** Iteration 57 ************
Eval_AverageReturn : 198.6666717529297
Eval_StdReturn : 1.8856180906295776
Eval_MaxReturn : 200.0
Eval_MinReturn : 196.0
Eval_AverageEpLen : 198.66666666666666
Train_AverageReturn : 199.0
Train_StdReturn : 4.4721360206604
Train_MaxReturn : 200.0
Train_MinReturn : 179.0
Train_AverageEpLen : 199.0
Actor Loss : -68.01232147216797
Train_EnvstepsSoFar : 236428
TimeSinceStart : 83.47940802574158

********** Iteration 58 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 198.23809814453125
Train_StdReturn : 6.661222457885742
Train_MaxReturn : 200.0
Train_MinReturn : 169.0
Train_AverageEpLen : 198.23809523809524
Actor Loss : -7.457500457763672
Train_EnvstepsSoFar : 240591
TimeSinceStart : 84.93445181846619

********** Iteration 59 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 196.95237731933594
Train_StdReturn : 6.778651237487793
Train_MaxReturn : 200.0
Train_MinReturn : 174.0
Train_AverageEpLen : 196.95238095238096
Actor Loss : -17.962505340576172
Train_EnvstepsSoFar : 244727
TimeSinceStart : 86.33482384681702

********** Iteration 60 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 198.61904907226562
Train_StdReturn : 4.391291618347168
Train_MaxReturn : 200.0
Train_MinReturn : 182.0
Train_AverageEpLen : 198.61904761904762
Actor Loss : -66.02915954589844
Train_EnvstepsSoFar : 248898
TimeSinceStart : 87.69419169425964

********** Iteration 61 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -41.68830871582031
Train_EnvstepsSoFar : 252898
TimeSinceStart : 89.0635871887207

********** Iteration 62 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 199.3333282470703
Train_StdReturn : 2.98142409324646
Train_MaxReturn : 200.0
Train_MinReturn : 186.0
Train_AverageEpLen : 199.33333333333334
Actor Loss : -12.892663955688477
Train_EnvstepsSoFar : 257084
TimeSinceStart : 90.51048159599304

********** Iteration 63 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 199.6666717529297
Train_StdReturn : 1.4907118082046509
Train_MaxReturn : 200.0
Train_MinReturn : 193.0
Train_AverageEpLen : 199.66666666666666
Actor Loss : -6.324845314025879
Train_EnvstepsSoFar : 261277
TimeSinceStart : 91.8660659790039

********** Iteration 64 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 199.09524536132812
Train_StdReturn : 3.0222158432006836
Train_MaxReturn : 200.0
Train_MinReturn : 186.0
Train_AverageEpLen : 199.0952380952381
Actor Loss : -29.486862182617188
Train_EnvstepsSoFar : 265458
TimeSinceStart : 93.266530752182

********** Iteration 65 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 199.2857208251953
Train_StdReturn : 2.4522652626037598
Train_MaxReturn : 200.0
Train_MinReturn : 189.0
Train_AverageEpLen : 199.28571428571428
Actor Loss : -59.69501876831055
Train_EnvstepsSoFar : 269643
TimeSinceStart : 94.68735408782959

********** Iteration 66 ************
Eval_AverageReturn : 195.3333282470703
Eval_StdReturn : 5.906681537628174
Eval_MaxReturn : 200.0
Eval_MinReturn : 187.0
Eval_AverageEpLen : 195.33333333333334
Train_AverageReturn : 193.14285278320312
Train_StdReturn : 7.466022968292236
Train_MaxReturn : 200.0
Train_MinReturn : 176.0
Train_AverageEpLen : 193.14285714285714
Actor Loss : -35.318748474121094
Train_EnvstepsSoFar : 273699
TimeSinceStart : 96.14977622032166

********** Iteration 67 ************
Eval_AverageReturn : 181.3333282470703
Eval_StdReturn : 14.727148056030273
Eval_MaxReturn : 200.0
Eval_MinReturn : 164.0
Eval_AverageEpLen : 181.33333333333334
Train_AverageReturn : 187.59091186523438
Train_StdReturn : 11.937941551208496
Train_MaxReturn : 200.0
Train_MinReturn : 163.0
Train_AverageEpLen : 187.5909090909091
Actor Loss : -57.941551208496094
Train_EnvstepsSoFar : 277826
TimeSinceStart : 97.643807888031

********** Iteration 68 ************
Eval_AverageReturn : 191.0
Eval_StdReturn : 12.727922439575195
Eval_MaxReturn : 200.0
Eval_MinReturn : 173.0
Eval_AverageEpLen : 191.0
Train_AverageReturn : 186.5
Train_StdReturn : 14.730148315429688
Train_MaxReturn : 200.0
Train_MinReturn : 163.0
Train_AverageEpLen : 186.5
Actor Loss : -79.44764709472656
Train_EnvstepsSoFar : 281929
TimeSinceStart : 99.05933785438538

********** Iteration 69 ************
Eval_AverageReturn : 170.0
Eval_StdReturn : 12.83225154876709
Eval_MaxReturn : 184.0
Eval_MinReturn : 153.0
Eval_AverageEpLen : 170.0
Train_AverageReturn : 182.86363220214844
Train_StdReturn : 14.7472505569458
Train_MaxReturn : 200.0
Train_MinReturn : 155.0
Train_AverageEpLen : 182.86363636363637
Actor Loss : -56.0843391418457
Train_EnvstepsSoFar : 285952
TimeSinceStart : 100.39280343055725

********** Iteration 70 ************
Eval_AverageReturn : 167.3333282470703
Eval_StdReturn : 7.039570331573486
Eval_MaxReturn : 175.0
Eval_MinReturn : 158.0
Eval_AverageEpLen : 167.33333333333334
Train_AverageReturn : 177.6086883544922
Train_StdReturn : 13.560617446899414
Train_MaxReturn : 200.0
Train_MinReturn : 154.0
Train_AverageEpLen : 177.6086956521739
Actor Loss : -43.22577667236328
Train_EnvstepsSoFar : 290037
TimeSinceStart : 101.80555272102356

********** Iteration 71 ************
Eval_AverageReturn : 160.0
Eval_StdReturn : 17.66352081298828
Eval_MaxReturn : 184.0
Eval_MinReturn : 142.0
Eval_AverageEpLen : 160.0
Train_AverageReturn : 174.04347229003906
Train_StdReturn : 15.596761703491211
Train_MaxReturn : 200.0
Train_MinReturn : 151.0
Train_AverageEpLen : 174.04347826086956
Actor Loss : -58.79120635986328
Train_EnvstepsSoFar : 294040
TimeSinceStart : 103.1609103679657

********** Iteration 72 ************
Eval_AverageReturn : 162.0
Eval_StdReturn : 16.872066497802734
Eval_MaxReturn : 185.0
Eval_MinReturn : 145.0
Eval_AverageEpLen : 162.0
Train_AverageReturn : 168.9583282470703
Train_StdReturn : 13.618245124816895
Train_MaxReturn : 200.0
Train_MinReturn : 143.0
Train_AverageEpLen : 168.95833333333334
Actor Loss : -75.49470520019531
Train_EnvstepsSoFar : 298095
TimeSinceStart : 104.50084900856018

********** Iteration 73 ************
Eval_AverageReturn : 180.6666717529297
Eval_StdReturn : 2.8674418926239014
Eval_MaxReturn : 184.0
Eval_MinReturn : 177.0
Eval_AverageEpLen : 180.66666666666666
Train_AverageReturn : 162.9199981689453
Train_StdReturn : 10.965108871459961
Train_MaxReturn : 190.0
Train_MinReturn : 140.0
Train_AverageEpLen : 162.92
Actor Loss : -116.7105484008789
Train_EnvstepsSoFar : 302168
TimeSinceStart : 105.94719672203064

********** Iteration 74 ************
Eval_AverageReturn : 188.3333282470703
Eval_StdReturn : 7.542471885681152
Eval_MaxReturn : 199.0
Eval_MinReturn : 183.0
Eval_AverageEpLen : 188.33333333333334
Train_AverageReturn : 174.52174377441406
Train_StdReturn : 14.033716201782227
Train_MaxReturn : 200.0
Train_MinReturn : 150.0
Train_AverageEpLen : 174.52173913043478
Actor Loss : -57.6607666015625
Train_EnvstepsSoFar : 306182
TimeSinceStart : 107.45650029182434

********** Iteration 75 ************
Eval_AverageReturn : 188.3333282470703
Eval_StdReturn : 10.27402400970459
Eval_MaxReturn : 200.0
Eval_MinReturn : 175.0
Eval_AverageEpLen : 188.33333333333334
Train_AverageReturn : 184.77272033691406
Train_StdReturn : 13.04165267944336
Train_MaxReturn : 200.0
Train_MinReturn : 159.0
Train_AverageEpLen : 184.77272727272728
Actor Loss : -96.34785461425781
Train_EnvstepsSoFar : 310247
TimeSinceStart : 109.08432602882385

********** Iteration 76 ************
Eval_AverageReturn : 192.3333282470703
Eval_StdReturn : 8.178563117980957
Eval_MaxReturn : 200.0
Eval_MinReturn : 181.0
Eval_AverageEpLen : 192.33333333333334
Train_AverageReturn : 187.0454559326172
Train_StdReturn : 14.05663013458252
Train_MaxReturn : 200.0
Train_MinReturn : 164.0
Train_AverageEpLen : 187.04545454545453
Actor Loss : -76.71510314941406
Train_EnvstepsSoFar : 314362
TimeSinceStart : 110.59562110900879

********** Iteration 77 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 197.6666717529297
Train_StdReturn : 5.02691125869751
Train_MaxReturn : 200.0
Train_MinReturn : 184.0
Train_AverageEpLen : 197.66666666666666
Actor Loss : -27.727697372436523
Train_EnvstepsSoFar : 318513
TimeSinceStart : 111.99711036682129

********** Iteration 78 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -29.39501190185547
Train_EnvstepsSoFar : 322513
TimeSinceStart : 113.34267091751099

********** Iteration 79 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -8.406923294067383
Train_EnvstepsSoFar : 326513
TimeSinceStart : 114.65317726135254

********** Iteration 80 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 14.368743896484375
Train_EnvstepsSoFar : 330513
TimeSinceStart : 116.06279706954956

********** Iteration 81 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -25.66946029663086
Train_EnvstepsSoFar : 334513
TimeSinceStart : 117.42857623100281

********** Iteration 82 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -70.3206787109375
Train_EnvstepsSoFar : 338513
TimeSinceStart : 118.77679204940796

********** Iteration 83 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -40.042877197265625
Train_EnvstepsSoFar : 342513
TimeSinceStart : 120.11285209655762

********** Iteration 84 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -69.62171936035156
Train_EnvstepsSoFar : 346513
TimeSinceStart : 121.41769361495972

********** Iteration 85 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -25.06314468383789
Train_EnvstepsSoFar : 350513
TimeSinceStart : 122.73317670822144

********** Iteration 86 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -59.767127990722656
Train_EnvstepsSoFar : 354513
TimeSinceStart : 124.04624104499817

********** Iteration 87 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -71.92204284667969
Train_EnvstepsSoFar : 358513
TimeSinceStart : 125.35744190216064

********** Iteration 88 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -1.1059858798980713
Train_EnvstepsSoFar : 362513
TimeSinceStart : 126.61782503128052

********** Iteration 89 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -14.69897747039795
Train_EnvstepsSoFar : 366513
TimeSinceStart : 127.95963835716248

********** Iteration 90 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 3.4586896896362305
Train_EnvstepsSoFar : 370513
TimeSinceStart : 129.3241183757782

********** Iteration 91 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 4.369742393493652
Train_EnvstepsSoFar : 374513
TimeSinceStart : 130.70522022247314

********** Iteration 92 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 11.317222595214844
Train_EnvstepsSoFar : 378513
TimeSinceStart : 132.04846048355103

********** Iteration 93 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 27.04658317565918
Train_EnvstepsSoFar : 382513
TimeSinceStart : 133.34954643249512

********** Iteration 94 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -59.44721221923828
Train_EnvstepsSoFar : 386513
TimeSinceStart : 134.71316599845886

********** Iteration 95 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -24.79283332824707
Train_EnvstepsSoFar : 390513
TimeSinceStart : 135.964120388031

********** Iteration 96 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : -18.781545639038086
Train_EnvstepsSoFar : 394513
TimeSinceStart : 137.18863773345947

********** Iteration 97 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 5.015036582946777
Train_EnvstepsSoFar : 398513
TimeSinceStart : 138.38803243637085

********** Iteration 98 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 19.398521423339844
Train_EnvstepsSoFar : 402513
TimeSinceStart : 139.57480454444885

********** Iteration 99 ************
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 5.248437881469727
Train_EnvstepsSoFar : 406513
TimeSinceStart : 140.7528371810913

Process finished with exit code 0
