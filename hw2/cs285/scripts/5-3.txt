C:\My_Project\ALLEN_Python\homework_fall2023\venv\Scripts\python.exe C:\My_Project\ALLEN_Python\homework_fall2023\hw2\cs285\scripts\run_hw2.py --env_name LunarLander-v2 --ep_len 1000 --discount 0.99 -n 300 -l 3 -s 128 -b 2000 -lr 0.001 --use_reward_to_go --use_baseline --gae_lambda 0.98 --exp_name lunar_lander_lambda0_98
########################
logging outputs to  C:\My_Project\ALLEN_Python\homework_fall2023\hw2\cs285\scripts\../../data\q2_pg_lunar_lander_lambda0_98_LunarLander-v2_25-09-2023_22-13-15
########################
Using CPU.
C:\My_Project\ALLEN_Python\homework_fall2023\venv\lib\site-packages\gym\core.py:317: DeprecationWarning: WARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.
  deprecation(
C:\My_Project\ALLEN_Python\homework_fall2023\venv\lib\site-packages\gym\wrappers\step_api_compatibility.py:39: DeprecationWarning: WARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.
  deprecation(
C:\My_Project\ALLEN_Python\homework_fall2023\venv\lib\site-packages\gym\utils\passive_env_checker.py:241: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):

********** Iteration 0 ************
C:\My_Project\ALLEN_Python\homework_fall2023\venv\lib\site-packages\tensorboardX\summary.py:153: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)
  scalar = float(scalar)
Eval_AverageReturn : -98.4168930053711
Eval_StdReturn : 14.66117000579834
Eval_MaxReturn : -78.13700866699219
Eval_MinReturn : -119.57392120361328
Eval_AverageEpLen : 81.4
Train_AverageReturn : -209.69676208496094
Train_StdReturn : 114.51374053955078
Train_MaxReturn : -14.993850708007812
Train_MinReturn : -432.10247802734375
Train_AverageEpLen : 88.78260869565217
Actor Loss : -182696.6875
Baseline Loss : 16341.009765625
Train_EnvstepsSoFar : 2042
TimeSinceStart : 1.5925898551940918
Initial_DataCollection_AverageReturn : -209.69676208496094

********** Iteration 1 ************
Eval_AverageReturn : -160.28115844726562
Eval_StdReturn : 46.923065185546875
Eval_MaxReturn : -107.7557373046875
Eval_MinReturn : -240.69424438476562
Eval_AverageEpLen : 96.6
Train_AverageReturn : -171.76846313476562
Train_StdReturn : 97.88479614257812
Train_MaxReturn : -19.95714569091797
Train_MinReturn : -385.1612243652344
Train_AverageEpLen : 87.69565217391305
Actor Loss : -135932.765625
Baseline Loss : 10042.3701171875
Train_EnvstepsSoFar : 4059
TimeSinceStart : 3.2244553565979004

********** Iteration 2 ************
Eval_AverageReturn : -241.02389526367188
Eval_StdReturn : 73.82386016845703
Eval_MaxReturn : -122.83683013916016
Eval_MinReturn : -326.42901611328125
Eval_AverageEpLen : 101.25
Train_AverageReturn : -148.01145935058594
Train_StdReturn : 66.26611328125
Train_MaxReturn : -68.37564849853516
Train_MinReturn : -334.1595764160156
Train_AverageEpLen : 94.5
Actor Loss : -110779.375
Baseline Loss : 6422.7177734375
Train_EnvstepsSoFar : 6138
TimeSinceStart : 5.530517339706421

********** Iteration 3 ************
Eval_AverageReturn : -162.07949829101562
Eval_StdReturn : 65.109619140625
Eval_MaxReturn : -103.47122192382812
Eval_MinReturn : -270.1067810058594
Eval_AverageEpLen : 103.5
Train_AverageReturn : -151.58192443847656
Train_StdReturn : 78.4422378540039
Train_MaxReturn : -65.75276184082031
Train_MinReturn : -351.5851135253906
Train_AverageEpLen : 93.0
Actor Loss : -105357.328125
Baseline Loss : 6556.2939453125
Train_EnvstepsSoFar : 8184
TimeSinceStart : 7.864087820053101

********** Iteration 4 ************
Eval_AverageReturn : -121.393310546875
Eval_StdReturn : 38.24809646606445
Eval_MaxReturn : -67.77656555175781
Eval_MinReturn : -160.03775024414062
Eval_AverageEpLen : 86.6
Train_AverageReturn : -140.2225799560547
Train_StdReturn : 51.89239501953125
Train_MaxReturn : -60.916996002197266
Train_MinReturn : -265.3135681152344
Train_AverageEpLen : 87.45833333333333
Actor Loss : -101401.765625
Baseline Loss : 4919.9931640625
Train_EnvstepsSoFar : 10283
TimeSinceStart : 10.180139303207397

********** Iteration 5 ************
Eval_AverageReturn : -172.70840454101562
Eval_StdReturn : 80.6700668334961
Eval_MaxReturn : -115.43968200683594
Eval_MinReturn : -311.6602783203125
Eval_AverageEpLen : 101.5
Train_AverageReturn : -163.6552276611328
Train_StdReturn : 68.89925384521484
Train_MaxReturn : -75.62548828125
Train_MinReturn : -365.31060791015625
Train_AverageEpLen : 98.9047619047619
Actor Loss : -99164.2109375
Baseline Loss : 5431.3662109375
Train_EnvstepsSoFar : 12360
TimeSinceStart : 12.379671096801758

********** Iteration 6 ************
Eval_AverageReturn : -131.1268768310547
Eval_StdReturn : 87.51502990722656
Eval_MaxReturn : -71.40813446044922
Eval_MinReturn : -305.1214294433594
Eval_AverageEpLen : 89.0
Train_AverageReturn : -142.54270935058594
Train_StdReturn : 70.33001708984375
Train_MaxReturn : -77.44510650634766
Train_MinReturn : -375.18048095703125
Train_AverageEpLen : 99.28571428571429
Actor Loss : -80223.0390625
Baseline Loss : 4165.3974609375
Train_EnvstepsSoFar : 14445
TimeSinceStart : 14.684890031814575

********** Iteration 7 ************
Eval_AverageReturn : -153.45851135253906
Eval_StdReturn : 88.859619140625
Eval_MaxReturn : -68.88961791992188
Eval_MinReturn : -313.36883544921875
Eval_AverageEpLen : 97.2
Train_AverageReturn : -133.54344177246094
Train_StdReturn : 89.22427368164062
Train_MaxReturn : -14.875717163085938
Train_MinReturn : -378.6502380371094
Train_AverageEpLen : 92.81818181818181
Actor Loss : -70895.984375
Baseline Loss : 5066.61669921875
Train_EnvstepsSoFar : 16487
TimeSinceStart : 16.942594289779663

********** Iteration 8 ************
Eval_AverageReturn : -123.95622253417969
Eval_StdReturn : 63.1162223815918
Eval_MaxReturn : -59.99313735961914
Eval_MinReturn : -217.27536010742188
Eval_AverageEpLen : 89.6
Train_AverageReturn : -142.18814086914062
Train_StdReturn : 71.99331665039062
Train_MaxReturn : -31.655235290527344
Train_MinReturn : -269.95306396484375
Train_AverageEpLen : 97.76190476190476
Actor Loss : -70926.453125
Baseline Loss : 3915.10498046875
Train_EnvstepsSoFar : 18540
TimeSinceStart : 19.23640251159668

********** Iteration 9 ************
Eval_AverageReturn : -82.04501342773438
Eval_StdReturn : 25.33576202392578
Eval_MaxReturn : -33.26567840576172
Eval_MinReturn : -113.38616943359375
Eval_AverageEpLen : 77.83333333333333
Train_AverageReturn : -108.76432037353516
Train_StdReturn : 82.8185043334961
Train_MaxReturn : 18.923873901367188
Train_MinReturn : -354.2196960449219
Train_AverageEpLen : 99.47619047619048
Actor Loss : -38291.0703125
Baseline Loss : 2568.179931640625
Train_EnvstepsSoFar : 20629
TimeSinceStart : 22.492791414260864

********** Iteration 10 ************
Eval_AverageReturn : -182.1180419921875
Eval_StdReturn : 74.78152465820312
Eval_MaxReturn : -76.78834533691406
Eval_MinReturn : -274.84185791015625
Eval_AverageEpLen : 116.25
Train_AverageReturn : -135.43289184570312
Train_StdReturn : 71.44926452636719
Train_MaxReturn : -52.329647064208984
Train_MinReturn : -338.50677490234375
Train_AverageEpLen : 100.45
Actor Loss : -54867.44921875
Baseline Loss : 3120.45947265625
Train_EnvstepsSoFar : 22638
TimeSinceStart : 24.97892451286316

********** Iteration 11 ************
Eval_AverageReturn : -118.33944702148438
Eval_StdReturn : 113.51152038574219
Eval_MaxReturn : -50.2989501953125
Eval_MinReturn : -314.91864013671875
Eval_AverageEpLen : 103.5
Train_AverageReturn : -157.3102569580078
Train_StdReturn : 68.35470581054688
Train_MaxReturn : -68.44956970214844
Train_MinReturn : -286.3439025878906
Train_AverageEpLen : 106.10526315789474
Actor Loss : -63509.63671875
Baseline Loss : 3894.82421875
Train_EnvstepsSoFar : 24654
TimeSinceStart : 27.374483823776245

********** Iteration 12 ************
Eval_AverageReturn : -236.97171020507812
Eval_StdReturn : 115.83136749267578
Eval_MaxReturn : -119.65299224853516
Eval_MinReturn : -426.28765869140625
Eval_AverageEpLen : 126.75
Train_AverageReturn : -166.9253387451172
Train_StdReturn : 84.79252624511719
Train_MaxReturn : -37.66958999633789
Train_MinReturn : -328.9356994628906
Train_AverageEpLen : 110.26315789473684
Actor Loss : -64326.8203125
Baseline Loss : 4166.35205078125
Train_EnvstepsSoFar : 26749
TimeSinceStart : 29.964669942855835

********** Iteration 13 ************
Eval_AverageReturn : -131.9198760986328
Eval_StdReturn : 53.91357421875
Eval_MaxReturn : -62.97916793823242
Eval_MinReturn : -203.6234130859375
Eval_AverageEpLen : 132.0
Train_AverageReturn : -118.31614685058594
Train_StdReturn : 89.81173706054688
Train_MaxReturn : 17.98128890991211
Train_MinReturn : -374.3289794921875
Train_AverageEpLen : 100.45
Actor Loss : -30782.64453125
Baseline Loss : 2769.271728515625
Train_EnvstepsSoFar : 28758
TimeSinceStart : 32.387415647506714

********** Iteration 14 ************
Eval_AverageReturn : -221.6025390625
Eval_StdReturn : 139.20176696777344
Eval_MaxReturn : -101.3223876953125
Eval_MinReturn : -416.70635986328125
Eval_AverageEpLen : 161.0
Train_AverageReturn : -142.08026123046875
Train_StdReturn : 89.18064880371094
Train_MaxReturn : 32.327667236328125
Train_MinReturn : -294.33074951171875
Train_AverageEpLen : 114.88888888888889
Actor Loss : -36900.4296875
Baseline Loss : 3428.862060546875
Train_EnvstepsSoFar : 30826
TimeSinceStart : 34.87720465660095

********** Iteration 15 ************
Eval_AverageReturn : -105.46607971191406
Eval_StdReturn : 84.30890655517578
Eval_MaxReturn : -51.340904235839844
Eval_MinReturn : -251.3414764404297
Eval_AverageEpLen : 114.5
Train_AverageReturn : -123.9325180053711
Train_StdReturn : 117.85570526123047
Train_MaxReturn : 1.355255126953125
Train_MinReturn : -470.5992126464844
Train_AverageEpLen : 120.52941176470588
Actor Loss : -20210.451171875
Baseline Loss : 3993.17626953125
Train_EnvstepsSoFar : 32875
TimeSinceStart : 37.29902744293213

********** Iteration 16 ************
Eval_AverageReturn : -140.31797790527344
Eval_StdReturn : 52.378604888916016
Eval_MaxReturn : -73.21975708007812
Eval_MinReturn : -201.04518127441406
Eval_AverageEpLen : 145.0
Train_AverageReturn : -130.30911254882812
Train_StdReturn : 108.97610473632812
Train_MaxReturn : -15.442825317382812
Train_MinReturn : -395.3389892578125
Train_AverageEpLen : 133.4
Actor Loss : -20088.443359375
Baseline Loss : 4099.7099609375
Train_EnvstepsSoFar : 34876
TimeSinceStart : 39.66523194313049

********** Iteration 17 ************
Eval_AverageReturn : -199.0865020751953
Eval_StdReturn : 128.79757690429688
Eval_MaxReturn : -106.96192932128906
Eval_MinReturn : -381.229736328125
Eval_AverageEpLen : 160.0
Train_AverageReturn : -101.3885726928711
Train_StdReturn : 91.44290924072266
Train_MaxReturn : 22.373245239257812
Train_MinReturn : -323.28424072265625
Train_AverageEpLen : 126.9375
Actor Loss : 4161.99365234375
Baseline Loss : 2063.76416015625
Train_EnvstepsSoFar : 36907
TimeSinceStart : 42.131890058517456

********** Iteration 18 ************
Eval_AverageReturn : -105.8157730102539
Eval_StdReturn : 45.781494140625
Eval_MaxReturn : -68.92849731445312
Eval_MinReturn : -170.33993530273438
Eval_AverageEpLen : 160.0
Train_AverageReturn : -131.02667236328125
Train_StdReturn : 119.82406616210938
Train_MaxReturn : 61.410640716552734
Train_MinReturn : -296.3344421386719
Train_AverageEpLen : 252.0
Actor Loss : 15568.783203125
Baseline Loss : 2963.106689453125
Train_EnvstepsSoFar : 38923
TimeSinceStart : 45.62289381027222

********** Iteration 19 ************
Eval_AverageReturn : -133.88674926757812
Eval_StdReturn : 13.058483123779297
Eval_MaxReturn : -120.8282699584961
Eval_MinReturn : -146.9452362060547
Eval_AverageEpLen : 211.5
Train_AverageReturn : -188.11000061035156
Train_StdReturn : 129.58387756347656
Train_MaxReturn : -16.696136474609375
Train_MinReturn : -448.4127197265625
Train_AverageEpLen : 160.15384615384616
Actor Loss : -30653.23828125
Baseline Loss : 3303.50244140625
Train_EnvstepsSoFar : 41005
TimeSinceStart : 48.16666340827942

********** Iteration 20 ************
Eval_AverageReturn : -215.96099853515625
Eval_StdReturn : 69.22161102294922
Eval_MaxReturn : -146.73939514160156
Eval_MinReturn : -285.1826171875
Eval_AverageEpLen : 215.5
Train_AverageReturn : -205.3802947998047
Train_StdReturn : 72.37176513671875
Train_MaxReturn : -97.03926086425781
Train_MinReturn : -340.28424072265625
Train_AverageEpLen : 169.25
Actor Loss : -30960.853515625
Baseline Loss : 2624.711669921875
Train_EnvstepsSoFar : 43036
TimeSinceStart : 50.71023631095886

********** Iteration 21 ************
Eval_AverageReturn : -91.62273406982422
Eval_StdReturn : 73.38713073730469
Eval_MaxReturn : -20.315507888793945
Eval_MinReturn : -206.12669372558594
Eval_AverageEpLen : 108.0
Train_AverageReturn : -224.75341796875
Train_StdReturn : 146.18722534179688
Train_MaxReturn : -38.48588562011719
Train_MinReturn : -532.7730102539062
Train_AverageEpLen : 173.0
Actor Loss : -34824.3046875
Baseline Loss : 5713.97216796875
Train_EnvstepsSoFar : 45112
TimeSinceStart : 53.2466094493866

********** Iteration 22 ************
Eval_AverageReturn : -57.67929458618164
Eval_StdReturn : 26.903837203979492
Eval_MaxReturn : -30.77545738220215
Eval_MinReturn : -84.5831298828125
Eval_AverageEpLen : 248.5
Train_AverageReturn : -171.89398193359375
Train_StdReturn : 125.49884033203125
Train_MaxReturn : 47.339271545410156
Train_MinReturn : -353.71435546875
Train_AverageEpLen : 249.66666666666666
Actor Loss : 3434.30517578125
Baseline Loss : 3337.950439453125
Train_EnvstepsSoFar : 48108
TimeSinceStart : 57.68132019042969

********** Iteration 23 ************
Eval_AverageReturn : 16.579978942871094
Eval_StdReturn : 0.0
Eval_MaxReturn : 16.579978942871094
Eval_MinReturn : 16.579978942871094
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -221.64581298828125
Train_StdReturn : 150.33462524414062
Train_MaxReturn : -21.299755096435547
Train_MinReturn : -467.9136962890625
Train_AverageEpLen : 186.9090909090909
Actor Loss : -29386.025390625
Baseline Loss : 3795.63525390625
Train_EnvstepsSoFar : 50164
TimeSinceStart : 61.57620167732239

********** Iteration 24 ************
Eval_AverageReturn : -179.15771484375
Eval_StdReturn : 62.68976593017578
Eval_MaxReturn : -95.10675811767578
Eval_MinReturn : -245.60833740234375
Eval_AverageEpLen : 166.0
Train_AverageReturn : -165.12998962402344
Train_StdReturn : 147.74240112304688
Train_MaxReturn : 7.302803039550781
Train_MinReturn : -476.9185791015625
Train_AverageEpLen : 289.14285714285717
Actor Loss : 15169.978515625
Baseline Loss : 3692.832763671875
Train_EnvstepsSoFar : 52188
TimeSinceStart : 64.98544931411743

********** Iteration 25 ************
Eval_AverageReturn : -106.01778411865234
Eval_StdReturn : 57.36559295654297
Eval_MaxReturn : -58.63307571411133
Eval_MinReturn : -186.73849487304688
Eval_AverageEpLen : 148.0
Train_AverageReturn : -111.08872985839844
Train_StdReturn : 98.04045104980469
Train_MaxReturn : 3.241565704345703
Train_MinReturn : -268.413818359375
Train_AverageEpLen : 230.0
Actor Loss : 25135.09375
Baseline Loss : 3140.27978515625
Train_EnvstepsSoFar : 54258
TimeSinceStart : 68.58711814880371

********** Iteration 26 ************
Eval_AverageReturn : -205.14585876464844
Eval_StdReturn : 47.19850540161133
Eval_MaxReturn : -151.94760131835938
Eval_MinReturn : -266.6592712402344
Eval_AverageEpLen : 198.0
Train_AverageReturn : -257.1298522949219
Train_StdReturn : 97.5477523803711
Train_MaxReturn : -35.413856506347656
Train_MinReturn : -433.40692138671875
Train_AverageEpLen : 173.0
Actor Loss : -47293.41796875
Baseline Loss : 4819.3994140625
Train_EnvstepsSoFar : 56334
TimeSinceStart : 71.30853343009949

********** Iteration 27 ************
Eval_AverageReturn : -103.9993896484375
Eval_StdReturn : 41.67792892456055
Eval_MaxReturn : -50.06114959716797
Eval_MinReturn : -151.5494384765625
Eval_AverageEpLen : 186.0
Train_AverageReturn : -131.0850067138672
Train_StdReturn : 113.24439239501953
Train_MaxReturn : -14.194345474243164
Train_MinReturn : -368.1591796875
Train_AverageEpLen : 168.75
Actor Loss : 8178.3251953125
Baseline Loss : 3658.5625
Train_EnvstepsSoFar : 58359
TimeSinceStart : 73.86826801300049

********** Iteration 28 ************
Eval_AverageReturn : -124.65462493896484
Eval_StdReturn : 37.01590347290039
Eval_MaxReturn : -88.46121215820312
Eval_MinReturn : -175.50485229492188
Eval_AverageEpLen : 137.33333333333334
Train_AverageReturn : -121.94882202148438
Train_StdReturn : 110.79271697998047
Train_MaxReturn : -16.386512756347656
Train_MinReturn : -322.72137451171875
Train_AverageEpLen : 155.15384615384616
Actor Loss : 6613.3056640625
Baseline Loss : 3145.397705078125
Train_EnvstepsSoFar : 60376
TimeSinceStart : 76.27626609802246

********** Iteration 29 ************
Eval_AverageReturn : -25.85028839111328
Eval_StdReturn : 34.24738311767578
Eval_MaxReturn : 6.949981212615967
Eval_MinReturn : -73.1119155883789
Eval_AverageEpLen : 145.33333333333334
Train_AverageReturn : -60.42854690551758
Train_StdReturn : 68.80784606933594
Train_MaxReturn : 26.120397567749023
Train_MinReturn : -208.36935424804688
Train_AverageEpLen : 287.57142857142856
Actor Loss : 44280.4921875
Baseline Loss : 3317.34423828125
Train_EnvstepsSoFar : 62389
TimeSinceStart : 79.82371258735657

********** Iteration 30 ************
Eval_AverageReturn : -23.113534927368164
Eval_StdReturn : 44.45053482055664
Eval_MaxReturn : 36.354793548583984
Eval_MinReturn : -70.4946060180664
Eval_AverageEpLen : 163.66666666666666
Train_AverageReturn : -106.06462097167969
Train_StdReturn : 85.40109252929688
Train_MaxReturn : 54.13731384277344
Train_MinReturn : -261.77728271484375
Train_AverageEpLen : 144.92857142857142
Actor Loss : 13304.275390625
Baseline Loss : 2413.1171875
Train_EnvstepsSoFar : 64418
TimeSinceStart : 82.40714573860168

********** Iteration 31 ************
Eval_AverageReturn : -168.2533721923828
Eval_StdReturn : 63.73453903198242
Eval_MaxReturn : -98.24046325683594
Eval_MinReturn : -252.42059326171875
Eval_AverageEpLen : 143.0
Train_AverageReturn : -60.27877426147461
Train_StdReturn : 61.89036560058594
Train_MaxReturn : -1.373687744140625
Train_MinReturn : -208.6118621826172
Train_AverageEpLen : 168.0
Actor Loss : 34644.328125
Baseline Loss : 2340.73779296875
Train_EnvstepsSoFar : 66434
TimeSinceStart : 85.18992853164673

********** Iteration 32 ************
Eval_AverageReturn : -21.5246639251709
Eval_StdReturn : 60.523475646972656
Eval_MaxReturn : 22.09685516357422
Eval_MinReturn : -107.1124496459961
Eval_AverageEpLen : 135.33333333333334
Train_AverageReturn : -33.036888122558594
Train_StdReturn : 73.65205383300781
Train_MaxReturn : 33.06713104248047
Train_MinReturn : -250.664794921875
Train_AverageEpLen : 234.9090909090909
Actor Loss : 58196.9609375
Baseline Loss : 3437.99267578125
Train_EnvstepsSoFar : 69018
TimeSinceStart : 89.30054044723511

********** Iteration 33 ************
Eval_AverageReturn : -79.0347900390625
Eval_StdReturn : 65.96358489990234
Eval_MaxReturn : -13.071205139160156
Eval_MinReturn : -144.99838256835938
Eval_AverageEpLen : 356.5
Train_AverageReturn : -59.54311752319336
Train_StdReturn : 67.83751678466797
Train_MaxReturn : 43.054046630859375
Train_MinReturn : -189.56443786621094
Train_AverageEpLen : 161.53846153846155
Actor Loss : 30375.78125
Baseline Loss : 2265.414794921875
Train_EnvstepsSoFar : 71118
TimeSinceStart : 92.51983880996704

********** Iteration 34 ************
Eval_AverageReturn : -84.90363311767578
Eval_StdReturn : 78.90833282470703
Eval_MaxReturn : 14.712780952453613
Eval_MinReturn : -178.2688751220703
Eval_AverageEpLen : 186.66666666666666
Train_AverageReturn : -37.19956588745117
Train_StdReturn : 37.87992477416992
Train_MaxReturn : 10.602619171142578
Train_MinReturn : -123.81230163574219
Train_AverageEpLen : 177.91666666666666
Actor Loss : 37505.734375
Baseline Loss : 2134.00390625
Train_EnvstepsSoFar : 73253
TimeSinceStart : 95.39079785346985

********** Iteration 35 ************
Eval_AverageReturn : -49.344696044921875
Eval_StdReturn : 57.87883758544922
Eval_MaxReturn : 8.534139633178711
Eval_MinReturn : -107.2235336303711
Eval_AverageEpLen : 228.0
Train_AverageReturn : -42.571441650390625
Train_StdReturn : 55.38426971435547
Train_MaxReturn : 15.290817260742188
Train_MinReturn : -167.93997192382812
Train_AverageEpLen : 369.625
Actor Loss : 56598.203125
Baseline Loss : 2266.40185546875
Train_EnvstepsSoFar : 76210
TimeSinceStart : 100.92540097236633

********** Iteration 36 ************
Eval_AverageReturn : -106.52201843261719
Eval_StdReturn : 0.0
Eval_MaxReturn : -106.52201843261719
Eval_MinReturn : -106.52201843261719
Eval_AverageEpLen : 563.0
Train_AverageReturn : -53.474365234375
Train_StdReturn : 81.85194396972656
Train_MaxReturn : 47.065914154052734
Train_MinReturn : -188.55418395996094
Train_AverageEpLen : 276.75
Actor Loss : 32633.953125
Baseline Loss : 2927.860107421875
Train_EnvstepsSoFar : 78424
TimeSinceStart : 105.75234889984131

********** Iteration 37 ************
Eval_AverageReturn : -75.76254272460938
Eval_StdReturn : 53.528770446777344
Eval_MaxReturn : -35.479278564453125
Eval_MinReturn : -151.41036987304688
Eval_AverageEpLen : 157.66666666666666
Train_AverageReturn : -103.56121826171875
Train_StdReturn : 96.63224029541016
Train_MaxReturn : 22.235124588012695
Train_MinReturn : -233.1109161376953
Train_AverageEpLen : 221.4
Actor Loss : 12784.0673828125
Baseline Loss : 2196.02392578125
Train_EnvstepsSoFar : 80638
TimeSinceStart : 109.20495796203613

********** Iteration 38 ************
Eval_AverageReturn : -56.394134521484375
Eval_StdReturn : 72.31473541259766
Eval_MaxReturn : 27.56265640258789
Eval_MinReturn : -148.9449920654297
Eval_AverageEpLen : 197.33333333333334
Train_AverageReturn : -60.75099563598633
Train_StdReturn : 73.94042205810547
Train_MaxReturn : 15.332237243652344
Train_MinReturn : -172.94508361816406
Train_AverageEpLen : 309.85714285714283
Actor Loss : 25829.5859375
Baseline Loss : 1989.298095703125
Train_EnvstepsSoFar : 82807
TimeSinceStart : 113.21931195259094

********** Iteration 39 ************
Eval_AverageReturn : -70.5617904663086
Eval_StdReturn : 77.70838165283203
Eval_MaxReturn : -15.331085205078125
Eval_MinReturn : -180.45755004882812
Eval_AverageEpLen : 194.33333333333334
Train_AverageReturn : -59.92802047729492
Train_StdReturn : 51.88056182861328
Train_MaxReturn : -6.5065460205078125
Train_MinReturn : -165.23171997070312
Train_AverageEpLen : 317.7142857142857
Actor Loss : 24293.71875
Baseline Loss : 1303.0618896484375
Train_EnvstepsSoFar : 85031
TimeSinceStart : 117.48201084136963

********** Iteration 40 ************
Eval_AverageReturn : -35.124961853027344
Eval_StdReturn : 14.182622909545898
Eval_MaxReturn : -20.942337036132812
Eval_MinReturn : -49.30758285522461
Eval_AverageEpLen : 222.5
Train_AverageReturn : -70.84085083007812
Train_StdReturn : 48.620635986328125
Train_MaxReturn : 9.954994201660156
Train_MinReturn : -156.36859130859375
Train_AverageEpLen : 216.5
Actor Loss : 18180.943359375
Baseline Loss : 1580.273681640625
Train_EnvstepsSoFar : 87196
TimeSinceStart : 120.56230401992798

********** Iteration 41 ************
Eval_AverageReturn : -23.96717643737793
Eval_StdReturn : 8.422361373901367
Eval_MaxReturn : -15.544815063476562
Eval_MinReturn : -32.3895378112793
Eval_AverageEpLen : 602.5
Train_AverageReturn : -45.85899353027344
Train_StdReturn : 43.042030334472656
Train_MaxReturn : 24.71312713623047
Train_MinReturn : -100.69692993164062
Train_AverageEpLen : 351.8333333333333
Actor Loss : 24531.8828125
Baseline Loss : 1587.210693359375
Train_EnvstepsSoFar : 89307
TimeSinceStart : 125.68231153488159

********** Iteration 42 ************
Eval_AverageReturn : -36.82444763183594
Eval_StdReturn : 38.79456329345703
Eval_MaxReturn : -7.0789289474487305
Eval_MinReturn : -91.62126159667969
Eval_AverageEpLen : 175.0
Train_AverageReturn : -57.5853157043457
Train_StdReturn : 77.70320892333984
Train_MaxReturn : 41.062347412109375
Train_MinReturn : -158.46847534179688
Train_AverageEpLen : 202.7
Actor Loss : 14938.1875
Baseline Loss : 2223.694091796875
Train_EnvstepsSoFar : 91334
TimeSinceStart : 128.63377618789673

********** Iteration 43 ************
Eval_AverageReturn : -17.286666870117188
Eval_StdReturn : 56.099212646484375
Eval_MaxReturn : 38.81254577636719
Eval_MinReturn : -73.38587951660156
Eval_AverageEpLen : 587.5
Train_AverageReturn : -23.467788696289062
Train_StdReturn : 94.40972900390625
Train_MaxReturn : 74.48847961425781
Train_MinReturn : -225.03897094726562
Train_AverageEpLen : 477.1666666666667
Actor Loss : 36759.75
Baseline Loss : 1877.8111572265625
Train_EnvstepsSoFar : 94197
TimeSinceStart : 136.1314024925232

********** Iteration 44 ************
Eval_AverageReturn : 9.858184814453125
Eval_StdReturn : 0.0
Eval_MaxReturn : 9.858184814453125
Eval_MinReturn : 9.858184814453125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -12.649175643920898
Train_StdReturn : 38.59564971923828
Train_MaxReturn : 29.263652801513672
Train_MinReturn : -82.65630340576172
Train_AverageEpLen : 266.75
Actor Loss : 22784.384765625
Baseline Loss : 1341.825927734375
Train_EnvstepsSoFar : 96331
TimeSinceStart : 141.76226663589478

********** Iteration 45 ************
Eval_AverageReturn : -34.5447883605957
Eval_StdReturn : 31.563587188720703
Eval_MaxReturn : -4.762298583984375
Eval_MinReturn : -78.23086547851562
Eval_AverageEpLen : 232.66666666666666
Train_AverageReturn : -19.17963218688965
Train_StdReturn : 30.989967346191406
Train_MaxReturn : 39.569190979003906
Train_MinReturn : -60.966949462890625
Train_AverageEpLen : 336.6666666666667
Actor Loss : 24048.021484375
Baseline Loss : 1420.8526611328125
Train_EnvstepsSoFar : 98351
TimeSinceStart : 146.2177917957306

********** Iteration 46 ************
Eval_AverageReturn : -15.771039009094238
Eval_StdReturn : 36.55219268798828
Eval_MaxReturn : 24.199676513671875
Eval_MinReturn : -64.14390563964844
Eval_AverageEpLen : 176.66666666666666
Train_AverageReturn : -31.926441192626953
Train_StdReturn : 33.33674621582031
Train_MaxReturn : 10.350090026855469
Train_MinReturn : -79.97593688964844
Train_AverageEpLen : 585.0
Actor Loss : 23412.056640625
Baseline Loss : 1322.112548828125
Train_EnvstepsSoFar : 100691
TimeSinceStart : 151.55435276031494

********** Iteration 47 ************
Eval_AverageReturn : 4.344850063323975
Eval_StdReturn : 30.627124786376953
Eval_MaxReturn : 35.07807159423828
Eval_MinReturn : -37.45343017578125
Eval_AverageEpLen : 174.33333333333334
Train_AverageReturn : 18.58298683166504
Train_StdReturn : 28.41468620300293
Train_MaxReturn : 60.524715423583984
Train_MinReturn : -15.741893768310547
Train_AverageEpLen : 303.85714285714283
Actor Loss : 29013.724609375
Baseline Loss : 1574.892578125
Train_EnvstepsSoFar : 102818
TimeSinceStart : 155.27760863304138

********** Iteration 48 ************
Eval_AverageReturn : -16.60303497314453
Eval_StdReturn : 21.29168701171875
Eval_MaxReturn : 4.688652038574219
Eval_MinReturn : -37.89472198486328
Eval_AverageEpLen : 245.5
Train_AverageReturn : -7.666985511779785
Train_StdReturn : 42.39189147949219
Train_MaxReturn : 77.39024353027344
Train_MinReturn : -73.29898071289062
Train_AverageEpLen : 296.14285714285717
Actor Loss : 20892.111328125
Baseline Loss : 1303.310302734375
Train_EnvstepsSoFar : 104891
TimeSinceStart : 159.20413064956665

********** Iteration 49 ************
Eval_AverageReturn : 14.607627868652344
Eval_StdReturn : 0.0
Eval_MaxReturn : 14.607627868652344
Eval_MinReturn : 14.607627868652344
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -1.9288626909255981
Train_StdReturn : 25.31723403930664
Train_MaxReturn : 27.39801025390625
Train_MinReturn : -48.38154220581055
Train_AverageEpLen : 302.2857142857143
Actor Loss : 19811.42578125
Baseline Loss : 1145.4261474609375
Train_EnvstepsSoFar : 107007
TimeSinceStart : 165.03982830047607

********** Iteration 50 ************
Eval_AverageReturn : -38.88698196411133
Eval_StdReturn : 31.181169509887695
Eval_MaxReturn : -7.705813884735107
Eval_MinReturn : -70.06815338134766
Eval_AverageEpLen : 218.0
Train_AverageReturn : -12.794058799743652
Train_StdReturn : 30.836688995361328
Train_MaxReturn : 28.669342041015625
Train_MinReturn : -72.81011962890625
Train_AverageEpLen : 305.42857142857144
Actor Loss : 15519.193359375
Baseline Loss : 1195.7586669921875
Train_EnvstepsSoFar : 109145
TimeSinceStart : 168.89786291122437

********** Iteration 51 ************
Eval_AverageReturn : 18.87318992614746
Eval_StdReturn : 7.1161017417907715
Eval_MaxReturn : 25.98929214477539
Eval_MinReturn : 11.757088661193848
Eval_AverageEpLen : 242.0
Train_AverageReturn : -1.950773000717163
Train_StdReturn : 67.32242584228516
Train_MaxReturn : 117.06423950195312
Train_MinReturn : -106.28416442871094
Train_AverageEpLen : 358.0
Actor Loss : 18360.0078125
Baseline Loss : 1230.4906005859375
Train_EnvstepsSoFar : 111651
TimeSinceStart : 173.54738330841064

********** Iteration 52 ************
Eval_AverageReturn : 9.326900482177734
Eval_StdReturn : 48.73707962036133
Eval_MaxReturn : 58.06398010253906
Eval_MinReturn : -39.410179138183594
Eval_AverageEpLen : 598.5
Train_AverageReturn : -2.059743642807007
Train_StdReturn : 22.25161361694336
Train_MaxReturn : 34.74542236328125
Train_MinReturn : -36.72587585449219
Train_AverageEpLen : 338.6666666666667
Actor Loss : 13363.1953125
Baseline Loss : 884.5430908203125
Train_EnvstepsSoFar : 113683
TimeSinceStart : 179.01854372024536

********** Iteration 53 ************
Eval_AverageReturn : 29.958114624023438
Eval_StdReturn : 0.0
Eval_MaxReturn : 29.958114624023438
Eval_MinReturn : 29.958114624023438
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -20.873371124267578
Train_StdReturn : 12.69092845916748
Train_MaxReturn : -1.1243648529052734
Train_MinReturn : -37.66680145263672
Train_AverageEpLen : 305.7142857142857
Actor Loss : 9203.1650390625
Baseline Loss : 910.2344970703125
Train_EnvstepsSoFar : 115823
TimeSinceStart : 184.25928139686584

********** Iteration 54 ************
Eval_AverageReturn : 21.5808162689209
Eval_StdReturn : 32.94304656982422
Eval_MaxReturn : 54.52386474609375
Eval_MinReturn : -11.362232208251953
Eval_AverageEpLen : 623.0
Train_AverageReturn : -4.438966751098633
Train_StdReturn : 33.29928970336914
Train_MaxReturn : 48.29461669921875
Train_MinReturn : -81.58523559570312
Train_AverageEpLen : 209.1
Actor Loss : 6449.771484375
Baseline Loss : 1448.5660400390625
Train_EnvstepsSoFar : 117914
TimeSinceStart : 189.42803955078125

********** Iteration 55 ************
Eval_AverageReturn : -4.874263763427734
Eval_StdReturn : 14.25577163696289
Eval_MaxReturn : 9.381507873535156
Eval_MinReturn : -19.130035400390625
Eval_AverageEpLen : 581.5
Train_AverageReturn : -57.9102668762207
Train_StdReturn : 104.54730224609375
Train_MaxReturn : 22.799659729003906
Train_MinReturn : -237.5182647705078
Train_AverageEpLen : 515.0
Actor Loss : 629.2136840820312
Baseline Loss : 1636.1986083984375
Train_EnvstepsSoFar : 119974
TimeSinceStart : 195.69361686706543

********** Iteration 56 ************
Eval_AverageReturn : -157.5731201171875
Eval_StdReturn : 0.0
Eval_MaxReturn : -157.5731201171875
Eval_MinReturn : -157.5731201171875
Eval_AverageEpLen : 558.0
Train_AverageReturn : -12.084807395935059
Train_StdReturn : 41.871910095214844
Train_MaxReturn : 52.07037353515625
Train_MinReturn : -109.61692810058594
Train_AverageEpLen : 233.44444444444446
Actor Loss : 8622.2109375
Baseline Loss : 1213.361572265625
Train_EnvstepsSoFar : 122075
TimeSinceStart : 199.3145649433136

********** Iteration 57 ************
Eval_AverageReturn : 28.927326202392578
Eval_StdReturn : 0.0
Eval_MaxReturn : 28.927326202392578
Eval_MinReturn : 28.927326202392578
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 23.38207244873047
Train_StdReturn : 57.85429382324219
Train_MaxReturn : 68.88524627685547
Train_MinReturn : -58.25732421875
Train_AverageEpLen : 771.3333333333334
Actor Loss : 12853.96875
Baseline Loss : 919.21435546875
Train_EnvstepsSoFar : 124389
TimeSinceStart : 206.22948217391968

********** Iteration 58 ************
Eval_AverageReturn : -34.51725769042969
Eval_StdReturn : 47.82817077636719
Eval_MaxReturn : 13.3109130859375
Eval_MinReturn : -82.34542846679688
Eval_AverageEpLen : 623.5
Train_AverageReturn : 46.7832145690918
Train_StdReturn : 9.899009704589844
Train_MaxReturn : 56.68222427368164
Train_MinReturn : 36.88420486450195
Train_AverageEpLen : 1000.0
Actor Loss : 11284.9970703125
Baseline Loss : 508.91717529296875
Train_EnvstepsSoFar : 126389
TimeSinceStart : 213.12393021583557

********** Iteration 59 ************
Eval_AverageReturn : -61.675453186035156
Eval_StdReturn : 43.127803802490234
Eval_MaxReturn : -18.547649383544922
Eval_MinReturn : -104.80325317382812
Eval_AverageEpLen : 265.0
Train_AverageReturn : -51.79825973510742
Train_StdReturn : 186.04942321777344
Train_MaxReturn : 121.51490020751953
Train_MinReturn : -309.900146484375
Train_AverageEpLen : 988.0
Actor Loss : 7146.53515625
Baseline Loss : 1474.4957275390625
Train_EnvstepsSoFar : 129353
TimeSinceStart : 219.75660490989685

********** Iteration 60 ************
Eval_AverageReturn : 107.03460693359375
Eval_StdReturn : 0.0
Eval_MaxReturn : 107.03460693359375
Eval_MinReturn : 107.03460693359375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -2.1483664512634277
Train_StdReturn : 60.85741424560547
Train_MaxReturn : 80.46212768554688
Train_MinReturn : -97.5714111328125
Train_AverageEpLen : 571.6
Actor Loss : 9034.35546875
Baseline Loss : 667.6768798828125
Train_EnvstepsSoFar : 132211
TimeSinceStart : 227.47070360183716

********** Iteration 61 ************
Eval_AverageReturn : 8.248161315917969
Eval_StdReturn : 0.0
Eval_MaxReturn : 8.248161315917969
Eval_MinReturn : 8.248161315917969
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 58.087318420410156
Train_StdReturn : 72.69581604003906
Train_MaxReturn : 130.78314208984375
Train_MinReturn : -14.608501434326172
Train_AverageEpLen : 1000.0
Actor Loss : 11806.171875
Baseline Loss : 642.5428466796875
Train_EnvstepsSoFar : 134211
TimeSinceStart : 232.97405743598938

********** Iteration 62 ************
Eval_AverageReturn : 38.01386260986328
Eval_StdReturn : 0.0
Eval_MaxReturn : 38.01386260986328
Eval_MinReturn : 38.01386260986328
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 16.939077377319336
Train_StdReturn : 70.83133697509766
Train_MaxReturn : 105.93091583251953
Train_MinReturn : -67.38092041015625
Train_AverageEpLen : 780.6666666666666
Actor Loss : 8946.6201171875
Baseline Loss : 634.8389892578125
Train_EnvstepsSoFar : 136553
TimeSinceStart : 239.79296493530273

********** Iteration 63 ************
Eval_AverageReturn : -27.527694702148438
Eval_StdReturn : 22.28639030456543
Eval_MaxReturn : -5.241304397583008
Eval_MinReturn : -49.8140869140625
Eval_AverageEpLen : 695.5
Train_AverageReturn : -79.59803009033203
Train_StdReturn : 42.07139205932617
Train_MaxReturn : -13.554588317871094
Train_MinReturn : -128.2811279296875
Train_AverageEpLen : 344.3333333333333
Actor Loss : -10805.109375
Baseline Loss : 1453.44287109375
Train_EnvstepsSoFar : 138619
TimeSinceStart : 245.06268095970154

********** Iteration 64 ************
Eval_AverageReturn : 9.150550842285156
Eval_StdReturn : 0.0
Eval_MaxReturn : 9.150550842285156
Eval_MinReturn : 9.150550842285156
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 80.5753402709961
Train_StdReturn : 50.55282211303711
Train_MaxReturn : 131.12815856933594
Train_MinReturn : 30.022518157958984
Train_AverageEpLen : 1000.0
Actor Loss : 8991.9423828125
Baseline Loss : 464.18524169921875
Train_EnvstepsSoFar : 140619
TimeSinceStart : 250.4556782245636

********** Iteration 65 ************
Eval_AverageReturn : -20.237388610839844
Eval_StdReturn : 23.27147674560547
Eval_MaxReturn : 3.034090042114258
Eval_MinReturn : -43.50886535644531
Eval_AverageEpLen : 230.0
Train_AverageReturn : 75.10026550292969
Train_StdReturn : 61.766353607177734
Train_MaxReturn : 136.8666229248047
Train_MinReturn : 13.333915710449219
Train_AverageEpLen : 1000.0
Actor Loss : 9272.755859375
Baseline Loss : 783.8003540039062
Train_EnvstepsSoFar : 142619
TimeSinceStart : 254.97408175468445

********** Iteration 66 ************
Eval_AverageReturn : 5.1089324951171875
Eval_StdReturn : 38.70354461669922
Eval_MaxReturn : 43.812477111816406
Eval_MinReturn : -33.59461212158203
Eval_AverageEpLen : 602.0
Train_AverageReturn : 44.11357879638672
Train_StdReturn : 64.54781341552734
Train_MaxReturn : 114.75401306152344
Train_MinReturn : -52.824485778808594
Train_AverageEpLen : 573.25
Actor Loss : 7767.63232421875
Baseline Loss : 951.4322509765625
Train_EnvstepsSoFar : 144912
TimeSinceStart : 260.7713232040405

********** Iteration 67 ************
Eval_AverageReturn : -27.538145065307617
Eval_StdReturn : 1.6993541717529297
Eval_MaxReturn : -25.838790893554688
Eval_MinReturn : -29.237499237060547
Eval_AverageEpLen : 233.0
Train_AverageReturn : -9.20338249206543
Train_StdReturn : 43.88985824584961
Train_MaxReturn : 71.37805938720703
Train_MinReturn : -70.29439544677734
Train_AverageEpLen : 347.1666666666667
Actor Loss : 1749.88525390625
Baseline Loss : 898.9100341796875
Train_EnvstepsSoFar : 146995
TimeSinceStart : 264.6410291194916

********** Iteration 68 ************
Eval_AverageReturn : 70.29425811767578
Eval_StdReturn : 63.38744354248047
Eval_MaxReturn : 133.68170166015625
Eval_MinReturn : 6.9068145751953125
Eval_AverageEpLen : 687.0
Train_AverageReturn : -7.489315509796143
Train_StdReturn : 38.48588180541992
Train_MaxReturn : 52.87372589111328
Train_MinReturn : -83.69309997558594
Train_AverageEpLen : 269.125
Actor Loss : -1488.8363037109375
Baseline Loss : 1237.5810546875
Train_EnvstepsSoFar : 149148
TimeSinceStart : 269.6799020767212

********** Iteration 69 ************
Eval_AverageReturn : -13.269882202148438
Eval_StdReturn : 0.0
Eval_MaxReturn : -13.269882202148438
Eval_MinReturn : -13.269882202148438
Eval_AverageEpLen : 418.0
Train_AverageReturn : 10.422685623168945
Train_StdReturn : 36.272727966308594
Train_MaxReturn : 79.81678771972656
Train_MinReturn : -33.47769546508789
Train_AverageEpLen : 376.1666666666667
Actor Loss : 5564.76171875
Baseline Loss : 763.79638671875
Train_EnvstepsSoFar : 151405
TimeSinceStart : 273.5616989135742

********** Iteration 70 ************
Eval_AverageReturn : -32.084983825683594
Eval_StdReturn : 55.593326568603516
Eval_MaxReturn : 23.508342742919922
Eval_MinReturn : -87.67831420898438
Eval_AverageEpLen : 357.5
Train_AverageReturn : 11.285771369934082
Train_StdReturn : 44.77918243408203
Train_MaxReturn : 86.91434478759766
Train_MinReturn : -49.80799865722656
Train_AverageEpLen : 391.42857142857144
Actor Loss : 5692.9482421875
Baseline Loss : 947.6143798828125
Train_EnvstepsSoFar : 154145
TimeSinceStart : 278.5327036380768

********** Iteration 71 ************
Eval_AverageReturn : 84.77706909179688
Eval_StdReturn : 0.0
Eval_MaxReturn : 84.77706909179688
Eval_MinReturn : 84.77706909179688
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 42.04743576049805
Train_StdReturn : 43.94695281982422
Train_MaxReturn : 111.17918395996094
Train_MinReturn : -7.519487380981445
Train_AverageEpLen : 478.6666666666667
Actor Loss : 7669.0107421875
Baseline Loss : 643.7423095703125
Train_EnvstepsSoFar : 157017
TimeSinceStart : 285.23273730278015

********** Iteration 72 ************
Eval_AverageReturn : 65.98007202148438
Eval_StdReturn : 0.0
Eval_MaxReturn : 65.98007202148438
Eval_MinReturn : 65.98007202148438
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 88.02501678466797
Train_StdReturn : 61.34359359741211
Train_MaxReturn : 181.58447265625
Train_MinReturn : 27.732379913330078
Train_AverageEpLen : 531.75
Actor Loss : 9758.830078125
Baseline Loss : 806.7113037109375
Train_EnvstepsSoFar : 159144
TimeSinceStart : 290.44045543670654

********** Iteration 73 ************
Eval_AverageReturn : -11.808357238769531
Eval_StdReturn : 92.66643524169922
Eval_MaxReturn : 80.85807800292969
Eval_MinReturn : -104.47479248046875
Eval_AverageEpLen : 699.5
Train_AverageReturn : -17.999773025512695
Train_StdReturn : 75.98932647705078
Train_MaxReturn : 102.13646697998047
Train_MinReturn : -104.75239562988281
Train_AverageEpLen : 531.25
Actor Loss : 1432.084228515625
Baseline Loss : 780.715087890625
Train_EnvstepsSoFar : 161269
TimeSinceStart : 296.60968351364136

********** Iteration 74 ************
Eval_AverageReturn : 67.87333679199219
Eval_StdReturn : 0.0
Eval_MaxReturn : 67.87333679199219
Eval_MinReturn : 67.87333679199219
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -39.227874755859375
Train_StdReturn : 59.20623779296875
Train_MaxReturn : 47.82463836669922
Train_MinReturn : -115.38758850097656
Train_AverageEpLen : 548.0
Actor Loss : -3057.159912109375
Baseline Loss : 1322.3642578125
Train_EnvstepsSoFar : 163461
TimeSinceStart : 301.737637758255

********** Iteration 75 ************
Eval_AverageReturn : 57.38389587402344
Eval_StdReturn : 0.0
Eval_MaxReturn : 57.38389587402344
Eval_MinReturn : 57.38389587402344
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 2.221752166748047
Train_StdReturn : 82.24211120605469
Train_MaxReturn : 120.49600219726562
Train_MinReturn : -77.38461303710938
Train_AverageEpLen : 706.0
Actor Loss : 1811.6654052734375
Baseline Loss : 717.0824584960938
Train_EnvstepsSoFar : 166285
TimeSinceStart : 308.9431142807007

********** Iteration 76 ************
Eval_AverageReturn : -129.97872924804688
Eval_StdReturn : 0.0
Eval_MaxReturn : -129.97872924804688
Eval_MinReturn : -129.97872924804688
Eval_AverageEpLen : 705.0
Train_AverageReturn : -92.1243667602539
Train_StdReturn : 43.462188720703125
Train_MaxReturn : -52.44190979003906
Train_MinReturn : -161.40853881835938
Train_AverageEpLen : 646.75
Actor Loss : -11013.939453125
Baseline Loss : 665.6505126953125
Train_EnvstepsSoFar : 168872
TimeSinceStart : 314.5166485309601

********** Iteration 77 ************
Eval_AverageReturn : -58.93422317504883
Eval_StdReturn : 0.0
Eval_MaxReturn : -58.93422317504883
Eval_MinReturn : -58.93422317504883
Eval_AverageEpLen : 406.0
Train_AverageReturn : -79.51187896728516
Train_StdReturn : 93.05599212646484
Train_MaxReturn : 47.43274688720703
Train_MinReturn : -173.03282165527344
Train_AverageEpLen : 692.3333333333334
Actor Loss : -6760.44384765625
Baseline Loss : 668.5413818359375
Train_EnvstepsSoFar : 170949
TimeSinceStart : 318.74163937568665

********** Iteration 78 ************
Eval_AverageReturn : -157.93997192382812
Eval_StdReturn : 0.0
Eval_MaxReturn : -157.93997192382812
Eval_MinReturn : -157.93997192382812
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -103.75980377197266
Train_StdReturn : 21.681833267211914
Train_MaxReturn : -79.19331359863281
Train_MinReturn : -131.9338836669922
Train_AverageEpLen : 720.3333333333334
Actor Loss : -10233.4755859375
Baseline Loss : 628.5087890625
Train_EnvstepsSoFar : 173110
TimeSinceStart : 325.895085811615

********** Iteration 79 ************
Eval_AverageReturn : -74.23619842529297
Eval_StdReturn : 0.0
Eval_MaxReturn : -74.23619842529297
Eval_MinReturn : -74.23619842529297
Eval_AverageEpLen : 814.0
Train_AverageReturn : -78.88538360595703
Train_StdReturn : 41.06751251220703
Train_MaxReturn : -37.81787109375
Train_MinReturn : -119.95289611816406
Train_AverageEpLen : 1000.0
Actor Loss : -2419.798583984375
Baseline Loss : 190.15184020996094
Train_EnvstepsSoFar : 175110
TimeSinceStart : 330.98603224754333

********** Iteration 80 ************
Eval_AverageReturn : -153.60260009765625
Eval_StdReturn : 0.0
Eval_MaxReturn : -153.60260009765625
Eval_MinReturn : -153.60260009765625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 16.842308044433594
Train_StdReturn : 1.2573204040527344
Train_MaxReturn : 18.099628448486328
Train_MinReturn : 15.58498764038086
Train_AverageEpLen : 1000.0
Actor Loss : 3608.75390625
Baseline Loss : 545.0942993164062
Train_EnvstepsSoFar : 177110
TimeSinceStart : 337.6120090484619

********** Iteration 81 ************
Eval_AverageReturn : -119.64635467529297
Eval_StdReturn : 0.0
Eval_MaxReturn : -119.64635467529297
Eval_MinReturn : -119.64635467529297
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -165.58187866210938
Train_StdReturn : 92.59913635253906
Train_MaxReturn : -80.29391479492188
Train_MinReturn : -294.2861328125
Train_AverageEpLen : 744.3333333333334
Actor Loss : -12591.474609375
Baseline Loss : 1566.564697265625
Train_EnvstepsSoFar : 179343
TimeSinceStart : 343.94234824180603

********** Iteration 82 ************
Eval_AverageReturn : -37.848350524902344
Eval_StdReturn : 0.0
Eval_MaxReturn : -37.848350524902344
Eval_MinReturn : -37.848350524902344
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -43.723487854003906
Train_StdReturn : 15.133296966552734
Train_MaxReturn : -28.590190887451172
Train_MinReturn : -58.85678482055664
Train_AverageEpLen : 1000.0
Actor Loss : 358.96124267578125
Baseline Loss : 242.24606323242188
Train_EnvstepsSoFar : 181343
TimeSinceStart : 350.75023317337036

********** Iteration 83 ************
Eval_AverageReturn : 27.71631622314453
Eval_StdReturn : 0.0
Eval_MaxReturn : 27.71631622314453
Eval_MinReturn : 27.71631622314453
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 5.056886672973633
Train_StdReturn : 14.43667221069336
Train_MaxReturn : 19.493558883666992
Train_MinReturn : -9.379785537719727
Train_AverageEpLen : 1000.0
Actor Loss : 3663.170166015625
Baseline Loss : 327.2420349121094
Train_EnvstepsSoFar : 183343
TimeSinceStart : 357.55201864242554

********** Iteration 84 ************
Eval_AverageReturn : -37.11553192138672
Eval_StdReturn : 0.0
Eval_MaxReturn : -37.11553192138672
Eval_MinReturn : -37.11553192138672
Eval_AverageEpLen : 605.0
Train_AverageReturn : -36.107967376708984
Train_StdReturn : 48.50297164916992
Train_MaxReturn : 26.82604217529297
Train_MinReturn : -91.20313262939453
Train_AverageEpLen : 785.3333333333334
Actor Loss : 287.896240234375
Baseline Loss : 617.939697265625
Train_EnvstepsSoFar : 185699
TimeSinceStart : 363.1909444332123

********** Iteration 85 ************
Eval_AverageReturn : 177.613525390625
Eval_StdReturn : 0.0
Eval_MaxReturn : 177.613525390625
Eval_MinReturn : 177.613525390625
Eval_AverageEpLen : 736.0
Train_AverageReturn : 68.36891174316406
Train_StdReturn : 74.21592712402344
Train_MaxReturn : 164.42681884765625
Train_MinReturn : -43.14122009277344
Train_AverageEpLen : 745.0
Actor Loss : 10838.1240234375
Baseline Loss : 885.4498901367188
Train_EnvstepsSoFar : 188679
TimeSinceStart : 370.9644629955292

********** Iteration 86 ************
Eval_AverageReturn : 115.60833740234375
Eval_StdReturn : 0.0
Eval_MaxReturn : 115.60833740234375
Eval_MinReturn : 115.60833740234375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 111.55534362792969
Train_StdReturn : 6.328701496124268
Train_MaxReturn : 117.88404846191406
Train_MinReturn : 105.22664642333984
Train_AverageEpLen : 1000.0
Actor Loss : 11876.1767578125
Baseline Loss : 430.1670837402344
Train_EnvstepsSoFar : 190679
TimeSinceStart : 376.69610476493835

********** Iteration 87 ************
Eval_AverageReturn : 132.40455627441406
Eval_StdReturn : 0.0
Eval_MaxReturn : 132.40455627441406
Eval_MinReturn : 132.40455627441406
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 95.1671142578125
Train_StdReturn : 11.65664291381836
Train_MaxReturn : 106.82376098632812
Train_MinReturn : 83.5104751586914
Train_AverageEpLen : 1000.0
Actor Loss : 10360.88671875
Baseline Loss : 316.79681396484375
Train_EnvstepsSoFar : 192679
TimeSinceStart : 381.9010896682739

********** Iteration 88 ************
Eval_AverageReturn : 124.83671569824219
Eval_StdReturn : 0.0
Eval_MaxReturn : 124.83671569824219
Eval_MinReturn : 124.83671569824219
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 126.97835540771484
Train_StdReturn : 64.0606918334961
Train_MaxReturn : 210.28253173828125
Train_MinReturn : 54.48847961425781
Train_AverageEpLen : 932.6666666666666
Actor Loss : 15281.2138671875
Baseline Loss : 625.6344604492188
Train_EnvstepsSoFar : 195477
TimeSinceStart : 389.49440717697144

********** Iteration 89 ************
Eval_AverageReturn : 79.85547637939453
Eval_StdReturn : 42.19654846191406
Eval_MaxReturn : 122.0520248413086
Eval_MinReturn : 37.65892791748047
Eval_AverageEpLen : 681.0
Train_AverageReturn : 113.29693603515625
Train_StdReturn : 8.27890396118164
Train_MaxReturn : 121.57583618164062
Train_MinReturn : 105.01802825927734
Train_AverageEpLen : 1000.0
Actor Loss : 8612.375
Baseline Loss : 366.553466796875
Train_EnvstepsSoFar : 197477
TimeSinceStart : 395.9704930782318

********** Iteration 90 ************
Eval_AverageReturn : -4.048763275146484
Eval_StdReturn : 15.49703598022461
Eval_MaxReturn : 11.448272705078125
Eval_MinReturn : -19.545799255371094
Eval_AverageEpLen : 292.0
Train_AverageReturn : -6.1281280517578125
Train_StdReturn : 63.73070526123047
Train_MaxReturn : 139.63734436035156
Train_MinReturn : -74.33100891113281
Train_AverageEpLen : 401.42857142857144
Actor Loss : -1942.85986328125
Baseline Loss : 1453.9190673828125
Train_EnvstepsSoFar : 200287
TimeSinceStart : 401.0643563270569

********** Iteration 91 ************
Eval_AverageReturn : 64.24278259277344
Eval_StdReturn : 44.78813934326172
Eval_MaxReturn : 109.03092193603516
Eval_MinReturn : 19.45464324951172
Eval_AverageEpLen : 615.5
Train_AverageReturn : 128.22900390625
Train_StdReturn : 14.903205871582031
Train_MaxReturn : 143.13221740722656
Train_MinReturn : 113.3258056640625
Train_AverageEpLen : 1000.0
Actor Loss : 8615.33203125
Baseline Loss : 377.4580993652344
Train_EnvstepsSoFar : 202287
TimeSinceStart : 407.3565504550934

********** Iteration 92 ************
Eval_AverageReturn : -76.68666076660156
Eval_StdReturn : 0.0
Eval_MaxReturn : -76.68666076660156
Eval_MinReturn : -76.68666076660156
Eval_AverageEpLen : 400.0
Train_AverageReturn : 166.7626953125
Train_StdReturn : 22.3306884765625
Train_MaxReturn : 189.0933837890625
Train_MinReturn : 144.4320068359375
Train_AverageEpLen : 1000.0
Actor Loss : 9726.98046875
Baseline Loss : 610.5432739257812
Train_EnvstepsSoFar : 204287
TimeSinceStart : 411.20466899871826

********** Iteration 93 ************
Eval_AverageReturn : 1.011810302734375
Eval_StdReturn : 0.0
Eval_MaxReturn : 1.011810302734375
Eval_MinReturn : 1.011810302734375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 129.862060546875
Train_StdReturn : 1.2069625854492188
Train_MaxReturn : 131.06903076171875
Train_MinReturn : 128.6551055908203
Train_AverageEpLen : 1000.0
Actor Loss : 7559.54150390625
Baseline Loss : 404.81903076171875
Train_EnvstepsSoFar : 206287
TimeSinceStart : 417.3088421821594

********** Iteration 94 ************
Eval_AverageReturn : 181.83123779296875
Eval_StdReturn : 0.0
Eval_MaxReturn : 181.83123779296875
Eval_MinReturn : 181.83123779296875
Eval_AverageEpLen : 532.0
Train_AverageReturn : 97.53285217285156
Train_StdReturn : 16.779468536376953
Train_MaxReturn : 114.31232452392578
Train_MinReturn : 80.75338745117188
Train_AverageEpLen : 1000.0
Actor Loss : 4244.763671875
Baseline Loss : 277.2525329589844
Train_EnvstepsSoFar : 208287
TimeSinceStart : 421.8443193435669

********** Iteration 95 ************
Eval_AverageReturn : -41.72815704345703
Eval_StdReturn : 3.0781116485595703
Eval_MaxReturn : -38.650047302246094
Eval_MinReturn : -44.806270599365234
Eval_AverageEpLen : 328.5
Train_AverageReturn : 65.85617065429688
Train_StdReturn : 24.630664825439453
Train_MaxReturn : 90.48683166503906
Train_MinReturn : 41.225502014160156
Train_AverageEpLen : 1000.0
Actor Loss : 850.8770751953125
Baseline Loss : 293.1742858886719
Train_EnvstepsSoFar : 210287
TimeSinceStart : 426.5769987106323

********** Iteration 96 ************
Eval_AverageReturn : 163.44009399414062
Eval_StdReturn : 0.0
Eval_MaxReturn : 163.44009399414062
Eval_MinReturn : 163.44009399414062
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -8.97183895111084
Train_StdReturn : 61.797786712646484
Train_MaxReturn : 55.05183029174805
Train_MinReturn : -92.50238037109375
Train_AverageEpLen : 776.0
Actor Loss : -3688.065673828125
Baseline Loss : 710.8729248046875
Train_EnvstepsSoFar : 212615
TimeSinceStart : 432.75999546051025

********** Iteration 97 ************
Eval_AverageReturn : 97.28947448730469
Eval_StdReturn : 0.0
Eval_MaxReturn : 97.28947448730469
Eval_MinReturn : 97.28947448730469
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 50.37098693847656
Train_StdReturn : 85.1971435546875
Train_MaxReturn : 135.02523803710938
Train_MinReturn : -65.60501861572266
Train_AverageEpLen : 640.75
Actor Loss : 1736.0087890625
Baseline Loss : 799.9593505859375
Train_EnvstepsSoFar : 215178
TimeSinceStart : 438.9845726490021

********** Iteration 98 ************
Eval_AverageReturn : 112.46685028076172
Eval_StdReturn : 0.0
Eval_MaxReturn : 112.46685028076172
Eval_MinReturn : 112.46685028076172
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 145.21017456054688
Train_StdReturn : 10.967308044433594
Train_MaxReturn : 156.177490234375
Train_MinReturn : 134.2428741455078
Train_AverageEpLen : 1000.0
Actor Loss : 6022.349609375
Baseline Loss : 413.1593322753906
Train_EnvstepsSoFar : 217178
TimeSinceStart : 444.5874493122101

********** Iteration 99 ************
Eval_AverageReturn : 144.4808807373047
Eval_StdReturn : 0.0
Eval_MaxReturn : 144.4808807373047
Eval_MinReturn : 144.4808807373047
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 105.2009048461914
Train_StdReturn : 61.224971771240234
Train_MaxReturn : 161.3552703857422
Train_MinReturn : 20.04692840576172
Train_AverageEpLen : 753.6666666666666
Actor Loss : 5288.3134765625
Baseline Loss : 620.40576171875
Train_EnvstepsSoFar : 219439
TimeSinceStart : 450.17392230033875

********** Iteration 100 ************
Eval_AverageReturn : 133.6421661376953
Eval_StdReturn : 0.0
Eval_MaxReturn : 133.6421661376953
Eval_MinReturn : 133.6421661376953
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 144.63235473632812
Train_StdReturn : 13.116058349609375
Train_MaxReturn : 157.7484130859375
Train_MinReturn : 131.51629638671875
Train_AverageEpLen : 1000.0
Actor Loss : 6404.6826171875
Baseline Loss : 505.0569763183594
Train_EnvstepsSoFar : 221439
TimeSinceStart : 455.95238637924194

********** Iteration 101 ************
Eval_AverageReturn : 143.2584686279297
Eval_StdReturn : 0.0
Eval_MaxReturn : 143.2584686279297
Eval_MinReturn : 143.2584686279297
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 140.34664916992188
Train_StdReturn : 12.659088134765625
Train_MaxReturn : 153.0057373046875
Train_MinReturn : 127.68756103515625
Train_AverageEpLen : 1000.0
Actor Loss : 4233.8662109375
Baseline Loss : 262.54022216796875
Train_EnvstepsSoFar : 223439
TimeSinceStart : 461.3628234863281

********** Iteration 102 ************
Eval_AverageReturn : 164.52459716796875
Eval_StdReturn : 0.0
Eval_MaxReturn : 164.52459716796875
Eval_MinReturn : 164.52459716796875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 121.24990844726562
Train_StdReturn : 5.324302673339844
Train_MaxReturn : 126.57421112060547
Train_MinReturn : 115.92560577392578
Train_AverageEpLen : 1000.0
Actor Loss : 2701.626708984375
Baseline Loss : 223.98141479492188
Train_EnvstepsSoFar : 225439
TimeSinceStart : 466.74402713775635

********** Iteration 103 ************
Eval_AverageReturn : 123.35404205322266
Eval_StdReturn : 0.0
Eval_MaxReturn : 123.35404205322266
Eval_MinReturn : 123.35404205322266
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 95.25301361083984
Train_StdReturn : 61.857810974121094
Train_MaxReturn : 147.8146209716797
Train_MinReturn : 8.411972045898438
Train_AverageEpLen : 740.0
Actor Loss : 3395.77197265625
Baseline Loss : 454.4659729003906
Train_EnvstepsSoFar : 227659
TimeSinceStart : 472.39034700393677

********** Iteration 104 ************
Eval_AverageReturn : 37.275882720947266
Eval_StdReturn : 92.68022155761719
Eval_MaxReturn : 129.9561004638672
Eval_MinReturn : -55.404335021972656
Eval_AverageEpLen : 686.0
Train_AverageReturn : 127.46638488769531
Train_StdReturn : 5.955532073974609
Train_MaxReturn : 133.4219207763672
Train_MinReturn : 121.51085662841797
Train_AverageEpLen : 1000.0
Actor Loss : 2520.243896484375
Baseline Loss : 249.6832275390625
Train_EnvstepsSoFar : 229659
TimeSinceStart : 479.5447905063629

********** Iteration 105 ************
Eval_AverageReturn : 117.85798645019531
Eval_StdReturn : 0.0
Eval_MaxReturn : 117.85798645019531
Eval_MinReturn : 117.85798645019531
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 112.79632568359375
Train_StdReturn : 13.33560562133789
Train_MaxReturn : 126.13192749023438
Train_MinReturn : 99.4607162475586
Train_AverageEpLen : 1000.0
Actor Loss : 2501.4853515625
Baseline Loss : 245.2139892578125
Train_EnvstepsSoFar : 231659
TimeSinceStart : 485.47343254089355

********** Iteration 106 ************
Eval_AverageReturn : 128.18887329101562
Eval_StdReturn : 0.0
Eval_MaxReturn : 128.18887329101562
Eval_MinReturn : 128.18887329101562
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 127.46487426757812
Train_StdReturn : 4.915191650390625
Train_MaxReturn : 132.38006591796875
Train_MinReturn : 122.5496826171875
Train_AverageEpLen : 1000.0
Actor Loss : 3321.618896484375
Baseline Loss : 276.3511047363281
Train_EnvstepsSoFar : 233659
TimeSinceStart : 491.186203956604

********** Iteration 107 ************
Eval_AverageReturn : 157.32907104492188
Eval_StdReturn : 0.0
Eval_MaxReturn : 157.32907104492188
Eval_MinReturn : 157.32907104492188
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 75.48797607421875
Train_StdReturn : 61.3515739440918
Train_MaxReturn : 157.98736572265625
Train_MinReturn : -2.2204208374023438
Train_AverageEpLen : 657.5
Actor Loss : 352.29205322265625
Baseline Loss : 597.982177734375
Train_EnvstepsSoFar : 236289
TimeSinceStart : 497.22896432876587

********** Iteration 108 ************
Eval_AverageReturn : 146.87701416015625
Eval_StdReturn : 0.0
Eval_MaxReturn : 146.87701416015625
Eval_MinReturn : 146.87701416015625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 123.70130920410156
Train_StdReturn : 18.709026336669922
Train_MaxReturn : 142.41033935546875
Train_MinReturn : 104.9922866821289
Train_AverageEpLen : 1000.0
Actor Loss : 1992.2996826171875
Baseline Loss : 244.45333862304688
Train_EnvstepsSoFar : 238289
TimeSinceStart : 502.726336479187

********** Iteration 109 ************
Eval_AverageReturn : 109.0908432006836
Eval_StdReturn : 0.0
Eval_MaxReturn : 109.0908432006836
Eval_MinReturn : 109.0908432006836
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 125.24715423583984
Train_StdReturn : 26.27136993408203
Train_MaxReturn : 151.51852416992188
Train_MinReturn : 98.97578430175781
Train_AverageEpLen : 1000.0
Actor Loss : 2673.4248046875
Baseline Loss : 387.6734313964844
Train_EnvstepsSoFar : 240289
TimeSinceStart : 508.033331155777

********** Iteration 110 ************
Eval_AverageReturn : 104.76528930664062
Eval_StdReturn : 0.0
Eval_MaxReturn : 104.76528930664062
Eval_MinReturn : 104.76528930664062
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 113.08848571777344
Train_StdReturn : 3.7892189025878906
Train_MaxReturn : 116.8777084350586
Train_MinReturn : 109.29927062988281
Train_AverageEpLen : 1000.0
Actor Loss : 1267.7822265625
Baseline Loss : 179.4083251953125
Train_EnvstepsSoFar : 242289
TimeSinceStart : 514.5832304954529

********** Iteration 111 ************
Eval_AverageReturn : 128.83364868164062
Eval_StdReturn : 0.0
Eval_MaxReturn : 128.83364868164062
Eval_MinReturn : 128.83364868164062
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 113.02564239501953
Train_StdReturn : 16.660499572753906
Train_MaxReturn : 129.68614196777344
Train_MinReturn : 96.36514282226562
Train_AverageEpLen : 1000.0
Actor Loss : 2214.945068359375
Baseline Loss : 185.66775512695312
Train_EnvstepsSoFar : 244289
TimeSinceStart : 520.0890581607819

********** Iteration 112 ************
Eval_AverageReturn : 137.2400665283203
Eval_StdReturn : 0.0
Eval_MaxReturn : 137.2400665283203
Eval_MinReturn : 137.2400665283203
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 108.23672485351562
Train_StdReturn : 1.2368431091308594
Train_MaxReturn : 109.47357177734375
Train_MinReturn : 106.99988555908203
Train_AverageEpLen : 1000.0
Actor Loss : 908.466552734375
Baseline Loss : 189.88369750976562
Train_EnvstepsSoFar : 246289
TimeSinceStart : 526.12149477005

********** Iteration 113 ************
Eval_AverageReturn : 76.3462142944336
Eval_StdReturn : 45.581077575683594
Eval_MaxReturn : 121.92729187011719
Eval_MinReturn : 30.76513671875
Eval_AverageEpLen : 635.0
Train_AverageReturn : 41.48288345336914
Train_StdReturn : 71.65135955810547
Train_MaxReturn : 117.6588134765625
Train_MinReturn : -35.18540954589844
Train_AverageEpLen : 667.75
Actor Loss : -3425.869384765625
Baseline Loss : 615.9782104492188
Train_EnvstepsSoFar : 248960
TimeSinceStart : 533.4012022018433

********** Iteration 114 ************
Eval_AverageReturn : 102.57173156738281
Eval_StdReturn : 0.0
Eval_MaxReturn : 102.57173156738281
Eval_MinReturn : 102.57173156738281
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 73.80872344970703
Train_StdReturn : 70.73302459716797
Train_MaxReturn : 150.8372802734375
Train_MinReturn : -17.41638946533203
Train_AverageEpLen : 690.5
Actor Loss : -1133.9332275390625
Baseline Loss : 777.7681884765625
Train_EnvstepsSoFar : 251722
TimeSinceStart : 539.8309729099274

********** Iteration 115 ************
Eval_AverageReturn : 75.68343353271484
Eval_StdReturn : 22.885231018066406
Eval_MaxReturn : 98.56866455078125
Eval_MinReturn : 52.79820251464844
Eval_AverageEpLen : 629.5
Train_AverageReturn : 91.74226379394531
Train_StdReturn : 11.82375717163086
Train_MaxReturn : 103.56602478027344
Train_MinReturn : 79.91851043701172
Train_AverageEpLen : 1000.0
Actor Loss : 533.0421142578125
Baseline Loss : 155.17636108398438
Train_EnvstepsSoFar : 253722
TimeSinceStart : 547.0943372249603

********** Iteration 116 ************
Eval_AverageReturn : 112.44944763183594
Eval_StdReturn : 0.0
Eval_MaxReturn : 112.44944763183594
Eval_MinReturn : 112.44944763183594
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 110.46333312988281
Train_StdReturn : 40.98069381713867
Train_MaxReturn : 151.44403076171875
Train_MinReturn : 69.4826431274414
Train_AverageEpLen : 1000.0
Actor Loss : 1940.521240234375
Baseline Loss : 323.69317626953125
Train_EnvstepsSoFar : 255722
TimeSinceStart : 553.6649954319

********** Iteration 117 ************
Eval_AverageReturn : 95.36751556396484
Eval_StdReturn : 0.0
Eval_MaxReturn : 95.36751556396484
Eval_MinReturn : 95.36751556396484
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 18.265161514282227
Train_StdReturn : 58.471012115478516
Train_MaxReturn : 67.21952819824219
Train_MinReturn : -63.925899505615234
Train_AverageEpLen : 865.0
Actor Loss : -5725.2451171875
Baseline Loss : 426.8247985839844
Train_EnvstepsSoFar : 258317
TimeSinceStart : 561.1871755123138

********** Iteration 118 ************
Eval_AverageReturn : 132.1470184326172
Eval_StdReturn : 0.0
Eval_MaxReturn : 132.1470184326172
Eval_MinReturn : 132.1470184326172
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 67.43877410888672
Train_StdReturn : 55.479305267333984
Train_MaxReturn : 112.72589874267578
Train_MinReturn : -10.691162109375
Train_AverageEpLen : 820.3333333333334
Actor Loss : -454.830322265625
Baseline Loss : 312.24688720703125
Train_EnvstepsSoFar : 260778
TimeSinceStart : 568.2684817314148

********** Iteration 119 ************
Eval_AverageReturn : 104.97249603271484
Eval_StdReturn : 0.0
Eval_MaxReturn : 104.97249603271484
Eval_MinReturn : 104.97249603271484
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 110.8253173828125
Train_StdReturn : 8.121662139892578
Train_MaxReturn : 118.94697570800781
Train_MinReturn : 102.70365142822266
Train_AverageEpLen : 1000.0
Actor Loss : 2697.697998046875
Baseline Loss : 224.9271240234375
Train_EnvstepsSoFar : 262778
TimeSinceStart : 574.2686262130737

********** Iteration 120 ************
Eval_AverageReturn : 183.5435028076172
Eval_StdReturn : 0.0
Eval_MaxReturn : 183.5435028076172
Eval_MinReturn : 183.5435028076172
Eval_AverageEpLen : 666.0
Train_AverageReturn : 125.82794189453125
Train_StdReturn : 12.11016845703125
Train_MaxReturn : 137.9381103515625
Train_MinReturn : 113.7177734375
Train_AverageEpLen : 1000.0
Actor Loss : 2455.240966796875
Baseline Loss : 298.8523864746094
Train_EnvstepsSoFar : 264778
TimeSinceStart : 579.3443641662598

********** Iteration 121 ************
Eval_AverageReturn : 57.519046783447266
Eval_StdReturn : 0.0
Eval_MaxReturn : 57.519046783447266
Eval_MinReturn : 57.519046783447266
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 80.81684112548828
Train_StdReturn : 44.42029571533203
Train_MaxReturn : 143.21041870117188
Train_MinReturn : 43.293487548828125
Train_AverageEpLen : 751.3333333333334
Actor Loss : 2354.306640625
Baseline Loss : 403.88116455078125
Train_EnvstepsSoFar : 267032
TimeSinceStart : 585.4397749900818

********** Iteration 122 ************
Eval_AverageReturn : 107.5650405883789
Eval_StdReturn : 0.0
Eval_MaxReturn : 107.5650405883789
Eval_MinReturn : 107.5650405883789
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 108.63877868652344
Train_StdReturn : 3.7001686096191406
Train_MaxReturn : 112.33894348144531
Train_MinReturn : 104.93860626220703
Train_AverageEpLen : 1000.0
Actor Loss : 2492.071533203125
Baseline Loss : 177.0189971923828
Train_EnvstepsSoFar : 269032
TimeSinceStart : 590.9496126174927

********** Iteration 123 ************
Eval_AverageReturn : 193.29115295410156
Eval_StdReturn : 0.0
Eval_MaxReturn : 193.29115295410156
Eval_MinReturn : 193.29115295410156
Eval_AverageEpLen : 883.0
Train_AverageReturn : 107.97590637207031
Train_StdReturn : 20.723262786865234
Train_MaxReturn : 128.6991729736328
Train_MinReturn : 87.25264739990234
Train_AverageEpLen : 1000.0
Actor Loss : 2044.9229736328125
Baseline Loss : 177.7153778076172
Train_EnvstepsSoFar : 271032
TimeSinceStart : 596.2628796100616

********** Iteration 124 ************
Eval_AverageReturn : 104.74971771240234
Eval_StdReturn : 0.0
Eval_MaxReturn : 104.74971771240234
Eval_MinReturn : 104.74971771240234
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 203.0398406982422
Train_StdReturn : 37.29415512084961
Train_MaxReturn : 240.63064575195312
Train_MinReturn : 152.20571899414062
Train_AverageEpLen : 924.6666666666666
Actor Loss : 9440.3603515625
Baseline Loss : 524.8790283203125
Train_EnvstepsSoFar : 273806
TimeSinceStart : 603.6149106025696

********** Iteration 125 ************
Eval_AverageReturn : 210.64486694335938
Eval_StdReturn : 0.0
Eval_MaxReturn : 210.64486694335938
Eval_MinReturn : 210.64486694335938
Eval_AverageEpLen : 932.0
Train_AverageReturn : 182.27133178710938
Train_StdReturn : 106.56706237792969
Train_MaxReturn : 275.1376953125
Train_MinReturn : 2.1539382934570312
Train_AverageEpLen : 561.0
Actor Loss : 12554.720703125
Baseline Loss : 1205.878173828125
Train_EnvstepsSoFar : 276050
TimeSinceStart : 609.2236928939819

********** Iteration 126 ************
Eval_AverageReturn : 126.82443237304688
Eval_StdReturn : 108.92514038085938
Eval_MaxReturn : 235.74957275390625
Eval_MinReturn : 17.89929962158203
Eval_AverageEpLen : 368.5
Train_AverageReturn : 259.27825927734375
Train_StdReturn : 20.071361541748047
Train_MaxReturn : 283.0058898925781
Train_MinReturn : 227.44247436523438
Train_AverageEpLen : 586.75
Actor Loss : 18123.05078125
Baseline Loss : 1426.2010498046875
Train_EnvstepsSoFar : 278397
TimeSinceStart : 614.2765653133392

********** Iteration 127 ************
Eval_AverageReturn : 4.478298187255859
Eval_StdReturn : 17.610111236572266
Eval_MaxReturn : 22.088409423828125
Eval_MinReturn : -13.131813049316406
Eval_AverageEpLen : 328.5
Train_AverageReturn : 180.6942596435547
Train_StdReturn : 101.47735595703125
Train_MaxReturn : 257.34991455078125
Train_MinReturn : -17.173423767089844
Train_AverageEpLen : 451.6
Actor Loss : 10987.142578125
Baseline Loss : 1621.446044921875
Train_EnvstepsSoFar : 280655
TimeSinceStart : 618.6998608112335

********** Iteration 128 ************
Eval_AverageReturn : 258.77392578125
Eval_StdReturn : 0.0
Eval_MaxReturn : 258.77392578125
Eval_MinReturn : 258.77392578125
Eval_AverageEpLen : 668.0
Train_AverageReturn : 242.3970184326172
Train_StdReturn : 16.801633834838867
Train_MaxReturn : 257.3252258300781
Train_MinReturn : 214.4603729248047
Train_AverageEpLen : 420.6
Actor Loss : 16564.861328125
Baseline Loss : 1524.096923828125
Train_EnvstepsSoFar : 282758
TimeSinceStart : 622.9740324020386

********** Iteration 129 ************
Eval_AverageReturn : 186.2412109375
Eval_StdReturn : 0.0
Eval_MaxReturn : 186.2412109375
Eval_MinReturn : 186.2412109375
Eval_AverageEpLen : 485.0
Train_AverageReturn : 162.3794708251953
Train_StdReturn : 111.50948333740234
Train_MaxReturn : 295.483642578125
Train_MinReturn : 28.792251586914062
Train_AverageEpLen : 325.14285714285717
Actor Loss : 9320.4931640625
Baseline Loss : 1755.205078125
Train_EnvstepsSoFar : 285034
TimeSinceStart : 626.9981286525726

********** Iteration 130 ************
Eval_AverageReturn : 253.829833984375
Eval_StdReturn : 0.0
Eval_MaxReturn : 253.829833984375
Eval_MinReturn : 253.829833984375
Eval_AverageEpLen : 416.0
Train_AverageReturn : 157.71115112304688
Train_StdReturn : 118.14584350585938
Train_MaxReturn : 294.4335021972656
Train_MinReturn : 9.866622924804688
Train_AverageEpLen : 515.75
Actor Loss : 2553.14111328125
Baseline Loss : 1500.39208984375
Train_EnvstepsSoFar : 287097
TimeSinceStart : 630.7274277210236

********** Iteration 131 ************
Eval_AverageReturn : 32.9418830871582
Eval_StdReturn : 34.08003616333008
Eval_MaxReturn : 67.02191925048828
Eval_MinReturn : -1.138153076171875
Eval_AverageEpLen : 255.5
Train_AverageReturn : 203.39053344726562
Train_StdReturn : 96.23151397705078
Train_MaxReturn : 280.69464111328125
Train_MinReturn : -23.52043914794922
Train_AverageEpLen : 348.7142857142857
Actor Loss : 11951.4404296875
Baseline Loss : 1764.965576171875
Train_EnvstepsSoFar : 289538
TimeSinceStart : 634.7319071292877

********** Iteration 132 ************
Eval_AverageReturn : 149.09317016601562
Eval_StdReturn : 105.46505737304688
Eval_MaxReturn : 254.5582275390625
Eval_MinReturn : 43.628116607666016
Eval_AverageEpLen : 276.0
Train_AverageReturn : 244.0353546142578
Train_StdReturn : 20.813312530517578
Train_MaxReturn : 259.841064453125
Train_MinReturn : 199.61497497558594
Train_AverageEpLen : 400.1666666666667
Actor Loss : 11494.70703125
Baseline Loss : 1125.2626953125
Train_EnvstepsSoFar : 291939
TimeSinceStart : 638.4144859313965

********** Iteration 133 ************
Eval_AverageReturn : 134.27627563476562
Eval_StdReturn : 107.5172119140625
Eval_MaxReturn : 241.79348754882812
Eval_MinReturn : 26.759056091308594
Eval_AverageEpLen : 257.0
Train_AverageReturn : 150.78860473632812
Train_StdReturn : 120.26414489746094
Train_MaxReturn : 284.5645751953125
Train_MinReturn : 1.1794872283935547
Train_AverageEpLen : 295.2857142857143
Actor Loss : 1527.591796875
Baseline Loss : 2135.06005859375
Train_EnvstepsSoFar : 294006
TimeSinceStart : 641.5067899227142

********** Iteration 134 ************
Eval_AverageReturn : 11.637672424316406
Eval_StdReturn : 22.469865798950195
Eval_MaxReturn : 40.029136657714844
Eval_MinReturn : -14.918716430664062
Eval_AverageEpLen : 204.33333333333334
Train_AverageReturn : 82.58750915527344
Train_StdReturn : 107.65481567382812
Train_MaxReturn : 270.91119384765625
Train_MinReturn : -15.782890319824219
Train_AverageEpLen : 292.42857142857144
Actor Loss : -8695.5087890625
Baseline Loss : 2775.808349609375
Train_EnvstepsSoFar : 296053
TimeSinceStart : 644.8155131340027

********** Iteration 135 ************
Eval_AverageReturn : 134.12225341796875
Eval_StdReturn : 135.2760009765625
Eval_MaxReturn : 269.39825439453125
Eval_MinReturn : -1.1537399291992188
Eval_AverageEpLen : 275.0
Train_AverageReturn : 139.98719787597656
Train_StdReturn : 107.3333969116211
Train_MaxReturn : 261.96588134765625
Train_MinReturn : 7.064704895019531
Train_AverageEpLen : 318.7142857142857
Actor Loss : -2521.868408203125
Baseline Loss : 2037.2255859375
Train_EnvstepsSoFar : 298284
TimeSinceStart : 648.282785654068

********** Iteration 136 ************
Eval_AverageReturn : 108.20109558105469
Eval_StdReturn : 128.47433471679688
Eval_MaxReturn : 236.67543029785156
Eval_MinReturn : -20.27324676513672
Eval_AverageEpLen : 270.0
Train_AverageReturn : 137.8011932373047
Train_StdReturn : 116.57801818847656
Train_MaxReturn : 263.8854064941406
Train_MinReturn : -26.764083862304688
Train_AverageEpLen : 271.875
Actor Loss : -878.3515014648438
Baseline Loss : 2320.456298828125
Train_EnvstepsSoFar : 300459
TimeSinceStart : 651.8421406745911

********** Iteration 137 ************
Eval_AverageReturn : 105.70199584960938
Eval_StdReturn : 108.2565689086914
Eval_MaxReturn : 213.95855712890625
Eval_MinReturn : -2.5545730590820312
Eval_AverageEpLen : 221.5
Train_AverageReturn : 168.63946533203125
Train_StdReturn : 119.92305755615234
Train_MaxReturn : 275.8573303222656
Train_MinReturn : 0.14333724975585938
Train_AverageEpLen : 267.25
Actor Loss : 3384.09765625
Baseline Loss : 2216.147216796875
Train_EnvstepsSoFar : 302597
TimeSinceStart : 655.0927641391754

********** Iteration 138 ************
Eval_AverageReturn : 225.83389282226562
Eval_StdReturn : 0.0
Eval_MaxReturn : 225.83389282226562
Eval_MinReturn : 225.83389282226562
Eval_AverageEpLen : 451.0
Train_AverageReturn : 108.23407745361328
Train_StdReturn : 118.2261734008789
Train_MaxReturn : 254.15792846679688
Train_MinReturn : -51.950069427490234
Train_AverageEpLen : 301.57142857142856
Actor Loss : -7746.91015625
Baseline Loss : 2099.662109375
Train_EnvstepsSoFar : 304708
TimeSinceStart : 658.6007173061371

********** Iteration 139 ************
Eval_AverageReturn : 197.84750366210938
Eval_StdReturn : 19.37017822265625
Eval_MaxReturn : 217.21768188476562
Eval_MinReturn : 178.47732543945312
Eval_AverageEpLen : 355.5
Train_AverageReturn : 149.7205810546875
Train_StdReturn : 114.91251373291016
Train_MaxReturn : 277.0010986328125
Train_MinReturn : -12.404304504394531
Train_AverageEpLen : 287.375
Actor Loss : -2819.048095703125
Baseline Loss : 2040.4788818359375
Train_EnvstepsSoFar : 307007
TimeSinceStart : 662.442099571228

********** Iteration 140 ************
Eval_AverageReturn : 117.0691146850586
Eval_StdReturn : 127.8440933227539
Eval_MaxReturn : 244.9132080078125
Eval_MinReturn : -10.774978637695312
Eval_AverageEpLen : 331.0
Train_AverageReturn : 49.009071350097656
Train_StdReturn : 131.09475708007812
Train_MaxReturn : 273.9940490722656
Train_MinReturn : -68.0716552734375
Train_AverageEpLen : 299.2857142857143
Actor Loss : -22466.572265625
Baseline Loss : 3772.924560546875
Train_EnvstepsSoFar : 309102
TimeSinceStart : 666.024272441864

********** Iteration 141 ************
Eval_AverageReturn : -40.20990753173828
Eval_StdReturn : 21.185205459594727
Eval_MaxReturn : -19.024703979492188
Eval_MinReturn : -61.39511489868164
Eval_AverageEpLen : 306.5
Train_AverageReturn : 117.10636138916016
Train_StdReturn : 117.52303314208984
Train_MaxReturn : 229.458984375
Train_MinReturn : -55.91447448730469
Train_AverageEpLen : 356.6666666666667
Actor Loss : -12863.126953125
Baseline Loss : 2249.592529296875
Train_EnvstepsSoFar : 311242
TimeSinceStart : 669.9725635051727

********** Iteration 142 ************
Eval_AverageReturn : 207.94317626953125
Eval_StdReturn : 0.0
Eval_MaxReturn : 207.94317626953125
Eval_MinReturn : 207.94317626953125
Eval_AverageEpLen : 444.0
Train_AverageReturn : 105.6462173461914
Train_StdReturn : 117.92385864257812
Train_MaxReturn : 224.79348754882812
Train_MinReturn : -60.150840759277344
Train_AverageEpLen : 400.8333333333333
Actor Loss : -16605.7265625
Baseline Loss : 1971.3245849609375
Train_EnvstepsSoFar : 313647
TimeSinceStart : 674.4119389057159

********** Iteration 143 ************
Eval_AverageReturn : 71.03083801269531
Eval_StdReturn : 131.38174438476562
Eval_MaxReturn : 202.41259765625
Eval_MinReturn : -60.350914001464844
Eval_AverageEpLen : 316.5
Train_AverageReturn : 155.5657196044922
Train_StdReturn : 83.74986267089844
Train_MaxReturn : 239.70909118652344
Train_MinReturn : 2.9527130126953125
Train_AverageEpLen : 428.0
Actor Loss : -6533.263671875
Baseline Loss : 1331.078125
Train_EnvstepsSoFar : 315787
TimeSinceStart : 678.4866290092468

********** Iteration 144 ************
Eval_AverageReturn : 58.801876068115234
Eval_StdReturn : 120.13240051269531
Eval_MaxReturn : 178.9342803955078
Eval_MinReturn : -61.330528259277344
Eval_AverageEpLen : 342.5
Train_AverageReturn : 87.80091094970703
Train_StdReturn : 148.11793518066406
Train_MaxReturn : 238.7661895751953
Train_MinReturn : -134.50575256347656
Train_AverageEpLen : 387.3333333333333
Actor Loss : -12982.46875
Baseline Loss : 2354.823974609375
Train_EnvstepsSoFar : 318111
TimeSinceStart : 682.674498796463

********** Iteration 145 ************
Eval_AverageReturn : 147.69044494628906
Eval_StdReturn : 0.0
Eval_MaxReturn : 147.69044494628906
Eval_MinReturn : 147.69044494628906
Eval_AverageEpLen : 739.0
Train_AverageReturn : 142.85003662109375
Train_StdReturn : 129.5925750732422
Train_MaxReturn : 273.0177307128906
Train_MinReturn : -36.70138931274414
Train_AverageEpLen : 379.0
Actor Loss : -5725.017578125
Baseline Loss : 1907.2532958984375
Train_EnvstepsSoFar : 320385
TimeSinceStart : 687.6226222515106

********** Iteration 146 ************
Eval_AverageReturn : 249.22900390625
Eval_StdReturn : 0.0
Eval_MaxReturn : 249.22900390625
Eval_MinReturn : 249.22900390625
Eval_AverageEpLen : 511.0
Train_AverageReturn : 162.83297729492188
Train_StdReturn : 102.1529541015625
Train_MaxReturn : 241.3501434326172
Train_MinReturn : -33.708099365234375
Train_AverageEpLen : 487.4
Actor Loss : -6785.36669921875
Baseline Loss : 1293.869384765625
Train_EnvstepsSoFar : 322822
TimeSinceStart : 692.263872385025

********** Iteration 147 ************
Eval_AverageReturn : 199.32467651367188
Eval_StdReturn : 0.0
Eval_MaxReturn : 199.32467651367188
Eval_MinReturn : 199.32467651367188
Eval_AverageEpLen : 476.0
Train_AverageReturn : 50.015663146972656
Train_StdReturn : 113.12773132324219
Train_MaxReturn : 190.9505615234375
Train_MinReturn : -78.62715148925781
Train_AverageEpLen : 440.4
Actor Loss : -14840.2841796875
Baseline Loss : 2570.349365234375
Train_EnvstepsSoFar : 325024
TimeSinceStart : 696.3445589542389

********** Iteration 148 ************
Eval_AverageReturn : 215.37686157226562
Eval_StdReturn : 0.0
Eval_MaxReturn : 215.37686157226562
Eval_MinReturn : 215.37686157226562
Eval_AverageEpLen : 673.0
Train_AverageReturn : 139.06292724609375
Train_StdReturn : 122.13209533691406
Train_MaxReturn : 218.21347045898438
Train_MinReturn : -72.14297485351562
Train_AverageEpLen : 561.5
Actor Loss : -10043.8271484375
Baseline Loss : 1346.2091064453125
Train_EnvstepsSoFar : 327270
TimeSinceStart : 701.4445130825043

********** Iteration 149 ************
Eval_AverageReturn : 171.7123565673828
Eval_StdReturn : 0.0
Eval_MaxReturn : 171.7123565673828
Eval_MinReturn : 171.7123565673828
Eval_AverageEpLen : 876.0
Train_AverageReturn : 165.9298095703125
Train_StdReturn : 4.0477614402771
Train_MaxReturn : 171.353759765625
Train_MinReturn : 161.6328582763672
Train_AverageEpLen : 672.6666666666666
Actor Loss : -6914.9326171875
Baseline Loss : 766.2794799804688
Train_EnvstepsSoFar : 329288
TimeSinceStart : 707.1820683479309

********** Iteration 150 ************
Eval_AverageReturn : 212.11764526367188
Eval_StdReturn : 0.0
Eval_MaxReturn : 212.11764526367188
Eval_MinReturn : 212.11764526367188
Eval_AverageEpLen : 604.0
Train_AverageReturn : 195.0196075439453
Train_StdReturn : 44.231143951416016
Train_MaxReturn : 235.07601928710938
Train_MinReturn : 133.3836669921875
Train_AverageEpLen : 666.6666666666666
Actor Loss : -4864.24267578125
Baseline Loss : 872.39208984375
Train_EnvstepsSoFar : 331288
TimeSinceStart : 712.1656363010406

********** Iteration 151 ************
Eval_AverageReturn : 88.88339233398438
Eval_StdReturn : 0.0
Eval_MaxReturn : 88.88339233398438
Eval_MinReturn : 88.88339233398438
Eval_AverageEpLen : 939.0
Train_AverageReturn : 130.0529327392578
Train_StdReturn : 99.60678100585938
Train_MaxReturn : 216.32559204101562
Train_MinReturn : -34.261287689208984
Train_AverageEpLen : 738.5
Actor Loss : -14429.95703125
Baseline Loss : 875.7406005859375
Train_EnvstepsSoFar : 334242
TimeSinceStart : 719.9426498413086

********** Iteration 152 ************
Eval_AverageReturn : -12.219947814941406
Eval_StdReturn : 0.0
Eval_MaxReturn : -12.219947814941406
Eval_MinReturn : -12.219947814941406
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 48.314876556396484
Train_StdReturn : 65.81383514404297
Train_MaxReturn : 97.96829986572266
Train_MinReturn : -44.68877029418945
Train_AverageEpLen : 969.6666666666666
Actor Loss : -21328.2421875
Baseline Loss : 883.3206787109375
Train_EnvstepsSoFar : 337151
TimeSinceStart : 727.5034248828888

********** Iteration 153 ************
Eval_AverageReturn : -15.98251724243164
Eval_StdReturn : 0.0
Eval_MaxReturn : -15.98251724243164
Eval_MinReturn : -15.98251724243164
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -16.148433685302734
Train_StdReturn : 22.18310546875
Train_MaxReturn : 6.034671783447266
Train_MinReturn : -38.331539154052734
Train_AverageEpLen : 1000.0
Actor Loss : -16504.15234375
Baseline Loss : 749.8624267578125
Train_EnvstepsSoFar : 339151
TimeSinceStart : 734.0030996799469

********** Iteration 154 ************
Eval_AverageReturn : 199.037353515625
Eval_StdReturn : 0.0
Eval_MaxReturn : 199.037353515625
Eval_MinReturn : 199.037353515625
Eval_AverageEpLen : 544.0
Train_AverageReturn : 18.438196182250977
Train_StdReturn : 107.34648132324219
Train_MaxReturn : 104.00608825683594
Train_MinReturn : -132.94363403320312
Train_AverageEpLen : 841.3333333333334
Actor Loss : -15725.0126953125
Baseline Loss : 981.3816528320312
Train_EnvstepsSoFar : 341675
TimeSinceStart : 739.4342091083527

********** Iteration 155 ************
Eval_AverageReturn : 147.96096801757812
Eval_StdReturn : 0.0
Eval_MaxReturn : 147.96096801757812
Eval_MinReturn : 147.96096801757812
Eval_AverageEpLen : 726.0
Train_AverageReturn : -80.35823059082031
Train_StdReturn : 23.38216781616211
Train_MaxReturn : -50.33195495605469
Train_MinReturn : -107.36743927001953
Train_AverageEpLen : 933.6666666666666
Actor Loss : -23545.70703125
Baseline Loss : 1115.919921875
Train_EnvstepsSoFar : 344476
TimeSinceStart : 745.9562628269196

********** Iteration 156 ************
Eval_AverageReturn : -168.948486328125
Eval_StdReturn : 0.0
Eval_MaxReturn : -168.948486328125
Eval_MinReturn : -168.948486328125
Eval_AverageEpLen : 792.0
Train_AverageReturn : -81.47596740722656
Train_StdReturn : 19.859577178955078
Train_MaxReturn : -56.00935363769531
Train_MinReturn : -104.46563720703125
Train_AverageEpLen : 907.3333333333334
Actor Loss : -20028.185546875
Baseline Loss : 815.2171630859375
Train_EnvstepsSoFar : 347198
TimeSinceStart : 752.8971657752991

********** Iteration 157 ************
Eval_AverageReturn : -50.18040466308594
Eval_StdReturn : 0.0
Eval_MaxReturn : -50.18040466308594
Eval_MinReturn : -50.18040466308594
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 116.5531234741211
Train_StdReturn : 152.92864990234375
Train_MaxReturn : 243.47518920898438
Train_MinReturn : -98.56163024902344
Train_AverageEpLen : 824.0
Actor Loss : -3943.52197265625
Baseline Loss : 1140.148681640625
Train_EnvstepsSoFar : 349670
TimeSinceStart : 759.3170709609985

********** Iteration 158 ************
Eval_AverageReturn : 211.068359375
Eval_StdReturn : 0.0
Eval_MaxReturn : 211.068359375
Eval_MinReturn : 211.068359375
Eval_AverageEpLen : 605.0
Train_AverageReturn : 26.76612663269043
Train_StdReturn : 142.9314727783203
Train_MaxReturn : 227.43496704101562
Train_MinReturn : -94.61864471435547
Train_AverageEpLen : 883.6666666666666
Actor Loss : -6740.8916015625
Baseline Loss : 671.9161376953125
Train_EnvstepsSoFar : 352321
TimeSinceStart : 764.9149463176727

********** Iteration 159 ************
Eval_AverageReturn : -77.30769348144531
Eval_StdReturn : 0.0
Eval_MaxReturn : -77.30769348144531
Eval_MinReturn : -77.30769348144531
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 87.168212890625
Train_StdReturn : 48.28028106689453
Train_MaxReturn : 143.0451202392578
Train_MinReturn : 25.24730682373047
Train_AverageEpLen : 701.0
Actor Loss : -1549.85107421875
Baseline Loss : 904.0970458984375
Train_EnvstepsSoFar : 354424
TimeSinceStart : 771.4791884422302

********** Iteration 160 ************
Eval_AverageReturn : 106.78756713867188
Eval_StdReturn : 191.75289916992188
Eval_MaxReturn : 298.54046630859375
Eval_MinReturn : -84.96533203125
Eval_AverageEpLen : 622.5
Train_AverageReturn : -89.36587524414062
Train_StdReturn : 37.472015380859375
Train_MaxReturn : -51.96956253051758
Train_MinReturn : -140.5811767578125
Train_AverageEpLen : 911.0
Actor Loss : -12120.748046875
Baseline Loss : 687.6083374023438
Train_EnvstepsSoFar : 357157
TimeSinceStart : 778.6133971214294

********** Iteration 161 ************
Eval_AverageReturn : 120.87083435058594
Eval_StdReturn : 0.0
Eval_MaxReturn : 120.87083435058594
Eval_MinReturn : 120.87083435058594
Eval_AverageEpLen : 561.0
Train_AverageReturn : -111.9737319946289
Train_StdReturn : 80.6903305053711
Train_MaxReturn : -53.46884536743164
Train_MinReturn : -226.07473754882812
Train_AverageEpLen : 835.0
Actor Loss : -12184.2099609375
Baseline Loss : 1382.51123046875
Train_EnvstepsSoFar : 359662
TimeSinceStart : 783.9829251766205

********** Iteration 162 ************
Eval_AverageReturn : -39.041412353515625
Eval_StdReturn : 0.0
Eval_MaxReturn : -39.041412353515625
Eval_MinReturn : -39.041412353515625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -84.26815795898438
Train_StdReturn : 39.78108215332031
Train_MaxReturn : -36.49410629272461
Train_MinReturn : -133.88516235351562
Train_AverageEpLen : 814.0
Actor Loss : -8904.142578125
Baseline Loss : 658.0877075195312
Train_EnvstepsSoFar : 362104
TimeSinceStart : 790.7418324947357

********** Iteration 163 ************
Eval_AverageReturn : -61.29039764404297
Eval_StdReturn : 0.0
Eval_MaxReturn : -61.29039764404297
Eval_MinReturn : -61.29039764404297
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -26.71786880493164
Train_StdReturn : 86.56092834472656
Train_MaxReturn : 141.2005615234375
Train_MinReturn : -107.95309448242188
Train_AverageEpLen : 589.6
Actor Loss : -6974.14501953125
Baseline Loss : 1480.0906982421875
Train_EnvstepsSoFar : 365052
TimeSinceStart : 797.4268825054169

********** Iteration 164 ************
Eval_AverageReturn : -44.33565902709961
Eval_StdReturn : 0.0
Eval_MaxReturn : -44.33565902709961
Eval_MinReturn : -44.33565902709961
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 53.18465042114258
Train_StdReturn : 92.07427978515625
Train_MaxReturn : 158.9364776611328
Train_MinReturn : -65.48580932617188
Train_AverageEpLen : 707.3333333333334
Actor Loss : 2183.326171875
Baseline Loss : 857.1412963867188
Train_EnvstepsSoFar : 367174
TimeSinceStart : 802.6043901443481

********** Iteration 165 ************
Eval_AverageReturn : -36.99291229248047
Eval_StdReturn : 0.0
Eval_MaxReturn : -36.99291229248047
Eval_MinReturn : -36.99291229248047
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 33.110023498535156
Train_StdReturn : 70.77326965332031
Train_MaxReturn : 103.88329315185547
Train_MinReturn : -37.66324234008789
Train_AverageEpLen : 1000.0
Actor Loss : 1013.6046142578125
Baseline Loss : 312.1431579589844
Train_EnvstepsSoFar : 369174
TimeSinceStart : 808.1816642284393

********** Iteration 166 ************
Eval_AverageReturn : -49.183860778808594
Eval_StdReturn : 0.0
Eval_MaxReturn : -49.183860778808594
Eval_MinReturn : -49.183860778808594
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -61.7568244934082
Train_StdReturn : 13.103878021240234
Train_MaxReturn : -48.65294647216797
Train_MinReturn : -74.86070251464844
Train_AverageEpLen : 1000.0
Actor Loss : -2117.265625
Baseline Loss : 274.9007873535156
Train_EnvstepsSoFar : 371174
TimeSinceStart : 815.6134271621704

********** Iteration 167 ************
Eval_AverageReturn : -55.966548919677734
Eval_StdReturn : 0.0
Eval_MaxReturn : -55.966548919677734
Eval_MinReturn : -55.966548919677734
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -65.24081420898438
Train_StdReturn : 7.065006256103516
Train_MaxReturn : -58.175811767578125
Train_MinReturn : -72.30582427978516
Train_AverageEpLen : 1000.0
Actor Loss : -2145.79052734375
Baseline Loss : 161.2855682373047
Train_EnvstepsSoFar : 373174
TimeSinceStart : 820.9984035491943

********** Iteration 168 ************
Eval_AverageReturn : -65.30760192871094
Eval_StdReturn : 0.0
Eval_MaxReturn : -65.30760192871094
Eval_MinReturn : -65.30760192871094
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -86.12405395507812
Train_StdReturn : 16.5526123046875
Train_MaxReturn : -69.57144165039062
Train_MinReturn : -102.67666625976562
Train_AverageEpLen : 1000.0
Actor Loss : -2478.5888671875
Baseline Loss : 148.22036743164062
Train_EnvstepsSoFar : 375174
TimeSinceStart : 826.8144905567169

********** Iteration 169 ************
Eval_AverageReturn : -58.95737075805664
Eval_StdReturn : 0.0
Eval_MaxReturn : -58.95737075805664
Eval_MinReturn : -58.95737075805664
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -61.5552978515625
Train_StdReturn : 18.495615005493164
Train_MaxReturn : -43.0596809387207
Train_MinReturn : -80.05091094970703
Train_AverageEpLen : 1000.0
Actor Loss : -1841.290771484375
Baseline Loss : 138.44522094726562
Train_EnvstepsSoFar : 377174
TimeSinceStart : 833.2298309803009

********** Iteration 170 ************
Eval_AverageReturn : -53.43130111694336
Eval_StdReturn : 0.0
Eval_MaxReturn : -53.43130111694336
Eval_MinReturn : -53.43130111694336
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -39.00016784667969
Train_StdReturn : 2.3183231353759766
Train_MaxReturn : -36.681846618652344
Train_MinReturn : -41.3184928894043
Train_AverageEpLen : 1000.0
Actor Loss : -215.24395751953125
Baseline Loss : 278.6521911621094
Train_EnvstepsSoFar : 379174
TimeSinceStart : 839.8933634757996

********** Iteration 171 ************
Eval_AverageReturn : -61.296142578125
Eval_StdReturn : 0.0
Eval_MaxReturn : -61.296142578125
Eval_MinReturn : -61.296142578125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -59.23735046386719
Train_StdReturn : 11.282913208007812
Train_MaxReturn : -47.954437255859375
Train_MinReturn : -70.520263671875
Train_AverageEpLen : 1000.0
Actor Loss : -876.97705078125
Baseline Loss : 195.36412048339844
Train_EnvstepsSoFar : 381174
TimeSinceStart : 847.0482592582703

********** Iteration 172 ************
Eval_AverageReturn : -44.59355926513672
Eval_StdReturn : 0.0
Eval_MaxReturn : -44.59355926513672
Eval_MinReturn : -44.59355926513672
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -40.24213790893555
Train_StdReturn : 33.96834182739258
Train_MaxReturn : -6.273796081542969
Train_MinReturn : -74.21047973632812
Train_AverageEpLen : 1000.0
Actor Loss : -159.19992065429688
Baseline Loss : 297.97674560546875
Train_EnvstepsSoFar : 383174
TimeSinceStart : 855.8496689796448

********** Iteration 173 ************
Eval_AverageReturn : -45.67979049682617
Eval_StdReturn : 0.0
Eval_MaxReturn : -45.67979049682617
Eval_MinReturn : -45.67979049682617
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 22.786462783813477
Train_StdReturn : 82.69170379638672
Train_MaxReturn : 139.02719116210938
Train_MinReturn : -46.421993255615234
Train_AverageEpLen : 973.6666666666666
Actor Loss : 3209.45654296875
Baseline Loss : 547.740234375
Train_EnvstepsSoFar : 386095
TimeSinceStart : 865.4651253223419

********** Iteration 174 ************
Eval_AverageReturn : 209.98680114746094
Eval_StdReturn : 72.96305847167969
Eval_MaxReturn : 282.9498596191406
Eval_MinReturn : 137.02374267578125
Eval_AverageEpLen : 630.5
Train_AverageReturn : -3.638782501220703
Train_StdReturn : 89.18364715576172
Train_MaxReturn : 120.00556182861328
Train_MinReturn : -87.01647186279297
Train_AverageEpLen : 888.0
Actor Loss : -397.01080322265625
Baseline Loss : 798.3040771484375
Train_EnvstepsSoFar : 388759
TimeSinceStart : 873.6723902225494

********** Iteration 175 ************
Eval_AverageReturn : 172.7445068359375
Eval_StdReturn : 0.0
Eval_MaxReturn : 172.7445068359375
Eval_MinReturn : 172.7445068359375
Eval_AverageEpLen : 657.0
Train_AverageReturn : 140.58692932128906
Train_StdReturn : 133.03704833984375
Train_MaxReturn : 249.06243896484375
Train_MinReturn : -46.77887725830078
Train_AverageEpLen : 688.6666666666666
Actor Loss : 11447.017578125
Baseline Loss : 1368.27197265625
Train_EnvstepsSoFar : 390825
TimeSinceStart : 878.4921684265137

********** Iteration 176 ************
Eval_AverageReturn : 248.73294067382812
Eval_StdReturn : 0.0
Eval_MaxReturn : 248.73294067382812
Eval_MinReturn : 248.73294067382812
Eval_AverageEpLen : 434.0
Train_AverageReturn : 120.23201751708984
Train_StdReturn : 40.592041015625
Train_MaxReturn : 177.53875732421875
Train_MinReturn : 88.65914916992188
Train_AverageEpLen : 792.6666666666666
Actor Loss : 9809.435546875
Baseline Loss : 1015.3863525390625
Train_EnvstepsSoFar : 393203
TimeSinceStart : 883.7604992389679

********** Iteration 177 ************
Eval_AverageReturn : 171.69757080078125
Eval_StdReturn : 0.0
Eval_MaxReturn : 171.69757080078125
Eval_MinReturn : 171.69757080078125
Eval_AverageEpLen : 544.0
Train_AverageReturn : 122.19805908203125
Train_StdReturn : 117.42227935791016
Train_MaxReturn : 222.34112548828125
Train_MinReturn : -27.346595764160156
Train_AverageEpLen : 472.2
Actor Loss : 11521.314453125
Baseline Loss : 2230.015625
Train_EnvstepsSoFar : 395564
TimeSinceStart : 888.2347228527069

********** Iteration 178 ************
Eval_AverageReturn : 211.22219848632812
Eval_StdReturn : 0.0
Eval_MaxReturn : 211.22219848632812
Eval_MinReturn : 211.22219848632812
Eval_AverageEpLen : 550.0
Train_AverageReturn : 216.8611297607422
Train_StdReturn : 60.154476165771484
Train_MaxReturn : 284.856201171875
Train_MinReturn : 136.1914520263672
Train_AverageEpLen : 567.75
Actor Loss : 16075.7392578125
Baseline Loss : 2019.6605224609375
Train_EnvstepsSoFar : 397835
TimeSinceStart : 892.7354142665863

********** Iteration 179 ************
Eval_AverageReturn : 254.6256866455078
Eval_StdReturn : 11.922775268554688
Eval_MaxReturn : 266.5484619140625
Eval_MinReturn : 242.70291137695312
Eval_AverageEpLen : 401.5
Train_AverageReturn : 204.51817321777344
Train_StdReturn : 81.66567993164062
Train_MaxReturn : 281.7359619140625
Train_MinReturn : 28.209136962890625
Train_AverageEpLen : 394.5
Actor Loss : 21773.1171875
Baseline Loss : 2361.67138671875
Train_EnvstepsSoFar : 400202
TimeSinceStart : 897.687581539154

********** Iteration 180 ************
Eval_AverageReturn : 111.74494934082031
Eval_StdReturn : 97.53931427001953
Eval_MaxReturn : 209.28427124023438
Eval_MinReturn : 14.205635070800781
Eval_AverageEpLen : 332.0
Train_AverageReturn : 265.578125
Train_StdReturn : 17.13248062133789
Train_MaxReturn : 288.296142578125
Train_MinReturn : 243.45315551757812
Train_AverageEpLen : 359.8333333333333
Actor Loss : 23139.01171875
Baseline Loss : 2829.924072265625
Train_EnvstepsSoFar : 402361
TimeSinceStart : 901.5659682750702

********** Iteration 181 ************
Eval_AverageReturn : 242.70501708984375
Eval_StdReturn : 6.9808197021484375
Eval_MaxReturn : 249.6858367919922
Eval_MinReturn : 235.7241973876953
Eval_AverageEpLen : 341.0
Train_AverageReturn : 255.3253631591797
Train_StdReturn : 5.994099140167236
Train_MaxReturn : 262.4828796386719
Train_MinReturn : 247.7834930419922
Train_AverageEpLen : 463.4
Actor Loss : 16002.4833984375
Baseline Loss : 1522.5443115234375
Train_EnvstepsSoFar : 404678
TimeSinceStart : 906.1182816028595

********** Iteration 182 ************
Eval_AverageReturn : 245.08279418945312
Eval_StdReturn : 4.8243408203125
Eval_MaxReturn : 249.90713500976562
Eval_MinReturn : 240.25845336914062
Eval_AverageEpLen : 344.5
Train_AverageReturn : 201.04269409179688
Train_StdReturn : 95.25682067871094
Train_MaxReturn : 281.74017333984375
Train_MinReturn : -21.86724853515625
Train_AverageEpLen : 343.14285714285717
Actor Loss : 12599.6708984375
Baseline Loss : 2019.294921875
Train_EnvstepsSoFar : 407080
TimeSinceStart : 910.4839549064636

********** Iteration 183 ************
Eval_AverageReturn : 224.138916015625
Eval_StdReturn : 0.0
Eval_MaxReturn : 224.138916015625
Eval_MinReturn : 224.138916015625
Eval_AverageEpLen : 494.0
Train_AverageReturn : 221.9285125732422
Train_StdReturn : 103.45964813232422
Train_MaxReturn : 307.2016296386719
Train_MinReturn : -25.80358123779297
Train_AverageEpLen : 308.57142857142856
Actor Loss : 13513.158203125
Baseline Loss : 2271.790283203125
Train_EnvstepsSoFar : 409240
TimeSinceStart : 914.1801176071167

********** Iteration 184 ************
Eval_AverageReturn : 200.4893035888672
Eval_StdReturn : 2.6595001220703125
Eval_MaxReturn : 203.1488037109375
Eval_MinReturn : 197.82980346679688
Eval_AverageEpLen : 377.5
Train_AverageReturn : 113.36260223388672
Train_StdReturn : 116.96695709228516
Train_MaxReturn : 260.9351806640625
Train_MinReturn : -20.710365295410156
Train_AverageEpLen : 337.1666666666667
Actor Loss : -5129.869140625
Baseline Loss : 1993.8131103515625
Train_EnvstepsSoFar : 411263
TimeSinceStart : 917.5598297119141

********** Iteration 185 ************
Eval_AverageReturn : 114.19476318359375
Eval_StdReturn : 119.50151062011719
Eval_MaxReturn : 233.69627380371094
Eval_MinReturn : -5.306743621826172
Eval_AverageEpLen : 260.5
Train_AverageReturn : 208.5792236328125
Train_StdReturn : 108.7496566772461
Train_MaxReturn : 296.30731201171875
Train_MinReturn : -49.175209045410156
Train_AverageEpLen : 300.85714285714283
Actor Loss : 5599.17626953125
Baseline Loss : 1957.0238037109375
Train_EnvstepsSoFar : 413369
TimeSinceStart : 920.549732208252

********** Iteration 186 ************
Eval_AverageReturn : -24.39598846435547
Eval_StdReturn : 6.233589172363281
Eval_MaxReturn : -18.162399291992188
Eval_MinReturn : -30.62957763671875
Eval_AverageEpLen : 213.5
Train_AverageReturn : 189.69915771484375
Train_StdReturn : 113.30547332763672
Train_MaxReturn : 283.250244140625
Train_MinReturn : -43.437034606933594
Train_AverageEpLen : 272.875
Actor Loss : 7524.9658203125
Baseline Loss : 1898.9111328125
Train_EnvstepsSoFar : 415552
TimeSinceStart : 923.8246290683746

********** Iteration 187 ************
Eval_AverageReturn : 230.21859741210938
Eval_StdReturn : 6.2425537109375
Eval_MaxReturn : 236.46115112304688
Eval_MinReturn : 223.97604370117188
Eval_AverageEpLen : 290.5
Train_AverageReturn : 121.60018920898438
Train_StdReturn : 130.4290008544922
Train_MaxReturn : 284.4825439453125
Train_MinReturn : -39.010093688964844
Train_AverageEpLen : 266.875
Actor Loss : -7176.82666015625
Baseline Loss : 3170.253173828125
Train_EnvstepsSoFar : 417687
TimeSinceStart : 926.8588502407074

********** Iteration 188 ************
Eval_AverageReturn : 143.90733337402344
Eval_StdReturn : 127.8574447631836
Eval_MaxReturn : 271.7647705078125
Eval_MinReturn : 16.049888610839844
Eval_AverageEpLen : 240.5
Train_AverageReturn : 122.07347869873047
Train_StdReturn : 137.04547119140625
Train_MaxReturn : 275.60357666015625
Train_MinReturn : -73.871826171875
Train_AverageEpLen : 287.5
Actor Loss : -6950.6552734375
Baseline Loss : 2790.39501953125
Train_EnvstepsSoFar : 419987
TimeSinceStart : 930.1325123310089

********** Iteration 189 ************
Eval_AverageReturn : 116.96730041503906
Eval_StdReturn : 174.58230590820312
Eval_MaxReturn : 291.5495910644531
Eval_MinReturn : -57.61499786376953
Eval_AverageEpLen : 247.5
Train_AverageReturn : 120.73367309570312
Train_StdReturn : 119.26848602294922
Train_MaxReturn : 304.49627685546875
Train_MinReturn : -32.353939056396484
Train_AverageEpLen : 224.22222222222223
Actor Loss : -6249.408203125
Baseline Loss : 2844.20654296875
Train_EnvstepsSoFar : 422005
TimeSinceStart : 933.1431634426117

********** Iteration 190 ************
Eval_AverageReturn : 142.12875366210938
Eval_StdReturn : 90.04911804199219
Eval_MaxReturn : 232.17787170410156
Eval_MinReturn : 52.07963562011719
Eval_AverageEpLen : 253.5
Train_AverageReturn : 201.8087615966797
Train_StdReturn : 119.39891052246094
Train_MaxReturn : 305.2018127441406
Train_MinReturn : -2.44329833984375
Train_AverageEpLen : 378.3333333333333
Actor Loss : -2781.166015625
Baseline Loss : 2373.14404296875
Train_EnvstepsSoFar : 424275
TimeSinceStart : 936.953873872757

********** Iteration 191 ************
Eval_AverageReturn : 225.74044799804688
Eval_StdReturn : 0.0
Eval_MaxReturn : 225.74044799804688
Eval_MinReturn : 225.74044799804688
Eval_AverageEpLen : 645.0
Train_AverageReturn : 117.55586242675781
Train_StdReturn : 126.5684585571289
Train_MaxReturn : 302.4869079589844
Train_MinReturn : -16.797874450683594
Train_AverageEpLen : 408.0
Actor Loss : -10415.4697265625
Baseline Loss : 2121.259765625
Train_EnvstepsSoFar : 426315
TimeSinceStart : 941.264347076416

********** Iteration 192 ************
Eval_AverageReturn : 60.80983352661133
Eval_StdReturn : 31.132022857666016
Eval_MaxReturn : 91.94185638427734
Eval_MinReturn : 29.677810668945312
Eval_AverageEpLen : 615.0
Train_AverageReturn : 163.4490509033203
Train_StdReturn : 138.4979248046875
Train_MaxReturn : 305.163818359375
Train_MinReturn : -36.059329986572266
Train_AverageEpLen : 257.125
Actor Loss : -1931.819091796875
Baseline Loss : 3100.697998046875
Train_EnvstepsSoFar : 428372
TimeSinceStart : 945.7010521888733

********** Iteration 193 ************
Eval_AverageReturn : 193.53878784179688
Eval_StdReturn : 4.473670959472656
Eval_MaxReturn : 198.012451171875
Eval_MinReturn : 189.0651092529297
Eval_AverageEpLen : 359.0
Train_AverageReturn : 163.76234436035156
Train_StdReturn : 123.15067291259766
Train_MaxReturn : 259.8272705078125
Train_MinReturn : -35.75214385986328
Train_AverageEpLen : 288.14285714285717
Actor Loss : -1055.677978515625
Baseline Loss : 2573.74609375
Train_EnvstepsSoFar : 430389
TimeSinceStart : 949.302806854248

********** Iteration 194 ************
Eval_AverageReturn : 251.3175506591797
Eval_StdReturn : 3.8884124755859375
Eval_MaxReturn : 255.20596313476562
Eval_MinReturn : 247.42913818359375
Eval_AverageEpLen : 314.5
Train_AverageReturn : 152.53909301757812
Train_StdReturn : 123.06317138671875
Train_MaxReturn : 281.7830810546875
Train_MinReturn : -16.34424591064453
Train_AverageEpLen : 275.0
Actor Loss : -1858.195556640625
Baseline Loss : 2259.648681640625
Train_EnvstepsSoFar : 432589
TimeSinceStart : 953.0771007537842

********** Iteration 195 ************
Eval_AverageReturn : 139.2802734375
Eval_StdReturn : 78.62097930908203
Eval_MaxReturn : 217.9012451171875
Eval_MinReturn : 60.65929412841797
Eval_AverageEpLen : 661.0
Train_AverageReturn : 185.34487915039062
Train_StdReturn : 109.71659088134766
Train_MaxReturn : 294.8084411621094
Train_MinReturn : -15.907493591308594
Train_AverageEpLen : 280.25
Actor Loss : 5506.2939453125
Baseline Loss : 1534.2196044921875
Train_EnvstepsSoFar : 434831
TimeSinceStart : 957.8933899402618

********** Iteration 196 ************
Eval_AverageReturn : 239.19515991210938
Eval_StdReturn : 6.903472900390625
Eval_MaxReturn : 246.0986328125
Eval_MinReturn : 232.29168701171875
Eval_AverageEpLen : 335.5
Train_AverageReturn : 140.30499267578125
Train_StdReturn : 115.13642883300781
Train_MaxReturn : 263.80059814453125
Train_MinReturn : -11.55291748046875
Train_AverageEpLen : 312.57142857142856
Actor Loss : -7557.818359375
Baseline Loss : 2209.41943359375
Train_EnvstepsSoFar : 437019
TimeSinceStart : 961.9895312786102

********** Iteration 197 ************
Eval_AverageReturn : 212.5037078857422
Eval_StdReturn : 0.0
Eval_MaxReturn : 212.5037078857422
Eval_MinReturn : 212.5037078857422
Eval_AverageEpLen : 484.0
Train_AverageReturn : 245.61146545410156
Train_StdReturn : 14.349072456359863
Train_MaxReturn : 265.64935302734375
Train_MinReturn : 225.99755859375
Train_AverageEpLen : 343.8333333333333
Actor Loss : 5084.1884765625
Baseline Loss : 875.1608276367188
Train_EnvstepsSoFar : 439082
TimeSinceStart : 965.7356512546539

********** Iteration 198 ************
Eval_AverageReturn : 211.64076232910156
Eval_StdReturn : 0.0
Eval_MaxReturn : 211.64076232910156
Eval_MinReturn : 211.64076232910156
Eval_AverageEpLen : 514.0
Train_AverageReturn : 257.6762390136719
Train_StdReturn : 26.651403427124023
Train_MaxReturn : 296.59423828125
Train_MinReturn : 219.7487335205078
Train_AverageEpLen : 366.6666666666667
Actor Loss : 2406.568359375
Baseline Loss : 973.1580810546875
Train_EnvstepsSoFar : 441282
TimeSinceStart : 969.7641263008118

********** Iteration 199 ************
Eval_AverageReturn : 217.6504669189453
Eval_StdReturn : 0.0
Eval_MaxReturn : 217.6504669189453
Eval_MinReturn : 217.6504669189453
Eval_AverageEpLen : 522.0
Train_AverageReturn : 228.6151123046875
Train_StdReturn : 18.939640045166016
Train_MaxReturn : 254.29345703125
Train_MinReturn : 208.04025268554688
Train_AverageEpLen : 490.0
Actor Loss : -9229.6611328125
Baseline Loss : 873.6583251953125
Train_EnvstepsSoFar : 443732
TimeSinceStart : 974.3706569671631

********** Iteration 200 ************
Eval_AverageReturn : 209.40682983398438
Eval_StdReturn : 0.0
Eval_MaxReturn : 209.40682983398438
Eval_MinReturn : 209.40682983398438
Eval_AverageEpLen : 421.0
Train_AverageReturn : 242.30886840820312
Train_StdReturn : 26.554018020629883
Train_MaxReturn : 278.2054443359375
Train_MinReturn : 208.11624145507812
Train_AverageEpLen : 519.0
Actor Loss : -6902.4677734375
Baseline Loss : 915.2664794921875
Train_EnvstepsSoFar : 445808
TimeSinceStart : 978.411746263504

********** Iteration 201 ************
Eval_AverageReturn : 212.7167510986328
Eval_StdReturn : 0.0
Eval_MaxReturn : 212.7167510986328
Eval_MinReturn : 212.7167510986328
Eval_AverageEpLen : 605.0
Train_AverageReturn : 170.4406280517578
Train_StdReturn : 64.11058807373047
Train_MaxReturn : 239.27725219726562
Train_MinReturn : 50.53129577636719
Train_AverageEpLen : 534.4
Actor Loss : -15084.39453125
Baseline Loss : 1278.3326416015625
Train_EnvstepsSoFar : 448480
TimeSinceStart : 984.2752819061279

********** Iteration 202 ************
Eval_AverageReturn : 149.30667114257812
Eval_StdReturn : 0.0
Eval_MaxReturn : 149.30667114257812
Eval_MinReturn : 149.30667114257812
Eval_AverageEpLen : 582.0
Train_AverageReturn : 219.86636352539062
Train_StdReturn : 51.951171875
Train_MaxReturn : 278.8997802734375
Train_MinReturn : 146.7545166015625
Train_AverageEpLen : 573.0
Actor Loss : -13530.9130859375
Baseline Loss : 1221.455322265625
Train_EnvstepsSoFar : 450772
TimeSinceStart : 989.106302022934

********** Iteration 203 ************
Eval_AverageReturn : 245.30018615722656
Eval_StdReturn : 15.653793334960938
Eval_MaxReturn : 260.9539794921875
Eval_MinReturn : 229.64639282226562
Eval_AverageEpLen : 378.0
Train_AverageReturn : 215.79441833496094
Train_StdReturn : 31.182077407836914
Train_MaxReturn : 250.38760375976562
Train_MinReturn : 169.74923706054688
Train_AverageEpLen : 507.0
Actor Loss : -8859.3740234375
Baseline Loss : 992.0948486328125
Train_EnvstepsSoFar : 452800
TimeSinceStart : 993.3821911811829

********** Iteration 204 ************
Eval_AverageReturn : 242.88807678222656
Eval_StdReturn : 0.0
Eval_MaxReturn : 242.88807678222656
Eval_MinReturn : 242.88807678222656
Eval_AverageEpLen : 410.0
Train_AverageReturn : 230.6549835205078
Train_StdReturn : 23.10350227355957
Train_MaxReturn : 258.8077087402344
Train_MinReturn : 203.06422424316406
Train_AverageEpLen : 482.0
Actor Loss : -6462.42041015625
Baseline Loss : 1025.169921875
Train_EnvstepsSoFar : 455210
TimeSinceStart : 997.8141360282898

********** Iteration 205 ************
Eval_AverageReturn : 227.49465942382812
Eval_StdReturn : 0.0
Eval_MaxReturn : 227.49465942382812
Eval_MinReturn : 227.49465942382812
Eval_AverageEpLen : 433.0
Train_AverageReturn : 175.54678344726562
Train_StdReturn : 93.17671966552734
Train_MaxReturn : 254.28887939453125
Train_MinReturn : 1.2384719848632812
Train_AverageEpLen : 338.0
Actor Loss : -3332.767822265625
Baseline Loss : 1206.9481201171875
Train_EnvstepsSoFar : 457576
TimeSinceStart : 1002.0663061141968

********** Iteration 206 ************
Eval_AverageReturn : 249.11546325683594
Eval_StdReturn : 9.969863891601562
Eval_MaxReturn : 259.0853271484375
Eval_MinReturn : 239.14559936523438
Eval_AverageEpLen : 352.5
Train_AverageReturn : 175.36090087890625
Train_StdReturn : 98.41840362548828
Train_MaxReturn : 289.4681701660156
Train_MinReturn : -6.7611846923828125
Train_AverageEpLen : 404.6
Actor Loss : -4303.73486328125
Baseline Loss : 1355.386474609375
Train_EnvstepsSoFar : 459599
TimeSinceStart : 1005.8790202140808

********** Iteration 207 ************
Eval_AverageReturn : 223.46786499023438
Eval_StdReturn : 5.300971984863281
Eval_MaxReturn : 228.7688446044922
Eval_MinReturn : 218.16690063476562
Eval_AverageEpLen : 373.5
Train_AverageReturn : 166.0161895751953
Train_StdReturn : 113.78237915039062
Train_MaxReturn : 278.4986267089844
Train_MinReturn : -15.641166687011719
Train_AverageEpLen : 320.2857142857143
Actor Loss : -1993.2174072265625
Baseline Loss : 2233.625
Train_EnvstepsSoFar : 461841
TimeSinceStart : 1010.016622543335

********** Iteration 208 ************
Eval_AverageReturn : 259.65948486328125
Eval_StdReturn : 15.449508666992188
Eval_MaxReturn : 275.1090087890625
Eval_MinReturn : 244.20999145507812
Eval_AverageEpLen : 318.5
Train_AverageReturn : 134.6352996826172
Train_StdReturn : 120.75933837890625
Train_MaxReturn : 267.8638610839844
Train_MinReturn : -7.174324035644531
Train_AverageEpLen : 269.375
Actor Loss : -6617.50146484375
Baseline Loss : 2942.96337890625
Train_EnvstepsSoFar : 463996
TimeSinceStart : 1013.7107589244843

********** Iteration 209 ************
Eval_AverageReturn : 256.07373046875
Eval_StdReturn : 17.257484436035156
Eval_MaxReturn : 273.3312072753906
Eval_MinReturn : 238.8162384033203
Eval_AverageEpLen : 311.5
Train_AverageReturn : 200.66664123535156
Train_StdReturn : 103.52758026123047
Train_MaxReturn : 278.7497863769531
Train_MinReturn : -26.38903045654297
Train_AverageEpLen : 334.1666666666667
Actor Loss : 1682.833740234375
Baseline Loss : 1633.75634765625
Train_EnvstepsSoFar : 466001
TimeSinceStart : 1016.9203941822052

********** Iteration 210 ************
Eval_AverageReturn : 243.43882751464844
Eval_StdReturn : 0.9148712158203125
Eval_MaxReturn : 244.35369873046875
Eval_MinReturn : 242.52395629882812
Eval_AverageEpLen : 290.5
Train_AverageReturn : 138.46156311035156
Train_StdReturn : 120.66022491455078
Train_MaxReturn : 260.7632141113281
Train_MinReturn : -11.852622985839844
Train_AverageEpLen : 300.14285714285717
Actor Loss : -3390.218505859375
Baseline Loss : 2965.97265625
Train_EnvstepsSoFar : 468102
TimeSinceStart : 1020.2906048297882

********** Iteration 211 ************
Eval_AverageReturn : 245.33163452148438
Eval_StdReturn : 17.599143981933594
Eval_MaxReturn : 262.9307861328125
Eval_MinReturn : 227.7324981689453
Eval_AverageEpLen : 302.5
Train_AverageReturn : 174.3299560546875
Train_StdReturn : 110.78256225585938
Train_MaxReturn : 268.04296875
Train_MinReturn : -15.067680358886719
Train_AverageEpLen : 299.2857142857143
Actor Loss : -966.7120361328125
Baseline Loss : 2146.09130859375
Train_EnvstepsSoFar : 470197
TimeSinceStart : 1023.8581507205963

********** Iteration 212 ************
Eval_AverageReturn : 256.54583740234375
Eval_StdReturn : 9.546241760253906
Eval_MaxReturn : 266.0920715332031
Eval_MinReturn : 246.9995880126953
Eval_AverageEpLen : 291.0
Train_AverageReturn : 186.8921661376953
Train_StdReturn : 116.14581298828125
Train_MaxReturn : 271.39996337890625
Train_MinReturn : -33.06641387939453
Train_AverageEpLen : 278.75
Actor Loss : 1902.422119140625
Baseline Loss : 2460.089111328125
Train_EnvstepsSoFar : 472427
TimeSinceStart : 1027.508113861084

********** Iteration 213 ************
Eval_AverageReturn : 271.31689453125
Eval_StdReturn : 24.394065856933594
Eval_MaxReturn : 295.7109680175781
Eval_MinReturn : 246.92283630371094
Eval_AverageEpLen : 306.5
Train_AverageReturn : 158.39366149902344
Train_StdReturn : 104.34715270996094
Train_MaxReturn : 242.4886474609375
Train_MinReturn : -2.3192520141601562
Train_AverageEpLen : 268.0
Actor Loss : -1688.192626953125
Baseline Loss : 1965.197998046875
Train_EnvstepsSoFar : 474571
TimeSinceStart : 1030.8789596557617

********** Iteration 214 ************
Eval_AverageReturn : 149.88563537597656
Eval_StdReturn : 149.85379028320312
Eval_MaxReturn : 299.73944091796875
Eval_MinReturn : 0.031841278076171875
Eval_AverageEpLen : 252.0
Train_AverageReturn : 78.59159088134766
Train_StdReturn : 133.86219787597656
Train_MaxReturn : 281.7161865234375
Train_MinReturn : -65.79060363769531
Train_AverageEpLen : 264.625
Actor Loss : -14779.220703125
Baseline Loss : 3818.88525390625
Train_EnvstepsSoFar : 476688
TimeSinceStart : 1034.2027924060822

********** Iteration 215 ************
Eval_AverageReturn : -8.466255187988281
Eval_StdReturn : 87.84111785888672
Eval_MaxReturn : 79.37486267089844
Eval_MinReturn : -96.307373046875
Eval_AverageEpLen : 691.0
Train_AverageReturn : 149.67532348632812
Train_StdReturn : 111.0489273071289
Train_MaxReturn : 287.2987060546875
Train_MinReturn : -21.299842834472656
Train_AverageEpLen : 354.1666666666667
Actor Loss : -7461.4951171875
Baseline Loss : 2267.76611328125
Train_EnvstepsSoFar : 478813
TimeSinceStart : 1039.285006761551

********** Iteration 216 ************
Eval_AverageReturn : 198.62359619140625
Eval_StdReturn : 10.875846862792969
Eval_MaxReturn : 209.4994354248047
Eval_MinReturn : 187.74774169921875
Eval_AverageEpLen : 395.0
Train_AverageReturn : 65.68887329101562
Train_StdReturn : 143.21336364746094
Train_MaxReturn : 250.697998046875
Train_MinReturn : -102.77430725097656
Train_AverageEpLen : 506.75
Actor Loss : -18043.83984375
Baseline Loss : 3005.956298828125
Train_EnvstepsSoFar : 480840
TimeSinceStart : 1043.3406615257263

********** Iteration 217 ************
Eval_AverageReturn : 242.408203125
Eval_StdReturn : 38.183837890625
Eval_MaxReturn : 280.592041015625
Eval_MinReturn : 204.224365234375
Eval_AverageEpLen : 351.5
Train_AverageReturn : 168.70675659179688
Train_StdReturn : 103.03335571289062
Train_MaxReturn : 264.38775634765625
Train_MinReturn : -30.971342086791992
Train_AverageEpLen : 583.8
Actor Loss : -15367.482421875
Baseline Loss : 1204.5184326171875
Train_EnvstepsSoFar : 483759
TimeSinceStart : 1048.720243692398

********** Iteration 218 ************
Eval_AverageReturn : 162.63052368164062
Eval_StdReturn : 0.0
Eval_MaxReturn : 162.63052368164062
Eval_MinReturn : 162.63052368164062
Eval_AverageEpLen : 421.0
Train_AverageReturn : 195.5247039794922
Train_StdReturn : 151.13803100585938
Train_MaxReturn : 301.6346130371094
Train_MinReturn : -103.9656982421875
Train_AverageEpLen : 403.0
Actor Loss : -5015.7646484375
Baseline Loss : 2392.7333984375
Train_EnvstepsSoFar : 485774
TimeSinceStart : 1052.2040269374847

********** Iteration 219 ************
Eval_AverageReturn : 152.63348388671875
Eval_StdReturn : 0.0
Eval_MaxReturn : 152.63348388671875
Eval_MinReturn : 152.63348388671875
Eval_AverageEpLen : 572.0
Train_AverageReturn : -16.353944778442383
Train_StdReturn : 101.14551544189453
Train_MaxReturn : 207.5436553955078
Train_MinReturn : -149.63914489746094
Train_AverageEpLen : 295.25
Actor Loss : -31544.162109375
Baseline Loss : 4770.4892578125
Train_EnvstepsSoFar : 488136
TimeSinceStart : 1056.2906317710876

********** Iteration 220 ************
Eval_AverageReturn : 124.6363525390625
Eval_StdReturn : 0.0
Eval_MaxReturn : 124.6363525390625
Eval_MinReturn : 124.6363525390625
Eval_AverageEpLen : 712.0
Train_AverageReturn : -65.25563049316406
Train_StdReturn : 87.2168197631836
Train_MaxReturn : 108.71870422363281
Train_MinReturn : -116.52330780029297
Train_AverageEpLen : 533.4
Actor Loss : -34038.828125
Baseline Loss : 3868.704345703125
Train_EnvstepsSoFar : 490803
TimeSinceStart : 1061.2792785167694

********** Iteration 221 ************
Eval_AverageReturn : -92.0096664428711
Eval_StdReturn : 0.0
Eval_MaxReturn : -92.0096664428711
Eval_MinReturn : -92.0096664428711
Eval_AverageEpLen : 411.0
Train_AverageReturn : 19.037477493286133
Train_StdReturn : 35.365562438964844
Train_MaxReturn : 54.40304183959961
Train_MinReturn : -16.328086853027344
Train_AverageEpLen : 1000.0
Actor Loss : -13438.5400390625
Baseline Loss : 844.9856567382812
Train_EnvstepsSoFar : 492803
TimeSinceStart : 1065.2394051551819

********** Iteration 222 ************
Eval_AverageReturn : 191.3707275390625
Eval_StdReturn : 0.0
Eval_MaxReturn : 191.3707275390625
Eval_MinReturn : 191.3707275390625
Eval_AverageEpLen : 436.0
Train_AverageReturn : 13.044249534606934
Train_StdReturn : 90.95767974853516
Train_MaxReturn : 145.2645263671875
Train_MinReturn : -108.08275604248047
Train_AverageEpLen : 528.5
Actor Loss : -13429.958984375
Baseline Loss : 1576.03515625
Train_EnvstepsSoFar : 494917
TimeSinceStart : 1069.0496578216553

********** Iteration 223 ************
Eval_AverageReturn : 209.8131103515625
Eval_StdReturn : 0.0
Eval_MaxReturn : 209.8131103515625
Eval_MinReturn : 209.8131103515625
Eval_AverageEpLen : 410.0
Train_AverageReturn : 150.189453125
Train_StdReturn : 16.828447341918945
Train_MaxReturn : 175.53013610839844
Train_MinReturn : 128.41537475585938
Train_AverageEpLen : 664.75
Actor Loss : -2254.927734375
Baseline Loss : 1010.1517333984375
Train_EnvstepsSoFar : 497576
TimeSinceStart : 1073.6413099765778

********** Iteration 224 ************
Eval_AverageReturn : -74.30332946777344
Eval_StdReturn : 0.0
Eval_MaxReturn : -74.30332946777344
Eval_MinReturn : -74.30332946777344
Eval_AverageEpLen : 442.0
Train_AverageReturn : 185.61825561523438
Train_StdReturn : 89.78630828857422
Train_MaxReturn : 250.07614135742188
Train_MinReturn : 8.869949340820312
Train_AverageEpLen : 504.4
Actor Loss : 5156.279296875
Baseline Loss : 1360.257568359375
Train_EnvstepsSoFar : 500098
TimeSinceStart : 1078.1775603294373

********** Iteration 225 ************
Eval_AverageReturn : 139.63790893554688
Eval_StdReturn : 0.0
Eval_MaxReturn : 139.63790893554688
Eval_MinReturn : 139.63790893554688
Eval_AverageEpLen : 608.0
Train_AverageReturn : -3.3834781646728516
Train_StdReturn : 48.08510971069336
Train_MaxReturn : 62.82024383544922
Train_MinReturn : -53.47377014160156
Train_AverageEpLen : 542.25
Actor Loss : -10850.0546875
Baseline Loss : 1569.2347412109375
Train_EnvstepsSoFar : 502267
TimeSinceStart : 1082.6248865127563

********** Iteration 226 ************
Eval_AverageReturn : 166.17007446289062
Eval_StdReturn : 0.0
Eval_MaxReturn : 166.17007446289062
Eval_MinReturn : 166.17007446289062
Eval_AverageEpLen : 603.0
Train_AverageReturn : 129.9713134765625
Train_StdReturn : 108.95028686523438
Train_MaxReturn : 220.80014038085938
Train_MinReturn : -54.493408203125
Train_AverageEpLen : 568.25
Actor Loss : -2524.28173828125
Baseline Loss : 1935.784423828125
Train_EnvstepsSoFar : 504540
TimeSinceStart : 1087.4918503761292

********** Iteration 227 ************
Eval_AverageReturn : -41.44793701171875
Eval_StdReturn : 0.0
Eval_MaxReturn : -41.44793701171875
Eval_MinReturn : -41.44793701171875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 138.7954559326172
Train_StdReturn : 84.72488403320312
Train_MaxReturn : 212.80438232421875
Train_MinReturn : -3.4937667846679688
Train_AverageEpLen : 731.25
Actor Loss : -3649.31982421875
Baseline Loss : 887.8289184570312
Train_EnvstepsSoFar : 507465
TimeSinceStart : 1094.1112160682678

********** Iteration 228 ************
Eval_AverageReturn : 138.48204040527344
Eval_StdReturn : 0.0
Eval_MaxReturn : 138.48204040527344
Eval_MinReturn : 138.48204040527344
Eval_AverageEpLen : 845.0
Train_AverageReturn : 129.9064483642578
Train_StdReturn : 15.549201965332031
Train_MaxReturn : 151.37486267089844
Train_MinReturn : 115.04948425292969
Train_AverageEpLen : 904.6666666666666
Actor Loss : -5588.3212890625
Baseline Loss : 856.4840698242188
Train_EnvstepsSoFar : 510179
TimeSinceStart : 1101.314016342163

********** Iteration 229 ************
Eval_AverageReturn : 181.15399169921875
Eval_StdReturn : 0.0
Eval_MaxReturn : 181.15399169921875
Eval_MinReturn : 181.15399169921875
Eval_AverageEpLen : 693.0
Train_AverageReturn : 36.1317024230957
Train_StdReturn : 76.80069732666016
Train_MaxReturn : 143.27685546875
Train_MinReturn : -32.85054397583008
Train_AverageEpLen : 941.3333333333334
Actor Loss : -9754.544921875
Baseline Loss : 618.0958251953125
Train_EnvstepsSoFar : 513003
TimeSinceStart : 1108.4510757923126

********** Iteration 230 ************
Eval_AverageReturn : 226.2896270751953
Eval_StdReturn : 0.0
Eval_MaxReturn : 226.2896270751953
Eval_MinReturn : 226.2896270751953
Eval_AverageEpLen : 594.0
Train_AverageReturn : 34.66613006591797
Train_StdReturn : 21.72785186767578
Train_MaxReturn : 56.39398193359375
Train_MinReturn : 12.938278198242188
Train_AverageEpLen : 1000.0
Actor Loss : -6275.83642578125
Baseline Loss : 449.18792724609375
Train_EnvstepsSoFar : 515003
TimeSinceStart : 1113.8531124591827

********** Iteration 231 ************
Eval_AverageReturn : 198.36312866210938
Eval_StdReturn : 0.0
Eval_MaxReturn : 198.36312866210938
Eval_MinReturn : 198.36312866210938
Eval_AverageEpLen : 498.0
Train_AverageReturn : 201.7958526611328
Train_StdReturn : 44.472537994384766
Train_MaxReturn : 260.4801025390625
Train_MinReturn : 152.8621826171875
Train_AverageEpLen : 682.6666666666666
Actor Loss : 3482.86083984375
Baseline Loss : 1123.7286376953125
Train_EnvstepsSoFar : 517051
TimeSinceStart : 1118.3285019397736

********** Iteration 232 ************
Eval_AverageReturn : 204.62835693359375
Eval_StdReturn : 0.0
Eval_MaxReturn : 204.62835693359375
Eval_MinReturn : 204.62835693359375
Eval_AverageEpLen : 653.0
Train_AverageReturn : 228.92108154296875
Train_StdReturn : 31.66879653930664
Train_MaxReturn : 264.3945617675781
Train_MinReturn : 179.87306213378906
Train_AverageEpLen : 617.0
Actor Loss : 7230.005859375
Baseline Loss : 1395.7867431640625
Train_EnvstepsSoFar : 519519
TimeSinceStart : 1123.9826567173004

********** Iteration 233 ************
Eval_AverageReturn : 236.23397827148438
Eval_StdReturn : 0.0
Eval_MaxReturn : 236.23397827148438
Eval_MinReturn : 236.23397827148438
Eval_AverageEpLen : 437.0
Train_AverageReturn : 204.5589141845703
Train_StdReturn : 9.424185752868652
Train_MaxReturn : 217.0283203125
Train_MinReturn : 190.09278869628906
Train_AverageEpLen : 479.8
Actor Loss : 12120.984375
Baseline Loss : 1320.937744140625
Train_EnvstepsSoFar : 521918
TimeSinceStart : 1128.2659199237823

********** Iteration 234 ************
Eval_AverageReturn : 265.38934326171875
Eval_StdReturn : 24.129745483398438
Eval_MaxReturn : 289.51910400390625
Eval_MinReturn : 241.25961303710938
Eval_AverageEpLen : 346.0
Train_AverageReturn : 236.528564453125
Train_StdReturn : 12.84531307220459
Train_MaxReturn : 260.63275146484375
Train_MinReturn : 221.89727783203125
Train_AverageEpLen : 434.6
Actor Loss : 13737.171875
Baseline Loss : 1536.6334228515625
Train_EnvstepsSoFar : 524091
TimeSinceStart : 1131.5325481891632

********** Iteration 235 ************
Eval_AverageReturn : 254.07272338867188
Eval_StdReturn : 23.325592041015625
Eval_MaxReturn : 277.3983154296875
Eval_MinReturn : 230.74713134765625
Eval_AverageEpLen : 356.5
Train_AverageReturn : 250.0785675048828
Train_StdReturn : 18.4738712310791
Train_MaxReturn : 270.4991455078125
Train_MinReturn : 228.01670837402344
Train_AverageEpLen : 386.3333333333333
Actor Loss : 18638.7734375
Baseline Loss : 1682.873779296875
Train_EnvstepsSoFar : 526409
TimeSinceStart : 1134.784883260727

********** Iteration 236 ************
Eval_AverageReturn : 261.9729309082031
Eval_StdReturn : 5.1754150390625
Eval_MaxReturn : 267.1483459472656
Eval_MinReturn : 256.7975158691406
Eval_AverageEpLen : 276.5
Train_AverageReturn : 241.3450164794922
Train_StdReturn : 15.403345108032227
Train_MaxReturn : 263.8033142089844
Train_MinReturn : 220.2337646484375
Train_AverageEpLen : 368.1666666666667
Actor Loss : 13575.21484375
Baseline Loss : 1303.7137451171875
Train_EnvstepsSoFar : 528618
TimeSinceStart : 1137.627511024475

********** Iteration 237 ************
Eval_AverageReturn : 264.8157043457031
Eval_StdReturn : 29.272003173828125
Eval_MaxReturn : 294.08770751953125
Eval_MinReturn : 235.543701171875
Eval_AverageEpLen : 329.5
Train_AverageReturn : 222.9023895263672
Train_StdReturn : 104.85010528564453
Train_MaxReturn : 291.00555419921875
Train_MinReturn : -9.504432678222656
Train_AverageEpLen : 349.1666666666667
Actor Loss : 9001.27734375
Baseline Loss : 1655.809814453125
Train_EnvstepsSoFar : 530713
TimeSinceStart : 1140.4424469470978

********** Iteration 238 ************
Eval_AverageReturn : 271.1860656738281
Eval_StdReturn : 1.31976318359375
Eval_MaxReturn : 272.5058288574219
Eval_MinReturn : 269.8663024902344
Eval_AverageEpLen : 261.5
Train_AverageReturn : 186.42474365234375
Train_StdReturn : 104.69282531738281
Train_MaxReturn : 286.70599365234375
Train_MinReturn : 6.470363616943359
Train_AverageEpLen : 275.625
Actor Loss : 9934.720703125
Baseline Loss : 2144.40478515625
Train_EnvstepsSoFar : 532918
TimeSinceStart : 1142.899828672409

********** Iteration 239 ************
Eval_AverageReturn : 56.5776252746582
Eval_StdReturn : 4.045406341552734
Eval_MaxReturn : 60.62303161621094
Eval_MinReturn : 52.53221893310547
Eval_AverageEpLen : 238.5
Train_AverageReturn : 181.21591186523438
Train_StdReturn : 103.98665618896484
Train_MaxReturn : 280.0067443847656
Train_MinReturn : 38.680912017822266
Train_AverageEpLen : 275.25
Actor Loss : 900.5938720703125
Baseline Loss : 2014.396484375
Train_EnvstepsSoFar : 535120
TimeSinceStart : 1145.3420021533966

********** Iteration 240 ************
Eval_AverageReturn : 136.87265014648438
Eval_StdReturn : 106.0038070678711
Eval_MaxReturn : 242.87646484375
Eval_MinReturn : 30.868850708007812
Eval_AverageEpLen : 246.5
Train_AverageReturn : 227.8977813720703
Train_StdReturn : 91.83663177490234
Train_MaxReturn : 290.75567626953125
Train_MinReturn : 7.9890289306640625
Train_AverageEpLen : 307.2857142857143
Actor Loss : 6301.22265625
Baseline Loss : 1436.275390625
Train_EnvstepsSoFar : 537271
TimeSinceStart : 1147.8047263622284

********** Iteration 241 ************
Eval_AverageReturn : 232.11065673828125
Eval_StdReturn : 7.3763651847839355
Eval_MaxReturn : 239.48703002929688
Eval_MinReturn : 224.7342987060547
Eval_AverageEpLen : 310.5
Train_AverageReturn : 227.34152221679688
Train_StdReturn : 71.68000030517578
Train_MaxReturn : 272.91009521484375
Train_MinReturn : 58.543434143066406
Train_AverageEpLen : 313.14285714285717
Actor Loss : 4630.373046875
Baseline Loss : 1475.1854248046875
Train_EnvstepsSoFar : 539463
TimeSinceStart : 1150.6175549030304

********** Iteration 242 ************
Eval_AverageReturn : 131.34518432617188
Eval_StdReturn : 153.79779052734375
Eval_MaxReturn : 285.1429748535156
Eval_MinReturn : -22.452621459960938
Eval_AverageEpLen : 233.5
Train_AverageReturn : 200.70433044433594
Train_StdReturn : 107.5598373413086
Train_MaxReturn : 291.22161865234375
Train_MinReturn : -6.1356658935546875
Train_AverageEpLen : 279.25
Actor Loss : 1384.5213623046875
Baseline Loss : 1883.7113037109375
Train_EnvstepsSoFar : 541697
TimeSinceStart : 1153.1249964237213

********** Iteration 243 ************
Eval_AverageReturn : 262.16851806640625
Eval_StdReturn : 12.656623840332031
Eval_MaxReturn : 274.82513427734375
Eval_MinReturn : 249.5118865966797
Eval_AverageEpLen : 308.0
Train_AverageReturn : 238.8748779296875
Train_StdReturn : 27.7854061126709
Train_MaxReturn : 301.561767578125
Train_MinReturn : 213.43814086914062
Train_AverageEpLen : 289.7142857142857
Actor Loss : 7827.3955078125
Baseline Loss : 686.6064453125
Train_EnvstepsSoFar : 543725
TimeSinceStart : 1155.6433358192444

********** Iteration 244 ************
Eval_AverageReturn : 253.63055419921875
Eval_StdReturn : 0.0
Eval_MaxReturn : 253.63055419921875
Eval_MinReturn : 253.63055419921875
Eval_AverageEpLen : 564.0
Train_AverageReturn : 250.35671997070312
Train_StdReturn : 26.527496337890625
Train_MaxReturn : 286.9149475097656
Train_MinReturn : 213.17233276367188
Train_AverageEpLen : 312.14285714285717
Actor Loss : 4463.853515625
Baseline Loss : 495.80645751953125
Train_EnvstepsSoFar : 545910
TimeSinceStart : 1158.4176363945007

********** Iteration 245 ************
Eval_AverageReturn : 213.39892578125
Eval_StdReturn : 0.0
Eval_MaxReturn : 213.39892578125
Eval_MinReturn : 213.39892578125
Eval_AverageEpLen : 435.0
Train_AverageReturn : 195.33387756347656
Train_StdReturn : 95.75334930419922
Train_MaxReturn : 285.631103515625
Train_MinReturn : -30.58423614501953
Train_AverageEpLen : 316.0
Actor Loss : -9226.515625
Baseline Loss : 1537.321533203125
Train_EnvstepsSoFar : 548122
TimeSinceStart : 1161.0992834568024

********** Iteration 246 ************
Eval_AverageReturn : 242.32008361816406
Eval_StdReturn : 27.467880249023438
Eval_MaxReturn : 269.7879638671875
Eval_MinReturn : 214.85220336914062
Eval_AverageEpLen : 421.5
Train_AverageReturn : 126.6180191040039
Train_StdReturn : 124.06139373779297
Train_MaxReturn : 268.6541748046875
Train_MinReturn : -33.594600677490234
Train_AverageEpLen : 303.7142857142857
Actor Loss : -18791.263671875
Baseline Loss : 2850.724609375
Train_EnvstepsSoFar : 550248
TimeSinceStart : 1164.065724849701

********** Iteration 247 ************
Eval_AverageReturn : 100.46023559570312
Eval_StdReturn : 127.08748626708984
Eval_MaxReturn : 227.54771423339844
Eval_MinReturn : -26.62725067138672
Eval_AverageEpLen : 456.5
Train_AverageReturn : 181.4138641357422
Train_StdReturn : 97.65928649902344
Train_MaxReturn : 264.4619140625
Train_MinReturn : -21.845069885253906
Train_AverageEpLen : 363.0
Actor Loss : -10278.5517578125
Baseline Loss : 1817.28125
Train_EnvstepsSoFar : 552426
TimeSinceStart : 1167.6232368946075

********** Iteration 248 ************
Eval_AverageReturn : 183.04205322265625
Eval_StdReturn : 0.0
Eval_MaxReturn : 183.04205322265625
Eval_MinReturn : 183.04205322265625
Eval_AverageEpLen : 700.0
Train_AverageReturn : 120.5736312866211
Train_StdReturn : 117.02774047851562
Train_MaxReturn : 228.263427734375
Train_MinReturn : -46.807891845703125
Train_AverageEpLen : 380.8333333333333
Actor Loss : -24878.34375
Baseline Loss : 2726.63623046875
Train_EnvstepsSoFar : 554711
TimeSinceStart : 1171.1811940670013

********** Iteration 249 ************
Eval_AverageReturn : 199.55322265625
Eval_StdReturn : 0.0
Eval_MaxReturn : 199.55322265625
Eval_MinReturn : 199.55322265625
Eval_AverageEpLen : 719.0
Train_AverageReturn : 187.50949096679688
Train_StdReturn : 26.084178924560547
Train_MaxReturn : 219.47625732421875
Train_MinReturn : 153.57760620117188
Train_AverageEpLen : 558.75
Actor Loss : -17280.861328125
Baseline Loss : 1122.7288818359375
Train_EnvstepsSoFar : 556946
TimeSinceStart : 1175.4713027477264

********** Iteration 250 ************
Eval_AverageReturn : 148.26385498046875
Eval_StdReturn : 0.0
Eval_MaxReturn : 148.26385498046875
Eval_MinReturn : 148.26385498046875
Eval_AverageEpLen : 762.0
Train_AverageReturn : 156.9081268310547
Train_StdReturn : 21.972929000854492
Train_MaxReturn : 181.178466796875
Train_MinReturn : 127.9673843383789
Train_AverageEpLen : 702.0
Actor Loss : -21331.603515625
Baseline Loss : 1655.9482421875
Train_EnvstepsSoFar : 559052
TimeSinceStart : 1180.2563166618347

********** Iteration 251 ************
Eval_AverageReturn : 0.9056549072265625
Eval_StdReturn : 0.0
Eval_MaxReturn : 0.9056549072265625
Eval_MinReturn : 0.9056549072265625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 9.132087707519531
Train_StdReturn : 83.65747833251953
Train_MaxReturn : 117.32731628417969
Train_MinReturn : -86.4167709350586
Train_AverageEpLen : 866.6666666666666
Actor Loss : -38053.046875
Baseline Loss : 2530.251708984375
Train_EnvstepsSoFar : 561652
TimeSinceStart : 1186.9739429950714

********** Iteration 252 ************
Eval_AverageReturn : -15.281753540039062
Eval_StdReturn : 0.0
Eval_MaxReturn : -15.281753540039062
Eval_MinReturn : -15.281753540039062
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -9.36016845703125
Train_StdReturn : 6.6572265625
Train_MaxReturn : -2.70294189453125
Train_MinReturn : -16.01739501953125
Train_AverageEpLen : 1000.0
Actor Loss : -28582.67578125
Baseline Loss : 1835.2271728515625
Train_EnvstepsSoFar : 563652
TimeSinceStart : 1192.6975905895233

********** Iteration 253 ************
Eval_AverageReturn : -51.220306396484375
Eval_StdReturn : 0.0
Eval_MaxReturn : -51.220306396484375
Eval_MinReturn : -51.220306396484375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -7.517292022705078
Train_StdReturn : 8.220935821533203
Train_MaxReturn : 0.703643798828125
Train_MinReturn : -15.738227844238281
Train_AverageEpLen : 1000.0
Actor Loss : -23767.623046875
Baseline Loss : 1431.605712890625
Train_EnvstepsSoFar : 565652
TimeSinceStart : 1199.1624448299408

********** Iteration 254 ************
Eval_AverageReturn : -40.638328552246094
Eval_StdReturn : 0.0
Eval_MaxReturn : -40.638328552246094
Eval_MinReturn : -40.638328552246094
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -34.95706558227539
Train_StdReturn : 1.5593147277832031
Train_MaxReturn : -33.39775085449219
Train_MinReturn : -36.516380310058594
Train_AverageEpLen : 1000.0
Actor Loss : -21453.01171875
Baseline Loss : 1045.3258056640625
Train_EnvstepsSoFar : 567652
TimeSinceStart : 1205.85853099823

********** Iteration 255 ************
Eval_AverageReturn : -30.84819793701172
Eval_StdReturn : 0.0
Eval_MaxReturn : -30.84819793701172
Eval_MinReturn : -30.84819793701172
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -43.57065963745117
Train_StdReturn : 18.912212371826172
Train_MaxReturn : -24.658447265625
Train_MinReturn : -62.482872009277344
Train_AverageEpLen : 1000.0
Actor Loss : -17724.775390625
Baseline Loss : 769.115234375
Train_EnvstepsSoFar : 569652
TimeSinceStart : 1211.9002523422241

********** Iteration 256 ************
Eval_AverageReturn : -29.585575103759766
Eval_StdReturn : 0.0
Eval_MaxReturn : -29.585575103759766
Eval_MinReturn : -29.585575103759766
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -41.1954460144043
Train_StdReturn : 14.737098693847656
Train_MaxReturn : -26.45834732055664
Train_MinReturn : -55.93254470825195
Train_AverageEpLen : 1000.0
Actor Loss : -14141.078125
Baseline Loss : 507.336669921875
Train_EnvstepsSoFar : 571652
TimeSinceStart : 1217.6886019706726

********** Iteration 257 ************
Eval_AverageReturn : -41.74150848388672
Eval_StdReturn : 0.0
Eval_MaxReturn : -41.74150848388672
Eval_MinReturn : -41.74150848388672
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -38.704063415527344
Train_StdReturn : 18.859344482421875
Train_MaxReturn : -19.84471893310547
Train_MinReturn : -57.56340789794922
Train_AverageEpLen : 1000.0
Actor Loss : -10989.2314453125
Baseline Loss : 439.6905212402344
Train_EnvstepsSoFar : 573652
TimeSinceStart : 1223.6472940444946

********** Iteration 258 ************
Eval_AverageReturn : -18.510360717773438
Eval_StdReturn : 0.0
Eval_MaxReturn : -18.510360717773438
Eval_MinReturn : -18.510360717773438
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -15.69649887084961
Train_StdReturn : 12.667972564697266
Train_MaxReturn : -3.0285263061523438
Train_MinReturn : -28.364471435546875
Train_AverageEpLen : 1000.0
Actor Loss : -9384.9208984375
Baseline Loss : 383.51263427734375
Train_EnvstepsSoFar : 575652
TimeSinceStart : 1230.0530650615692

********** Iteration 259 ************
Eval_AverageReturn : -36.30659484863281
Eval_StdReturn : 0.0
Eval_MaxReturn : -36.30659484863281
Eval_MinReturn : -36.30659484863281
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -51.58716583251953
Train_StdReturn : 15.76348876953125
Train_MaxReturn : -35.82367706298828
Train_MinReturn : -67.35065460205078
Train_AverageEpLen : 1000.0
Actor Loss : -7782.8974609375
Baseline Loss : 243.58642578125
Train_EnvstepsSoFar : 577652
TimeSinceStart : 1236.7889397144318

********** Iteration 260 ************
Eval_AverageReturn : -17.363021850585938
Eval_StdReturn : 0.0
Eval_MaxReturn : -17.363021850585938
Eval_MinReturn : -17.363021850585938
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -45.409912109375
Train_StdReturn : 4.264238357543945
Train_MaxReturn : -41.14567184448242
Train_MinReturn : -49.67414855957031
Train_AverageEpLen : 1000.0
Actor Loss : -5058.5908203125
Baseline Loss : 175.2140655517578
Train_EnvstepsSoFar : 579652
TimeSinceStart : 1242.37708568573

********** Iteration 261 ************
Eval_AverageReturn : -16.925003051757812
Eval_StdReturn : 0.0
Eval_MaxReturn : -16.925003051757812
Eval_MinReturn : -16.925003051757812
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -43.79943084716797
Train_StdReturn : 16.566810607910156
Train_MaxReturn : -27.232620239257812
Train_MinReturn : -60.366241455078125
Train_AverageEpLen : 1000.0
Actor Loss : -3837.595947265625
Baseline Loss : 192.86883544921875
Train_EnvstepsSoFar : 581652
TimeSinceStart : 1247.8362839221954

********** Iteration 262 ************
Eval_AverageReturn : -18.614086151123047
Eval_StdReturn : 0.0
Eval_MaxReturn : -18.614086151123047
Eval_MinReturn : -18.614086151123047
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -38.420631408691406
Train_StdReturn : 7.121286392211914
Train_MaxReturn : -31.29934310913086
Train_MinReturn : -45.54191589355469
Train_AverageEpLen : 1000.0
Actor Loss : -2756.215087890625
Baseline Loss : 211.35537719726562
Train_EnvstepsSoFar : 583652
TimeSinceStart : 1253.6996619701385

********** Iteration 263 ************
Eval_AverageReturn : -24.53494644165039
Eval_StdReturn : 0.0
Eval_MaxReturn : -24.53494644165039
Eval_MinReturn : -24.53494644165039
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -38.99744415283203
Train_StdReturn : 24.13796043395996
Train_MaxReturn : -14.859481811523438
Train_MinReturn : -63.13540267944336
Train_AverageEpLen : 1000.0
Actor Loss : -2039.037109375
Baseline Loss : 212.2182159423828
Train_EnvstepsSoFar : 585652
TimeSinceStart : 1259.451639175415

********** Iteration 264 ************
Eval_AverageReturn : -56.20317077636719
Eval_StdReturn : 0.0
Eval_MaxReturn : -56.20317077636719
Eval_MinReturn : -56.20317077636719
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -114.5908432006836
Train_StdReturn : 54.081787109375
Train_MaxReturn : -38.48384094238281
Train_MinReturn : -159.20587158203125
Train_AverageEpLen : 804.3333333333334
Actor Loss : -5706.4033203125
Baseline Loss : 1050.1903076171875
Train_EnvstepsSoFar : 588065
TimeSinceStart : 1266.2160563468933

********** Iteration 265 ************
Eval_AverageReturn : -29.161209106445312
Eval_StdReturn : 0.0
Eval_MaxReturn : -29.161209106445312
Eval_MinReturn : -29.161209106445312
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -4.235130310058594
Train_StdReturn : 4.665809631347656
Train_MaxReturn : 0.4306793212890625
Train_MinReturn : -8.90093994140625
Train_AverageEpLen : 1000.0
Actor Loss : 1791.49658203125
Baseline Loss : 310.32781982421875
Train_EnvstepsSoFar : 590065
TimeSinceStart : 1271.386207818985

********** Iteration 266 ************
Eval_AverageReturn : -0.5098342895507812
Eval_StdReturn : 0.0
Eval_MaxReturn : -0.5098342895507812
Eval_MinReturn : -0.5098342895507812
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -15.319786071777344
Train_StdReturn : 9.194374084472656
Train_MaxReturn : -6.1254119873046875
Train_MinReturn : -24.51416015625
Train_AverageEpLen : 1000.0
Actor Loss : 1953.7562255859375
Baseline Loss : 268.914306640625
Train_EnvstepsSoFar : 592065
TimeSinceStart : 1276.9255893230438

********** Iteration 267 ************
Eval_AverageReturn : -10.508872985839844
Eval_StdReturn : 0.0
Eval_MaxReturn : -10.508872985839844
Eval_MinReturn : -10.508872985839844
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -18.04261016845703
Train_StdReturn : 20.586082458496094
Train_MaxReturn : 2.5434722900390625
Train_MinReturn : -38.628692626953125
Train_AverageEpLen : 1000.0
Actor Loss : 2355.364990234375
Baseline Loss : 268.5630798339844
Train_EnvstepsSoFar : 594065
TimeSinceStart : 1282.7354702949524

********** Iteration 268 ************
Eval_AverageReturn : -7.240486145019531
Eval_StdReturn : 0.0
Eval_MaxReturn : -7.240486145019531
Eval_MinReturn : -7.240486145019531
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -18.878864288330078
Train_StdReturn : 18.938297271728516
Train_MaxReturn : 0.0594329833984375
Train_MinReturn : -37.817161560058594
Train_AverageEpLen : 1000.0
Actor Loss : 1596.64990234375
Baseline Loss : 244.09042358398438
Train_EnvstepsSoFar : 596065
TimeSinceStart : 1290.141061782837

********** Iteration 269 ************
Eval_AverageReturn : -22.543052673339844
Eval_StdReturn : 0.0
Eval_MaxReturn : -22.543052673339844
Eval_MinReturn : -22.543052673339844
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -36.76312255859375
Train_StdReturn : 11.05293083190918
Train_MaxReturn : -25.710189819335938
Train_MinReturn : -47.8160514831543
Train_AverageEpLen : 1000.0
Actor Loss : 1342.197021484375
Baseline Loss : 148.1073760986328
Train_EnvstepsSoFar : 598065
TimeSinceStart : 1296.0943636894226

********** Iteration 270 ************
Eval_AverageReturn : -36.484893798828125
Eval_StdReturn : 0.0
Eval_MaxReturn : -36.484893798828125
Eval_MinReturn : -36.484893798828125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -2.303424835205078
Train_StdReturn : 6.862087249755859
Train_MaxReturn : 4.558662414550781
Train_MinReturn : -9.165512084960938
Train_AverageEpLen : 1000.0
Actor Loss : 2532.46630859375
Baseline Loss : 376.05853271484375
Train_EnvstepsSoFar : 600065
TimeSinceStart : 1301.8355920314789

********** Iteration 271 ************
Eval_AverageReturn : 7.808326721191406
Eval_StdReturn : 0.0
Eval_MaxReturn : 7.808326721191406
Eval_MinReturn : 7.808326721191406
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -15.465478897094727
Train_StdReturn : 6.56932258605957
Train_MaxReturn : -8.896156311035156
Train_MinReturn : -22.034801483154297
Train_AverageEpLen : 1000.0
Actor Loss : 2070.77490234375
Baseline Loss : 261.5578308105469
Train_EnvstepsSoFar : 602065
TimeSinceStart : 1308.555703163147

********** Iteration 272 ************
Eval_AverageReturn : -15.872303009033203
Eval_StdReturn : 0.0
Eval_MaxReturn : -15.872303009033203
Eval_MinReturn : -15.872303009033203
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -33.24190902709961
Train_StdReturn : 9.951244354248047
Train_MaxReturn : -23.290664672851562
Train_MinReturn : -43.193153381347656
Train_AverageEpLen : 1000.0
Actor Loss : 930.8718872070312
Baseline Loss : 165.81661987304688
Train_EnvstepsSoFar : 604065
TimeSinceStart : 1314.313458442688

********** Iteration 273 ************
Eval_AverageReturn : -55.33438491821289
Eval_StdReturn : 0.0
Eval_MaxReturn : -55.33438491821289
Eval_MinReturn : -55.33438491821289
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -44.06761169433594
Train_StdReturn : 11.033239364624023
Train_MaxReturn : -33.03437042236328
Train_MinReturn : -55.10084915161133
Train_AverageEpLen : 1000.0
Actor Loss : 273.8019104003906
Baseline Loss : 185.3353729248047
Train_EnvstepsSoFar : 606065
TimeSinceStart : 1320.5926530361176

********** Iteration 274 ************
Eval_AverageReturn : -39.523963928222656
Eval_StdReturn : 0.0
Eval_MaxReturn : -39.523963928222656
Eval_MinReturn : -39.523963928222656
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -26.769451141357422
Train_StdReturn : 0.3408699035644531
Train_MaxReturn : -26.42858123779297
Train_MinReturn : -27.110321044921875
Train_AverageEpLen : 1000.0
Actor Loss : 211.55996704101562
Baseline Loss : 176.87777709960938
Train_EnvstepsSoFar : 608065
TimeSinceStart : 1326.4894759654999

********** Iteration 275 ************
Eval_AverageReturn : -18.297508239746094
Eval_StdReturn : 0.0
Eval_MaxReturn : -18.297508239746094
Eval_MinReturn : -18.297508239746094
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -13.7469482421875
Train_StdReturn : 15.784866333007812
Train_MaxReturn : 2.0379180908203125
Train_MinReturn : -29.531814575195312
Train_AverageEpLen : 1000.0
Actor Loss : 528.6206665039062
Baseline Loss : 248.8164520263672
Train_EnvstepsSoFar : 610065
TimeSinceStart : 1332.2276263237

********** Iteration 276 ************
Eval_AverageReturn : 195.467041015625
Eval_StdReturn : 0.0
Eval_MaxReturn : 195.467041015625
Eval_MinReturn : 195.467041015625
Eval_AverageEpLen : 766.0
Train_AverageReturn : 67.97503662109375
Train_StdReturn : 101.52203369140625
Train_MaxReturn : 209.57305908203125
Train_MinReturn : -23.380836486816406
Train_AverageEpLen : 907.0
Actor Loss : 4969.017578125
Baseline Loss : 668.5596923828125
Train_EnvstepsSoFar : 612786
TimeSinceStart : 1339.0090734958649

********** Iteration 277 ************
Eval_AverageReturn : -17.658912658691406
Eval_StdReturn : 0.0
Eval_MaxReturn : -17.658912658691406
Eval_MinReturn : -17.658912658691406
Eval_AverageEpLen : 1000.0
Train_AverageReturn : -2.7763900756835938
Train_StdReturn : 19.596595764160156
Train_MaxReturn : 16.820205688476562
Train_MinReturn : -22.37298583984375
Train_AverageEpLen : 1000.0
Actor Loss : 551.2888793945312
Baseline Loss : 315.5612487792969
Train_EnvstepsSoFar : 614786
TimeSinceStart : 1345.6756930351257

********** Iteration 278 ************
Eval_AverageReturn : 205.67344665527344
Eval_StdReturn : 0.0
Eval_MaxReturn : 205.67344665527344
Eval_MinReturn : 205.67344665527344
Eval_AverageEpLen : 738.0
Train_AverageReturn : 94.90570068359375
Train_StdReturn : 83.07034301757812
Train_MaxReturn : 163.16366577148438
Train_MinReturn : -22.028244018554688
Train_AverageEpLen : 890.0
Actor Loss : 6115.97509765625
Baseline Loss : 813.1248779296875
Train_EnvstepsSoFar : 617456
TimeSinceStart : 1351.7451977729797

********** Iteration 279 ************
Eval_AverageReturn : 228.0869140625
Eval_StdReturn : 0.0
Eval_MaxReturn : 228.0869140625
Eval_MinReturn : 228.0869140625
Eval_AverageEpLen : 563.0
Train_AverageReturn : 197.7266845703125
Train_StdReturn : 13.5816068649292
Train_MaxReturn : 215.80841064453125
Train_MinReturn : 178.21849060058594
Train_AverageEpLen : 630.25
Actor Loss : 14346.4794921875
Baseline Loss : 1612.748779296875
Train_EnvstepsSoFar : 619977
TimeSinceStart : 1356.3985459804535

********** Iteration 280 ************
Eval_AverageReturn : 207.40570068359375
Eval_StdReturn : 0.0
Eval_MaxReturn : 207.40570068359375
Eval_MinReturn : 207.40570068359375
Eval_AverageEpLen : 477.0
Train_AverageReturn : 217.6040802001953
Train_StdReturn : 13.718074798583984
Train_MaxReturn : 227.26901245117188
Train_MinReturn : 193.95164489746094
Train_AverageEpLen : 576.25
Actor Loss : 14761.220703125
Baseline Loss : 1712.7620849609375
Train_EnvstepsSoFar : 622282
TimeSinceStart : 1360.264922618866

********** Iteration 281 ************
Eval_AverageReturn : -24.040626525878906
Eval_StdReturn : 0.0
Eval_MaxReturn : -24.040626525878906
Eval_MinReturn : -24.040626525878906
Eval_AverageEpLen : 489.0
Train_AverageReturn : 199.86495971679688
Train_StdReturn : 19.087350845336914
Train_MaxReturn : 228.95252990722656
Train_MinReturn : 177.828369140625
Train_AverageEpLen : 535.25
Actor Loss : 13096.86328125
Baseline Loss : 1422.3822021484375
Train_EnvstepsSoFar : 624423
TimeSinceStart : 1363.7400732040405

********** Iteration 282 ************
Eval_AverageReturn : 58.17704772949219
Eval_StdReturn : 0.0
Eval_MaxReturn : 58.17704772949219
Eval_MinReturn : 58.17704772949219
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 228.38336181640625
Train_StdReturn : 25.979839324951172
Train_MaxReturn : 264.98333740234375
Train_MinReturn : 193.6922607421875
Train_AverageEpLen : 502.5
Actor Loss : 10732.2880859375
Baseline Loss : 1493.6109619140625
Train_EnvstepsSoFar : 626433
TimeSinceStart : 1367.6856455802917

********** Iteration 283 ************
Eval_AverageReturn : 198.1199493408203
Eval_StdReturn : 104.1781005859375
Eval_MaxReturn : 285.0456848144531
Eval_MinReturn : 51.639835357666016
Eval_AverageEpLen : 256.0
Train_AverageReturn : 196.32301330566406
Train_StdReturn : 72.60680389404297
Train_MaxReturn : 271.19012451171875
Train_MinReturn : 78.17084503173828
Train_AverageEpLen : 581.0
Actor Loss : 6828.6982421875
Baseline Loss : 1054.4705810546875
Train_EnvstepsSoFar : 628757
TimeSinceStart : 1371.697229385376

********** Iteration 284 ************
Eval_AverageReturn : 178.57472229003906
Eval_StdReturn : 0.0
Eval_MaxReturn : 178.57472229003906
Eval_MinReturn : 178.57472229003906
Eval_AverageEpLen : 457.0
Train_AverageReturn : 120.3938980102539
Train_StdReturn : 118.65315246582031
Train_MaxReturn : 229.3075714111328
Train_MinReturn : -31.616424560546875
Train_AverageEpLen : 426.8
Actor Loss : -2248.631591796875
Baseline Loss : 1850.3001708984375
Train_EnvstepsSoFar : 630891
TimeSinceStart : 1374.4943046569824

********** Iteration 285 ************
Eval_AverageReturn : 206.48760986328125
Eval_StdReturn : 0.0
Eval_MaxReturn : 206.48760986328125
Eval_MinReturn : 206.48760986328125
Eval_AverageEpLen : 429.0
Train_AverageReturn : 96.5943374633789
Train_StdReturn : 162.69017028808594
Train_MaxReturn : 293.64678955078125
Train_MinReturn : -92.2425765991211
Train_AverageEpLen : 360.6666666666667
Actor Loss : -3291.13671875
Baseline Loss : 2760.048583984375
Train_EnvstepsSoFar : 633055
TimeSinceStart : 1377.2058691978455

********** Iteration 286 ************
Eval_AverageReturn : 256.9264831542969
Eval_StdReturn : 6.643333435058594
Eval_MaxReturn : 263.56982421875
Eval_MinReturn : 250.2831573486328
Eval_AverageEpLen : 321.0
Train_AverageReturn : 109.81985473632812
Train_StdReturn : 120.54547882080078
Train_MaxReturn : 260.6035461425781
Train_MinReturn : -72.3758544921875
Train_AverageEpLen : 543.25
Actor Loss : -4148.3154296875
Baseline Loss : 1319.2623291015625
Train_EnvstepsSoFar : 635228
TimeSinceStart : 1380.5870661735535

********** Iteration 287 ************
Eval_AverageReturn : 279.74200439453125
Eval_StdReturn : 29.243270874023438
Eval_MaxReturn : 308.98529052734375
Eval_MinReturn : 250.49874877929688
Eval_AverageEpLen : 356.5
Train_AverageReturn : 82.25249481201172
Train_StdReturn : 144.97447204589844
Train_MaxReturn : 267.46673583984375
Train_MinReturn : -88.3890609741211
Train_AverageEpLen : 333.5
Actor Loss : -6182.3037109375
Baseline Loss : 3171.87353515625
Train_EnvstepsSoFar : 637229
TimeSinceStart : 1383.4108157157898

********** Iteration 288 ************
Eval_AverageReturn : 74.03715515136719
Eval_StdReturn : 118.22628021240234
Eval_MaxReturn : 192.26344299316406
Eval_MinReturn : -44.189125061035156
Eval_AverageEpLen : 294.5
Train_AverageReturn : 88.86587524414062
Train_StdReturn : 139.17918395996094
Train_MaxReturn : 273.0293884277344
Train_MinReturn : -74.71343994140625
Train_AverageEpLen : 370.6666666666667
Actor Loss : -4421.54541015625
Baseline Loss : 2333.272705078125
Train_EnvstepsSoFar : 639453
TimeSinceStart : 1386.5104324817657

********** Iteration 289 ************
Eval_AverageReturn : 231.57855224609375
Eval_StdReturn : 7.143096923828125
Eval_MaxReturn : 238.72164916992188
Eval_MinReturn : 224.43545532226562
Eval_AverageEpLen : 410.0
Train_AverageReturn : 132.6324005126953
Train_StdReturn : 131.25497436523438
Train_MaxReturn : 256.06396484375
Train_MinReturn : -56.63623046875
Train_AverageEpLen : 411.3333333333333
Actor Loss : 1281.1414794921875
Baseline Loss : 2083.04833984375
Train_EnvstepsSoFar : 641921
TimeSinceStart : 1390.2158410549164

********** Iteration 290 ************
Eval_AverageReturn : 123.76431274414062
Eval_StdReturn : 0.0
Eval_MaxReturn : 123.76431274414062
Eval_MinReturn : 123.76431274414062
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 200.42881774902344
Train_StdReturn : 69.83240509033203
Train_MaxReturn : 274.5775451660156
Train_MinReturn : 85.74897766113281
Train_AverageEpLen : 524.75
Actor Loss : 3724.748046875
Baseline Loss : 979.92724609375
Train_EnvstepsSoFar : 644020
TimeSinceStart : 1393.9405422210693

********** Iteration 291 ************
Eval_AverageReturn : 282.64837646484375
Eval_StdReturn : 11.329513549804688
Eval_MaxReturn : 293.9779052734375
Eval_MinReturn : 271.3188781738281
Eval_AverageEpLen : 277.0
Train_AverageReturn : 203.44932556152344
Train_StdReturn : 94.417724609375
Train_MaxReturn : 264.492431640625
Train_MinReturn : -6.57293701171875
Train_AverageEpLen : 389.6666666666667
Actor Loss : 8976.9794921875
Baseline Loss : 1556.9053955078125
Train_EnvstepsSoFar : 646358
TimeSinceStart : 1397.0013799667358

********** Iteration 292 ************
Eval_AverageReturn : 260.1585388183594
Eval_StdReturn : 30.17193603515625
Eval_MaxReturn : 290.3304748535156
Eval_MinReturn : 229.98660278320312
Eval_AverageEpLen : 285.5
Train_AverageReturn : 194.4767608642578
Train_StdReturn : 124.56513977050781
Train_MaxReturn : 301.3909912109375
Train_MinReturn : -10.167850494384766
Train_AverageEpLen : 290.7142857142857
Actor Loss : 12365.484375
Baseline Loss : 3035.06298828125
Train_EnvstepsSoFar : 648393
TimeSinceStart : 1399.3886873722076

********** Iteration 293 ************
Eval_AverageReturn : 116.1025390625
Eval_StdReturn : 127.24647521972656
Eval_MaxReturn : 243.34901428222656
Eval_MinReturn : -11.143943786621094
Eval_AverageEpLen : 302.5
Train_AverageReturn : 189.0098876953125
Train_StdReturn : 123.03993225097656
Train_MaxReturn : 294.87939453125
Train_MinReturn : -26.928573608398438
Train_AverageEpLen : 296.5
Actor Loss : 12414.90625
Baseline Loss : 2612.532470703125
Train_EnvstepsSoFar : 650765
TimeSinceStart : 1402.1851403713226

********** Iteration 294 ************
Eval_AverageReturn : 49.96010208129883
Eval_StdReturn : 38.8927116394043
Eval_MaxReturn : 88.85281372070312
Eval_MinReturn : 11.067390441894531
Eval_AverageEpLen : 607.5
Train_AverageReturn : 191.0953369140625
Train_StdReturn : 103.48868560791016
Train_MaxReturn : 276.4669189453125
Train_MinReturn : 8.819747924804688
Train_AverageEpLen : 494.2
Actor Loss : 2683.86474609375
Baseline Loss : 1454.564208984375
Train_EnvstepsSoFar : 653236
TimeSinceStart : 1406.218722820282

********** Iteration 295 ************
Eval_AverageReturn : 188.12542724609375
Eval_StdReturn : 48.581764221191406
Eval_MaxReturn : 236.70718383789062
Eval_MinReturn : 139.5436553955078
Eval_AverageEpLen : 642.5
Train_AverageReturn : 111.17091369628906
Train_StdReturn : 114.5125961303711
Train_MaxReturn : 281.3204650878906
Train_MinReturn : -2.281841278076172
Train_AverageEpLen : 250.125
Actor Loss : -3420.947021484375
Baseline Loss : 3185.723876953125
Train_EnvstepsSoFar : 655237
TimeSinceStart : 1409.7431616783142

********** Iteration 296 ************
Eval_AverageReturn : 237.4985809326172
Eval_StdReturn : 40.77815246582031
Eval_MaxReturn : 278.2767333984375
Eval_MinReturn : 196.72042846679688
Eval_AverageEpLen : 316.0
Train_AverageReturn : 172.03050231933594
Train_StdReturn : 134.33888244628906
Train_MaxReturn : 285.073486328125
Train_MinReturn : -34.6750373840332
Train_AverageEpLen : 260.125
Actor Loss : 7953.9970703125
Baseline Loss : 3194.95654296875
Train_EnvstepsSoFar : 657318
TimeSinceStart : 1412.1054649353027

********** Iteration 297 ************
Eval_AverageReturn : 227.67086791992188
Eval_StdReturn : 2.3422927856445312
Eval_MaxReturn : 230.01315307617188
Eval_MinReturn : 225.3285675048828
Eval_AverageEpLen : 316.5
Train_AverageReturn : 205.50845336914062
Train_StdReturn : 88.85247802734375
Train_MaxReturn : 293.9554443359375
Train_MinReturn : -0.6798858642578125
Train_AverageEpLen : 301.57142857142856
Actor Loss : 4931.30908203125
Baseline Loss : 1889.287353515625
Train_EnvstepsSoFar : 659429
TimeSinceStart : 1414.7790582180023

********** Iteration 298 ************
Eval_AverageReturn : 139.0865020751953
Eval_StdReturn : 79.3586654663086
Eval_MaxReturn : 218.44515991210938
Eval_MinReturn : 59.72783279418945
Eval_AverageEpLen : 455.5
Train_AverageReturn : 190.9969024658203
Train_StdReturn : 128.93902587890625
Train_MaxReturn : 303.4570007324219
Train_MinReturn : -21.071937561035156
Train_AverageEpLen : 297.14285714285717
Actor Loss : 4063.095703125
Baseline Loss : 2558.00537109375
Train_EnvstepsSoFar : 661509
TimeSinceStart : 1417.809986591339

********** Iteration 299 ************
Eval_AverageReturn : -19.687057495117188
Eval_StdReturn : 3.8135223388671875
Eval_MaxReturn : -15.87353515625
Eval_MinReturn : -23.500579833984375
Eval_AverageEpLen : 260.0
Train_AverageReturn : 89.99591827392578
Train_StdReturn : 138.20379638671875
Train_MaxReturn : 255.100341796875
Train_MinReturn : -75.23445129394531
Train_AverageEpLen : 381.2857142857143
Actor Loss : -16154.5224609375
Baseline Loss : 2905.81494140625
Train_EnvstepsSoFar : 664178
TimeSinceStart : 1421.1956839561462

Process finished with exit code 0
